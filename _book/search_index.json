[
["index.html", "R para preparación y visualización de datos Doctorado en Neurociencia Social y Cognición Introducción Objetivos Como empezar Bibliografía", " R para preparación y visualización de datos Doctorado en Neurociencia Social y Cognición Gorka Navarrete, ORCID: 0000-0001-7678-8656 Introducción El seminario estará centrado en el uso de R para la preparación y visualización de datos, además de la generación de reportes reproducibles. R es un lenguaje de programación abierto, con una gran comunidad orientada al trabajo, visualización y modelado de datos en contextos científicos y técnicos. Nos introduciremos de manera práctica a R, resolviendo problemas que encontramos habitualmente durante el quehacer científico, focalizándonos en el trabajo abierto, colaborativo y reproducible. Objetivos Dar las herramientas básicas a los alumnos para que puedan trabajar de manera autónoma con R y RStudio para el proceso de importación, transformación, visualización y reporte de datos. Al finalizar el curso los alumnos serán capaces de: Importar archivos de datos, transformar los datos, crear nuevas variables. Realizar análisis de datos exploratorios, visualizar distribuciones y comparar grupos. Generar reportes reproducibles con RMarkdown. Como empezar Si ya has completado los pasos indicados en Preparando nuesto sistema, puedes lanzar el siguiente código en tu ordenador para descargar los materiales del curso: if (!require(&#39;usethis&#39;)) install.packages(&#39;usethis&#39;); library(&#39;usethis&#39;) usethis::use_course(&quot;gorkang/R_preparacion_visualizacion_datos&quot;) Bibliografía Bryan, J., &amp; Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/ Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ Wickham, H. (2014). Advanced r. Chapman and Hall/CRC. https://adv-r.hadley.nz/ Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Yihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html "],
["preparando-sistema.html", "Preparando nuestro sistema 0.1 Empezando en A-B-C 0.2 Algo más sobre la instalación de paquetes Bibliografía", " Preparando nuestro sistema 0.1 Empezando en A-B-C Para poder iniciar el workshop necesitamos tener R y RStudio instalados, además de algunas librerías. Para tener un sistema funcional, completa los pasos A, B y C. Si ya tienes R y Rstudio instalados (recientemente), puedes pasar directamente al paso (C). (A) Instalar R R, es un lenguaje de programación especializado en el computación estadística y visualización de datos. Es recomendable tener instalada la última versión de R. Puedes usar uno de los enlaces siguientes: Windows: Descargar e instalar R para Windows Mac: Descargar e instalar R para Mac Ubuntu Linux: más detalles en la web de R. En un terminal: sudo apt-get install r-base (B) Instalar RStudio RStudio es un entorno integrado de desarrollo (IDE) para la programación R. Descargar e instalar RStudio. Una vez descargado e instalado, abre RStudio. Deberías ver algo parecido a lo siguiente: (C) Paquetes para el workshop Usaremos un buen numero de paquetes en el workshop. Hay algunos meta-paquetes que simplifican la instalación de múltiples paquetes (e.g. pacman, pak, …), pero en este caso vamos a usar una versión casera. Copia y pega el código de abajo y ejecútalo [tecla ENTER] en la consola de RStudio. El proceso de instalación requiere Internet y tardará un buen rato. list_of_packages = c(&quot;bookdown&quot;, &quot;corrplot&quot;, &quot;cowplot&quot;, &quot;esquisse&quot;, &quot;gapminder&quot;, &quot;ggpubr&quot;, &quot;ggridges&quot;, &quot;ggthemes&quot;, &quot;hrbrthemes&quot;, &quot;janitor&quot;, &quot;knitr&quot;, &quot;plotly&quot;, &quot;psych&quot;, &quot;remotes&quot;, &quot;stringr&quot;, &quot;tictoc&quot;, &quot;tidyverse&quot;, &quot;usethis&quot;, &quot;yarrr&quot;) new_packages &lt;- list_of_packages[!(list_of_packages %in% installed.packages()[,&quot;Package&quot;])] if (length(new_packages)) install.packages(new_packages, dependencies = TRUE) 0.2 Algo más sobre la instalación de paquetes Los paquetes de R son una colección de funciones, datos y documentación que amplían las capacidades básicas de R. En 2019 el numero de paquetes en R-cran ha superado los 14,000 (ver este buscador de paquetes). Gran parte de las funciones y paquetes que utilizaremos en este workshop se encuentran contenidas en el meta-paquete “tidyverse” (este es un paquete de paquetes). Ya lo instalamos en (C), pero si quisieras instalarlo solo tendrías que ejecutar la siguiente linea en la consola de RStudio ((1) en la imagen de arriba): install.packages(&quot;tidyverse&quot;) Para instalar otro paquete diferente de “tidyverse”, remplaza su nombre entre comillas dentro de la función: install.packages(&quot;NOMBRE_DE_PAQUETE&quot;). Una vez instalado un paquete, no es necesario volver hacerlo, a menos que reinstales R. 0.2.1 Cargar paquetes Las funciones, datos y documentación dentro de nuestros paquetes no podrán ser utilizadas hasta que se carguen en R (en realidad también pueden ser llamadas usando su referencia absoluta ::, por ejemplo: dplyr::tibble(columna = 1). La estructura de lo anterior es: nombre_paquete::nombre_de_funcion(parametros)). Una vez instalados, para cargar los paquetes se usa la función library(): library(tidyverse) 0.2.2 Todo en uno El siguiente código simplifica lo anterior. Comprueba que el paquete esta instalado; Si no se encuentra instalado, lo instala. Finalmente lo carga. if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) Para instalar múltiples paquetes, podemos repetir la linea de mas arriba tantas veces como sea necesaria, o usar una versión algo mas sofisticada como el código del apartado (C): if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse') if (!require('bookdown')) install.packages('bookdown'); library('bookdown') ... 0.2.3 Instalar paquetes de Github En ocasiones querremos instalar directamente la versión en desarrollo del paquete desde Github. Para eso podemos usar la función install_github del paquete remotes. Por ejemplo, para instalar el paquete {renv} desde su repositorio de Github: if (!require('remotes')) install.packages('remotes'); library('remotes') remotes::install_github(&quot;rstudio/renv&quot;) Bibliografía Algunos de los manuales que vamos a usar para el workshop son los siguientes: Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Bryan, J., &amp; Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/ "],
["introduccion-a-r-y-visualizacion-de-datos.html", "Capítulo 1 Introducción a R y visualización de datos 1.1 Introducción: porque la visualización de datos es importante 1.2 Por qué R? 1.3 Visualización de datos con ggplot2 1.4 Visualización interactiva 1.5 Ejercicios Bibliografía", " Capítulo 1 Introducción a R y visualización de datos Paquetes para este capítulo if (!require(&#39;cowplot&#39;)) install.packages(&#39;cowplot&#39;); library(&#39;cowplot&#39;) if (!require(&#39;esquisse&#39;)) install.packages(&#39;esquisse&#39;); library(&#39;esquisse&#39;) if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;gganimate&#39;)) install.packages(&#39;gganimate&#39;); library(&#39;gganimate&#39;) if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) if (!require(&#39;ggthemes&#39;)) install.packages(&#39;ggthemes&#39;); library(&#39;ggthemes&#39;) if (!require(&#39;ggridges&#39;)) install.packages(&#39;ggridges&#39;); library(&#39;ggridges&#39;) if (!require(&#39;hrbrthemes&#39;)) install.packages(&#39;hrbrthemes&#39;); library(&#39;hrbrthemes&#39;) if (!require(&#39;plotly&#39;)) install.packages(&#39;plotly&#39;); library(&#39;plotly&#39;) if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) # if (!require(&#39;gganimate&#39;)) devtools::install_github(&#39;thomasp85/gganimate&#39;); library(&#39;gganimate&#39;) 1.1 Introducción: porque la visualización de datos es importante “These 13 datasets (the Datasaurus, plus 12 others) each have the same summary statistics (x/y mean, x/y standard deviation, and Pearson’s correlation) to two decimal places, while being drastically different in appearance.” (Matejka, J., &amp; Fitzmaurice, G., 2017) SOURCE: https://www.autodeskresearch.com/publications/samestats 1.1.1 Porque la visualización de datos es importante - ejemplo del mundo real Este ejemplo viene de un experimento que realizamos junto con Carlos Santamaría hace algún tiempo. Presentamos una tarea sobre cálculo de probabilidades en un contexto real. Nuestros participantes estaban entrando a un examen para convertirse en trabajadores del estado. La historia real tiene algunos matices, pero simplificando, digamos que la materia para el examen eran unos 80 temas. Las personas generalmente no podían estudiar con profundidad todos los temas (o sabían que esa no era la estrategia óptima), así que se concentraban en un subconjunto de esos temas (e.g. 30 de 80). En el examen, se seleccionaban al azar 5 de estos temas, y las personas tenían que elegir uno de ellos para desarrollar. Abajo se puede ver como cambia la probabilidad de que uno de los temas estudiados aparezca dentro de los 5 seleccionados al azar. Con 30 temas estudiados (de los 80 totales), la probabilidad de que uno de ellos salga en la prueba es del 91%. Si estudiáramos 47, subiríamos a una probabilidad del 99%. En el experimento le preguntamos a las personas por la probabilidad de que les aparezca alguno de los temas que han estudiado en la prueba. Comparamos las siguientes dos preguntas: ¿Cuál es la probabilidad de que salga uno de los temas que has estudiado? ¿Cuál es la probabilidad de que no salga ninguno de los temas que has estudiado? Miramos el error promedio en función de la pregunta (cuanto se han alejado de la probabilidad correcta), y vemos que nuestra manipulación ha tenido un efecto considerable: if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) # Leemos datos DF = read_csv( here::here(&quot;data&quot;, &quot;files&quot;, &quot;01-visualizacion-importante.csv&quot;)) %&gt;% mutate(Question = as.factor( case_when(Question_p_of == 1 ~ &quot;p (salga uno)&quot;, Question_p_of == 0 ~ &quot;p (no salga ninguno)&quot;))) # Promedio por condicion DF %&gt;% group_by(Question) %&gt;% summarise(Error_promedio = mean(Error), SD = sd(Error, na.rm = TRUE), N = n()) ## # A tibble: 2 x 4 ## Question Error_promedio SD N ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 p (no salga ninguno) 4.02 35.8 31 ## 2 p (salga uno) -30.7 20.0 31 Hay una diferencia notable entre condiciones. Pasamos de un error promedio del -30.7% a tan solo 4%, simplemente cambiando la pregunta. Hagamos un sencillo análisis de regresión para ver si la diferencia es significativa, y cuanta varianza explica nuestro modelo. # Modelo de regresion modelo_regresion = lm(Error ~ Question, DF) # Resultados summary(modelo_regresion) ## ## Call: ## lm(formula = Error ~ Question, data = DF) ## ## Residuals: ## Min 1Q Median 3Q Max ## -53.516 -15.758 -2.758 25.984 70.742 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.016 5.212 0.771 0.444 ## Questionp (salga uno) -34.758 7.370 -4.716 1.48e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29.02 on 60 degrees of freedom ## Multiple R-squared: 0.2704, Adjusted R-squared: 0.2583 ## F-statistic: 22.24 on 1 and 60 DF, p-value: 1.479e-05 # Histograma de los residuos hist(modelo_regresion$residuals) # Supuesto de normalidad de residuales shapiro.test(modelo_regresion$residuals) ## ## Shapiro-Wilk normality test ## ## data: modelo_regresion$residuals ## W = 0.96215, p-value = 0.0532 Todo es hermoso. Tenemos un efecto claramente significativo de la pregunta (y con un R2-ajustado de .258, no está nada mal), y además, nuestro modelo no incumple el supuesto de normalidad de residuos (por los pelos!). Preparamos un plot con promedios y barras con error standard para nuestro paper: # Plot para publicación plot_inicial = ggplot(DF, aes(Question, Error, fill = Question)) + stat_summary( fun.y = mean, geom = &quot;point&quot;, size = 4, color = &quot;darkgrey&quot;) + stat_summary(geom = &quot;errorbar&quot;, fun.data = mean_se, position = &quot;dodge&quot;, color = &quot;black&quot;, width = .2) + scale_y_continuous(limits = c(-50, 50), breaks = seq(-50, 50, 10)) + theme_minimal(base_size = 12) + theme(legend.position = &quot;none&quot;) plot_inicial Estamos listos para escribir nuestro paper. Solo por curiosidad, veamos boxplots de los dos grupos. Mmmm… hay algo extraño: # Boxplots por condición ggplot(DF, aes(Question, Error, color = Question, group = Question)) + geom_boxplot(alpha = .5) + theme_minimal() + scale_y_continuous(limits = c(-50, 50), breaks = seq(-50, 50, 10)) + labs(x = &quot;What is the probability of x?&quot;) Volvemos a extraer descriptivos… pero esta vez incluimos la mediana. # Promedio y mediana por condicion DF %&gt;% group_by(Question) %&gt;% summarise(Error_promedio = mean(Error), Error_mediana = median(Error), SD = sd(Error, na.rm = TRUE), N = n()) ## # A tibble: 2 x 5 ## Question Error_promedio Error_mediana SD N ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 p (no salga ninguno) 4.02 25 35.8 31 ## 2 p (salga uno) -30.7 -37 20.0 31 Que esta pasando? Veamos las respuestas de todos los participantes, junto con la distribución de los datos, más la media y mediana por condición. plot_final = ggplot(DF, aes(Question, Error, color = Question, group = Question)) + geom_jitter(size = 2) + geom_violin(alpha = .2) + stat_summary( fun.y = median, geom = &quot;point&quot;, size = 3, color = &quot;black&quot;, shape = 0) + stat_summary( fun.y = mean, geom = &quot;point&quot;, size = 3, color = &quot;darkgrey&quot;, shape = 1) + theme_minimal() + scale_y_continuous(limits = c(-50, 50), breaks = seq(-50, 50, 10)) + labs(x = &quot;What is the probability of x?&quot;) plot_final TLDR: La manera en la visualizamos la información determina las conclusiones a las que llegamos. # Visualizamos el grafico inicial y el final, uno al lado del otro cowplot::plot_grid(plot_inicial, plot_final) Moraleja: es importante mostrar los datos individuales y/o la distribución de los datos SOURCE: https://www.autodeskresearch.com/publications/samestats 1.2 Por qué R? R es uno de los programas para data science mas populares, especialmente usado en la academia. El numero de paquetes que ofrecen funcionalidades de todo tipo no ha dejado de crecer. En 2019 el numero de paquetes en R-cran ha superado los 14,000, y el ritmo de crecimiento nos acerca a la singularidad… ;) SOURCE: https://gist.github.com/daroczig/3cf06d6db4be2bbe3368 Además de lo anterior, R es un programa de código abierto (esencial para poder hacer buena ciencia), con una comunidad de usuarios muy acogedora. Sus funciones de visualización son muy potentes (ver la r-graph-gallery para algunos ejemplos), siendo usadas como herramienta principal en algunos medios como la BBC. Con R puedes recoger datos interactivamente con shiny, preparar datos (o extraerlos de paginas web con rvest o RSelenium), visualizar datos estáticos con ggplot, animarlos con gganimate, visualizarlos con interactivamente con plotly o shiny. Puedes también analizar los datos con todas las técnicas imaginables, desde anovas con afex a modelos mixtos con lmer y/o afex, pasando por meta-análisis con metafor, SEM, Path analysis, mediación, con lavaan, análisis Bayesianos con brms o bayesfactor, y un larguísimo etc. Puedes llevar tus visualizaciones y análisis a reportes automáticos en múltiples formatos (pdf, html, docx) con Rmarkdown, crear libros como este con bookdown, páginas web con blogdown, e incluso papers completamente reproducibles (preparación y análisis de datos) en formato APA con papaja. 1.2.1 Bienvenida al tidyverse El tidyverse es un conjunto de paquetes que nos permitirán hacer de manera (habitualmente) intuitiva muchas tareas de preparación y visualización de datos. 1.2.1.1 Tidyverse vs Base R Muchas de las funciones que existen en el Tidyverse tienen un equivalente en base-R (la instalación por defecto de R). El Tidyverse tiene ventajas y desventajas. La ventaja fundamental es que el código resulta (habitualmente) más fácil de leer, los nombres de las funciones son mas intuitivos, y las maneras de hacer las cosas tienen a ser consistentes. La desventaja fundamental es que incrementamos el numero de dependencias (paquetes) de nuestro código. Veamos un ejemplo extraído de aqui. La misma operación con base-R o con tidyverse: Filter rows with conditions evaluated within groups: iris flowers with maximum “Petal.Width” for each “Species” 1.2.1.1.1 Tidyverse iris %&gt;% group_by(Species) %&gt;% filter(Petal.Width == max(Petal.Width)) ## # A tibble: 5 x 5 ## # Groups: Species [3] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5 3.5 1.6 0.6 setosa ## 2 5.9 3.2 4.8 1.8 versicolor ## 3 6.3 3.3 6 2.5 virginica ## 4 7.2 3.6 6.1 2.5 virginica ## 5 6.7 3.3 5.7 2.5 virginica 1.2.1.1.2 Base-R # First operate in the data.frame by group (split-apply) widest_petals &lt;- by(iris, INDICES = iris$Species, FUN = function(x){ x[x$Petal.Width == max(x$Petal.Width), ] }) # Then combine the results into a data.frame do.call(rbind, widest_petals) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## setosa 5.0 3.5 1.6 0.6 setosa ## versicolor 5.9 3.2 4.8 1.8 versicolor ## virginica.101 6.3 3.3 6.0 2.5 virginica ## virginica.110 7.2 3.6 6.1 2.5 virginica ## virginica.145 6.7 3.3 5.7 2.5 virginica 1.2.2 Antes de empezar Programar (tras la fase de euforia inicial) es muy difícil. Todos necesitamos ayuda. Contar con una comunidad robusta con la que compartir, preguntar, contribuir, ayuda muchísimo. SOURCE: http://www.keywordbasket.com/ZWZlY3RvIGR1bm5pbmcta3J1Z2Vy/ Hay algunos recursos que resultan muy útiles: Comunidad de usuarios de Rstudio Twiter!. Por ejemplo: #TidyTuesday ((???)) (???) (???) (???) Webs como R bloggers Y otros que son más que imprescindibles. Nadie sabe como los antiguos podían programar antes de la llegada de Stackoverflow: Google: text size ggplot Stack overflow!!! 1.2.3 R para visualización de datos ggplot2 es el paquete por excelencia para visualización de datos. Su potencia va asociada a un nivel de complejidad considerable, hasta el punto que hay Cheat sheets oficiales, Cheat sheets buscables, y decenas de miles de preguntas en Stack Overflow. 1.2.3.1 Primeros pasos - con training wheels Para empezar a usar ggplot sin tener que preocuparnos de su complejidad, podemos usar la función esquisse:::esquisser() del paquete esquisse. Esta nos permite usar la potencia de ggplot para explorar una base de datos de manera muy sencilla. SOURCE: https://www.williamrchase.com/slides/intro_r_anthropology_2018#93 La manera fácil (1, 2, 3), usando esquisse: # 1) Asegurate que hemos instalado el paquete esquisse if (!require(&#39;esquisse&#39;)) install.packages(&#39;esquisse&#39;); library(&#39;esquisse&#39;) # 2) Carga el dataframe que desees. En este caso, &quot;iris&quot; data(iris) # 3) Lanza el wizard esquisser esquisse:::esquisser() 1.2.3.2 Aprendamos con Garrick Garrick Aden-Buie ((???)) ha creado una excelente introducción a ggplot2 y la gramática de gráficos. Vamos a usarla para familiarizarnos con algunas de las funcionalidades de ggplot. Antes de LANZAR LA PRESENTACION introducción a ggplot2 y la gramática de gráficos, asegúrate que tienes instalados los paquetes tidyverse y gapminder, y crea el DF pop_simple usando el código de abajo. if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) tidy_pop &lt;- gapminder %&gt;% filter(country %in% c(&quot;Canada&quot;, &quot;China&quot;, &quot;United States&quot;), year &gt;= 1997) %&gt;% select(country, year, pop) %&gt;% mutate(pop = pop / 10^6) 1.3 Visualización de datos con ggplot2 1.3.1 Primeros pasos En esta sección vamos a ver algunos de los componentes que usaremos cuando visualicemos datos. Los ingredientes esenciales son: Aesthetic mappings (aes): Variables, colores, rellenos, formas, … Geoms (geom_): puntos, lineas, boxplots, … Facets (facet_): facet_wrap() y facet_grid() Transformaciones estadísticas: stat_summary, ..prop.., … SOURCE: https://skillgaze.com/2017/10/31/understanding-different-visualization-layers-of-ggplot/ Muchos de los ejemplos que usamos en esta sección vienen de R for data science: 1.3.2 Aesthetic mappings En aes() vamos a indicar las variables que queremos en los ejes x e y, el color de los puntos o lineas, el relleno de las barras, la forma de los puntos, el tipo de linea, la agrupación de los datos, etc. x: x = gdpPercap y: y = lifeExp color: color = continent; color = “red”; color = “#FAA627” fill: fill = continent; fill = “red”; fill = “#FAA627” alpha: alpha = continent; alpha = 0.2 size: size = continent; size = 5 shape: shape = continent; shape = 0 ver codigo de las distintas formas linetype: linetype = continent; linetype = “dashed” group: group = continent # x = gdpPercap, y = lifeExp ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() # x = lifeExp, y = gdpPercap ggplot(data = gapminder, mapping = aes(x = lifeExp, y = gdpPercap)) + geom_point() 1.3.2.1 Color, alpha, size Para elegir paletas de colores: colorbrewer Codigo HEX de colores # Grafico inicial ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() # Color &quot;rojo&quot; para los puntos ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(color = &quot;red&quot;) # Color en funcion de la variable &#39;continent&#39; ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() # Color en funcion de la variable &#39;continent&#39; + size ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2)) + geom_point() # Color en funcion de la variable &#39;continent&#39; + size + alpha ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2, alpha = .1)) + geom_point() Imagina que queremos asignar colores manualmente. ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(color = c(&quot;red&quot;, &quot;grey&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;black&quot;)) # Error: Aesthetics must be either length 1 or the same as the data (1704): colour Tenemos que indicar que el color depende de ‘class’, y después usar scale_color_manual() ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() + scale_color_manual(values = c(&quot;red&quot;, &quot;grey&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;black&quot;)) 1.3.2.2 Shape Códigos para las distintas formas: SOURCE: https://r4ds.had.co.nz/data-visualisation.html#aesthetic-mappings ggplot(gapminder, aes(gdpPercap, lifeExp, shape = continent)) + geom_point() 1.3.2.3 Linetype Códigos para los distintos estilos de linea: SOURCE: http://sape.inf.usi.ch/quick-reference/ggplot2/linetype ggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) + stat_summary(fun.y = mean, geom = &quot;line&quot;) 1.3.3 Geoms Una de las cosas más difíciles (inicialmente) cuando nos enfrentamos a unos datos nuevos es elegir el método más efectivo para visualizar los datos. Hay varios recursos interesantes sobre cómo elegir una gráfica. En esta sección veremos distintos tipos de geoms_(). 1.3.3.1 geom_point y geom_jitter # Points ggplot(mpg, aes(displ, hwy)) + geom_point() # Jitter Points ggplot(mpg, aes(displ, hwy)) + geom_jitter() 1.3.3.2 geom_smooth # Linea de tendencia (default loess) ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() + geom_smooth() # Usamos lm ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() + geom_smooth(method = &quot;lm&quot;) # Un smooth por cada clase ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() + geom_smooth() # Coloreamos puntos pero mantenemos un solo smooth ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(aes(color = continent)) + geom_smooth() Hagamos una pausa para hacer algunos ejercicios usando diferentes geoms, colores… 1.3.3.3 geom_boxplot y geom_violin # Boxplot base ggplot(gapminder, aes(continent, lifeExp)) + geom_boxplot(alpha = .2) # Boxplot con fill ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_boxplot(alpha = .2) # Violins ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) # Combinamos ambos ggplot(gapminder, aes(continent, lifeExp)) + geom_boxplot(alpha = .2) + geom_violin(alpha = .2, aes(fill = continent)) 1.3.3.4 geom_histogram # Histogram - variable continua ggplot(gapminder, aes(lifeExp)) + geom_histogram() # Histogram - variable categorica ggplot(gapminder, aes(continent)) + geom_histogram(stat = &quot;count&quot;) # Histogram - variable categorica, con fill y alpha ggplot(gapminder, aes(continent, fill = continent, alpha = .2)) + geom_histogram(stat = &quot;count&quot;) 1.3.3.5 geom_dotplot # Dotplot ggplot(mpg, aes(manufacturer)) + geom_dotplot() + coord_flip() 1.3.3.6 geom_density # Density ggplot(gapminder, aes(lifeExp)) + geom_density() # Density with fill ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density() # Density with fill and alpha ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(alpha = .2) # Density - position stack ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(position = &quot;stack&quot;, alpha = .2) # Density - position fill ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(position = &quot;fill&quot;, alpha = .2) 1.3.3.7 geom_density_ridges # geom_density_ridges ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(alpha = .2) # geom_density_ridges junto con raincloud points y histograma ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.7, scale = 0.9) 1.3.4 Facets Hay dos funciones para facet_grid y facet_wrap. facet_grid(~ variable) nos devuelve una matriz simétrica de gráficas. facet_wrap(~ variable) nos devuelve tantas facetas como niveles de la variable. 1.3.4.1 facet_grid # Plot inicial ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .2) + facet_grid(~ continent) + guides(alpha = FALSE, color = FALSE) # Cambiamos ejes ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .2) + facet_grid(continent ~ .) + guides(alpha = FALSE, color = FALSE) # Añadimos una segunda variable ggplot(gapminder, aes(gdpPercap, lifeExp, color = country)) + geom_line(alpha = .2) + facet_grid(continent ~ pop &gt; 5000000) + guides(alpha = FALSE, color = FALSE) 1.3.4.2 facet_wrap # Plot base ggplot(gapminder, aes(year, lifeExp, color = continent)) + geom_line(alpha = .2) + facet_wrap( ~ continent) + guides(alpha = FALSE, color = FALSE) # Una sola fila ggplot(gapminder, aes(year, lifeExp, color = continent)) + geom_line(alpha = .2) + facet_wrap( ~ continent, nrow = 1) + guides(alpha = FALSE, color = FALSE) # 5 filas ggplot(gapminder, aes(year, lifeExp, color = continent)) + geom_line(alpha = .2) + facet_wrap(continent ~ gdpPercap &gt; 4000, nrow = 5) + guides(alpha = FALSE, color = FALSE) 1.3.5 Transformaciones estadísticas VER: https://r4ds.had.co.nz/data-visualisation.html#statistical-transformations 1.3.5.1 Proporciones # Gráfico inicial ggplot(gapminder, aes(continent)) + geom_bar() # Proporciones ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() 1.3.5.2 stat_summary # Mediana, máximo y mínimo ggplot(gapminder, aes(continent, lifeExp)) + stat_summary( fun.ymin = min, fun.ymax = max, fun.y = median) # Media y media ± sd ggplot(gapminder, aes(continent, lifeExp)) + stat_summary( fun.ymin = function(x) mean(x) - sd(x), fun.ymax = function(x) mean(x) + sd(x), fun.y = mean) 1.3.5.3 Promedios por grupo # Usando lineas ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .6, size = 4) + # geom_line(alpha = .3, size = 1) + stat_summary(fun.y = mean, geom = &quot;line&quot;, size = 1, alpha = .3) # Gapminder ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + stat_summary(data = gapminder %&gt;% group_by(continent) %&gt;% summarise(gdpPercap = mean(gdpPercap), lifeExp = mean(lifeExp)), fun.y = mean, geom = &quot;point&quot;, size = 4) # Iris ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point(alpha = .4) + stat_summary(data = iris %&gt;% group_by(Species) %&gt;% summarise(Petal.Length = mean(Petal.Length), Petal.Width = mean(Petal.Width)), fun.y = mean, geom = &quot;point&quot;, size = 4) Hagamos una pausa para hacer algunos ejercicios con transformaciones estadísticas 1.3.6 Personalización de gráficas 1.3.6.1 Coords # Gráfico inicial ggplot(gapminder, aes(continent)) + geom_bar() # coord_flip() ggplot(gapminder, aes(continent)) + geom_bar() + coord_flip() # coord_polar() ggplot(gapminder, aes(continent)) + geom_bar() + coord_polar() 1.3.6.2 Scales # Grafico inicial ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) # Añadimos breaks en eje y ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) # Separador de miles y breaks en x ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + hrbrthemes::scale_x_comma(breaks = seq(0, 100000, 10000)) # Formato de $ ($M) ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_continuous(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;), breaks = seq(0, 100000, 20000)) # Escala log ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;)) # Invertimos escala ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_reverse() # No mostramos el texto de los breaks de x ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_reverse() + theme(axis.text.x = element_blank()) # Proporciones ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() # % ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() + scale_y_continuous(labels = scales::percent) 1.3.6.3 Colors and fill scales # Plot inicial ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) # Relleno usando paleta blues ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) + scale_fill_brewer(palette = &quot;Blues&quot;) # Color grey ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) + geom_point() + scale_color_grey(start = 0.2, end = 0.8, na.value = &quot;red&quot;) # Gradient ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) + geom_point() + scale_color_gradient(low = &quot;red&quot;, high = &quot;blue&quot;) # Gradient con un numero predefinidos de una paleta ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) + geom_point() + scale_colour_gradientn(colours = terrain.colors(3)) 1.3.6.4 Combinando gráficas plot1 = ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;)) + theme(legend.position = &quot;top&quot;) plot2 = ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() + scale_y_continuous(labels = scales::percent) + coord_flip() cowplot::plot_grid(plot2, plot1, rel_widths = c(.3, 0.7)) # SOURCE: https://stackoverflow.com/questions/8545035/scatterplot-with-marginal-histograms-in-ggplot2/56440634#56440634 if (!require(&#39;cowplot&#39;)) install.packages(&#39;cowplot&#39;); library(&#39;cowplot&#39;) # Set up scatterplot scatterplot &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point(size = 3, alpha = 0.6) + guides(color = FALSE) + theme(plot.margin = margin()) # Define marginal histogram marginal_distribution &lt;- function(x, var, group) { ggplot(x, aes_string(x = var, fill = group)) + geom_histogram(bins = 30, alpha = 0.4, position = &quot;identity&quot;) + # geom_density(alpha = 0.4, size = 0.1) + guides(fill = FALSE) + theme_void() + theme(plot.margin = margin()) } # Set up marginal histograms x_hist &lt;- marginal_distribution(iris, &quot;Sepal.Length&quot;, &quot;Species&quot;) y_hist &lt;- marginal_distribution(iris, &quot;Sepal.Width&quot;, &quot;Species&quot;) + coord_flip() # Align histograms with scatterplot aligned_x_hist &lt;- align_plots(x_hist, scatterplot, align = &quot;v&quot;)[[1]] aligned_y_hist &lt;- align_plots(y_hist, scatterplot, align = &quot;h&quot;)[[1]] # Arrange plots plot_grid( aligned_x_hist , NULL , scatterplot , aligned_y_hist , ncol = 2 , nrow = 2 , rel_heights = c(0.2, 1) , rel_widths = c(1, 0.2)) 1.3.6.5 Usando estilos https://ggplot2.tidyverse.org/reference/ggtheme.html https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) # Create a base graph p &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) + geom_point() + labs(title = &#39;A ggplot simple graph&#39;, subtitle = &#39;Simple tweaks to improve plots, or not&#39;, x = &#39;&#39;, y = &#39;&#39;, caption = &#39;https://github.com/gorkang / @gorkang&#39;) + theme_gray() # This is the default. Needed here because of the Bookdown theme p Usando el tema fivethirtyeight # if (!require(&#39;hrbrthemes&#39;)) install.packages(&#39;hrbrthemes&#39;); library(&#39;hrbrthemes&#39;) if (!require(&#39;ggthemes&#39;)) install.packages(&#39;ggthemes&#39;); library(&#39;ggthemes&#39;) p + ggthemes::scale_color_fivethirtyeight() + ggthemes::theme_fivethirtyeight() Usando el tema economist p + ggthemes::scale_color_economist() + ggthemes::theme_economist() Hagamos una pausa para hacer algunos ejercicios usando temas, paletas… 1.4 Visualización interactiva 1.4.0.1 Gráficas interactivas if (!require(&#39;plotly&#39;)) install.packages(&#39;plotly&#39;); library(&#39;plotly&#39;) plotly::ggplotly( ggplot(gapminder %&gt;% filter(year == 2007), aes(gdpPercap, lifeExp, color = continent, size = country)) + geom_point(alpha = .3, point = 2) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;)) + theme(legend.position = &quot;none&quot;) ) 1.4.0.2 Animando gráficas if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;gganimate&#39;)) devtools::install_github(&#39;thomasp85/gganimate&#39;); library(&#39;gganimate&#39;) #sudo apt-get install ffmpeg p = ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) + geom_point(alpha = 0.7, show.legend = FALSE) + scale_colour_manual(values = country_colors) + scale_size(range = c(2, 12)) + scale_x_log10() + facet_wrap(~continent) + # Here comes the gganimate specific bits labs(title = &#39;Year: {frame_time}&#39;, x = &#39;GDP per capita&#39;, y = &#39;life expectancy&#39;) + transition_time(year) + ease_aes(&#39;linear&#39;) animate(p, renderer = ffmpeg_renderer()) 1.5 Ejercicios 1.5.1 Ejercicios con Geoms, colores… Usando el df mpg, Crea los 6 plots que se pueden ver más abajo. Aquí tienes el plot base, para hacer mas fácil la tarea: ggplot(mpg, aes(displ, hwy)) + geom_point() + theme_grey() Además de generar uno a uno los 6 plots, serías capaz de generar la figura que se ve abajo? Esto es, un plot que incluye los 6 plots juntos. Con el DF diamonds, crea el siguiente plot: El plot del panel (A) tiene varios problemas (los años no son enteros o factores, los casos no se muestran con un separador de miles, la leyenda esta a la derecha ocupado un espacio precioso, etc.). Trata de resolverlos e intenta llegar al resultado que se ve en el panel (B). Usa el df table1 del paquete {tidyr}? 1.5.2 Sintaxis aes() Alguna de estas gráficas dará un error? Sin correr el código, sabrías decir cuál de ellas? Hay varias soluciones posibles, ¿Cuales serían?. ggplot(mpg, mapping = aes(displ, hwy, color = class)) + geom_point() + stat_summary(fun.y = mean, geom = &quot;line&quot;, linetype = &quot;dashed&quot;) ggplot(mpg, mapping = aes(displ, hwy, color = class, linetype = class)) + geom_point() + stat_summary(fun.y = mean, geom = &quot;line&quot;) ggplot(mpg, mapping = aes(displ, hwy, color = class)) + geom_point() + stat_summary(fun.y = mean, geom = &quot;line&quot;, linetype = class) 1.5.3 Temas 6a. Serías capaz de reproducir este gráfico, usando el df diamonds y el theme_economist? 6b. Serías capaz de reproducir este gráfico, usando el df gapminder y la paleta Accent? 1.5.4 Transformaciones estadísticas Cuando al plot A trato de añadirle lineas con me aparece algo como lo de B. plotA = ggplot(mpg, aes(displ, hwy, color = class)) + geom_point() + theme(legend.position = &quot;bottom&quot;) plotB = ggplot(mpg, aes(displ, hwy, color = class)) + geom_point() + geom_line() + theme(legend.position = &quot;bottom&quot;) cowplot::plot_grid(plotA, plotB, labels = c(&quot;A&quot;, &quot;B&quot;)) Pero en realidad yo quiero algo como esto. ¿Podrías reproducirlo? Podrías crear este gráfico? Mostramos mediana ± sd para cada país, organizado por continente. Bibliografía Matejka, J., &amp; Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM. https://bbc.github.io/rcookbook/ https://github.com/bbc/bbplot https://github.com/dreamRs/esquisse Garrick Aden-Buie. A Gentle Guide to the Grammar of Graphics with ggplot2: https://github.com/gadenbuie/gentle-ggplot2 Michael Toth. You Need to Start Branding Your Graphs. Here’s How, with ggplot!: https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html "],
["preparacion-y-transformacion-de-datos.html", "Capítulo 2 Preparación y transformación de datos 2.1 Importar y exportar datos 2.2 Preparación y transformación de datos 2.3 Combinar bases de datos 2.4 Datasets interesantes Bibliografía", " Capítulo 2 Preparación y transformación de datos En este capítulo vamos a aprender a importar y exportar todo tipo de archivos, ademas de pasar de una base de datos no especialmente amigable, a una base de datos tidy, esto es, siguiendo algunas reglas bien sencillas que harán más fácil trabajar con los datos. Paquetes para este capítulo if (!require(&quot;tidyverse&quot;)) install.packages(&quot;tidyverse&quot;); library(&quot;tidyverse&quot;) if (!require(&quot;readxl&quot;)) install.packages(&quot;readxl&quot;); library(&quot;readxl&quot;) if (!require(&quot;haven&quot;)) install.packages(&quot;haven&quot;); library(&quot;haven&quot;) if (!require(&quot;readODS&quot;)) install.packages(&quot;readODS&quot;); library(&quot;readODS&quot;) if (!require(&quot;writexl&quot;)) install.packages(&quot;writexl&quot;); library(&quot;writexl&quot;) if (!require(&quot;DT&quot;)) install.packages(&quot;DT&quot;); library(&quot;DT&quot;) if (!require(&quot;gsheet&quot;)) install.packages(&quot;gsheet&quot;); library(&quot;gsheet&quot;) if (!require(&quot;janitor&quot;)) install.packages(&quot;janitor&quot;); library(&quot;janitor&quot;) 2.1 Importar y exportar datos Podemos ver las funciones de esta sección y como usarlas en la Cheatsheet importar datos 2.1.1 Importar un solo archivo Vamos a ver con más detalle los archivos CSV (comma separated values). Las funciones para importar archivos excel, Libreoffice, SPSS, etc. tienen parámetros muy similares. 2.1.1.1 Archivos CSV Usaremos las siguientes funciones del paquete readr: readr::read_csv(): valores separados por coma (“,”) readr::read_csv2(): valores separados por punto y coma (“;”) readr::read_delim( , delim = &quot;|&quot;): valores separados por un delimitador arbitrario # Cargamos libreria if (!require(&quot;readr&quot;)) install.packages(&quot;readr&quot;); library(&quot;readr&quot;) # Version simple DF_name = read_csv(&quot;data/files/02-read-csv.csv&quot;) # Version avanzada name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.1.2 Otros tipos de archivos 2.1.1.2.1 Archivos excel if (!require(&quot;readxl&quot;)) install.packages(&quot;readxl&quot;); library(&quot;readxl&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-xlsx.xlsx&quot;) readxl::read_excel(name_of_file) ## # A tibble: 103 x 8 ## ...1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.1.2.2 Archivos SPSS if (!require(&quot;haven&quot;)) install.packages(&quot;haven&quot;); library(&quot;haven&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-sav.sav&quot;) haven::read_sav(name_of_file) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.1.2.3 Archivos Libreoffice if (!require(&quot;readODS&quot;)) install.packages(&quot;readODS&quot;); library(&quot;readODS&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-ods.ods&quot;) df_ODS = readODS::read_ods(name_of_file) # Vemos las primeras filas head(df_ODS) ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 2.1.1.2.4 Google sheets Para poder leer una gsheet debemos antes crear un enlace para compartirla: &quot;Share&quot; -&gt; &quot;Get shareable link&quot; if (!require(&quot;gsheet&quot;)) install.packages(&quot;gsheet&quot;); library(&quot;gsheet&quot;) name_of_sheet = &quot;1jjb91j2X13_JKDAeIwrKIdNv0rcseMdteSqb0ZMVOig/edit#gid=807114896&quot; gsheet::gsheet2tbl(name_of_sheet) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.2 Ejercicios - Importar datos En el repositorio R para preparación y visualización de datos - DNSC - UAI de la Open Science Foundation podrás ver una carpeta llamada Capitulo 2. Importa los archivos que ahí aparecen: 02-extralines-1.xlsx 02-extralines-2.xlsx 02-extralines-3.xlsx 02-spanish.csv 2.1.3 Importar múltiples archivos En ocasiones tenemos múltiples archivos en una carpeta (e.g. uno por participante) y queremos combinarlos todos en un solo DF. if (!require(&quot;purrr&quot;)) install.packages(&quot;purrr&quot;); library(&quot;purrr&quot;) if (!require(&quot;readr&quot;)) install.packages(&quot;readr&quot;); library(&quot;readr&quot;) if (!require(&quot;readxl&quot;)) install.packages(&quot;readxl&quot;); library(&quot;readxl&quot;) Importamos los archivos que están en la carpeta data/files/02-CSVs # Directorio donde se encuentran los archivos name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) # Listamos los archivos a leer files &lt;- list.files(name_of_folder, full.names = TRUE) # Leemos todos los archivos, combinandolos en un dataframe full &lt;- map_df(files, read_csv) full ## # A tibble: 1,600 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,590 more rows 2.1.3.1 Incluir nombres de archivos Incluimos nombres de archivo en una columna: name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) files &lt;- list.files(name_of_folder, full.names = TRUE) %&gt;% set_names(basename(.)) full2 &lt;- map_df(files, read_csv, .id = &quot;file&quot;) full2 ## # A tibble: 1,600 x 10 ## file Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 01.csv male Collecti… 1 we ofensivo negati… yes left 623 ## 2 01.csv male Collecti… 2 we resentido negati… no right 1235 ## 3 01.csv male Collecti… 3 we ego�sta negati… yes left 335 ## 4 01.csv male Collecti… 4 we indiscre… negati… yes left 355 ## 5 01.csv male Collecti… 5 we sumiso negati… yes left 618 ## 6 01.csv male Collecti… 6 we agradable positi… yes left 328 ## 7 01.csv male Collecti… 7 we clasista negati… yes left 348 ## 8 01.csv male Collecti… 8 we altruista positi… yes left 1620 ## 9 01.csv male Collecti… 9 we ansioso negati… yes left 346 ## 10 01.csv male Collecti… 10 we presumido negati… yes left 778 ## # … with 1,590 more rows 2.1.3.2 Con parametros Añadimos parametros a la funcion de lectura. En este caso, definimos el tipo de columna esperado con la función col_types(). Con esto nos aseguraremos que si alguno de los archivos tiene el tipo de datos “incorrecto”, aparecerán warnings en la importación: name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) files &lt;- list.files(name_of_folder, full.names = TRUE) full &lt;- map_df(files, read_csv, col_types = cols( Sex = col_factor(), Priming = col_character(), trialN = col_integer(), Block = col_character(), Adjective = col_character(), Valence = col_factor(), Answer = col_character(), Arrow = col_character(), rT = col_double())) full ## # A tibble: 1,600 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,590 more rows 2.1.4 Ejercicios - Importar múltiples archivos Cuando más arriba importamos los archivos que están en la carpeta data/files/02-CSVs, ¿qué archivos importamos exáctamente? ¿Ves algún problema en lo que hicimos? El resultado final deberia ser así: ## # A tibble: 1,200 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,190 more rows Leed los archivos .xlsx de la carpeta data/files/02-XLSs, combinándolos en un único DF. El resultado final debería ser como se ve a continuación: ## # A tibble: 1,200 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,190 more rows 2.1.5 Exportar datos 2.1.5.1 Archivos CSV # Versión simple write_csv(DF_name, &quot;data/files/02-write-csv.csv&quot;) # Versión avanzada name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-csv.csv&quot;) write_csv(DF_name, name_of_file) 2.1.5.2 Otros Archivos if (!require(&quot;writexl&quot;)) install.packages(&quot;writexl&quot;); library(&quot;writexl&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-xlsx.xlsx&quot;) writexl::write_xlsx(DF_name, name_of_file) if (!require(&quot;haven&quot;)) install.packages(&quot;haven&quot;); library(&quot;haven&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-sav.sav&quot;) haven::write_sav(DF_name, name_of_file) if (!require(&quot;readODS&quot;)) install.packages(&quot;readODS&quot;); library(&quot;readODS&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-ods.ods&quot;) readODS::write_ods(DF_name, name_of_file) 2.2 Preparación y transformación de datos Para la preparación y transformación de datos usaremos fundamentalmente dplyr. Hay otros paquetes más rápidos como data.table. Si trabajas con datos gigantescos (millones de filas), sin duda notarás la diferencia. La desventaja es que la sintaxis es (habitualmente) algo más difícil. 2.2.1 Tidy data Existen tres sencillas reglas que definen la Tidy data: Cada variable tiene su columna propia Cada observacion tiene su fila propia Cada valor tiene su celda propia Las ventajas fundamentales son: Uso de una manera consistente de trabajar, que se alinea con el tidyverse Facilidad para trabajar con la logica vectorizada Por ejemplo. De manera muy sencilla y rápida podemos crear una nueva columna realizando algún cómputo arbitrario con los valores de otra columna. if (!require(&quot;tidyverse&quot;)) install.packages(&quot;tidyverse&quot;); library(&quot;tidyverse&quot;) # Compute rate per 100,000 table1 %&gt;% mutate(rate_per_100K = cases / population * 100000) ## # A tibble: 6 x 5 ## country year cases population rate_per_100K ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 3.73 ## 2 Afghanistan 2000 2666 20595360 12.9 ## 3 Brazil 1999 37737 172006362 21.9 ## 4 Brazil 2000 80488 174504898 46.1 ## 5 China 1999 212258 1272915272 16.7 ## 6 China 2000 213766 1280428583 16.7 O contar el número de casos por valor de una variable. # Compute cases per year table1 %&gt;% count(year, wt = cases) ## # A tibble: 2 x 2 ## year n ## &lt;int&gt; &lt;int&gt; ## 1 1999 250740 ## 2 2000 296920 Y, como no, ggplot funciona con datos tidy, en formato long. # Visualise changes over time if (!require(&quot;tidyverse&quot;)) install.packages(&quot;tidyverse&quot;); library(&quot;tidyverse&quot;) ggplot(table1, aes(as.factor(year), cases)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country)) 2.2.2 Verbos dplyr Usaremos {dplyr}, un paquete muy potente para la manipulación de datos. Su sintaxis, además, es bastante intuitiva (¡son verbos en inglés!). Usando pipes %&gt;% (CONTROL + SHIFT + M) podemos enlazar operaciones de transformación de datos de manera muy sencilla (una vez nos aprendamos los verbos). Verbos esenciales: filter(): filtrar filas arrange(): ordenar filas select(): seleccionar columnas rename(): renombrar columnas mutate(): crear columnas, modificar columnas, etc. Podemos ver mas detalle y ejemplos en la Cheatsheet de dplyr. Tabla resumen dplyr 2.2.2.1 Filtrar y ordenar filas # DF original name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Filtrar DF_name %&gt;% filter(Educacion &gt; 8) ## # A tibble: 3 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 157 12207 1 26 9 57 PPV_Cond2 45 ## 2 287 60873 1 72 10 51 PPV_Cond3 99 ## 3 381 64486 2 19 9 80 PPV_Cond4 92 # Ordenar DF_name %&gt;% arrange(Educacion, desc(Genero)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 350 20439 2 41 1 81 PPV_Cond4 92 ## 2 399 81379 1 36 1 90 PPV_Cond4 92 ## 3 42 20361 2 37 2 60 PPV_Cond1 1 ## 4 364 19201 2 21 2 67 PPV_Cond4 10 ## 5 412 60292 1 28 2 90 PPV_Cond4 80 ## 6 44 92735 2 30 3 95 PPV_Cond1 99 ## 7 135 32344 2 34 3 81 PPV_Cond2 46 ## 8 299 33562 2 35 3 95 PPV_Cond3 99 ## 9 333 29837 2 28 3 80 PPV_Cond4 60 ## 10 361 57804 2 40 3 30 PPV_Cond4 90 ## # … with 93 more rows 2.2.2.2 Seleccionar, ordenar y renombrar columnas # Seleccionar columnas DF_name %&gt;% select(Genero, Edad) ## # A tibble: 103 x 2 ## Genero Edad ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 47 ## 2 2 21 ## 3 2 29 ## 4 2 27 ## 5 1 29 ## 6 2 28 ## 7 2 27 ## 8 2 55 ## 9 2 28 ## 10 1 46 ## # … with 93 more rows # Eliminar columnas DF_name %&gt;% select(-X1) ## # A tibble: 103 x 7 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 1 47 8 80 PPV_Cond1 99 ## 2 95041 2 21 6 90 PPV_Cond1 99 ## 3 74594 2 29 6 10 PPV_Cond1 99 ## 4 72903 2 27 7 75 PPV_Cond1 1 ## 5 21260 1 29 5 35 PPV_Cond1 24 ## 6 50315 2 28 6 14 PPV_Cond1 99 ## 7 21774 2 27 4 2 PPV_Cond1 99 ## 8 20881 2 55 6 89 PPV_Cond1 99 ## 9 39751 2 28 6 6 PPV_Cond1 99 ## 10 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Ordenar y eliminar columnas DF_name %&gt;% select(ID, Edad, Genero, everything(), -X1) ## # A tibble: 103 x 7 ## ID Edad Genero Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 47 1 8 80 PPV_Cond1 99 ## 2 95041 21 2 6 90 PPV_Cond1 99 ## 3 74594 29 2 6 10 PPV_Cond1 99 ## 4 72903 27 2 7 75 PPV_Cond1 1 ## 5 21260 29 1 5 35 PPV_Cond1 24 ## 6 50315 28 2 6 14 PPV_Cond1 99 ## 7 21774 27 2 4 2 PPV_Cond1 99 ## 8 20881 55 2 6 89 PPV_Cond1 99 ## 9 39751 28 2 6 6 PPV_Cond1 99 ## 10 99384 46 1 5 0 PPV_Cond1 1 ## # … with 93 more rows # Renombrar columnas DF_name %&gt;% rename(Identificador = ID, Sexo = Genero) ## # A tibble: 103 x 8 ## X1 Identificador Sexo Edad Educacion FollowUP condition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 ## 2 5 95041 2 21 6 90 PPV_Cond1 ## 3 6 74594 2 29 6 10 PPV_Cond1 ## 4 15 72903 2 27 7 75 PPV_Cond1 ## 5 16 21260 1 29 5 35 PPV_Cond1 ## 6 18 50315 2 28 6 14 PPV_Cond1 ## 7 19 21774 2 27 4 2 PPV_Cond1 ## 8 20 20881 2 55 6 89 PPV_Cond1 ## 9 21 39751 2 28 6 6 PPV_Cond1 ## 10 22 99384 1 46 5 0 PPV_Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; # Renombrar usando la posicion (DANGER!) DF_name %&gt;% rename(Identificador = 2) ## # A tibble: 103 x 8 ## X1 Identificador Genero Edad Educacion FollowUP condition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 ## 2 5 95041 2 21 6 90 PPV_Cond1 ## 3 6 74594 2 29 6 10 PPV_Cond1 ## 4 15 72903 2 27 7 75 PPV_Cond1 ## 5 16 21260 1 29 5 35 PPV_Cond1 ## 6 18 50315 2 28 6 14 PPV_Cond1 ## 7 19 21774 2 27 4 2 PPV_Cond1 ## 8 20 20881 2 55 6 89 PPV_Cond1 ## 9 21 39751 2 28 6 6 PPV_Cond1 ## 10 22 99384 1 46 5 0 PPV_Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; # Renombrar usando vectores oldnames = c(&quot;ID&quot;,&quot;Genero&quot;) newnames = c(&quot;Identificador&quot;,&quot;Sexo&quot;) DF_name %&gt;% rename_at(vars(oldnames), ~ newnames) ## # A tibble: 103 x 8 ## X1 Identificador Sexo Edad Educacion FollowUP condition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 ## 2 5 95041 2 21 6 90 PPV_Cond1 ## 3 6 74594 2 29 6 10 PPV_Cond1 ## 4 15 72903 2 27 7 75 PPV_Cond1 ## 5 16 21260 1 29 5 35 PPV_Cond1 ## 6 18 50315 2 28 6 14 PPV_Cond1 ## 7 19 21774 2 27 4 2 PPV_Cond1 ## 8 20 20881 2 55 6 89 PPV_Cond1 ## 9 21 39751 2 28 6 6 PPV_Cond1 ## 10 22 99384 1 46 5 0 PPV_Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; 2.2.2.2.1 Selección avanzada con select_helpers() El everything() que usamos dentro de select() más arriba es uno de los select_helpers() existentes. Estos permiten realizar operaciones de selección de variables de manera más sencilla. select_helpers() starts_with(): Empieza con un prefijo (e.g. starts_with(&quot;)) ends_with(): Ends with a suffix contains(): Contains a literal string matches(): Matches a regular expression num_range(): Matches a numerical range like x01, x02, x03 one_of(): Matches variable names in a character vector everything(): Matches all variables last_col(): Select last variable, possibly with an offset Trabajaremos con los datos del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base RAW en formato wide. # DF original df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) cat(names(df_wide)) ## ID dem_genero dem_edad dem_nivedu WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod WVOC_06_cod WVOC_07_cod WVOC_08_cod WVOC_09_cod WVOC_10_cod WVOC_11_cod WVOC_12_cod WVOC_13_cod WVOC_14_cod WVOC_15_cod WVOC_16_cod WVOC_17_cod WVOC_18_cod WVOC_19_cod WVOC_20_cod WVOC_21_cod WVOC_22_cod WVOC_23_cod WVOC_24_cod WVOC_25_cod WVOC_26_cod WVOC_27_cod WVOC_28_cod WVOC_29_cod WVOC_30_cod WVOC_31_cod WVOC_32_cod WVOC_33_cod WVOC_TOTAL WVOC_TOTAL_STD WMAT_01_cod WMAT_01_raw WMAT_02_cod WMAT_02_raw WMAT_03_cod WMAT_03_raw WMAT_04_cod WMAT_04_raw WMAT_05_cod WMAT_05_raw WMAT_06_cod WMAT_06_raw WMAT_07_cod WMAT_07_raw WMAT_08_cod WMAT_08_raw WMAT_09_cod WMAT_09_raw WMAT_10_cod WMAT_10_raw WMAT_11_cod WMAT_11_raw WMAT_12_cod WMAT_12_raw WMAT_13_cod WMAT_13_raw WMAT_14_cod WMAT_14_raw WMAT_15_cod WMAT_15_raw WMAT_16_cod WMAT_16_raw WMAT_17_cod WMAT_17_raw WMAT_18_cod WMAT_18_raw WMAT_19_cod WMAT_19_raw WMAT_20_cod WMAT_20_raw WMAT_21_cod WMAT_21_raw WMAT_22_cod WMAT_22_raw WMAT_23_cod WMAT_23_raw WMAT_24_cod WMAT_24_raw WMAT_25_cod WMAT_25_raw WMAT_26_cod WMAT_26_raw WMAT_A WMAT_B WMAT_C wmat_total wmat_total_std bfbs_01_cod bfbs_01_conf bfbs_01_raw bfbs_03_cod bfbs_03_conf bfbs_03_raw bfbs_04_cod bfbs_04_conf bfbs_04_raw bfbs_10_cod bfbs_10_conf bfbs_10_raw bfbs_12_cod bfbs_12_conf bfbs_12_raw bfbs_14_cod bfbs_14_conf bfbs_14_raw bfbs_17_cod bfbs_17_conf bfbs_17_raw bfbs_23_cod bfbs_23_conf bfbs_23_raw bfbs_conf_total bfbs_cong_conf bfbs_cong_total bfbs_creib_conf bfbs_creib_total bfbs_incong_conf bfbs_incon_total bfbs_increib_conf bfbs_increib_total bfbs_invalid_conf bfbs_invalid_total bfbs_total bfbs_valid_conf bfbs_valid_total EA_01_raw EA_02_raw EA_03_raw EA_04_raw EA_05_raw EA_06_raw EA_07_raw EA_08_raw EA_09_raw EA_10_raw EA_11_raw EA_12_raw EA_13_raw EA_14_raw EA_15_raw EA_16_raw EA_17_raw EA_18_raw EA_19_raw EA_20_raw EA_21_raw EA_22_raw EA_23_raw EA_24_raw EA_azar_TOTAL EA_control_interno_TOTAL EA_otros_poderosos_TOTAL EAR_01_raw EAR_02_raw EAR_03_raw EAR_04_raw EAR_05_raw EAR_06_raw EAR_07_raw EAR_08_raw EAR_09_raw EAR_10_raw EAR_TOTAL ECRRS_ansiedad_TOTAL ECRRS_evitacion_TOTAL ECRRS_madre_01_raw ECRRS_madre_02_raw ECRRS_madre_03_raw ECRRS_madre_04_raw ECRRS_madre_05_raw ECRRS_madre_06_raw ECRRS_madre_07_raw ECRRS_madre_08_raw ECRRS_madre_09_raw ECRRS_madre_ansiedad_TOTAL ECRRS_madre_evitacion_TOTAL ECRRS_mejoramig_01_raw ECRRS_mejoramig_02_raw ECRRS_mejoramig_03_raw ECRRS_mejoramig_04_raw ECRRS_mejoramig_05_raw ECRRS_mejoramig_06_raw ECRRS_mejoramig_07_raw ECRRS_mejoramig_08_raw ECRRS_mejoramig_09_raw ECRRS_mejoramigo_ansiedad_TOTAL ECRRS_mejoramigo_evitacion_TOTAL ECRRS_padre_01_raw ECRRS_padre_02_raw ECRRS_padre_03_raw ECRRS_padre_04_raw ECRRS_padre_05_raw ECRRS_padre_06_raw ECRRS_padre_07_raw ECRRS_padre_08_raw ECRRS_padre_09_raw ECRRS_padre_ansiedad_TOTAL ECRRS_padre_evitacion_TOTAL ECRRS_pareja_01_raw ECRRS_pareja_02_raw ECRRS_pareja_03_raw ECRRS_pareja_04_raw ECRRS_pareja_05_raw ECRRS_pareja_06_raw ECRRS_pareja_07_raw ECRRS_pareja_08_raw ECRRS_pareja_09_raw ECRRS_pareja_ansiedad_TOTAL ECRRS_pareja_evitacion_TOTAL GHQ_01 GHQ_02 GHQ_03 GHQ_04 GHQ_05 GHQ_06 GHQ_07 GHQ_08 GHQ_09 GHQ_10 GHQ_11 GHQ_12 GHQ_autoestima_TOTAL GHQ_estres_TOTAL GHQ_exito_afrontamiento_TOTAL GHQ_TOTAL wdig_dir_total wdig_inv_total WDIGSIMB_TOTAL wdig_total wdig_total_std lkns_01_cod lkns_01_raw lkns_02_cod lkns_02_raw lkns_03_cod lkns_03_raw lkns_04_cod lkns_04_raw lkns_05_cod lkns_05_raw lkns_06_cod lkns_06_raw lkns_07_cod lkns_07_raw lkns_08_cod lkns_08_raw lkns_09_cod lkns_09_raw lkns_10_cod lkns_10_raw lkns_11_cod lkns_11_raw lkns_total SASS_01_raw SASS_02_raw SASS_03_raw SASS_04_raw SASS_05_raw SASS_06_raw SASS_07_raw SASS_08_raw SASS_09_raw SASS_10_raw SASS_11_raw SASS_12_raw SASS_13_raw SASS_14_raw SASS_15_raw SASS_16_raw SASS_17_raw SASS_18_raw SASS_19_raw SASS_20_raw SASS_21_raw SASS_TOTAL SASS_trabajo bayes_all_accuracy bayes_all_confidence bayes_pictorial_qualitative_accuracy bayes_pictorial_quantitative_accuracy bayes_text_qualitative_accuracy bayes_text_quantitative_accuracy # Seleccionamos variables que contienen la cadena de texto &quot;dem&quot; df_wide %&gt;% select(contains(&quot;dem&quot;)) ## # A tibble: 232 x 3 ## dem_genero dem_edad dem_nivedu ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 38 4 ## 2 0 67 2 ## 3 0 24 4 ## 4 0 30 4 ## 5 0 38 3 ## 6 0 45 4 ## 7 1 58 3 ## 8 1 47 4 ## 9 1 52 3 ## 10 1 49 4 ## # … with 222 more rows # Seleccionamos variables que acacan con la cadena de texto &quot;cod&quot; df_wide %&gt;% select(ID, ends_with(&quot;cod&quot;)) ## # A tibble: 232 x 79 ## ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 2 2 1 2 ## 2 2 2 2 2 1 0 ## 3 3 2 2 2 1 2 ## 4 4 2 1 1 1 2 ## 5 5 2 2 1 1 0 ## 6 6 1 1 2 1 2 ## 7 7 1 0 2 1 0 ## 8 8 2 2 2 1 2 ## 9 9 2 2 2 2 2 ## 10 10 2 2 2 2 2 ## # … with 222 more rows, and 73 more variables: WVOC_06_cod &lt;dbl&gt;, ## # WVOC_07_cod &lt;dbl&gt;, WVOC_08_cod &lt;dbl&gt;, WVOC_09_cod &lt;dbl&gt;, ## # WVOC_10_cod &lt;dbl&gt;, WVOC_11_cod &lt;dbl&gt;, WVOC_12_cod &lt;dbl&gt;, ## # WVOC_13_cod &lt;dbl&gt;, WVOC_14_cod &lt;dbl&gt;, WVOC_15_cod &lt;dbl&gt;, ## # WVOC_16_cod &lt;dbl&gt;, WVOC_17_cod &lt;dbl&gt;, WVOC_18_cod &lt;dbl&gt;, ## # WVOC_19_cod &lt;dbl&gt;, WVOC_20_cod &lt;dbl&gt;, WVOC_21_cod &lt;dbl&gt;, ## # WVOC_22_cod &lt;dbl&gt;, WVOC_23_cod &lt;dbl&gt;, WVOC_24_cod &lt;dbl&gt;, ## # WVOC_25_cod &lt;dbl&gt;, WVOC_26_cod &lt;dbl&gt;, WVOC_27_cod &lt;dbl&gt;, ## # WVOC_28_cod &lt;dbl&gt;, WVOC_29_cod &lt;dbl&gt;, WVOC_30_cod &lt;dbl&gt;, ## # WVOC_31_cod &lt;dbl&gt;, WVOC_32_cod &lt;dbl&gt;, WVOC_33_cod &lt;dbl&gt;, ## # WMAT_01_cod &lt;dbl&gt;, WMAT_02_cod &lt;dbl&gt;, WMAT_03_cod &lt;dbl&gt;, ## # WMAT_04_cod &lt;dbl&gt;, WMAT_05_cod &lt;dbl&gt;, WMAT_06_cod &lt;dbl&gt;, ## # WMAT_07_cod &lt;dbl&gt;, WMAT_08_cod &lt;dbl&gt;, WMAT_09_cod &lt;dbl&gt;, ## # WMAT_10_cod &lt;dbl&gt;, WMAT_11_cod &lt;dbl&gt;, WMAT_12_cod &lt;dbl&gt;, ## # WMAT_13_cod &lt;dbl&gt;, WMAT_14_cod &lt;dbl&gt;, WMAT_15_cod &lt;dbl&gt;, ## # WMAT_16_cod &lt;dbl&gt;, WMAT_17_cod &lt;dbl&gt;, WMAT_18_cod &lt;dbl&gt;, ## # WMAT_19_cod &lt;dbl&gt;, WMAT_20_cod &lt;dbl&gt;, WMAT_21_cod &lt;dbl&gt;, ## # WMAT_22_cod &lt;dbl&gt;, WMAT_23_cod &lt;dbl&gt;, WMAT_24_cod &lt;dbl&gt;, ## # WMAT_25_cod &lt;dbl&gt;, WMAT_26_cod &lt;dbl&gt;, bfbs_01_cod &lt;dbl&gt;, ## # bfbs_03_cod &lt;dbl&gt;, bfbs_04_cod &lt;dbl&gt;, bfbs_10_cod &lt;dbl&gt;, ## # bfbs_12_cod &lt;dbl&gt;, bfbs_14_cod &lt;dbl&gt;, bfbs_17_cod &lt;dbl&gt;, ## # bfbs_23_cod &lt;dbl&gt;, lkns_01_cod &lt;dbl&gt;, lkns_02_cod &lt;dbl&gt;, ## # lkns_03_cod &lt;dbl&gt;, lkns_04_cod &lt;dbl&gt;, lkns_05_cod &lt;dbl&gt;, ## # lkns_06_cod &lt;dbl&gt;, lkns_07_cod &lt;dbl&gt;, lkns_08_cod &lt;dbl&gt;, ## # lkns_09_cod &lt;dbl&gt;, lkns_10_cod &lt;dbl&gt;, lkns_11_cod &lt;dbl&gt; # Lo mismo, pero usando expresiones regulares df_wide %&gt;% select(ID, matches(&quot;cod$&quot;)) ## # A tibble: 232 x 79 ## ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 2 2 1 2 ## 2 2 2 2 2 1 0 ## 3 3 2 2 2 1 2 ## 4 4 2 1 1 1 2 ## 5 5 2 2 1 1 0 ## 6 6 1 1 2 1 2 ## 7 7 1 0 2 1 0 ## 8 8 2 2 2 1 2 ## 9 9 2 2 2 2 2 ## 10 10 2 2 2 2 2 ## # … with 222 more rows, and 73 more variables: WVOC_06_cod &lt;dbl&gt;, ## # WVOC_07_cod &lt;dbl&gt;, WVOC_08_cod &lt;dbl&gt;, WVOC_09_cod &lt;dbl&gt;, ## # WVOC_10_cod &lt;dbl&gt;, WVOC_11_cod &lt;dbl&gt;, WVOC_12_cod &lt;dbl&gt;, ## # WVOC_13_cod &lt;dbl&gt;, WVOC_14_cod &lt;dbl&gt;, WVOC_15_cod &lt;dbl&gt;, ## # WVOC_16_cod &lt;dbl&gt;, WVOC_17_cod &lt;dbl&gt;, WVOC_18_cod &lt;dbl&gt;, ## # WVOC_19_cod &lt;dbl&gt;, WVOC_20_cod &lt;dbl&gt;, WVOC_21_cod &lt;dbl&gt;, ## # WVOC_22_cod &lt;dbl&gt;, WVOC_23_cod &lt;dbl&gt;, WVOC_24_cod &lt;dbl&gt;, ## # WVOC_25_cod &lt;dbl&gt;, WVOC_26_cod &lt;dbl&gt;, WVOC_27_cod &lt;dbl&gt;, ## # WVOC_28_cod &lt;dbl&gt;, WVOC_29_cod &lt;dbl&gt;, WVOC_30_cod &lt;dbl&gt;, ## # WVOC_31_cod &lt;dbl&gt;, WVOC_32_cod &lt;dbl&gt;, WVOC_33_cod &lt;dbl&gt;, ## # WMAT_01_cod &lt;dbl&gt;, WMAT_02_cod &lt;dbl&gt;, WMAT_03_cod &lt;dbl&gt;, ## # WMAT_04_cod &lt;dbl&gt;, WMAT_05_cod &lt;dbl&gt;, WMAT_06_cod &lt;dbl&gt;, ## # WMAT_07_cod &lt;dbl&gt;, WMAT_08_cod &lt;dbl&gt;, WMAT_09_cod &lt;dbl&gt;, ## # WMAT_10_cod &lt;dbl&gt;, WMAT_11_cod &lt;dbl&gt;, WMAT_12_cod &lt;dbl&gt;, ## # WMAT_13_cod &lt;dbl&gt;, WMAT_14_cod &lt;dbl&gt;, WMAT_15_cod &lt;dbl&gt;, ## # WMAT_16_cod &lt;dbl&gt;, WMAT_17_cod &lt;dbl&gt;, WMAT_18_cod &lt;dbl&gt;, ## # WMAT_19_cod &lt;dbl&gt;, WMAT_20_cod &lt;dbl&gt;, WMAT_21_cod &lt;dbl&gt;, ## # WMAT_22_cod &lt;dbl&gt;, WMAT_23_cod &lt;dbl&gt;, WMAT_24_cod &lt;dbl&gt;, ## # WMAT_25_cod &lt;dbl&gt;, WMAT_26_cod &lt;dbl&gt;, bfbs_01_cod &lt;dbl&gt;, ## # bfbs_03_cod &lt;dbl&gt;, bfbs_04_cod &lt;dbl&gt;, bfbs_10_cod &lt;dbl&gt;, ## # bfbs_12_cod &lt;dbl&gt;, bfbs_14_cod &lt;dbl&gt;, bfbs_17_cod &lt;dbl&gt;, ## # bfbs_23_cod &lt;dbl&gt;, lkns_01_cod &lt;dbl&gt;, lkns_02_cod &lt;dbl&gt;, ## # lkns_03_cod &lt;dbl&gt;, lkns_04_cod &lt;dbl&gt;, lkns_05_cod &lt;dbl&gt;, ## # lkns_06_cod &lt;dbl&gt;, lkns_07_cod &lt;dbl&gt;, lkns_08_cod &lt;dbl&gt;, ## # lkns_09_cod &lt;dbl&gt;, lkns_10_cod &lt;dbl&gt;, lkns_11_cod &lt;dbl&gt; 2.2.2.3 Modificar y añadir variables # DF original DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Modificar variable reemplazando valor DF_name %&gt;% mutate(PPV_DECLARED = PPV_DECLARED/100) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 0.99 ## 2 5 95041 2 21 6 90 PPV_Cond1 0.99 ## 3 6 74594 2 29 6 10 PPV_Cond1 0.99 ## 4 15 72903 2 27 7 75 PPV_Cond1 0.01 ## 5 16 21260 1 29 5 35 PPV_Cond1 0.24 ## 6 18 50315 2 28 6 14 PPV_Cond1 0.99 ## 7 19 21774 2 27 4 2 PPV_Cond1 0.99 ## 8 20 20881 2 55 6 89 PPV_Cond1 0.99 ## 9 21 39751 2 28 6 6 PPV_Cond1 0.99 ## 10 22 99384 1 46 5 0 PPV_Cond1 0.01 ## # … with 93 more rows # Añadir variable DF_name %&gt;% mutate(PPV_DECLARED_PCT = PPV_DECLARED/100) ## # A tibble: 103 x 9 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED_PCT &lt;dbl&gt; # Añadir variable destruyendo el resto del DF DF_name %&gt;% transmute(PPV_DECLARED_PCT = PPV_DECLARED/100) ## # A tibble: 103 x 1 ## PPV_DECLARED_PCT ## &lt;dbl&gt; ## 1 0.99 ## 2 0.99 ## 3 0.99 ## 4 0.01 ## 5 0.24 ## 6 0.99 ## 7 0.99 ## 8 0.99 ## 9 0.99 ## 10 0.01 ## # … with 93 more rows # Limpiar nombres if (!require(&quot;janitor&quot;)) install.packages(&quot;janitor&quot;); library(&quot;janitor&quot;) DF_name %&gt;% janitor::clean_names() ## # A tibble: 103 x 8 ## x1 id genero edad educacion follow_up condition ppv_declared ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.2.2.4 Resúmenes agrupados La combinación de verbos group_by() y summarise() es una de las más usadas. Con esta podemos calcular promedios, medianas, etc. por condición de manera sencilla. # Resumen DF_name %&gt;% summarise(Promedio_PPV = mean(PPV_DECLARED), N = n()) ## # A tibble: 1 x 2 ## Promedio_PPV N ## &lt;dbl&gt; &lt;int&gt; ## 1 68.5 103 # Resumen agrupado DF_name %&gt;% group_by(Genero) %&gt;% summarise(Promedio_PPV = mean(PPV_DECLARED), N = n()) ## # A tibble: 2 x 3 ## Genero Promedio_PPV N ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 66.4 40 ## 2 2 69.9 63 # Resumen agrupando por multiples variables, y calculando varias cosas DF_name %&gt;% group_by(Genero, condition) %&gt;% summarise(promedio_PPV = mean(PPV_DECLARED), mediana_PPV = median(PPV_DECLARED), SD = sd(PPV_DECLARED), N = n()) ## # A tibble: 8 x 6 ## # Groups: Genero [2] ## Genero condition promedio_PPV mediana_PPV SD N ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 PPV_Cond1 63.8 88 43.1 9 ## 2 1 PPV_Cond2 51 46 10.3 13 ## 3 1 PPV_Cond3 75.6 80 32.5 5 ## 4 1 PPV_Cond4 80.1 92 19.4 13 ## 5 2 PPV_Cond1 74 99 43.0 19 ## 6 2 PPV_Cond2 49.4 46 16.3 8 ## 7 2 PPV_Cond3 69.2 98.5 38.9 16 ## 8 2 PPV_Cond4 74.7 90 27.3 20 2.2.3 Ejercicios - verbos dplyr Usando la base df_wide, haz las siguientes cosas, una a una: Filtra el DF para quedarnos solo con edades entre 18 y 50 años Ordena los datos por genero y edad, esta última decreciente Selecciona las columnas para quedarnos solo con ID, variables demograficas, y respuestas crudas (raw) Crea una nueva variable que sea niv_edu_porc, en la que calcules cual es el porcentaje de nivel educativo al que han llegado relativo al máximo de la base de datos (nivel educativo persona / nivel educativo maximo; en porcentaje) Ahora combina el resultado de todas las operaciones anteriores en un DF Calcula el promedio y desviación típica de edad para cada género df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) 2.2.4 Verbos avanzados y otras criaturas indómitas 2.2.4.1 Wide to long # Leemos documento en formato WIDE df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) %&gt;% # Seleccionamos solo algunas de las filas select(ID, dem_genero, dem_edad, dem_nivedu, matches(&quot;lkns_[0-9]{2}_raw&quot;)) # Wide to long df_wide %&gt;% gather(Item, Response, lkns_01_raw:lkns_11_raw) ## # A tibble: 2,552 x 6 ## ID dem_genero dem_edad dem_nivedu Item Response ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 lkns_01_raw 500 ## 2 2 0 67 2 lkns_01_raw 0 ## 3 3 0 24 4 lkns_01_raw 700 ## 4 4 0 30 4 lkns_01_raw 500 ## 5 5 0 38 3 lkns_01_raw 6 ## 6 6 0 45 4 lkns_01_raw 40 ## 7 7 1 58 3 lkns_01_raw 0 ## 8 8 1 47 4 lkns_01_raw 500 ## 9 9 1 52 3 lkns_01_raw 600 ## 10 10 1 49 4 lkns_01_raw 600 ## # … with 2,542 more rows df_wide %&gt;% gather(Item, Response, 5:15) ## # A tibble: 2,552 x 6 ## ID dem_genero dem_edad dem_nivedu Item Response ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 lkns_01_raw 500 ## 2 2 0 67 2 lkns_01_raw 0 ## 3 3 0 24 4 lkns_01_raw 700 ## 4 4 0 30 4 lkns_01_raw 500 ## 5 5 0 38 3 lkns_01_raw 6 ## 6 6 0 45 4 lkns_01_raw 40 ## 7 7 1 58 3 lkns_01_raw 0 ## 8 8 1 47 4 lkns_01_raw 500 ## 9 9 1 52 3 lkns_01_raw 600 ## 10 10 1 49 4 lkns_01_raw 600 ## # … with 2,542 more rows df_long = df_wide %&gt;% gather(Item, Response, matches(&quot;lkns&quot;)) DT::datatable(df_long) 2.2.4.2 Long to wide # Long to wide df_long %&gt;% spread(Item, Response) ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;chr&gt;, lkns_07_raw &lt;chr&gt;, ## # lkns_08_raw &lt;chr&gt;, lkns_09_raw &lt;chr&gt;, lkns_10_raw &lt;chr&gt;, ## # lkns_11_raw &lt;chr&gt; 2.2.4.3 Separate, omit, ifelse, case_when, tipos de variables… # Base original name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) # Separate DF_name %&gt;% separate(condition, c(&quot;primer_chunk&quot;, &quot;segundo_chunk&quot;), sep = &quot;_&quot;) ## # A tibble: 103 x 9 ## X1 ID Genero Edad Educacion FollowUP primer_chunk segundo_chunk ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV Cond1 ## 2 5 95041 2 21 6 90 PPV Cond1 ## 3 6 74594 2 29 6 10 PPV Cond1 ## 4 15 72903 2 27 7 75 PPV Cond1 ## 5 16 21260 1 29 5 35 PPV Cond1 ## 6 18 50315 2 28 6 14 PPV Cond1 ## 7 19 21774 2 27 4 2 PPV Cond1 ## 8 20 20881 2 55 6 89 PPV Cond1 ## 9 21 39751 2 28 6 6 PPV Cond1 ## 10 22 99384 1 46 5 0 PPV Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; # Separate in rows DF_name %&gt;% separate_rows(condition, sep = &quot;_&quot;) ## # A tibble: 206 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV 99 ## 2 4 41904 1 47 8 80 Cond1 99 ## 3 5 95041 2 21 6 90 PPV 99 ## 4 5 95041 2 21 6 90 Cond1 99 ## 5 6 74594 2 29 6 10 PPV 99 ## 6 6 74594 2 29 6 10 Cond1 99 ## 7 15 72903 2 27 7 75 PPV 1 ## 8 15 72903 2 27 7 75 Cond1 1 ## 9 16 21260 1 29 5 35 PPV 24 ## 10 16 21260 1 29 5 35 Cond1 24 ## # … with 196 more rows # Drop NAs DF_name %&gt;% drop_na(PPV_DECLARED) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # If else DF_name %&gt;% mutate(Genero = ifelse(Genero == 1, &quot;Hombre&quot;, &quot;Mujer&quot;)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 Hombre 47 8 80 PPV_Cond1 99 ## 2 5 95041 Mujer 21 6 90 PPV_Cond1 99 ## 3 6 74594 Mujer 29 6 10 PPV_Cond1 99 ## 4 15 72903 Mujer 27 7 75 PPV_Cond1 1 ## 5 16 21260 Hombre 29 5 35 PPV_Cond1 24 ## 6 18 50315 Mujer 28 6 14 PPV_Cond1 99 ## 7 19 21774 Mujer 27 4 2 PPV_Cond1 99 ## 8 20 20881 Mujer 55 6 89 PPV_Cond1 99 ## 9 21 39751 Mujer 28 6 6 PPV_Cond1 99 ## 10 22 99384 Hombre 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Case when DF_name %&gt;% mutate(Genero = case_when( Genero == 1 ~ &quot;Hombre&quot;, Genero == 2 ~ &quot;Mujer&quot;, TRUE ~ &quot;Otros&quot;)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 Hombre 47 8 80 PPV_Cond1 99 ## 2 5 95041 Mujer 21 6 90 PPV_Cond1 99 ## 3 6 74594 Mujer 29 6 10 PPV_Cond1 99 ## 4 15 72903 Mujer 27 7 75 PPV_Cond1 1 ## 5 16 21260 Hombre 29 5 35 PPV_Cond1 24 ## 6 18 50315 Mujer 28 6 14 PPV_Cond1 99 ## 7 19 21774 Mujer 27 4 2 PPV_Cond1 99 ## 8 20 20881 Mujer 55 6 89 PPV_Cond1 99 ## 9 21 39751 Mujer 28 6 6 PPV_Cond1 99 ## 10 22 99384 Hombre 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Unite DF_separated = DF_name %&gt;% separate(condition, c(&quot;primer_chunk&quot;, &quot;segundo_chunk&quot;), sep = &quot;_&quot;) DF_separated %&gt;% unite(condition, c(primer_chunk, segundo_chunk), sep = &quot;_&quot;) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Pull DF_name %&gt;% pull(PPV_DECLARED) %&gt;% mean(.) ## [1] 68.52427 2.2.4.4 Regular expressions Basic Regular Expressions Cheatsheet SOURCE: https://xkcd.com/208/ DF_regexp = DF_name %&gt;% select(-X1); DF_regexp ## # A tibble: 103 x 7 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 1 47 8 80 PPV_Cond1 99 ## 2 95041 2 21 6 90 PPV_Cond1 99 ## 3 74594 2 29 6 10 PPV_Cond1 99 ## 4 72903 2 27 7 75 PPV_Cond1 1 ## 5 21260 1 29 5 35 PPV_Cond1 24 ## 6 50315 2 28 6 14 PPV_Cond1 99 ## 7 21774 2 27 4 2 PPV_Cond1 99 ## 8 20881 2 55 6 89 PPV_Cond1 99 ## 9 39751 2 28 6 6 PPV_Cond1 99 ## 10 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Regexp DF_regexp %&gt;% mutate(condition = gsub(&quot;PPV_&quot;, &quot;&quot;, condition)) %&gt;% mutate(condition_N = gsub(&quot;.*([[:digit:]]$)&quot;, &quot;\\\\1&quot;, condition)) ## # A tibble: 103 x 8 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED condition_N ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 41904 1 47 8 80 Cond1 99 1 ## 2 95041 2 21 6 90 Cond1 99 1 ## 3 74594 2 29 6 10 Cond1 99 1 ## 4 72903 2 27 7 75 Cond1 1 1 ## 5 21260 1 29 5 35 Cond1 24 1 ## 6 50315 2 28 6 14 Cond1 99 1 ## 7 21774 2 27 4 2 Cond1 99 1 ## 8 20881 2 55 6 89 Cond1 99 1 ## 9 39751 2 28 6 6 Cond1 99 1 ## 10 99384 1 46 5 0 Cond1 1 1 ## # … with 93 more rows read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) %&gt;% # Seleccionamos solo algunas de las filas select(ID, dem_genero, dem_edad, dem_nivedu, matches(&quot;lkns_[0-9]{2}_raw&quot;)) ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;dbl&gt;, lkns_07_raw &lt;chr&gt;, ## # lkns_08_raw &lt;dbl&gt;, lkns_09_raw &lt;dbl&gt;, lkns_10_raw &lt;dbl&gt;, ## # lkns_11_raw &lt;dbl&gt; Una aplicación Shiny para ayudar a construir Regular Expressions: devtools::install_github(&quot;gadenbuie/regexplain&quot;) regexplain::regex_gadget() 2.2.5 Ejercicios - verbos avanzados dplyr Trabajaremos con los datos procesados del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base final en formato wide (archivo: /outputs/data/sa-prepared.csv). Cambia el orden de las variables para que ID sea la primera columna. Transforma la base a formato long. Crea un nuevo DF (DF_split) donde crees una variable llamada social_adaptation_split con la median split para la variable Social.Adaptation. La mitad superior se llamará high_social_adaptation y la mitad inferior low_social_adaptation. Asegúrate que no hay valores NA. El resultado final debería ser: Ahora volvemos a usar con los datos brutos (sa-raw-anonymised.csv) del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. En estos datos se muestran las puntuaciones crudas (e.g. WMAT_01_raw) y ya codificadas/corregidas (WMAT_01_cod) para los ítems de varias pruebas. Con los datos de los ítems de cada prueba, necesitamos calcular el puntaje para cada participante. Empezaremos con la prueba de Matrices de WAIS (WMAT_). Extrae la suma para cada participante de los ítems WMAT_*_cod. Hay al menos dos estrategias posibles: Selecciona las columnas relevantes y haz la suma de columnas Convierte a long, filtra para quedarte con las filas correspondientes a la prueba relevante, y haz una suma agrupada if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) df_wide_raw = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) 2.3 Combinar bases de datos 2.3.1 Bind # Importar CSVs DF1 = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;, &quot;01.csv&quot;)) DF2 = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;, &quot;02.csv&quot;)) # Bind DFs añadiendo las *filas* de DF2 a DF1 DF1 %&gt;% bind_rows(DF2) ## # A tibble: 800 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 790 more rows # Bind DFs añadiendo las *columnas* de DF2 a DF1 # bind_cols renombra automaticamente los nombres de las columnas para que no haya coincidencias DF1 %&gt;% bind_cols(DF2) ## # A tibble: 400 x 18 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT Sex1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 male Collec… 1 we ofensivo negati… yes left 623 male ## 2 male Collec… 2 we resentido negati… no right 1235 male ## 3 male Collec… 3 we ego�sta negati… yes left 335 male ## 4 male Collec… 4 we indiscre… negati… yes left 355 male ## 5 male Collec… 5 we sumiso negati… yes left 618 male ## 6 male Collec… 6 we agradable positi… yes left 328 male ## 7 male Collec… 7 we clasista negati… yes left 348 male ## 8 male Collec… 8 we altruista positi… yes left 1620 male ## 9 male Collec… 9 we ansioso negati… yes left 346 male ## 10 male Collec… 10 we presumido negati… yes left 778 male ## # … with 390 more rows, and 8 more variables: Priming1 &lt;chr&gt;, ## # trialN1 &lt;dbl&gt;, Block1 &lt;chr&gt;, Adjective1 &lt;chr&gt;, Valence1 &lt;chr&gt;, ## # Answer1 &lt;chr&gt;, Arrow1 &lt;chr&gt;, rT1 &lt;dbl&gt; 2.3.2 Joins El paquete {dplyr} tiene funciones que permiten trabajar combinando, filtrando, etc. distintos dataframes. Podéis ver más detalle y algunas ilustraciones fantásticas (como la de abajo; inner_join()) en el capítulo relational data de r4ds. SOURCE: https://r4ds.had.co.nz/relational-data.html#mutating-joins Tipos de Join Estas operaciones tendrán la forma: DF_x %&gt;% WHATEVER_join(DF_y) Mutating joins: inner_join(): preserva pares de observaciones de de DF_x y de DF_y con claves iguales left_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales right_join(): preserva las observaciones de DF_y, añadiendo las de DF_x con claves iguales full_join(): preserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales Filtering joins: semi_join(): preserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y anti_join(): preserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y Nesting joins: nest_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales 2.3.2.1 Mutating joins Importamos datos Tenemos los siguientes dataframes: DF_IDs: Variables demográficas de participantes DF_results: Resultados en variables de interés de participantes DF_BAD: Grupo de participantes “selectos” # Importar CSVs para los joins DF_IDs = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-IDs.csv&quot;)) DF_results = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-results.csv&quot;)) DF_BAD = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-BAD.csv&quot;)) # DT::datatable(DF_IDs) # DT::datatable(DF_results) # DT::datatable(DF_BAD) # inner_join DF_inner_joined = DF_IDs %&gt;% inner_join(DF_results) #nrow(DF_inner_joined) DT::datatable(DF_inner_joined) # left_join DF_left_joined = DF_IDs %&gt;% left_join(DF_results) #nrow(DF_left_joined) DT::datatable(DF_left_joined) # full_join DF_full_joined = DF_IDs %&gt;% full_join(DF_results) #nrow(DF_full_joined) DT::datatable(DF_full_joined) 2.3.2.2 Filtering joins # anti_join # AVOID the people present in DF_BAD DF_anti_joined = DF_IDs %&gt;% anti_join(DF_BAD, by = &quot;ID&quot;) %&gt;% left_join(DF_results) DT::datatable(DF_anti_joined) # semi_join # INCLUDE ONLY the people present in DF_BAD DF_semi_joined = DF_IDs %&gt;% semi_join(DF_BAD, by = &quot;ID&quot;) %&gt;% left_join(DF_results) DT::datatable(DF_semi_joined) 2.3.2.3 Nesting joins DF_nest_joined = DF_IDs %&gt;% nest_join(DF_results, by = &quot;ID&quot;) DT::datatable(DF_nest_joined) 2.3.3 Ejercicios JOINS Con los DFs de abajo, haz las siguientes operaciones: DF_IDs = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-IDs2.csv&quot;)) DF_results = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-results.csv&quot;)) DF_BAD = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-BAD.csv&quot;)) Une los datos demográficos con los resultados A la base resultante, quítale los sujetos descartados de DF_BAD Crea una nueva base con datos demográficos y resultados para los sujetos descartados Comprueba si el promedio para Crystallized Intelligence de los participantes descartados difiere de la de los no descartados Haz una gráfica donde se puedan ver las diferencias En el ejercicio 3 de verbos avanzados creaste un DF llamado DF_split con la median split a partir de la variable Social.Adaptation. Uno ese DF al DF_long que habías creado en el ejercicio 2 de la misma sección. El DF final se vera así: Haz un plot donde se vea la distribución para todas las variables de resultados de los dos niveles de social_adaptation_split. El plot que vimos en el tema anterior tiene el problema de que los datos de tuberculosis son en números absolutos. Serias capaz de convertir estos a % de la población, como se ve en el plot de abajo? 2.4 Datasets interesantes En los siguientes repositorios podréis encontrar datasets interesantes para jugar. fivethirtyeight Our World in Data TidyTuesday Bibliografía Cheatsheets RStudio Cheatsheet dplyr data-carpentry-week lesson_joins R4ds - Joins "],
["paquetes-usados.html", "Paquetes usados References", " Paquetes usados En la documentación y ejercicios de este workshop se usaron los paquetes que se pueden ver abajo. Este listado se creó automáticamente usando {grateful}: base (R Core Team 2019) renv (Ushey 2019) remotes (Hester et al. 2019) papaja (Aust and Barth 2018) tinytex (Xie 2019) hexbin (Carr et al. 2019) janitor (Firke 2019) gsheet (Conway 2016) writexl (Ooms 2018) readODS (Schutten et al. 2018) haven (Wickham and Miller 2019) readxl (Wickham and Bryan 2019) plotly (Sievert 2018) hrbrthemes (Rudis 2019) ggridges (Wilke 2018) ggthemes (Arnold 2019) gganimate (Pedersen and Robinson 2019) gapminder (Bryan 2017) esquisse (Meyer and Perrier 2018) cowplot (Wilke 2019) forcats (Wickham 2019a) stringr (Wickham 2019b) dplyr (Wickham et al. 2019) purrr (Henry and Wickham 2019) readr (Wickham, Hester, and Francois 2018) tidyr (Wickham and Henry 2019) tibble (Müller and Wickham 2019) ggplot2 (Wickham 2016) tidyverse (Wickham 2017) References "]
]
