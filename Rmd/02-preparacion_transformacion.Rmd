---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Preparación y transformación de datos

En este capítulo vamos a aprender a importar y exportar todo tipo de archivos, ademas de pasar de una base de datos no especialmente amigable, a una base de datos `tidy`, esto es, siguiendo algunas reglas bien sencillas que harán más fácil trabajar con los datos.

---  

#### Paquetes para este capítulo {-}

```{r setup-02}

if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require("DT")) install.packages("DT"); library("DT")
if (!require("googlesheets4")) install.packages("googlesheets4"); library("googlesheets4")
if (!require("haven")) install.packages("haven"); library("haven")
if (!require("here")) install.packages("here"); library("here")
if (!require("janitor")) install.packages("janitor"); library("janitor")
if (!require("purrr")) install.packages("purrr"); library("purrr")
if (!require('readr')) install.packages('readr'); library('readr')
if (!require("readxl")) install.packages("readxl"); library("readxl")
if (!require("readODS")) install.packages("readODS"); library("readODS")
if (!require("tidyr")) install.packages("tidyr"); library("tidyr")
if (!require("waldo")) install.packages("waldo"); library("waldo")
if (!require("writexl")) install.packages("writexl"); library("writexl")

if (!require('regexplain')) remotes::install_github("gadenbuie/regexplain"); library('regexplain')

```  

---  

## Importar y exportar datos

Hasta ahora hemos trabajado con data-frames como `mpg` o `gaminder`, que forman parte de la instalación por defecto de R, o alguno de sus paquetes. Pero habitualmente trabajaremos con datos propios, por lo que necesitaremos leer uno o varios archivos. RStudio tiene un menú para ayudar a importar datos en formatos habituales ![](`r here::here("data", "images", "import'data.png")`), pero aquí aprenderemos a hacerlo todo en código, para que nuestros scripts sean autocontenidos.    

Podemos ver algunas de las funciones de esta sección y cómo usarlas en la [Cheatsheet importar datos](https://github.com/rstudio/cheatsheets/raw/main/data-import.pdf)  


### Importar un solo archivo

Empezaremos por la situación básica más común, cómo importar un solo archivo. Vamos a ver con más detalle los archivos CSV (*comma separated values*). Las funciones para importar archivos excel, Libreoffice, SPSS, etc. tienen parámetros muy similares.    


#### Archivos CSV

Usaremos las siguientes funciones del paquete `readr`:    

###### {.parameters -}    

* `readr::read_csv()`: valores separados por coma (",")  
* `readr::read_csv2()`: valores separados por punto y coma (";")  
* `readr::read_delim( , delim = "|")`: valores separados por un delimitador arbitrario  

###### {-}    

Leemos el archivo `02-read-csv.csv` de la carpeta `data/files/`: 

```{r read-csv-01, eval=FALSE}

DF_name = read_csv("data/files/02-read-csv.csv")

```

Si estamos usando rmarkdown, o similar, es recomendable usar `here::here()` para evitar problemas con los paths a los archivos.  

```{r read-csv-02}
  
name_of_file = here::here("data/files/02-read-csv.csv")
DF_name = read_csv(name_of_file)

DF_name

```

Si usamos un repositorio online para almacenar los archivos, podemos leer directamente de una URL.  

```{r read-csv-URL, eval=FALSE}

URL = "https://raw.githubusercontent.com/gorkang/R_preparacion_visualizacion_datos/master/data/files/02-read-csv.csv"
read_csv(URL)

```


#### Otros tipos de archivos

##### Archivos excel {-}

```{r read-others-xls, eval=FALSE}

name_of_file = here::here("data/files/02-read-xlsx.xlsx")
readxl::read_excel(name_of_file)

```


##### Archivos SPSS {-}

```{r read-others-spss, eval=FALSE}

name_of_file = here::here("data/files/02-read-sav.sav")
haven::read_sav(name_of_file)

```


##### Archivos Libreoffice {-}

```{r read-others-libreoffice, eval=FALSE}

name_of_file = here::here("data/files/02-read-ods.ods")
df_ODS = readODS::read_ods(name_of_file)

# Vemos las primeras filas
head(df_ODS)

```

##### Google sheets {-}

Para poder leer una gsheet debemos: 

1) Crear un enlace para compartirla: `"Share" -> "Get shareable link"`   
2) Extraemos el identificador de la google sheet:  
  + De `https://docs.google.com/spreadsheets/d/1KFmnYnKhPCi3zRJpkZzZii8H-aGSTwr97lonoaz76AY/edit?usp=sharing`  
  + Usaremos: `1KFmnYnKhPCi3zRJpkZzZii8H-aGSTwr97lonoaz76AY`  

```{r google-sheets, eval=FALSE}

if (!require("googlesheets4")) install.packages("googlesheets4"); library("googlesheets4")
name_of_sheet = "1KFmnYnKhPCi3zRJpkZzZii8H-aGSTwr97lonoaz76AY"
googlesheets4::read_sheet(name_of_sheet)   

```



### Ejercicios - Importar datos {.ejercicio -} 


En el repositorio [R para preparación y visualización de datos - DNSC - UAI](https://osf.io/jdn37/) de la Open Science Foundation podrás ver una carpeta llamada `Capitulo 2`. Si no tenéis conexión a internet, podéis encontrar los archivos en `data/files/OSF_files`.  

Importa los archivos que ahí aparecen, asegurándote que los nombres de columna se leen adecuadamente:  
<details><summary>Solucion: ![](data/images/hint.png)</summary><span style="color: orange;">La función `read_excel()` tiene parámetros como `skip`, que permite no leer las primeras n lineas, o `sheet`, con la que puedes indicar que pestaña leer.</span></details>

+ 02-extralines-1.xlsx
+ 02-extralines-2.xlsx
+ 02-extralines-3.xlsx
+ 02-spanish.csv


```{r ejercicios-importar-datos, eval=FALSE, include=FALSE}

  read_excel("data/files/OSF_files/02-extralines-1.xlsx")
  read_excel("data/files/OSF_files/02-extralines-2.xlsx", skip = 2)
  read_excel("data/files/OSF_files/02-extralines-3.xlsx", skip = 2, sheet = 2)
  read_csv2("data/files/OSF_files/02-spanish.csv", skip = 2)

```



### Importar múltiples archivos

En ocasiones tenemos múltiples archivos en una carpeta (e.g. uno por participante) y queremos combinarlos todos en un solo DF.    


Importamos los archivos que están en la carpeta `data/files/02-CSVs`  

```{r importar-multiples-archivos}

# Directorio donde se encuentran los archivos
name_of_folder = here::here("data/files/02-CSVs")

# Listamos los archivos a leer
files <- list.files(name_of_folder, full.names = TRUE)

# Leemos todos los archivos, combinandolos en un dataframe
full <- purrr::map_df(files, read_csv)
full

```


#### Incluir nombres de archivos

Habitualmente será importante saber a que archivo pertenecen los datos que hemos leído.  

Podemos incluir los nombres de archivo en una columna:  

```{r importar-multiples-archivos-nombres}

name_of_folder = here::here("data/files/02-CSVs")

files <- list.files(name_of_folder, full.names = TRUE) %>% 
  # Asignamos nombres a los elementos del vector
  set_names(basename(.))

# Con el parámetro .id, almacenamos los nombres en la columna "file"
full2 <- map_df(files, read_csv, .id = "file")

full2

```


#### Con parametros

Añadimos parámetros a la función de lectura. En este caso, definimos el tipo de columna esperado con la función `col_types()`. Con esto nos aseguraremos que si alguno de los archivos tiene el tipo de datos "incorrecto", aparecerán warnings en la importación:  

```{r importar-multiples-archivos-parametros}

name_of_folder = here::here("data/files/02-CSVs")
files <- list.files(name_of_folder, full.names = TRUE)
full <- map_df(files, read_csv, 
               col_types = cols(
                 Sex = col_factor(),
                 Priming = col_character(),
                 trialN = col_integer(),
                 Block = col_character(),
                 Adjective = col_character(),
                 Valence = col_factor(),
                 Answer = col_character(),
                 Arrow = col_character(),
                 rT = col_double()))

full

```


### Ejercicios - Importar múltiples archivos {.ejercicio -}


1. Cuando más arriba importamos los archivos que están en la carpeta `data/files/02-CSVs`:  

- ¿Qué archivos importamos exáctamente?  
- <details><summary>¿Ves algún problema en lo que hicimos?![](`r here::here("data/images/hint.png")`)</summary><span style="color: orange;">Revisa el número de filas y la variable `files`.</span></details>  

El resultado final debería ser así:  


```{r ejercicios-importar-multiples-1, echo=FALSE}

# Directorio donde se encuentran los archivos
name_of_folder = here::here("data/files/02-CSVs")

# Listamos los archivos a leer
files <- list.files(name_of_folder, pattern = "csv", full.names = TRUE)

# Leemos todos los archivos, combinandolos en un dataframe
full <- map_df(files, read_csv)

full

```


2. Leed los archivos .xlsx de la carpeta `data/files/02-XLSs`, combinándolos en un único DF. El resultado final debería ser como se ve a continuación:  

```{r ejercicios-importar-multiples-2, echo=FALSE}

name_of_folder = here::here("data/files/02-XLSs")

# Listamos los archivos a leer
files <- list.files(name_of_folder, pattern = "xls", full.names = TRUE)
map_df(files, read_xlsx, sheet = 2, skip = 5)

```



### Exportar datos

Muchas veces guardaremos los datos una vez procesados. Esto se puede hacer con la familia de funciones `write_*`.  

#### Archivos CSV

```{r write-csv, eval = FALSE}

# Versión simple
write_csv(DF_name, "data/files/02-write-csv.csv")

# Versión para Rmarkdown
name_of_file = here::here("data/files/02-write-csv.csv")
write_csv(DF_name, name_of_file)


```

#### Otros Archivos

```{r write-otros, eval = FALSE}

name_of_file = here::here("data/files/02-write-xlsx.xlsx")
writexl::write_xlsx(DF_name, name_of_file)

name_of_file = here::here("data/files/02-write-sav.sav")
haven::write_sav(DF_name, name_of_file)

name_of_file = here::here("data/files/02-write-ods.ods")
readODS::write_ods(DF_name, name_of_file)

```



## Preparación y transformación de datos

Para la preparación y transformación de datos usaremos fundamentalmente `dplyr`. Hay otros paquetes [más rápidos](https://h2oai.github.io/db-benchmark/) como `data.table`. Si trabajas con datos gigantescos (millones de filas), sin duda notarás la diferencia. La desventaja es que la sintaxis es (habitualmente) menos intuitiva.      


### Tidy data

Existen tres sencillas reglas que definen la *Tidy data*:

1. Cada variable tiene su columna propia
2. Cada observación tiene su fila propia
3. Cada valor tiene su celda propia
    
    
Las ventajas fundamentales son:

* Uso de una manera consistente de trabajar, que se alinea con el tidyverse  
* Facilidad para trabajar con la lógica vectorizada  

---  

Por ejemplo. De manera muy sencilla y rápida podemos crear una nueva columna realizando algún cómputo arbitrario con los valores de otra columna.  

```{r tidy_vector-1}

# Computa ratio por 100,000
table1 %>% 
  mutate(rate_per_100K = cases / population * 100000)

```

O contar el número de casos por valor de una variable.  

```{r tidy_vector-2}

# Computa casos para cada año
table1 %>% 
  count(year, cases)

# La suma total de casos para cada año
table1 %>% 
  count(year, wt = cases)


```

Y, como no, `ggplot` funciona con datos `tidy`, en formato long.  

```{r tidy_vector-3}

# Visualizar cambios a lo largo del tiempo
ggplot(table1, aes(as.factor(year), cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))

```

    
### Verbos dplyr

Usaremos [{dplyr}](https://dplyr.tidyverse.org/), un paquete muy potente para la manipulación de datos. Su sintaxis, además, es bastante intuitiva (¡son verbos en inglés!).   

Usando pipes **%>%** (CONTROL + SHIFT + M) podemos enlazar operaciones de transformación de datos de manera muy sencilla (una vez nos aprendamos los verbos).  

Podemos ver más detalle y ejemplos en la [Cheatsheet de dplyr](https://github.com/rstudio/cheatsheets/raw/main/data-transformation.pdf).   

**Verbos esenciales**:  

###### {.parameters -}    

* filter(): filtrar filas  
* arrange(): ordenar filas  
* select(): seleccionar columnas  
* rename(): renombrar columnas  
* mutate(): crear columnas, modificar columnas, etc.   



#### Tabla resumen dplyr {-}  

```{r tabla-dp, echo=FALSE}

DT::datatable(data.frame(
  tarea = c("Filtrar", "Ordenar", "Seleccionar/eliminar variables", "Renombrar variables", "Separar contenidos de variable", 
            "Extraer valores únicos", "Crear/modificar variables", "Omitir NAs", "Wide to long", "Long to wide", "Combinar bases de datos", "Recodificar valores", "Recodificar valores"),
  funcion = c("filter()", "arrange()", "select()", "rename()", "separate()", "distinct()", "mutate()", "drop_na()", "pivot_longer()", "pivot_wider()", "left_join()", "ifelse()", "case_when()"),
  ejemplo = c("datos %>% filter(Sexo == 1)", "datos %>% arrange(Sexo)", "datos %>% select(-Sexo)", "datos %>% rename(Genero = Sexo)", 
              "datos %>% separate(var_name, c('First', 'Second'), sep = '_')", "datos %>% distinct(Edad, .keep_all = T)", "datos %>% mutate(Viejo = Edad > 30)", 
              "datos %>% drop_na(Sexo)", "datos %>% pivot_longer(4:6, names_to = 'Condition', values_to = 'VD')", "datos %>% pivot_wider(names_from = Condition, values_from = VD)", "left_join(datos1, datos2, by = 'ID')", 
              "datos %>%  mutate(Edad = ifelse(Edad > 30, 'Viejo', 'Joven'))", "datos %>%  mutate(Edad = case_when(.$Edad > 30 ~ 'Viejo', 'Joven')")))

```

#### Filtrar y ordenar filas

```{r filtrando-ordenando}

# DF original
name_of_file = here::here("data/files/02-read-csv.csv")
DF_name = read_csv(name_of_file)
DF_name

# Filtrar
DF_name %>% 
  filter(Educacion > 8)

# Ordenar
DF_name %>% 
  arrange(Educacion, desc(Genero))

```

#### Seleccionar, ordenar y renombrar columnas

```{r seleccionando-ordenando-columnas}

# Seleccionar columnas
DF_name %>% 
  select(Genero, Edad)

# Eliminar columnas  
DF_name %>% 
  select(-...1)

# Ordenar y eliminar columnas
DF_name %>% 
  select(ID, Edad, Genero, everything(), -...1) 

```


```{r renombrando}

# Renombrar columnas
DF_name %>% 
  rename(Identificador = ID,
         Sexo = Genero)

# Renombrar usando la posicion (DANGER!)
DF_name %>% 
  rename(Identificador = 2)

# Renombrar usando vectores
oldnames = c("ID","Genero")
newnames = c("Identificador","Sexo")
DF_name %>% rename_at(all_of(oldnames), ~ newnames)

```


##### Ejercicios - verbos dplyr simples {.ejercicio -} 

- Cuenta los registros por año en el dataframe `mpg`  
- Filtra los datos para quedarnos solo con los del año 1999
- Renombra la variable displ para que se llame "engine displacement"
  + Si aparece el error `Error: unexpected symbol in ...`, puedes ver la ayuda de la función ?make.names, o [este post](https://stackoverflow.com/questions/22842232/dplyr-nonstandard-column-names-white-space-punctuation-starts-with-numbers)
- Ordena por consumo en ciudad `cty` y clase de vehículo `class`
- Crea un data-frame que no contenga la variable `model`


<details><summary>Soluciones: ![](data/images/hint.png)</summary><span style="color: orange;">
- `mpg %>% count(year)`  
- `mpg %>% filter(year == 1999)`  
- `mpg %>% rename(engine displacement = displ)` #ERROR  
- `mpg %>% rename(engine_displacement = displ)` #SOLUCION1  
- `mpg %>% rename(`engine displacement` = displ)`#SOLUCION2  
- `mpg %>% arrange(cty, class)`  
- `mpg %>% select(-model)`

</span></details>  

```{r verbos-simples-ej, eval=FALSE, include=FALSE}
mpg %>% count(year)

mpg %>% filter(year == 1999)

mpg %>% rename(engine displacement = displ) # ERROR
mpg %>% rename(engine_displacement = displ) # Solucion 1
mpg %>% rename(`engine displacement` = displ) # solucion 2

mpg %>% arrange(cty, class)

mpg %>% select(-model)


```


#### Selección avanzada con select_helpers()  

El `everything()` que usamos dentro de `select()` más arriba es uno de los `select_helpers()` existentes. Estos nos ayudan a realizar operaciones de selección de variables sin necesidad de escribir a mano todas las variables.  

###### select_helpers() {.parameters -}   

* starts_with(): Empieza con un prefijo (e.g. starts_with("CI_"))  
* ends_with(): Acaba con un sufijo  
* contains(): Contiene una cadena de texto específica  
* matches(): Matches a regular expression   
* num_range(): Matches a numerical range like x01, x02, x03  
* one_of(): Matches variable names in a character vector  
* everything(): Matches all variables  
* last_col(): Select last variable  


###### {-}  


Trabajaremos con los datos del paper [Cognitive and Socio-affective Predictors of Social Adaptation](https://osf.io/egxy5/), de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base RAW en formato wide.    

```{r seleccion-avanzada}

  # DF original  
  df_wide = read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv")  
  cat(names(df_wide))

  # Seleccionamos variables que contienen la cadena de texto "dem"
  df_wide %>% 
    select(contains("dem"))

  # Seleccionamos variables que acacan con la cadena de texto "cod"
  df_wide %>% 
    select(ID, ends_with("cod"))

  # Lo mismo, pero usando expresiones regulares
  df_wide %>% 
    select(ID, matches("cod$")) # $: fin de la cadena de texto
  
```


#### Modificar y añadir variables


```{r modificar-anadir-variables}

# DF original
DF_name

# Modificar variable reemplazando valor
DF_name %>% 
  mutate(PPV_DECLARED = PPV_DECLARED/100)
  
# Añadir variable
DF_name %>% 
  mutate(PPV_DECLARED_PCT = PPV_DECLARED/100)

# Añadir variable destruyendo el resto del DF
DF_name %>% 
  transmute(PPV_DECLARED_PCT = PPV_DECLARED/100)

# Limpiar nombres con el paquete {janitor}
DF_name %>% 
  janitor::clean_names()

```


#### Resúmenes agrupados

La combinación de verbos `group_by()` y `summarise()` es una de las más usadas. Con esta podemos calcular promedios, medianas, etc. por condición de manera sencilla.  

```{r resumenes-agrupados}

# Resumen
DF_name %>% 
  summarise(Promedio_PPV = mean(PPV_DECLARED), 
            N = n())

# Resumen agrupado
DF_name %>% 
  group_by(Genero) %>% 
  summarise(Promedio_PPV = mean(PPV_DECLARED), 
            N = n())

# Resumen agrupando por multiples variables, y calculando varias cosas  
DF_name %>% 
  group_by(Genero, condition) %>% 
  summarise(promedio_PPV = mean(PPV_DECLARED),
            mediana_PPV = median(PPV_DECLARED),
            SD = sd(PPV_DECLARED),
            N = n())

```


### Ejercicios - verbos dplyr {.ejercicio -} 


1. Usando la base df_wide, haz las siguientes cosas, una a una:  

* Importa los datos (ver código abajo)
* Filtra el DF para quedarnos solo con edades entre 18 y 50 años  
* Ordena los datos por genero y edad, esta última decreciente  
* Selecciona las columnas para quedarnos solo con ID, variables demograficas, y respuestas crudas (raw)  
* Crea una nueva variable que sea niv_edu_porc, en la que calcules cual es el porcentaje de nivel educativo al que han llegado relativo al máximo de la base de datos (nivel educativo persona / nivel educativo maximo; en porcentaje)  

2. Ahora combina el resultado de todas las operaciones anteriores en un DF  

3. Calcula el promedio y desviación típica de edad para cada género  

---  


```{r ejercicios-dplyr-1}

  df_wide = read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv")  


```

```{r ejercicios-dplyr-soluciones, eval=FALSE, include=FALSE}

# 1. Usando la base df_wide, haz las siguientes cosas, una a una:  
# 
# * Filtra el DF para quedarnos solo con edades entre 18 y 50 años  
# * Ordena los datos por genero y edad, esta última decreciente  
# * Selecciona las columnas para quedarnos solo con ID, variables demograficas, y respuestas crudas (raw)  
# * Crea una nueva variable que sea niv_edu_porc, en la que calcules cual es el porcentaje de nivel educativo al que han llegado relativo al máximo de la base de datos (nivel educativo persona / nivel educativo maximo; en porcentaje)  
  
  df_wide %>% 
    filter(dem_edad >= 18 & dem_edad <= 50)
  
  df_wide %>% 
    arrange(dem_genero, desc(dem_edad))
  
  df_wide %>% 
    select(ID, contains("dem_"), contains("raw"))
  
  df_wide %>% 
    mutate(niv_edu_porc = dem_nivedu / max(dem_nivedu) * 100)


# 2. Ahora combina el resultado de todas las operaciones anteriores en un DF  

  
  df_final = df_wide %>% 
    filter(dem_edad >= 18 & dem_edad <= 50) %>%
    arrange(dem_genero, desc(dem_edad)) %>%
    select(ID, contains("dem_"), contains("raw")) %>%
    mutate(niv_edu_porc = dem_nivedu / max(dem_nivedu) * 100)


# 3. Calcula el promedio y desviación típica de edad para cada género  
  
  df_final %>%
    group_by(dem_genero) %>%
    summarize(edad_media = mean(dem_edad), SD = sd(dem_edad))

```



### Verbos avanzados y otras criaturas indómitas


#### Wide to long

Empecemos con un ejemplo muy sencillo. 3 participantes, 2 items.  

```{r wide-to-long}

# Creamos un DF
df_simple_wide = data.frame(ID = c("Participante1", "Participante2", "Participante3"),
           Item1 = c(22, 33, 44),
           Item2 = c(88, 99, 77))

df_simple_wide

# Wide to long
df_simple_long = df_simple_wide %>% 
  pivot_longer(Item1:Item2, names_to = "Item", values_to = "Response")
  

df_simple_long

```


Ahora pasemos a un ejemplo mas complejo. Tenemos las puntuaciones a los 11 items de la lipkus numeracy scale de 232 participantes, ademas de datos demográficos.  


```{r wide-to-long2}

# Leemos documento en formato WIDE
df_wide = read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv") %>% 
  # Seleccionamos solo algunas de las filas
  select(ID, dem_genero, dem_edad, dem_nivedu, matches("lkns_[0-9]{2}_raw"))

df_wide  


# Wide to long
df_wide %>% 
  pivot_longer(cols = lkns_01_raw:lkns_11_raw, names_to = "Item", values_to = "Response", values_transform = list(Response = as.character))

df_wide %>% 
  pivot_longer(5:15, names_to = "Item", values_to = "Response", values_transform = list(Response = as.character))
  
df_long = df_wide %>% 
  pivot_longer(matches("lkns"), names_to = "Item", values_to = "Response", values_transform = list(Response = as.character))


DT::datatable(df_long)

```


#### Long to wide

Retomamos el ejemplo simple de antes:  

```{r long-to-wide}

# Long to wide simple
df_simple_long %>% 
  pivot_wider(names_from = Item, values_from = Response)

```

Y lo mismo con el ejemplo mas complejo:  

```{r long-to-wide-2}

# Long to wide
df_long %>%  
  pivot_wider(names_from = Item, values_from = Response)

```


##### ¿Para que sirve tener los datos en formato long?  

```{r long-wide-plots}

DF_plot = df_long %>% 
  mutate(Response_num = as.numeric(Response))

DF_plot %>% 
  drop_na(Response_num) %>% 
  ggplot(aes(Item, Response_num, color = Item)) +
  geom_jitter(alpha = .5) +
  geom_violin(alpha = .4) +
  scale_y_log10() +
  coord_flip()
  
DF_plot %>% 
  filter(is.na(Response_num)) %>% 
  ggplot(aes(Item, Response, color = Item)) +
  geom_jitter(alpha = .5, height = .2) +
  facet_wrap(~ Item, scales = "free")

```


### Ejercicios - wide to long {.ejercicio -} 

Trabajaremos con los datos *procesados* del paper [Cognitive and Socio-affective Predictors of Social Adaptation](https://osf.io/egxy5/), de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base final en formato wide (Dentro de https://osf.io/egxy5/, ver archivo: `/outputs/data/sa-prepared.csv`).  

1. Cambia el orden de las variables para que ID sea la primera columna.  

2. Transforma la base a formato long (eso sí, mantén las variables demográficas en formato wide).  

3. Aprovechando que tenemos la base en formato long, sabrías hacer una gráfica con un histograma o densidad para cada una de las variables no deográficas?    

<details><summary>Pista: ![](data/images/hint.png)</summary><span style="color: orange;">Tendras que usar la función `select()` y el select helper `everything()` para el primer paso.  Para el segundo paso, `pivot_longer(primera_variable:ultima_variable)`  Para el tercer paso, `facet_wrap(~name, scales = "free") te ayudara a crear paneles para cada nombre, donde las escalas x/y pueden variar libremente.`</span></details>

---  

Importamos datos, y limpiamos nombres de variables:  
```{r ejercicios-dplyr-avanzado-1-2-import, echo=TRUE}

DF_wide = read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv") %>% 
  janitor::clean_names()

```

```{r ejercicios-dplyr-avanzado-1-2, include=FALSE}

DF_wide = read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv") %>% 
  janitor::clean_names()
  # mutate(anxious_attachment = round(anxious_attachment, 2))


  # 1. Cambia el orden de las variables para que ID sea la primera columna.  
    DF_wide = DF_wide %>% select(id, everything())
  
  
  # 2. Transforma la base a formato long (eso sí, mantén las variables demográficas en formato wide).   
    DF_long = DF_wide %>% pivot_longer(fluid_intelligence:working_memory)
    
  
    # 3. Aprovechando que tenemos la base en formato long, sabrías hacer una gráfica con un histograma o densidad para cada una de las variables no deográficas?    
    DF_long %>% 
      ggplot(aes(value)) +
      geom_density() + 
      facet_wrap(~name, scales = "free")
    
```



### Separate, omit, ifelse, case_when, tipos de variables...

Para transformaciones algo más complejas, pero muy habituales, usaremos algunos verbos del paquete {tidyr}, y variaciones con {dplyr}  

```{r separate-omit-ifelse-casewhen}

# Base original
name_of_file = here::here("data/files/02-read-csv.csv")
DF_name = read_csv(name_of_file)

# Separate
DF_name %>% 
  separate(condition, c("primer_chunk", "segundo_chunk"), sep = "_")

# Separate in rows
DF_name %>% 
  separate_rows(condition, sep = "_")

# Drop NAs
DF_name %>%
  drop_na(PPV_DECLARED)

# Para re-etiquetar, cambiar valores condicionalmente, etc.
## If else
DF_name %>%
  mutate(Genero = ifelse(Genero == 1, "Hombre", "Mujer"))

## Case when
### las condiciones lógicas pueden ser arbitrariamente complejas
DF_name %>%
  mutate(Genero = 
           case_when(
             Genero == 1 ~ "Hombre",
             Genero == 2 ~ "Mujer",
             TRUE ~ "Otros")
         )



# Unite: inversa de separate
DF_separated = DF_name %>% 
  separate(condition, c("primer_chunk", "segundo_chunk"), sep = "_")

DF_separated %>% 
  unite(condition, c(primer_chunk, segundo_chunk), sep = "_")


# Pull
DF_name %>% pull(PPV_DECLARED) %>% mean(.)

```


### Ejercicios - verbos avanzados dplyr {.ejercicio -} 

1. Importa los datos y limpia los nombres de columna:  

```{r ejercicios-dplyr-avanzado-import}

# Leemos los datos y usamos janitor::clean_names() para limpiar los nombres de las columnas
 DF_wide = 
  read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv") %>% 
  janitor::clean_names()

```

2. En un nuevo DF (`DF_split`), crea una variable llamada `social_adaptation_split` con la median split para la variable social_adaptation. La mitad superior se llamará `high_social_adaptation` y la mitad inferior `low_social_adaptation`.

3. Asegúrate que no hay valores NA.  

<details><summary>Pista: ![](data/images/hint.png)</summary><span style="color: orange;">Necesitarás extraer la mediana a una variable a parte, y después usar `case_when()` para crear la nueva variable `social_adaptation_split`. La función `drop_na()` será necesaria para el paso 3.</span></details>

---  

El resultado final debería ser:    

```{r ejercicios-dplyr-avanzado-3, echo=FALSE}

  DF_wide = read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv") %>% 
  janitor::clean_names()

    median_social_adaptation = DF_wide %>% pull(social_adaptation) %>% median(., na.rm = TRUE)

    DF_split = DF_wide %>% 
      mutate(social_adaptation_split = 
               as.factor(
                 case_when(
                   social_adaptation >= median_social_adaptation ~ "high_social_adaptation",
                   social_adaptation < median_social_adaptation ~ "low_social_adaptation",
                   TRUE ~ NA_character_))) %>% 
      select(id, social_adaptation, social_adaptation_split) %>% 
      drop_na(social_adaptation_split)

    DT::datatable(DF_split)
    
    # DF_split %>% summary(.)
  
```


### Regular expressions

[Basic Regular Expressions Cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/regex.pdf). [Introduction to Regular Expressions](https://tobyhodges.gitbooks.io/introduction-to-regular-expressions/content/).  

![SOURCE: https://xkcd.com/208/](`r here::here("data/images/regular_expressions.png")`)


Usando este data-frame:  

```{r regular-expressions}
DF_regexp = DF_name %>% select(-...1); DF_regexp
```


Podemos usar la función `gsub()` para eliminar partes de una cadena de texto, o para extraer un número:  
```{r regular-expressions-1}

DF_regexp %>% 
  mutate(condition = gsub("PPV_", "", condition)) %>%  # Buscamos PPV_ y lo reemplazamos por nada (lo eliminamos!)
  mutate(condition_N = gsub(".*([[:digit:]]$)", "\\1", condition)) # Busca cualquier dígito al final de la cadena de texto y elimina el resto

```

Con `select()` y `matches()` seleccionamos columnas usando la siguiente regular expression `lkns_[0-9]{2}_raw`:

- `lkns_` contiene esta cadena de texto  
- `[0-9]{2}` a continuación, contiene cualquier dígito del 0 al 9, dos veces.
- `_raw`a continuación, contiene esta cadena de texto  

```{r regular-expressions-2}

read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv") %>% 
  # Seleccionamos solo algunas de las filas
  select(ID, dem_genero, dem_edad, dem_nivedu, matches("lkns_[0-9]{2}_raw"))

```

Una aplicación Shiny para ayudar a construir Regular Expressions:  

```{r regular-expressions-gadget, eval=FALSE}

regexplain::regexplain_gadget()

```


### Ejercicios - Calcular puntajes de escalas usando regular expressions {.ejercicio -} 

Ahora volvemos a usar con los datos brutos (`sa-raw-anonymised.csv`) del paper [Cognitive and Socio-affective Predictors of Social Adaptation](https://osf.io/egxy5/), de Neely et al.      

En estos datos tenemos las puntuaciones crudas (e.g. WMAT_01_raw) y ya codificadas/corregidas (WMAT_01_cod) para los ítems de varias escalas Para preparar los datos de cara al análisis final, necesitamos calcular el puntaje para cada participante y escala. Empezaremos con la prueba de Matrices de WAIS (`WMAT_`). 

1. **Extrae la suma para cada participante de los ítems WMAT_[NUMEROS]_cod**  
  
  Hay al menos dos estrategias posibles:
  
  A) Selecciona las columnas relevantes y haz la suma de columnas  
  
  B) Convierte a long, filtra para quedarte con las filas correspondientes a la prueba relevante, y haz una suma agrupada  

<details><summary>Pista para seleccionar o filtrar columnas: ![](data/images/hint.png)</summary><span style="color: orange;">Recuerda que usamos `select()` para seleccionar columnas, o `filter()` para filtrar.</span></details>

<details><summary>Pista para seleccionar columnas: ![](data/images/hint.png)</summary><span style="color: orange;">Podemos usar `matches("WMAT_[0-9]{2}_cod")` para seleccionar o filtrar todas las columnas o ítems que contienen: `WMAT_`, 2 numeros del 0 al 9, y acaban en `_cod`.</span></details>

<details><summary>Pista para suma de columnas: ![](data/images/hint.png)</summary><span style="color: orange;">`rowSums()` es la función que podemos usar, pero su sintaxis es algo complicada.</span></details>

<details><summary>Pista para suma agrupada: ![](data/images/hint.png)</summary><span style="color: orange;">Usamos `group_by() %>% summarise()` poniendo parámetros dentro de cada función.</span></details>
  
---  

Importar datos:  

```{r ejercicios-dplyr-avanzado-4datos}

df_wide_raw = read_csv("https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv")

```


```{r ejercicios-dplyr-avanzado-4solucion, eval=FALSE, include=FALSE}

# Estrategia A - wide
DF_A = 
  df_wide_raw %>% 
  select(ID, matches("WMAT_[0-9]{2}_cod")) %>% 
  transmute(ID = ID,
            WMAT_sum = rowSums(.[,2:27]))


# Estrategia A2 - wide con intervalos entre nombres de variables
DF_A2 = 
  df_wide_raw %>% 
  # select(ID, matches("WMAT_[0-9]{2}_cod")) %>% # si no usamos esta linea, se suman también las WMAT_[09]_raw
  mutate(WMAT_sum = rowSums(.[,which(names(.) == "WMAT_01_cod"):which(names(.) == "WMAT_26_cod")])) %>% 
  select(ID, WMAT_sum)

# Estrategia B - long
DF_B = 
  df_wide_raw %>% 
  select(ID, matches("WMAT_[0-9]{2}_cod")) %>% 
  pivot_longer(starts_with("WMAT")) %>% 
  group_by(ID) %>% 
  summarise(WMAT_sum = sum(value, na.rm = FALSE))


# Estrategia C - long
DF_C = 
  df_wide_raw %>% 
  pivot_longer(WVOC_01_cod:bayes_text_quantitative_accuracy, 
               values_transform = list(value = as.character)) %>% 
  filter(grepl("WMAT_[0-9]{2}_cod", name)) %>% 
  mutate(value = as.numeric(value)) %>%  
  group_by(ID) %>% 
  summarise(WMAT_sum = sum(value, na.rm = FALSE))
   



# Todas las versiones dan resultados identicos
 waldo::compare(DF_A, DF_B)
 waldo::compare(DF_A, DF_C)
 waldo::compare(DF_B, DF_C)

 # Diferente si no se pre-seleccionan las variables "_cod" 
 waldo::compare(DF_A, DF_A2)

```


## Combinar datos


### Bind rows or columns

El método más sencillo. Simplemente unimos las filas o columnas de los data-frames.  

```{r bind}

# Importar CSVs
DF1 = read_csv(here::here("data/files/02-CSVs/01.csv"))
DF2 = read_csv(here::here("data/files/02-CSVs/02.csv"))


# Bind DFs añadiendo las *filas* de DF2 a DF1
DF1 %>% 
   bind_rows(DF2)


# Bind DFs añadiendo las *columnas* de DF2 a DF1
  ## bind_cols renombra automaticamente los nombres de las columnas para que no haya coincidencias
DF1 %>% 
  bind_cols(DF2) 

```

### Joins

El paquete {dplyr} tiene funciones que permiten trabajar combinando, filtrando, etc. distintos dataframes. Podéis ver más detalle y algunas ilustraciones fantásticas (como la de abajo; **inner_join()**) en el capítulo [relational data de r4ds](https://r4ds.had.co.nz/relational-data.html).

![SOURCE: https://r4ds.had.co.nz/relational-data.html#mutating-joins](`r here::here("data/images/join-inner.png")`)  

En [https://github.com/gadenbuie/tidyexplain](https://github.com/gadenbuie/tidyexplain) se pueden ver animaciones mostrando estas operaciones.  

---  


#### Tipos de Join {.parameters -}  

Estas operaciones tendrán la forma: `DF_x %>% WHATEVER_join(DF_y)`  


* **Mutating joins**:  
    + inner_join(): preserva pares de observaciones de `DF_x` y de `DF_y` con claves iguales   
    + left_join(): preserva las observaciones de `DF_x`, añadiendo las de `DF_y` con claves iguales    
    + right_join(): preserva las observaciones de `DF_y`, añadiendo las de `DF_x` con claves iguales  
    + full_join(): preserva todas las observaciones de `DF_x` y `DF_y`, alineándolas cuando tengan claves iguales  
    
* **Filtering joins**:  
    + semi_join(): preserva solo aquellas observaciones de `DF_x` cuyas claves aparezcan en `DF_y`   
    + anti_join(): preserva solo aquellas observaciones de `DF_x` cuyas claves NO aparezcan en `DF_y`  

* **Nesting joins**:  
    + nest_join(): preserva las observaciones de `DF_x`, añadiendo las de `DF_y` con claves iguales  


#### Mutating joins  


**Importamos datos**

Tenemos los siguientes dataframes:  

* DF_IDs: Variables demográficas de participantes  
* DF_results: Resultados en variables de interés de participantes    
* DF_BAD: Grupo de participantes "selectos"  


```{r joins-data}

# Importar CSVs para los joins  
DF_IDs = read_csv(here::here("data/files/02-join-IDs.csv"))
DF_results = read_csv(here::here("data/files/02-join-results.csv"))
DF_BAD = read_csv(here::here("data/files/02-join-BAD.csv"))

```


##### Inner join  

Preserva pares de observaciones de `DF_x` y de `DF_y` con claves iguales.   

![SOURCE: https://github.com/gadenbuie/tidyexplain](`r here::here("data/images/inner-join.gif")`)

```{r inner-join}

DF_inner_joined = 
  DF_IDs %>% 
  inner_join(DF_results)

#nrow(DF_inner_joined)

DT::datatable(DF_inner_joined)

```


##### Left join  

Preserva las observaciones de `DF_x`, añadiendo las de `DF_y` con claves iguales.  

![SOURCE: https://github.com/gadenbuie/tidyexplain](`r here::here("data/images/left-join.gif")`)

```{r left-join}

DF_left_joined = DF_IDs %>% 
   left_join(DF_results)

# nrow(DF_left_joined)
# map(list("DF_left_joined" = DF_left_joined, "DF_IDs" = DF_IDs, "DF_results" = DF_results), nrow)

DT::datatable(DF_left_joined)
```


##### Full join  

Preserva todas las observaciones de `DF_x` y `DF_y`, alineándolas cuando tengan claves iguales.  

![SOURCE: https://github.com/gadenbuie/tidyexplain](`r here::here("data/images/full-join.gif")`)

```{r full-join}

DF_full_joined = DF_IDs %>% 
   full_join(DF_results)

# CHECK
# map(list("DF_full_joined" = DF_full_joined, "DF_IDs" = DF_IDs, "DF_results" = DF_results), nrow)

DT::datatable(DF_full_joined)

```


#### Filtering joins  

##### Anti join  

Preserva solo aquellas observaciones de `DF_x` cuyas claves NO aparezcan en `DF_y`.  

![SOURCE: https://github.com/gadenbuie/tidyexplain](`r here::here("data/images/anti-join.gif")`)

```{r anti-join}

# AVOID the people present in DF_BAD
DF_anti_joined = DF_IDs %>% 
  anti_join(DF_BAD, by = "ID") %>% 
  left_join(DF_results)

# CHECK
# map(list("DF_anti_joined" = DF_anti_joined, "DF_IDs" = DF_IDs, "DF_BAD" = DF_BAD, "DF_results" = DF_results), nrow)


DT::datatable(DF_anti_joined)
```


##### Semi join  

Preserva solo aquellas observaciones de `DF_x` cuyas claves aparezcan en `DF_y`.  

![SOURCE: https://github.com/gadenbuie/tidyexplain](`r here::here("data/images/semi-join.gif")`)

```{r semi-join}

# INCLUDE ONLY the people present in DF_BAD
DF_semi_joined = DF_IDs %>% 
  semi_join(DF_BAD, by = "ID") %>% 
  left_join(DF_results)

# CHECK
# map(list("DF_semi_joined" = DF_semi_joined, "DF_IDs" = DF_IDs, "DF_BAD" = DF_BAD, "DF_results" = DF_results), nrow)

DT::datatable(DF_semi_joined)

```


#### Nesting joins  


```{r joins-nesting}

DF_nest_joined = DF_IDs %>% 
  nest_join(DF_results, by = "ID")

DT::datatable(DF_nest_joined)

```


### Ejercicios JOINS {.ejercicio -}

Con los DFs de abajo, haz las siguientes operaciones:

```{r ejercicios-joins-dfs}

DF_IDs = read_csv(here::here("data/files/02-join-IDs2.csv"))
DF_results = read_csv(here::here("data/files/02-join-results.csv"))
DF_BAD = read_csv(here::here("data/files/02-join-BAD.csv"))

```


1. Une los datos demográficos con los resultados  

2. A la base resultante, quítale los sujetos descartados de `DF_BAD`  

3. Crea una nueva base con datos demográficos y resultados para los sujetos descartados  

4. Comprueba si el promedio para `Crystallized Intelligence` de los participantes descartados difiere de la de los no descartados  

5. Haz una gráfica donde se puedan ver las diferencias  


```{r ejercicios-joins-responses, eval=FALSE, include=FALSE}
# 1. Une los datos demográficos con los resultados  

  # Solucion 1  
  DF_joined = DF_IDs %>% 
    left_join(DF_results, by = c("Identificador" = "ID"))
  
  # Solucion 2
  DF_joined2 = DF_IDs %>% 
    rename(ID = Identificador) %>% 
    left_join(DF_results, by = "ID")
  
  # Comprobamos que son iguales
  waldo::compare(DF_joined, DF_joined2)

  
  
# 2. A la base resultante, quítale los sujetos descartados de `DF_BAD`  

  DF_joined_clean = DF_joined2 %>% 
    anti_join(DF_BAD, by = "ID")
  
  

# 3. Crea una nueva base con datos demográficos y resultados para los sujetos descartados  

  # Solucion 1
  DF_joined_discarded = DF_IDs %>% 
    rename(ID = Identificador) %>% 
    left_join(DF_results, by = "ID") %>% 
    semi_join(DF_BAD, by = "ID")

  # Solucion 2
  DF_joined_discarded2 = DF_BAD %>% 
    left_join(DF_results, by = "ID")
  
  # Comprobamos que son iguales
  waldo::compare(DF_joined_discarded, DF_joined_discarded2)

  
  
# 4. Comprueba si el promedio para `Crystallized Intelligence` de los participantes descartados difiere de la de los no descartados  
  
  # Solucion basica
  DF_joined_clean %>% 
    summarise(mean_CI = mean(`Crystallized Intelligence`, na.rm = TRUE))

  DF_joined_discarded %>% 
      summarise(mean_CI = mean(`Crystallized Intelligence`, na.rm = TRUE))
  
  # Solucion avanzada
  DF_all = DF_joined_clean %>% mutate(type = "clean") %>% 
    bind_rows(DF_joined_discarded %>% mutate(type = "discarded")) 
  
  DF_all %>% 
    group_by(type) %>% 
    summarise(mean_CI = mean(`Crystallized Intelligence`, na.rm = TRUE))
  

  
# 5. Haz una gráfica donde se puedan ver las diferencias  
  
  DF_all %>% 
    ggplot(aes(type, `Crystallized Intelligence`, color = type)) +
    geom_jitter(width = .2, height = 0) +
    stat_summary(fun = mean,
                 geom = "point",
                 size = 3, 
                 color = "black",
                 alpha = .5)
    
```

---  

6. En el ejercicio 3 de verbos avanzados creaste un DF llamado `DF_split` con la median split a partir de la variable `Social.Adaptation`. Uno ese DF al `DF_long` que habías creado en el ejercicio 2 de la misma sección. El DF final se vera así: 

```{r ejercicios-joins-responses-5, echo=FALSE}

    DF_final = DF_long %>% 
      right_join(DF_split, by = "id")
  
    DT::datatable(DF_final)
    
```

7. Haz un plot donde se vea la distribución para todas las variables de resultados de los dos niveles de `social_adaptation_split`.

```{r ejercicios-joins-responses-6, echo=FALSE}
    
  DF_final %>% 
    ggplot(aes(value, color = social_adaptation_split, fill = social_adaptation_split)) +
    geom_density(alpha = .2) +
    theme(legend.position = "bottom") +
    facet_wrap(~ name, scales = "free", nrow = 3)

  DF_final %>%
    ggplot(aes(value, name, color = social_adaptation_split, fill = social_adaptation_split)) +
    ggridges::geom_density_ridges(alpha = .2) +
    theme(legend.position = "bottom")

```

---  

8. El plot que vimos en el tema anterior tiene el problema de que los datos de tuberculosis son en números absolutos.  Serias capaz de convertir estos a % de la población, como se ve en el plot de abajo?  

```{r ejercicios-joins-responses-7, echo=FALSE, fig.height=12, fig.width=8}

df_plot = table1 %>% 
  mutate(relative = cases/population)


plot1 = ggplot(table1, aes(as.factor(year), cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country), size = 2) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Casos de Tuberculosis por año",
       x = "year",
       caption = "SOURCE: http://www.who.int/tb/country/data/download/en/") +
  theme(legend.position = "bottom", 
        legend.title = element_blank())


plot2 = ggplot(df_plot, aes(as.factor(year), relative)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country), size = 2) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Casos de Tuberculosis por año",
       x = "year",
       caption = "SOURCE: http://www.who.int/tb/country/data/download/en/") +
  theme(legend.position = "bottom", 
        legend.title = element_blank())

cowplot::plot_grid(plot1, plot2, nrow = 2)

```


## Datasets interesantes  

En los siguientes repositorios podréis encontrar datasets interesantes para jugar.  

* [fivethirtyeight](https://github.com/fivethirtyeight/data)  

* [Our World in Data](https://github.com/owid/owid-datasets)  

* [TidyTuesday](https://github.com/rfordatascience/tidytuesday)  


---  



## Bibliografía {.bibliografia -}

[Cheatsheets RStudio](https://github.com/rstudio/cheatsheets)

[Cheatsheet dplyr](https://github.com/rstudio/cheatsheets/raw/main/data-transformation.pdf)

[data-carpentry-week lesson_joins](https://mikoontz.github.io/data-carpentry-week/lesson_joins.html)

[R4ds - Joins](https://r4ds.had.co.nz/relational-data.html#mutating-joins)

[Tidyexplain](https://github.com/gadenbuie/tidyexplain)
