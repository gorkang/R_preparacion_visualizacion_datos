[["index.html", "R para preparación y visualización de datos Doctorado en Neurociencia Social y Cognición Introducción Objetivos Como empezar Bibliografía", " R para preparación y visualización de datos Doctorado en Neurociencia Social y Cognición Gorka Navarrete, ORCID: 0000-0001-7678-8656 Introducción El seminario estará centrado en el uso de R para la preparación y visualización de datos, además de la generación de reportes reproducibles. R es un lenguaje de programación abierto, con una gran comunidad orientada al trabajo, visualización y modelado de datos en contextos científicos y técnicos. Nos introduciremos de manera práctica a R, resolviendo problemas que encontramos habitualmente durante el quehacer científico, focalizándonos en el trabajo abierto, colaborativo y reproducible. Objetivos Dar las herramientas básicas a los alumnos para que puedan trabajar de manera autónoma con R y RStudio para el proceso de importación, transformación, visualización y reporte de datos. Al finalizar el curso deberíamos ser capaces de: Importar archivos de datos, transformar los datos, crear nuevas variables. Realizar análisis de datos exploratorios, visualizar distribuciones y comparar grupos. Generar reportes reproducibles con RMarkdown. Como empezar Si ya has completado los pasos indicados en Preparando nuesto sistema, puedes lanzar el siguiente código en tu ordenador para descargar los materiales del curso: if (!require(&#39;usethis&#39;)) install.packages(&#39;usethis&#39;); library(&#39;usethis&#39;) usethis::use_course(&quot;gorkang/R_preparacion_visualizacion_datos&quot;) Sigue las instrucciones que aparecen en la Consola para tener un nuevo proyecto de RStudio con todos los materiales del curso. El codigo anterior creará una carpeta llamada R_preparacion_visualizacion_datos-master. Dentro de esa carpeta tendrás un archivo llamado R_preparacion_visualizacion_datos.Rproj que te permitirá abrir el proyecto de RStudio del workshop. La carpeta R_preparacion_visualizacion_datos-master contiene varias cosas. Las mas importantes son: Carpeta docs: puedes abrir docs/index.html en tu navegador para ver el “libro” de este curso. Alternativamente, puedes consultar una version online del libro. Carpeta Rmd: En esa carpeta esta el codigo fuente de los capitulos del libro Carpeta data: Cuando usemos archivos de datos, vendrán de aquí En ocasiones encontraras una bombilla como esta: ¡No hagas click en mi sin antes haber intentado resolver el ejercicio sin ayuda! Si haces click sobre ella aparecerá una pista sobre como resolver el ejercicio. Bibliografía Bryan, J., &amp; Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/ Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ Wickham, H. (2014). Advanced r. Chapman and Hall/CRC. https://adv-r.hadley.nz/ Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Yihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html "],["preparando-sistema.html", "Preparando nuestro sistema 0.1 Empezando en A-B-C 0.2 Algo más sobre la instalación de paquetes Bibliografía", " Preparando nuestro sistema 0.1 Empezando en A-B-C Para poder iniciar el workshop necesitamos tener R y RStudio instalados, además de algunas librerías. Para tener un sistema funcional, completa los pasos A, B y C. Si ya tienes R y Rstudio instalados (recientemente), puedes pasar directamente al paso (C). (A) Instalar R R, es un lenguaje de programación especializado en la computación estadística y visualización de datos. Es recomendable tener instalada la última versión de R. Puedes usar uno de los enlaces siguientes: Windows: Descargar e instalar R para Windows Mac: Descargar e instalar R para Mac Ubuntu Linux: más detalles en la web de R. En un terminal: sudo apt-get install r-base (B) Instalar RStudio RStudio es un entorno integrado de desarrollo (IDE) para la programación R. Descargar e instalar RStudio. Una vez descargado e instalado, abre RStudio. Deberías ver algo parecido a lo siguiente: (C) Paquetes para el workshop Usaremos un buen numero de paquetes en el workshop. Hay algunos meta-paquetes que simplifican la instalación de múltiples paquetes (e.g. pacman, pak, …), pero en este caso vamos a usar una versión casera. Copia y pega el código de abajo y ejecútalo [tecla ENTER] en la consola de RStudio. El proceso de instalación requiere Internet y tardará un buen rato (en algunos sistemas puede ser facilmente 1 hora). if (!require(&#39;parallel&#39;)) install.packages(&#39;parallel&#39;) options(Ncpus = parallel::detectCores() - 2) list_of_packages = c(&quot;afex&quot;, &quot;caret&quot;, &quot;correlation&quot;, &quot;corrr&quot;, &quot;cowplot&quot;, &quot;dplyr&quot;, &quot;DT&quot;, &quot;esquisse&quot;, &quot;gapminder&quot;, &quot;ggplot2&quot;, &quot;ggraph&quot;, &quot;ggridges&quot;, &quot;ggthemes&quot;, &quot;gtsummary&quot;, &quot;haven&quot;, &quot;here&quot;, &quot;hexbin&quot;, &quot;inspectdf&quot;, &quot;janitor&quot;, &quot;knitr&quot;, &quot;plotly&quot;, &quot;purrr&quot;, &quot;readODS&quot;, &quot;readr&quot;, &quot;readxl&quot;, &quot;remotes&quot;, &quot;renv&quot;, &quot;rticles&quot;, &quot;see&quot;, &quot;sjPlot&quot;, &quot;stargazer&quot;, &quot;tidyr&quot;, &quot;writexl&quot;) new_packages &lt;- list_of_packages[!(list_of_packages %in% installed.packages()[,&quot;Package&quot;])] if (length(new_packages)) install.packages(new_packages, dependencies = TRUE) Otros paquetes que usaremos. if (!require(&#39;FFTrees&#39;)) remotes::install_github(&quot;ndphillips/FFTrees&quot;); library(&#39;FFTrees&#39;) if (!require(&#39;grateful&#39;)) remotes::install_github(&quot;Pakillo/grateful&quot;); library(&#39;grateful&#39;) if (!require(&#39;papaja&#39;)) remotes::install_github(&quot;crsh/papaja&quot;); library(&#39;papaja&#39;) if (!require(&#39;regexplain&#39;)) remotes::install_github(&quot;gadenbuie/regexplain&quot;); library(&#39;regexplain&#39;) if (!require(&#39;report&#39;)) remotes::install_github(&quot;easystats/report&quot;); library(&#39;report&#39;) # googlesheets4 # gganimate 0.2 Algo más sobre la instalación de paquetes Los paquetes de R son una colección de funciones, datos y documentación que amplían las capacidades básicas de R. Gran parte de las funciones y paquetes que utilizaremos en este workshop se encuentran contenidas en el meta-paquete tidyverse (este es un paquete de paquetes). Ya lo instalamos en (C), pero si quisieras instalarlo solo tendrías que ejecutar la siguiente linea en la consola de RStudio ((1) en la imagen de arriba): install.packages(\"ggplot2\") Para instalar otro paquete diferente de “tidyverse,” remplaza su nombre entre comillas dentro de la función: install.packages(\"NOMBRE_DE_PAQUETE\"). Una vez instalado un paquete, no es necesario volver hacerlo, a menos que reinstales R. 0.2.1 Cargar paquetes Las funciones, datos y documentación dentro de nuestros paquetes no podrán ser utilizadas hasta que se carguen en R. Una vez instalados, para cargar los paquetes se usa la función library(): library(ggplot2) En realidad las funciones también pueden ser llamadas usando su referencia absoluta ::, sin necesidad de cargarlas antes. Por ejemplo: dplyr::tibble(columna = 1). En general: nombre_paquete::nombre_de_funcion(parametros)). 0.2.2 Todo en uno El siguiente código simplifica lo anterior. Comprueba que el paquete esta instalado; Si no se encuentra instalado, lo instala. Finalmente lo carga. if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) Para instalar múltiples paquetes, podemos repetir la linea de mas arriba tantas veces como sea necesaria, o usar una versión algo mas sofisticada como el código del apartado (C): if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2') if (!require('bookdown')) install.packages('bookdown'); library('bookdown') ... Al principio de cada capítulo, verás una sección llamada Paquetes para este capítulo. Si pegas el contenido de esa sección en un script de R al empezar cada capítulo, te asegurarás de tener disponibles todas las funciones que usaremos. . 0.2.3 Instalar paquetes de Github En ocasiones querremos instalar directamente la versión en desarrollo del paquete desde Github. Para eso podemos usar la función install_github() del paquete remotes. Por ejemplo, para instalar el paquete {BayesianReasoning} desde su repositorio de Github: if (!require('remotes')) install.packages('remotes'); library('remotes') remotes::install_github(\"gorkang/BayesianReasoning\") Bibliografía Algunos de los manuales que vamos a usar para el workshop son los siguientes: Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Bryan, J., &amp; Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/ "],["introducción-a-r-y-visualización-de-datos.html", "Capítulo 1 Introducción a R y visualización de datos 1.1 Introducción: porque la visualización de datos es importante 1.2 Por qué R? 1.3 Visualización de datos con ggplot2 Ejercicios 1.4 Visualización interactiva Bibliografía", " Capítulo 1 Introducción a R y visualización de datos Paquetes para este capítulo if (!require(&#39;cowplot&#39;)) install.packages(&#39;cowplot&#39;); library(&#39;cowplot&#39;) if (!require(&#39;dplyr&#39;)) install.packages(&#39;dplyr&#39;); library(&#39;dplyr&#39;) if (!require(&#39;esquisse&#39;)) install.packages(&#39;esquisse&#39;); library(&#39;esquisse&#39;) if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;gghighlight&#39;)) install.packages(&#39;gghighlight&#39;); library(&#39;gghighlight&#39;) if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) if (!require(&#39;ggthemes&#39;)) install.packages(&#39;ggthemes&#39;); library(&#39;ggthemes&#39;) if (!require(&#39;ggridges&#39;)) install.packages(&#39;ggridges&#39;); library(&#39;ggridges&#39;) if (!require(&#39;knitr&#39;)) install.packages(&#39;knitr&#39;); library(&#39;knitr&#39;) if (!require(&#39;plotly&#39;)) install.packages(&#39;plotly&#39;); library(&#39;plotly&#39;) if (!require(&#39;purrr&#39;)) install.packages(&#39;purrr&#39;); library(&#39;purrr&#39;) if (!require(&#39;readr&#39;)) install.packages(&#39;readr&#39;); library(&#39;readr&#39;) if (!require(&#39;sjPlot&#39;)) install.packages(&#39;sjPlot&#39;); library(&#39;sjPlot&#39;) if (!require(&#39;tidyr&#39;)) install.packages(&#39;tidyr&#39;); library(&#39;tidyr&#39;) 1.1 Introducción: porque la visualización de datos es importante “These 13 datasets (the Datasaurus, plus 12 others) each have the same summary statistics (x/y mean, x/y standard deviation, and Pearson’s correlation) to two decimal places, while being drastically different in appearance.” (Matejka, J., &amp; Fitzmaurice, G., 2017) SOURCE: https://www.autodeskresearch.com/publications/samestats 1.1.1 Porque la visualización de datos es importante - ejemplo del mundo real Este ejemplo viene de un experimento que realizamos junto con Carlos Santamaría hace algún tiempo. Presentamos una tarea sobre cálculo de probabilidades a personas que estaban entrando a un examen para convertirse en trabajadores del estado. Simplificando algo, digamos que la materia para el examen eran 80 temas. No es posible estudiar con profundidad todos los temas, así que los opositores se concentraban en un subconjunto de esos temas (e.g. 30 de 80). Al empezar el examen, se seleccionaban al azar 5 de los 80 temas, y cada persona elegía uno de ellos para desarrollar. Abajo se puede ver como cambia la probabilidad de que uno de los temas estudiados aparezca dentro de los 5 seleccionados al azar. Con 30 de los 80 temas estudiados, la probabilidad de que uno de ellos salga en la prueba es del 91%. Si estudiáramos 47, subiríamos a una probabilidad del 99%. En el experimento le preguntamos a las personas por la probabilidad de que les apareciera alguno de los temas estudiados en la prueba. Comparamos las siguientes dos preguntas: ¿Cuál es la probabilidad de que salga uno de los temas que has estudiado? ¿Cuál es la probabilidad de que no salga ninguno de los temas que has estudiado? Miramos el error promedio en función de la pregunta (cuanto se han alejado de la probabilidad correcta), y vimos que nuestra manipulación había tenido un efecto considerable: Question Error_promedio SD N p (no salga ninguno) 4.016129 35.82469 31 p (salga uno) -30.741936 20.01494 31 Hay una diferencia notable entre condiciones. Pasamos de un error promedio del -30.7% a tan solo 4%, simplemente cambiando la pregunta. Hagamos un sencillo análisis de regresión para ver si la diferencia es significativa, y cuanta varianza explica nuestro modelo.   Error Predictors Estimates CI p (Intercept) 4.02 -6.41 – 14.44 0.444 Question [p (salga uno)] -34.76 -49.50 – -20.02 &lt;0.001 Observations 62 R2 / R2 adjusted 0.270 / 0.258 ## ## Shapiro-Wilk normality test ## ## data: modelo_regresion$residuals ## W = 0.96215, p-value = 0.0532 Todo es hermoso. Tenemos un efecto claramente significativo de la pregunta (y con un R2-ajustado de .258, no está nada mal), y además, nuestro modelo no incumple el supuesto de normalidad de residuos (por los pelos!). Leeme Las pruebas de normalidad son muy sensibles al n de la muestra Preparamos un plot con promedios y barras con error standard para nuestro paper. Estamos listos para escribir el paper. Solo por curiosidad, veamos boxplots de los dos grupos. Mmmm… hay algo extraño: Volvemos a extraer descriptivos… pero esta vez incluimos la mediana. Question Error_promedio Error_mediana SD N p (no salga ninguno) 4.016129 25 35.82469 31 p (salga uno) -30.741936 -37 20.01494 31 ¿Qué está pasando? Veamos las respuestas de todos los participantes, junto con la distribución de los datos, más la media y mediana por condición. TLDR: La manera en la visualizamos la información determina las conclusiones a las que llegamos. En una sola gráfica: Moraleja: es importante mostrar los datos individuales y/o la distribución de los datos SOURCE: https://www.autodeskresearch.com/publications/samestats 1.2 Por qué R? R es uno de los programas para data science mas populares, especialmente usado en la academia. El numero de paquetes que ofrecen funcionalidades de todo tipo no ha dejado de crecer. En 2021 el numero de paquetes en R-cran ha superado los 19,000 (ver este buscador de paquetes), y el ritmo de crecimiento nos acerca a la singularidad… ;) SOURCE: https://gist.github.com/daroczig/3cf06d6db4be2bbe3368 Además de lo anterior, R es un programa de código abierto (algo esencial para poder hacer ciencia reproducible), con una comunidad de usuarios muy acogedora. Sus funciones de visualización son muy potentes (ver la r-graph-gallery para algunos ejemplos), siendo usadas como herramienta principal en algunos medios como la BBC. No menos importante, hay una gran cantidad de cursos, tutoriales, presentaciones, etc. de una calidad excelente, con los que podemos aprender de manera autónoma. Por ejemplo: psyTeachR team at the University of Glasgow A Gentle Guide to the Grammar of Graphics with ggplot2 Con R puedes recoger datos interactivamente con shiny, preparar datos (o extraerlos de paginas web con rvest o RSelenium), visualizar datos estáticos con ggplot, animarlos con gganimate, visualizarlos con interactivamente con plotly o shiny. Puedes también analizar los datos con todas las técnicas imaginables, desde anovas con afex a modelos mixtos con lmer y/o afex, pasando por meta-análisis con metafor, SEM, Path analysis, mediación, con lavaan, análisis Bayesianos con brms o bayesfactor, y un larguísimo etc. Puedes llevar tus visualizaciones y análisis a reportes automáticos en múltiples formatos (pdf, html, docx) con Rmarkdown, crear libros como este con bookdown, páginas web con blogdown o distill, e incluso papers completamente reproducibles (preparación y análisis de datos) en formato APA con papaja. 1.2.1 Bienvenida al tidyverse El tidyverse es un conjunto de paquetes que nos permitirán hacer de manera (habitualmente) intuitiva muchas tareas de preparación y visualización de datos. 1.2.1.1 Tidyverse vs Base R Muchas de las funciones que existen en el Tidyverse tienen un equivalente en base-R (la instalación por defecto de R). El Tidyverse tiene ventajas y desventajas. La ventaja fundamental es que el código resulta (habitualmente) más fácil de leer, los nombres de las funciones son mas intuitivos, y las maneras de hacer las cosas tienen a ser consistentes. La desventaja fundamental es que incrementamos el numero de dependencias (paquetes) de nuestro código. Veamos un ejemplo extraído de aqui. La misma operación con base-R o con tidyverse: Filter rows with conditions evaluated within groups: iris flowers with maximum “Petal.Width” for each “Species” Tidyverse iris %&gt;% group_by(Species) %&gt;% filter(Petal.Width == max(Petal.Width)) Base-R # First operate in the data.frame by group (split-apply) widest_petals &lt;- by(iris, INDICES = iris$Species, FUN = function(x){ x[x$Petal.Width == max(x$Petal.Width), ] }) # Then combine the results into a data.frame do.call(rbind, widest_petals) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## setosa 5.0 3.5 1.6 0.6 setosa ## versicolor 5.9 3.2 4.8 1.8 versicolor ## virginica.101 6.3 3.3 6.0 2.5 virginica ## virginica.110 7.2 3.6 6.1 2.5 virginica ## virginica.145 6.7 3.3 5.7 2.5 virginica 1.2.2 Antes de empezar Programar es muy difícil. Todos necesitamos ayuda. Contar con una comunidad robusta con la que compartir, preguntar, contribuir, ayuda muchísimo. SOURCE: http://www.keywordbasket.com/ZWZlY3RvIGR1bm5pbmcta3J1Z2Vy/ Hay algunos recursos que son imprescindibles. Nadie sabe como los antiguos podían programar antes de la llegada de Stackoverflow: Stack overflow Google: text size ggplot Y otros recursos que resultan muy útiles: Comunidad de usuarios de Rstudio Twiter! Por ejemplo: #TidyTuesday (@thomas_mock) @dataandme @rivaquiroga @RLadiesSantiago Webs como R bloggers 1.2.3 R para visualización de datos ggplot2 es el paquete por excelencia para visualización de datos. Su potencia va asociada a un nivel de complejidad considerable, hasta el punto que hay Cheat sheets oficiales, Cheat sheets buscables, y decenas de miles de preguntas en Stack Overflow. 1.2.3.1 Primeros pasos - con training wheels Para empezar a usar ggplot sin tener que preocuparnos de su complejidad, podemos usar la función esquisse:::esquisser() del paquete esquisse. Esta nos permite usar la potencia de ggplot para explorar una base de datos de manera muy sencilla. SOURCE: https://www.williamrchase.com/slides/intro_r_anthropology_2018#93 La manera fácil (1, 2, 3), usando esquisse: # 1) Asegurate que hemos instalado el paquete esquisse if (!require(&#39;esquisse&#39;)) install.packages(&#39;esquisse&#39;); library(&#39;esquisse&#39;) # 2) Carga el dataframe que desees. En este caso, &quot;iris&quot; data(iris) # 3) Lanza el wizard esquisser esquisse:::esquisser() 1.2.3.2 Aprendamos con Garrick Garrick Aden-Buie (@grrrck) ha creado una excelente introducción a ggplot2 y la gramática de gráficos. Os recomiendo revisarla para familiarizaros con las funcionalidades de ggplot. Antes de empezar, asegúrate que tienes instalados los paquetes tidyverse y gapminder. if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) gapminder ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. ## 2 Afghanistan Asia 1957 30.3 9240934 821. ## 3 Afghanistan Asia 1962 32.0 10267083 853. ## 4 Afghanistan Asia 1967 34.0 11537966 836. ## 5 Afghanistan Asia 1972 36.1 13079460 740. ## 6 Afghanistan Asia 1977 38.4 14880372 786. ## 7 Afghanistan Asia 1982 39.9 12881816 978. ## 8 Afghanistan Asia 1987 40.8 13867957 852. ## 9 Afghanistan Asia 1992 41.7 16317921 649. ## 10 Afghanistan Asia 1997 41.8 22227415 635. ## # … with 1,694 more rows 1.3 Visualización de datos con ggplot2 1.3.1 Primeros pasos En esta sección vamos a ver algunos de los componentes que usaremos cuando visualicemos datos. Muchos de los ejemplos que usaremos vienen de R for data science. Los ingredientes esenciales de una gráfica son: Aesthetic mappings (aes): Variables, colores, rellenos, formas, … Geoms (geom_): puntos, lineas, boxplots, … Facets (facet_): facet_wrap() y facet_grid() Transformaciones estadísticas: stat_summary, ..prop.., … SOURCE: https://skillgaze.com/2017/10/31/understanding-different-visualization-layers-of-ggplot/ 1.3.2 Aesthetic mappings En aes() vamos a indicar las variables que queremos en los ejes x e y, el color de los puntos o lineas, el relleno de las barras, la forma de los puntos, el tipo de linea, la agrupación de los datos, etc. x: x = gdpPercap y: y = lifeExp color: color = continent; color = “red”; color = “#FAA627” fill: fill = continent; fill = “red”; fill = “#FAA627” alpha: alpha = continent; alpha = 0.2 size: size = continent; size = 5 shape: shape = continent; shape = 0 ver codigo de las distintas formas linetype: linetype = continent; linetype = “dashed” group: group = continent 1.3.2.1 x-y Usando los datos de gapminder, visualizamos la relacion entre gdpPercap (eje x), y lifeExp (eje y). ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() Si respetamos el orden, podemos simplificar nuestro código, evitando el data = y mapping =. En este caso, vemos de nuevo lifeExp y gdpPercap, invirtiendo los ejes. ggplot(gapminder, aes(lifeExp, gdpPercap)) + geom_point() Ejercicio Usando gapminder, ¿podrías crear un gráfico de gdp per capita por población como éste? 1.3.2.2 Color, alpha, size Para elegir paletas de colores: colorbrewer Codigo HEX de colores # Gráfico inicial ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() # Color &quot;rojo&quot; para los puntos ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(color = &quot;red&quot;) # Color en función de la variable &#39;continent&#39; ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() # Color en función de la variable &#39;continent&#39; + size ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2)) + geom_point() # Color en función de la variable &#39;continent&#39; + size + alpha ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2, alpha = .1)) + geom_point() Imagina que queremos asignar colores manualmente. ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(color = c(&quot;red&quot;, &quot;grey&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;black&quot;)) # Error: Aesthetics must be either length 1 or the same as the data (1704): colour Tenemos que indicar que el color depende de continent, y después usar scale_color_manual() ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() + scale_color_manual(values = c(&quot;red&quot;, &quot;grey&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;black&quot;)) Ejercicios Usando como base el plot del ejercicio anterior (GDP x población), ¿podrías hacer lo siguiente? Colorear los puntos por continente Tamaño del punto 4 Alpha 0.5 Cada uno de los siguientes gráficos tiene un error. ¿Sabrias corregirlos? Solucion: color = continent debe ir dentro de aes() ggplot(gapminder, aes(gdpPercap, pop), color = continent) + geom_point(size = 4, alpha = .5) Solucion: color = “blue” debe ir fuera de aes() ggplot(gapminder, aes(gdpPercap, pop, color = &quot;blue&quot;)) + geom_point(size = 4, alpha = .5) 1.3.2.3 Shape Códigos para las distintas formas: SOURCE: https://r4ds.had.co.nz/data-visualisation.html#aesthetic-mappings ggplot(gapminder, aes(gdpPercap, lifeExp, shape = continent)) + geom_point() 1.3.2.4 Linetype Códigos para los distintos estilos de linea: SOURCE: http://sape.inf.usi.ch/quick-reference/ggplot2/linetype Podemos directamente definir el tipo de linea que queremos en geom_line(): ggplot(gapminder, aes(year, lifeExp, color = country, group = country)) + geom_line(linetype = &quot;dashed&quot;, show.legend = FALSE) + facet_wrap(~continent) O que el tipo de linea dependa de una variable: ggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) + stat_summary(fun = mean, geom = &quot;line&quot;) 1.3.3 Geoms Una de las cosas más difíciles cuando nos enfrentamos a nuevos datos es elegir el método más efectivo para visualizarlos. Hay varios recursos interesantes sobre cómo elegir una gráfica. En esta sección veremos distintos tipos de geometria, o geoms_(). En ggplot, despues de indicar los datos y coordenadas (e.g. ggplot(mpg, aes(displ, hwy))), podemos sumar uno o varios geoms con una lógica de capas superpuestas, por ejemplo, + geom_point(). Algunos tipos de geoms Para una lista exhaustiva ver el manual de ggplot2. SOURCE: https://nbisweden.github.io/RaukR-2019/ggplot/presentation/ggplot_presentation_assets/geoms.png 1.3.3.1 geom_point y geom_jitter Si queremos un gráfico de dispersión o scatterplor, podemos usar el geom_point() ggplot(mpg, aes(displ, hwy)) + geom_point() En algunos casos, tenemos muchos puntos que se superponen. Si usamos geom_jitter() la posición de los puntos cambia levemente de manera aleatoria para evitar superposiciones. Con las propiedades ´width´ y ´height´ podemos controlar cuando desplazamiento queremos horizontal y verticalmente. ggplot(mpg, aes(displ, hwy)) + geom_jitter() 1.3.3.2 geom_smooth Podemos usar lineas de tendencia con geom_smooth(). El method por defecto es loess, pero podemos usar otros distintas funciones (e.g. geom_smooth(method = \"lm\") para usar una regresión lineal). # Linea de tendencia (default loess) ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() + geom_smooth() # Usamos lm ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() + geom_smooth(method = &quot;lm&quot;) # Un smooth por cada clase ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() + geom_smooth() # Coloreamos puntos pero mantenemos un solo smooth ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(aes(color = continent)) + geom_smooth() Ejercicios Usando como base el plot de la sección Shape: Colorear los puntos por continente Mostrar una línea de tendencia por continente (sin el intervalo de confianza) Que el tipo de línea cambie por continente Añadir transparencia para que las lineas destaquen Usando el df mpg, intenta crear los 6 plots que se pueden ver más abajo. Aquí tienes el plot base, para hacer mas fácil la tarea: ggplot(mpg, aes(displ, hwy)) + geom_point() + theme_grey() Además de generar uno a uno los 6 plots, serías capaz de generar la figura que se ve abajo? Esto es, un plot que incluye los 6 plots juntos. Solucion: En la sección Combinando gráficas veras un ejemplo del uso de la función cowplot::plot_grid() 1.3.3.3 geom_boxplot y geom_violin Podemos crear diagramas de cajas (boxplots) con geom_boxplot o violines con geom_violin para visualizar como cambian los datos por grupo. # Boxplot con fill ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_boxplot(alpha = .2) # Violins ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) # Combinamos ambos ggplot(gapminder, aes(continent, lifeExp)) + geom_boxplot(alpha = .2) + geom_violin(alpha = .2, aes(fill = continent)) 1.3.3.4 geom_histogram y geom_bar Podemos usar histogramas geom_histogram() con variables continuas. ggplot(gapminder, aes(lifeExp)) + geom_histogram() O geom_bar() con variables categóricas. ggplot(gapminder, aes(continent, fill = continent)) + geom_bar(alpha = .6) 1.3.3.5 geom_density Para visualizar distribuciones (cuando tenemos muchos datos), podemos usar geom_density(). # Density with fill and alpha ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(alpha = .2) # Density - position stack ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(position = &quot;stack&quot;, alpha = .2) # Density - position fill ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(position = &quot;fill&quot;, alpha = .2) 1.3.3.6 geom_density_ridges Uno de mis geoms favoritos para comparar distribuciones es geom_density_ridges: # geom_density_ridges ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(alpha = .2) Especialmente porque podemos incluir en el mismo gráfico información sobre distribuciones y puntos individuales. # geom_density_ridges junto con raincloud points y histograma ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.7, scale = 0.9) Ejercicios Usando como base el plot de la seccion geom_histrogram(): Colorea los puntos por continente Sabrias hacer que no se amontonen unos continentes sobre otros? Necesitarás añadir transparencia para ver todos los datos Solucion: geom_histogram(position = \"identity\", alpha = .3). 1.3.4 Facets Cuando queremos separar en gráficos independientes distintas categorías dentro de nuestros datos, podemos usar facetas. Hay dos funciones para esto, facet_grid y facet_wrap. 1.3.4.1 facet_grid facet_grid(~ variable) nos devuelve una matriz simétrica de gráficas. # Plot inicial ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .2) + facet_grid(~ continent) + guides(alpha = FALSE, color = FALSE) # Cambiamos ejes ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .2) + facet_grid(continent ~ .) + guides(alpha = FALSE, color = FALSE) # Añadimos una segunda variable ggplot(gapminder, aes(gdpPercap, lifeExp, color = country)) + geom_line(alpha = .2) + facet_grid(continent ~ pop &gt; 5000000) + guides(alpha = FALSE, color = FALSE) 1.3.4.2 facet_wrap facet_wrap(~ variable) nos devuelve tantas facetas como niveles de la variable, pudiendo definir el número de filas y columnas que queremos. # Plot base ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_histogram(alpha = .5) + facet_wrap( ~ continent) + guides(alpha = FALSE, color = FALSE) Con la función gghighlight() podemos añadir una capa para facilitar la comparación de cada faceta con los datos completos. # 1 fila ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_histogram(alpha = .5) + facet_wrap( ~ continent, nrow = 1) + guides(alpha = FALSE, color = FALSE) + gghighlight::gghighlight() 1.3.5 Transformaciones estadísticas ggplot2 nos permite hacer algunas transformaciones estadísticas al crear los gráficos. Para más detalles, ver r4ds. 1.3.5.1 stat_summary Algunas funciones que podemos usar en los gráficos min(): mínimo max(): máximo mean(): media median(): mediana sd(): desviación estandard Podemos usar funciones simples de manera directa. En este caso, mostramos un punto con la mediana, y barras que muestran el rango completo de los datos: ggplot(gapminder, aes(continent, lifeExp)) + stat_summary( fun.ymin = min, fun.ymax = max, fun = median) Si queremos usar funciones algo mas complejas, la sintaxis es algo diferente. En este caso mostramos media ± desviación estandard: ggplot(gapminder, aes(continent, lifeExp)) + stat_summary( fun.ymin = function(x) mean(x) - sd(x), fun.ymax = function(x) mean(x) + sd(x), fun = mean) 1.3.5.2 Promedios por grupo Lo interesante es que podemos añadir estas transformaciones estadísticas como una capa más en los gráficos. Asi que, a este gráfico inicial… ggplot(mpg) + geom_jitter(aes(x = class, y = hwy), width = 0.2) + theme_minimal() Le podemos añadir el promedio por grupo: ggplot(mpg) + geom_jitter(aes(x = class, y = hwy), width = 0.2) + stat_summary(aes(x = class, y = hwy), fun = mean, color = &quot;red&quot;, geom = &quot;point&quot;, size = 4, alpha = .7) + theme_minimal() O cosas aún más elaboradas: # Gapminder ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + stat_summary(data = gapminder %&gt;% group_by(continent) %&gt;% summarise(gdpPercap = mean(gdpPercap), lifeExp = mean(lifeExp)), fun = mean, geom = &quot;point&quot;, size = 4) Ejercicios Cuando al plot A trato de añadirle lineas para cada class, me aparece algo como lo de B. plotA = ggplot(mpg, aes(displ, hwy, color = class)) + geom_point() + theme(legend.position = &quot;bottom&quot;) plotB = ggplot(mpg, aes(displ, hwy, color = class)) + geom_point() + geom_line() + theme(legend.position = &quot;bottom&quot;) cowplot::plot_grid(plotA, plotB, labels = c(&quot;A&quot;, &quot;B&quot;)) Pero en realidad no quiero que las lineas pasen por todos los puntos, sino que muestren el promedio ¿Podrías reproducir el gráfico de abajo? Podrías crear este gráfico? Mostramos mediana ± sd para cada país, organizado por continente. 1.3.6 Personalización de gráficas Habitualmente, un vez tenemos la gráfica que queremos querremos personalizar varias cosas, como las escalas, colores, estilos, etc. 1.3.6.1 Coordenadas # Gráfico inicial ggplot(gapminder, aes(continent)) + geom_bar() # coord_flip() ggplot(gapminder, aes(continent)) + geom_bar() + coord_flip() # coord_polar() ggplot(gapminder, aes(continent)) + geom_bar() + coord_polar() 1.3.6.2 Scales # Grafico inicial ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) # Añadimos breaks en eje y ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) # Definimos cuantos breaks queremos ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_x_continuous(n.breaks = 20, guide = guide_axis(angle = 90)) + scale_y_continuous(n.breaks = 20) # Separador de miles y breaks en x ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_continuous(labels = scales::comma, n.breaks = 10) # Formato de $ ($M) ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_continuous(labels = scales::dollar_format(prefix = &quot;$&quot;, suffix = &quot;M&quot;), breaks = seq(0, 100000, 20000)) # Escala log ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix = &quot;$&quot;, suffix = &quot;M&quot;)) # Invertimos escala ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_reverse() # No mostramos el texto de los breaks de x ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_reverse() + theme(axis.text.x = element_blank()) # Porcentaje ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() + scale_y_continuous(labels = scales::percent) 1.3.6.3 Colors and fill scales # Plot inicial ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) # Relleno usando paleta blues ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) + scale_fill_brewer(palette = &quot;Blues&quot;) # Color grey ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) + geom_point() + scale_color_grey(start = 0.2, end = 0.8, na.value = &quot;red&quot;) # Gradient ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) + geom_point() + scale_color_gradient(low = &quot;red&quot;, high = &quot;blue&quot;) # Gradient con un numero predefinidos de una paleta ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) + geom_point() + scale_colour_gradientn(colours = terrain.colors(3)) 1.3.6.4 Combinando gráficas plot1 = ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix = &quot;$&quot;, suffix = &quot;M&quot;)) + theme(legend.position = &quot;top&quot;) plot2 = ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() + scale_y_continuous(labels = scales::percent) + coord_flip() cowplot::plot_grid(plot2, plot1, rel_widths = c(.3, 0.7)) # SOURCE: https://stackoverflow.com/questions/8545035/scatterplot-with-marginal-histograms-in-ggplot2/56440634#56440634 # Set up scatterplot scatterplot &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point(size = 3, alpha = 0.6) + guides(color = FALSE) + theme(plot.margin = margin()) # Define marginal histogram marginal_distribution &lt;- function(x, var, group) { ggplot(x, aes_string(x = var, fill = group)) + geom_histogram(bins = 30, alpha = 0.4, position = &quot;identity&quot;) + # geom_density(alpha = 0.4, size = 0.1) + guides(fill = FALSE) + theme_void() + theme(plot.margin = margin()) } # Set up marginal histograms x_hist &lt;- marginal_distribution(iris, &quot;Sepal.Length&quot;, &quot;Species&quot;) y_hist &lt;- marginal_distribution(iris, &quot;Sepal.Width&quot;, &quot;Species&quot;) + coord_flip() # Align histograms with scatterplot aligned_x_hist &lt;- align_plots(x_hist, scatterplot, align = &quot;v&quot;)[[1]] aligned_y_hist &lt;- align_plots(y_hist, scatterplot, align = &quot;h&quot;)[[1]] # Arrange plots cowplot::plot_grid( aligned_x_hist , NULL , scatterplot , aligned_y_hist , ncol = 2 , nrow = 2 , rel_heights = c(0.2, 1) , rel_widths = c(1, 0.2)) 1.3.6.5 Usando estilos https://ggplot2.tidyverse.org/reference/ggtheme.html https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html # Create a base graph p &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) + geom_point() + labs(title = &#39;A ggplot simple graph&#39;, subtitle = &#39;Simple tweaks to improve plots, or not&#39;, x = &#39;&#39;, y = &#39;&#39;, caption = &#39;https://github.com/gorkang / @gorkang&#39;) + theme_gray() # This is the default. Needed here because of the Bookdown theme p Usando el tema fivethirtyeight p + ggthemes::scale_color_fivethirtyeight() + ggthemes::theme_fivethirtyeight() Usando el tema economist p + ggthemes::scale_color_economist() + ggthemes::theme_economist() Ejercicios Con el DF diamonds, crea el siguiente plot: Solucion: Tienes que usar el geom_bar() y el parametro fill. El plot del panel (A) tiene varios problemas (los años no son enteros o factores, los casos no se muestran con un separador de miles, la leyenda esta a la derecha ocupado un espacio precioso, etc.). Trata de resolverlos e intenta llegar al resultado que se ve en el panel (B). Usa el df table1 del paquete {tidyr}? Sintaxis aes() Alguna de estas gráficas dará un error? Sin correr el código, sabrías decir cuál de ellas? Hay varias soluciones posibles, ¿Cuales serían?. ggplot(mpg, mapping = aes(displ, hwy, color = class)) + geom_point() + stat_summary(fun = mean, geom = &quot;line&quot;, linetype = &quot;dashed&quot;) ggplot(mpg, mapping = aes(displ, hwy, color = class, linetype = class)) + geom_point() + stat_summary(fun = mean, geom = &quot;line&quot;) ggplot(mpg, mapping = aes(displ, hwy, color = class)) + geom_point() + stat_summary(fun = mean, geom = &quot;line&quot;, linetype = class) Temas Serías capaz de reproducir este gráfico, usando el df diamonds y el theme_economist? Serías capaz de reproducir este gráfico, usando el df gapminder y la paleta Accent? 1.4 Visualización interactiva 1.4.0.1 Gráficas interactivas plotly::ggplotly( ggplot(gapminder %&gt;% filter(year == 2007), aes(gdpPercap, lifeExp, color = continent, size = country)) + geom_point(alpha = .3, point = 2) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix = &quot;$&quot;, suffix = &quot;M&quot;)) + theme(legend.position = &quot;none&quot;) ) 1.4.0.2 Animando gráficas if (!require(&#39;gganimate&#39;)) remotes::install_github(&#39;thomasp85/gganimate&#39;); library(&#39;gganimate&#39;) #sudo apt-get install ffmpeg p = ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) + geom_point(alpha = 0.7, show.legend = FALSE) + scale_colour_manual(values = country_colors) + scale_size(range = c(2, 12)) + scale_x_log10() + facet_wrap(~continent) + # Here comes the gganimate specific bits labs(title = &#39;Year: {frame_time}&#39;, x = &#39;GDP per capita&#39;, y = &#39;life expectancy&#39;) + transition_time(year) + ease_aes(&#39;linear&#39;) animate(p, renderer = ffmpeg_renderer(), height = 6, width = 10, units = &quot;in&quot;, res = 300) # anim_save(&quot;name_file.mp4&quot;, animation = last_animation()) Video Bibliografía Matejka, J., &amp; Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM. https://bbc.github.io/rcookbook/ https://github.com/bbc/bbplot https://github.com/dreamRs/esquisse Garrick Aden-Buie. A Gentle Guide to the Grammar of Graphics with ggplot2: https://github.com/gadenbuie/gentle-ggplot2 Michael Toth. You Need to Start Branding Your Graphs. Here’s How, with ggplot!: https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html Claus Wilke: https://wilkelab.org/practicalgg/ Thomas Lin Pedersen: Part 1: https://www.youtube.com/watch?v=h29g21z0a68 Part 2: https://www.youtube.com/watch?v=0m4yywqNPVY "],["preparación-y-transformación-de-datos.html", "Capítulo 2 Preparación y transformación de datos 2.1 Importar y exportar datos 2.2 Preparación y transformación de datos 2.3 Combinar bases de datos 2.4 Más allá de la manipulación 2.5 Datasets interesantes Bibliografía", " Capítulo 2 Preparación y transformación de datos En este capítulo vamos a aprender a importar y exportar todo tipo de archivos, ademas de pasar de una base de datos no especialmente amigable, a una base de datos tidy, esto es, siguiendo algunas reglas bien sencillas que harán más fácil trabajar con los datos. Paquetes para este capítulo if (!require(&#39;dplyr&#39;)) install.packages(&#39;dplyr&#39;); library(&#39;dplyr&#39;) if (!require(&quot;DT&quot;)) install.packages(&quot;DT&quot;); library(&quot;DT&quot;) if (!require(&quot;janitor&quot;)) install.packages(&quot;janitor&quot;); library(&quot;janitor&quot;) if (!require(&#39;readr&#39;)) install.packages(&#39;readr&#39;); library(&#39;readr&#39;) if (!require(&quot;readxl&quot;)) install.packages(&quot;readxl&quot;); library(&quot;readxl&quot;) if (!require(&quot;haven&quot;)) install.packages(&quot;haven&quot;); library(&quot;haven&quot;) if (!require(&quot;here&quot;)) install.packages(&quot;here&quot;); library(&quot;here&quot;) if (!require(&quot;purrr&quot;)) install.packages(&quot;purrr&quot;); library(&quot;purrr&quot;) if (!require(&quot;readODS&quot;)) install.packages(&quot;readODS&quot;); library(&quot;readODS&quot;) if (!require(&quot;tidyr&quot;)) install.packages(&quot;tidyr&quot;); library(&quot;tidyr&quot;) if (!require(&quot;writexl&quot;)) install.packages(&quot;writexl&quot;); library(&quot;writexl&quot;) # if (!require(&#39;caret&#39;)) install.packages(&quot;caret&quot;, dependencies = c(&quot;Depends&quot;, &quot;Suggests&quot;)); library(&#39;caret&#39;) if (!require(&#39;caret&#39;)) install.packages(&#39;caret&#39;); library(&#39;caret&#39;) if (!require(&#39;regexplain&#39;)) remotes::install_github(&quot;gadenbuie/regexplain&quot;); library(&#39;regexplain&#39;) if (!require(&#39;FFTrees&#39;)) remotes::install_github(&quot;ndphillips/FFTrees&quot;); library(&#39;FFTrees&#39;) 2.1 Importar y exportar datos Podemos ver las funciones de esta sección y como usarlas en la Cheatsheet importar datos 2.1.1 Importar un solo archivo Vamos a ver con más detalle los archivos CSV (comma separated values). Las funciones para importar archivos excel, Libreoffice, SPSS, etc. tienen parámetros muy similares. 2.1.1.1 Archivos CSV Usaremos las siguientes funciones del paquete readr: readr::read_csv(): valores separados por coma (“,”) readr::read_csv2(): valores separados por punto y coma (“;”) readr::read_delim( , delim = \"|\"): valores separados por un delimitador arbitrario Leemos el archivo 02-read-csv.csv de la carpeta data/files/: DF_name = read_csv(&quot;data/files/02-read-csv.csv&quot;) Si estamos usando rmarkdown, o similar, es recomendable usar here::here() para evitar problemas con los paths a los archivos. name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.1.2 Otros tipos de archivos Archivos excel name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-xlsx.xlsx&quot;) readxl::read_excel(name_of_file) Archivos SPSS name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-sav.sav&quot;) haven::read_sav(name_of_file) Archivos Libreoffice name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-ods.ods&quot;) df_ODS = readODS::read_ods(name_of_file) # Vemos las primeras filas head(df_ODS) Google sheets Para poder leer una gsheet debemos antes crear un enlace para compartirla: \"Share\" -&gt; \"Get shareable link\" if (!require(&quot;googlesheets4&quot;)) install.packages(&quot;googlesheets4&quot;); library(&quot;googlesheets4&quot;) name_of_sheet = &quot;1jjb91j2X13_JKDAeIwrKIdNv0rcseMdteSqb0ZMVOig/edit#gid=807114896&quot; googlesheets4::read_sheet(name_of_sheet) 2.1.2 Ejercicios - Importar datos En el repositorio R para preparación y visualización de datos - DNSC - UAI de la Open Science Foundation podrás ver una carpeta llamada Capitulo 2. Importa los archivos que ahí aparecen, asegurándote que los nombres de columna se leen adecuadamente: Solucion: La función read_excel() tiene parámetros como skip, que permite no leer las primeras n lineas, o sheet, con la que puedes indicar que pestaña leer. 02-extralines-1.xlsx 02-extralines-2.xlsx 02-extralines-3.xlsx 02-spanish.csv 2.1.3 Importar múltiples archivos En ocasiones tenemos múltiples archivos en una carpeta (e.g. uno por participante) y queremos combinarlos todos en un solo DF. Importamos los archivos que están en la carpeta data/files/02-CSVs # Directorio donde se encuentran los archivos name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) # Listamos los archivos a leer files &lt;- list.files(name_of_folder, full.names = TRUE) # Leemos todos los archivos, combinandolos en un dataframe full &lt;- purrr::map_df(files, read_csv) full ## # A tibble: 1,600 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,590 more rows 2.1.3.1 Incluir nombres de archivos Incluimos nombres de archivo en una columna: name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) files &lt;- list.files(name_of_folder, full.names = TRUE) %&gt;% set_names(basename(.)) full2 &lt;- map_df(files, read_csv, .id = &quot;file&quot;) full2 ## # A tibble: 1,600 x 10 ## file Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 01.csv male Collective 1 we ofensivo negative yes left 623 ## 2 01.csv male Collective 2 we resentido negative no right 1235 ## 3 01.csv male Collective 3 we ego�sta negative yes left 335 ## 4 01.csv male Collective 4 we indiscreto negative yes left 355 ## 5 01.csv male Collective 5 we sumiso negative yes left 618 ## 6 01.csv male Collective 6 we agradable positive yes left 328 ## 7 01.csv male Collective 7 we clasista negative yes left 348 ## 8 01.csv male Collective 8 we altruista positive yes left 1620 ## 9 01.csv male Collective 9 we ansioso negative yes left 346 ## 10 01.csv male Collective 10 we presumido negative yes left 778 ## # … with 1,590 more rows 2.1.3.2 Con parametros Añadimos parametros a la funcion de lectura. En este caso, definimos el tipo de columna esperado con la función col_types(). Con esto nos aseguraremos que si alguno de los archivos tiene el tipo de datos “incorrecto,” aparecerán warnings en la importación: name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) files &lt;- list.files(name_of_folder, full.names = TRUE) full &lt;- map_df(files, read_csv, col_types = cols( Sex = col_factor(), Priming = col_character(), trialN = col_integer(), Block = col_character(), Adjective = col_character(), Valence = col_factor(), Answer = col_character(), Arrow = col_character(), rT = col_double())) full ## # A tibble: 1,600 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,590 more rows 2.1.4 Ejercicios - Importar múltiples archivos Cuando más arriba importamos los archivos que están en la carpeta data/files/02-CSVs: ¿Qué archivos importamos exáctamente? ¿Ves algún problema en lo que hicimos? Revisa el número de filas y la variable files. El resultado final deberia ser así: ## # A tibble: 1,200 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,190 more rows Leed los archivos .xlsx de la carpeta data/files/02-XLSs, combinándolos en un único DF. El resultado final debería ser como se ve a continuación: ## # A tibble: 1,200 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,190 more rows 2.1.5 Exportar datos 2.1.5.1 Archivos CSV # Versión simple write_csv(DF_name, &quot;data/files/02-write-csv.csv&quot;) # Versión avanzada name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-csv.csv&quot;) write_csv(DF_name, name_of_file) 2.1.5.2 Otros Archivos name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-xlsx.xlsx&quot;) writexl::write_xlsx(DF_name, name_of_file) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-sav.sav&quot;) haven::write_sav(DF_name, name_of_file) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-ods.ods&quot;) readODS::write_ods(DF_name, name_of_file) 2.2 Preparación y transformación de datos Para la preparación y transformación de datos usaremos fundamentalmente dplyr. Hay otros paquetes más rápidos como data.table. Si trabajas con datos gigantescos (millones de filas), sin duda notarás la diferencia. La desventaja es que la sintaxis es (habitualmente) algo más difícil. 2.2.1 Tidy data Existen tres sencillas reglas que definen la Tidy data: Cada variable tiene su columna propia Cada observacion tiene su fila propia Cada valor tiene su celda propia Las ventajas fundamentales son: Uso de una manera consistente de trabajar, que se alinea con el tidyverse Facilidad para trabajar con la logica vectorizada Por ejemplo. De manera muy sencilla y rápida podemos crear una nueva columna realizando algún cómputo arbitrario con los valores de otra columna. # Compute rate per 100,000 table1 %&gt;% mutate(rate_per_100K = cases / population * 100000) ## # A tibble: 6 x 5 ## country year cases population rate_per_100K ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 3.73 ## 2 Afghanistan 2000 2666 20595360 12.9 ## 3 Brazil 1999 37737 172006362 21.9 ## 4 Brazil 2000 80488 174504898 46.1 ## 5 China 1999 212258 1272915272 16.7 ## 6 China 2000 213766 1280428583 16.7 O contar el número de casos por valor de una variable. # Compute cases per year table1 %&gt;% count(year, wt = cases) ## # A tibble: 2 x 2 ## year n ## &lt;int&gt; &lt;int&gt; ## 1 1999 250740 ## 2 2000 296920 Y, como no, ggplot funciona con datos tidy, en formato long. # Visualise changes over time ggplot(table1, aes(as.factor(year), cases)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country)) 2.2.2 Verbos dplyr Usaremos {dplyr}, un paquete muy potente para la manipulación de datos. Su sintaxis, además, es bastante intuitiva (¡son verbos en inglés!). Usando pipes %&gt;% (CONTROL + SHIFT + M) podemos enlazar operaciones de transformación de datos de manera muy sencilla (una vez nos aprendamos los verbos). Podemos ver mas detalle y ejemplos en la Cheatsheet de dplyr. Verbos esenciales: filter(): filtrar filas arrange(): ordenar filas select(): seleccionar columnas rename(): renombrar columnas mutate(): crear columnas, modificar columnas, etc. Tabla resumen dplyr 2.2.2.1 Filtrar y ordenar filas # DF original name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Filtrar DF_name %&gt;% filter(Educacion &gt; 8) ## # A tibble: 3 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 157 12207 1 26 9 57 PPV_Cond2 45 ## 2 287 60873 1 72 10 51 PPV_Cond3 99 ## 3 381 64486 2 19 9 80 PPV_Cond4 92 # Ordenar DF_name %&gt;% arrange(Educacion, desc(Genero)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 350 20439 2 41 1 81 PPV_Cond4 92 ## 2 399 81379 1 36 1 90 PPV_Cond4 92 ## 3 42 20361 2 37 2 60 PPV_Cond1 1 ## 4 364 19201 2 21 2 67 PPV_Cond4 10 ## 5 412 60292 1 28 2 90 PPV_Cond4 80 ## 6 44 92735 2 30 3 95 PPV_Cond1 99 ## 7 135 32344 2 34 3 81 PPV_Cond2 46 ## 8 299 33562 2 35 3 95 PPV_Cond3 99 ## 9 333 29837 2 28 3 80 PPV_Cond4 60 ## 10 361 57804 2 40 3 30 PPV_Cond4 90 ## # … with 93 more rows 2.2.2.2 Seleccionar, ordenar y renombrar columnas # Seleccionar columnas DF_name %&gt;% select(Genero, Edad) ## # A tibble: 103 x 2 ## Genero Edad ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 47 ## 2 2 21 ## 3 2 29 ## 4 2 27 ## 5 1 29 ## 6 2 28 ## 7 2 27 ## 8 2 55 ## 9 2 28 ## 10 1 46 ## # … with 93 more rows # Eliminar columnas DF_name %&gt;% select(-X1) ## # A tibble: 103 x 7 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 1 47 8 80 PPV_Cond1 99 ## 2 95041 2 21 6 90 PPV_Cond1 99 ## 3 74594 2 29 6 10 PPV_Cond1 99 ## 4 72903 2 27 7 75 PPV_Cond1 1 ## 5 21260 1 29 5 35 PPV_Cond1 24 ## 6 50315 2 28 6 14 PPV_Cond1 99 ## 7 21774 2 27 4 2 PPV_Cond1 99 ## 8 20881 2 55 6 89 PPV_Cond1 99 ## 9 39751 2 28 6 6 PPV_Cond1 99 ## 10 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Ordenar y eliminar columnas DF_name %&gt;% select(ID, Edad, Genero, everything(), -X1) ## # A tibble: 103 x 7 ## ID Edad Genero Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 47 1 8 80 PPV_Cond1 99 ## 2 95041 21 2 6 90 PPV_Cond1 99 ## 3 74594 29 2 6 10 PPV_Cond1 99 ## 4 72903 27 2 7 75 PPV_Cond1 1 ## 5 21260 29 1 5 35 PPV_Cond1 24 ## 6 50315 28 2 6 14 PPV_Cond1 99 ## 7 21774 27 2 4 2 PPV_Cond1 99 ## 8 20881 55 2 6 89 PPV_Cond1 99 ## 9 39751 28 2 6 6 PPV_Cond1 99 ## 10 99384 46 1 5 0 PPV_Cond1 1 ## # … with 93 more rows # Renombrar columnas DF_name %&gt;% rename(Identificador = ID, Sexo = Genero) ## # A tibble: 103 x 8 ## X1 Identificador Sexo Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Renombrar usando la posicion (DANGER!) DF_name %&gt;% rename(Identificador = 2) ## # A tibble: 103 x 8 ## X1 Identificador Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Renombrar usando vectores oldnames = c(&quot;ID&quot;,&quot;Genero&quot;) newnames = c(&quot;Identificador&quot;,&quot;Sexo&quot;) DF_name %&gt;% rename_at(vars(oldnames), ~ newnames) ## # A tibble: 103 x 8 ## X1 Identificador Sexo Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.2.2.2.1 Selección avanzada con select_helpers() El everything() que usamos dentro de select() más arriba es uno de los select_helpers() existentes. Estos permiten realizar operaciones de selección de variables de manera más sencilla. select_helpers() starts_with(): Empieza con un prefijo (e.g. starts_with(\")) ends_with(): Ends with a suffix contains(): Contains a literal string matches(): Matches a regular expression num_range(): Matches a numerical range like x01, x02, x03 one_of(): Matches variable names in a character vector everything(): Matches all variables last_col(): Select last variable, possibly with an offset Trabajaremos con los datos del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base RAW en formato wide. # DF original df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) cat(names(df_wide)) ## ID dem_genero dem_edad dem_nivedu WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod WVOC_06_cod WVOC_07_cod WVOC_08_cod WVOC_09_cod WVOC_10_cod WVOC_11_cod WVOC_12_cod WVOC_13_cod WVOC_14_cod WVOC_15_cod WVOC_16_cod WVOC_17_cod WVOC_18_cod WVOC_19_cod WVOC_20_cod WVOC_21_cod WVOC_22_cod WVOC_23_cod WVOC_24_cod WVOC_25_cod WVOC_26_cod WVOC_27_cod WVOC_28_cod WVOC_29_cod WVOC_30_cod WVOC_31_cod WVOC_32_cod WVOC_33_cod WVOC_TOTAL WVOC_TOTAL_STD WMAT_01_cod WMAT_01_raw WMAT_02_cod WMAT_02_raw WMAT_03_cod WMAT_03_raw WMAT_04_cod WMAT_04_raw WMAT_05_cod WMAT_05_raw WMAT_06_cod WMAT_06_raw WMAT_07_cod WMAT_07_raw WMAT_08_cod WMAT_08_raw WMAT_09_cod WMAT_09_raw WMAT_10_cod WMAT_10_raw WMAT_11_cod WMAT_11_raw WMAT_12_cod WMAT_12_raw WMAT_13_cod WMAT_13_raw WMAT_14_cod WMAT_14_raw WMAT_15_cod WMAT_15_raw WMAT_16_cod WMAT_16_raw WMAT_17_cod WMAT_17_raw WMAT_18_cod WMAT_18_raw WMAT_19_cod WMAT_19_raw WMAT_20_cod WMAT_20_raw WMAT_21_cod WMAT_21_raw WMAT_22_cod WMAT_22_raw WMAT_23_cod WMAT_23_raw WMAT_24_cod WMAT_24_raw WMAT_25_cod WMAT_25_raw WMAT_26_cod WMAT_26_raw WMAT_A WMAT_B WMAT_C wmat_total wmat_total_std bfbs_01_cod bfbs_01_conf bfbs_01_raw bfbs_03_cod bfbs_03_conf bfbs_03_raw bfbs_04_cod bfbs_04_conf bfbs_04_raw bfbs_10_cod bfbs_10_conf bfbs_10_raw bfbs_12_cod bfbs_12_conf bfbs_12_raw bfbs_14_cod bfbs_14_conf bfbs_14_raw bfbs_17_cod bfbs_17_conf bfbs_17_raw bfbs_23_cod bfbs_23_conf bfbs_23_raw bfbs_conf_total bfbs_cong_conf bfbs_cong_total bfbs_creib_conf bfbs_creib_total bfbs_incong_conf bfbs_incon_total bfbs_increib_conf bfbs_increib_total bfbs_invalid_conf bfbs_invalid_total bfbs_total bfbs_valid_conf bfbs_valid_total EA_01_raw EA_02_raw EA_03_raw EA_04_raw EA_05_raw EA_06_raw EA_07_raw EA_08_raw EA_09_raw EA_10_raw EA_11_raw EA_12_raw EA_13_raw EA_14_raw EA_15_raw EA_16_raw EA_17_raw EA_18_raw EA_19_raw EA_20_raw EA_21_raw EA_22_raw EA_23_raw EA_24_raw EA_azar_TOTAL EA_control_interno_TOTAL EA_otros_poderosos_TOTAL EAR_01_raw EAR_02_raw EAR_03_raw EAR_04_raw EAR_05_raw EAR_06_raw EAR_07_raw EAR_08_raw EAR_09_raw EAR_10_raw EAR_TOTAL ECRRS_ansiedad_TOTAL ECRRS_evitacion_TOTAL ECRRS_madre_01_raw ECRRS_madre_02_raw ECRRS_madre_03_raw ECRRS_madre_04_raw ECRRS_madre_05_raw ECRRS_madre_06_raw ECRRS_madre_07_raw ECRRS_madre_08_raw ECRRS_madre_09_raw ECRRS_madre_ansiedad_TOTAL ECRRS_madre_evitacion_TOTAL ECRRS_mejoramig_01_raw ECRRS_mejoramig_02_raw ECRRS_mejoramig_03_raw ECRRS_mejoramig_04_raw ECRRS_mejoramig_05_raw ECRRS_mejoramig_06_raw ECRRS_mejoramig_07_raw ECRRS_mejoramig_08_raw ECRRS_mejoramig_09_raw ECRRS_mejoramigo_ansiedad_TOTAL ECRRS_mejoramigo_evitacion_TOTAL ECRRS_padre_01_raw ECRRS_padre_02_raw ECRRS_padre_03_raw ECRRS_padre_04_raw ECRRS_padre_05_raw ECRRS_padre_06_raw ECRRS_padre_07_raw ECRRS_padre_08_raw ECRRS_padre_09_raw ECRRS_padre_ansiedad_TOTAL ECRRS_padre_evitacion_TOTAL ECRRS_pareja_01_raw ECRRS_pareja_02_raw ECRRS_pareja_03_raw ECRRS_pareja_04_raw ECRRS_pareja_05_raw ECRRS_pareja_06_raw ECRRS_pareja_07_raw ECRRS_pareja_08_raw ECRRS_pareja_09_raw ECRRS_pareja_ansiedad_TOTAL ECRRS_pareja_evitacion_TOTAL GHQ_01 GHQ_02 GHQ_03 GHQ_04 GHQ_05 GHQ_06 GHQ_07 GHQ_08 GHQ_09 GHQ_10 GHQ_11 GHQ_12 GHQ_autoestima_TOTAL GHQ_estres_TOTAL GHQ_exito_afrontamiento_TOTAL GHQ_TOTAL wdig_dir_total wdig_inv_total WDIGSIMB_TOTAL wdig_total wdig_total_std lkns_01_cod lkns_01_raw lkns_02_cod lkns_02_raw lkns_03_cod lkns_03_raw lkns_04_cod lkns_04_raw lkns_05_cod lkns_05_raw lkns_06_cod lkns_06_raw lkns_07_cod lkns_07_raw lkns_08_cod lkns_08_raw lkns_09_cod lkns_09_raw lkns_10_cod lkns_10_raw lkns_11_cod lkns_11_raw lkns_total SASS_01_raw SASS_02_raw SASS_03_raw SASS_04_raw SASS_05_raw SASS_06_raw SASS_07_raw SASS_08_raw SASS_09_raw SASS_10_raw SASS_11_raw SASS_12_raw SASS_13_raw SASS_14_raw SASS_15_raw SASS_16_raw SASS_17_raw SASS_18_raw SASS_19_raw SASS_20_raw SASS_21_raw SASS_TOTAL SASS_trabajo bayes_all_accuracy bayes_all_confidence bayes_pictorial_qualitative_accuracy bayes_pictorial_quantitative_accuracy bayes_text_qualitative_accuracy bayes_text_quantitative_accuracy # Seleccionamos variables que contienen la cadena de texto &quot;dem&quot; df_wide %&gt;% select(contains(&quot;dem&quot;)) ## # A tibble: 232 x 3 ## dem_genero dem_edad dem_nivedu ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 38 4 ## 2 0 67 2 ## 3 0 24 4 ## 4 0 30 4 ## 5 0 38 3 ## 6 0 45 4 ## 7 1 58 3 ## 8 1 47 4 ## 9 1 52 3 ## 10 1 49 4 ## # … with 222 more rows # Seleccionamos variables que acacan con la cadena de texto &quot;cod&quot; df_wide %&gt;% select(ID, ends_with(&quot;cod&quot;)) ## # A tibble: 232 x 79 ## ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod WVOC_06_cod ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 2 2 1 2 2 ## 2 2 2 2 2 1 0 0 ## 3 3 2 2 2 1 2 2 ## 4 4 2 1 1 1 2 2 ## 5 5 2 2 1 1 0 0 ## 6 6 1 1 2 1 2 2 ## 7 7 1 0 2 1 0 0 ## 8 8 2 2 2 1 2 2 ## 9 9 2 2 2 2 2 1 ## 10 10 2 2 2 2 2 0 ## # … with 222 more rows, and 72 more variables: WVOC_07_cod &lt;dbl&gt;, ## # WVOC_08_cod &lt;dbl&gt;, WVOC_09_cod &lt;dbl&gt;, WVOC_10_cod &lt;dbl&gt;, WVOC_11_cod &lt;dbl&gt;, ## # WVOC_12_cod &lt;dbl&gt;, WVOC_13_cod &lt;dbl&gt;, WVOC_14_cod &lt;dbl&gt;, WVOC_15_cod &lt;dbl&gt;, ## # WVOC_16_cod &lt;dbl&gt;, WVOC_17_cod &lt;dbl&gt;, WVOC_18_cod &lt;dbl&gt;, WVOC_19_cod &lt;dbl&gt;, ## # WVOC_20_cod &lt;dbl&gt;, WVOC_21_cod &lt;dbl&gt;, WVOC_22_cod &lt;dbl&gt;, WVOC_23_cod &lt;dbl&gt;, ## # WVOC_24_cod &lt;dbl&gt;, WVOC_25_cod &lt;dbl&gt;, WVOC_26_cod &lt;dbl&gt;, WVOC_27_cod &lt;dbl&gt;, ## # WVOC_28_cod &lt;dbl&gt;, WVOC_29_cod &lt;dbl&gt;, WVOC_30_cod &lt;dbl&gt;, WVOC_31_cod &lt;dbl&gt;, ## # WVOC_32_cod &lt;dbl&gt;, WVOC_33_cod &lt;dbl&gt;, WMAT_01_cod &lt;dbl&gt;, WMAT_02_cod &lt;dbl&gt;, ## # WMAT_03_cod &lt;dbl&gt;, WMAT_04_cod &lt;dbl&gt;, WMAT_05_cod &lt;dbl&gt;, WMAT_06_cod &lt;dbl&gt;, ## # WMAT_07_cod &lt;dbl&gt;, WMAT_08_cod &lt;dbl&gt;, WMAT_09_cod &lt;dbl&gt;, WMAT_10_cod &lt;dbl&gt;, ## # WMAT_11_cod &lt;dbl&gt;, WMAT_12_cod &lt;dbl&gt;, WMAT_13_cod &lt;dbl&gt;, WMAT_14_cod &lt;dbl&gt;, ## # WMAT_15_cod &lt;dbl&gt;, WMAT_16_cod &lt;dbl&gt;, WMAT_17_cod &lt;dbl&gt;, WMAT_18_cod &lt;dbl&gt;, ## # WMAT_19_cod &lt;dbl&gt;, WMAT_20_cod &lt;dbl&gt;, WMAT_21_cod &lt;dbl&gt;, WMAT_22_cod &lt;dbl&gt;, ## # WMAT_23_cod &lt;dbl&gt;, WMAT_24_cod &lt;dbl&gt;, WMAT_25_cod &lt;dbl&gt;, WMAT_26_cod &lt;dbl&gt;, ## # bfbs_01_cod &lt;dbl&gt;, bfbs_03_cod &lt;dbl&gt;, bfbs_04_cod &lt;dbl&gt;, bfbs_10_cod &lt;dbl&gt;, ## # bfbs_12_cod &lt;dbl&gt;, bfbs_14_cod &lt;dbl&gt;, bfbs_17_cod &lt;dbl&gt;, bfbs_23_cod &lt;dbl&gt;, ## # lkns_01_cod &lt;dbl&gt;, lkns_02_cod &lt;dbl&gt;, lkns_03_cod &lt;dbl&gt;, lkns_04_cod &lt;dbl&gt;, ## # lkns_05_cod &lt;dbl&gt;, lkns_06_cod &lt;dbl&gt;, lkns_07_cod &lt;dbl&gt;, lkns_08_cod &lt;dbl&gt;, ## # lkns_09_cod &lt;dbl&gt;, lkns_10_cod &lt;dbl&gt;, lkns_11_cod &lt;dbl&gt; # Lo mismo, pero usando expresiones regulares df_wide %&gt;% select(ID, matches(&quot;cod$&quot;)) ## # A tibble: 232 x 79 ## ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod WVOC_06_cod ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 2 2 1 2 2 ## 2 2 2 2 2 1 0 0 ## 3 3 2 2 2 1 2 2 ## 4 4 2 1 1 1 2 2 ## 5 5 2 2 1 1 0 0 ## 6 6 1 1 2 1 2 2 ## 7 7 1 0 2 1 0 0 ## 8 8 2 2 2 1 2 2 ## 9 9 2 2 2 2 2 1 ## 10 10 2 2 2 2 2 0 ## # … with 222 more rows, and 72 more variables: WVOC_07_cod &lt;dbl&gt;, ## # WVOC_08_cod &lt;dbl&gt;, WVOC_09_cod &lt;dbl&gt;, WVOC_10_cod &lt;dbl&gt;, WVOC_11_cod &lt;dbl&gt;, ## # WVOC_12_cod &lt;dbl&gt;, WVOC_13_cod &lt;dbl&gt;, WVOC_14_cod &lt;dbl&gt;, WVOC_15_cod &lt;dbl&gt;, ## # WVOC_16_cod &lt;dbl&gt;, WVOC_17_cod &lt;dbl&gt;, WVOC_18_cod &lt;dbl&gt;, WVOC_19_cod &lt;dbl&gt;, ## # WVOC_20_cod &lt;dbl&gt;, WVOC_21_cod &lt;dbl&gt;, WVOC_22_cod &lt;dbl&gt;, WVOC_23_cod &lt;dbl&gt;, ## # WVOC_24_cod &lt;dbl&gt;, WVOC_25_cod &lt;dbl&gt;, WVOC_26_cod &lt;dbl&gt;, WVOC_27_cod &lt;dbl&gt;, ## # WVOC_28_cod &lt;dbl&gt;, WVOC_29_cod &lt;dbl&gt;, WVOC_30_cod &lt;dbl&gt;, WVOC_31_cod &lt;dbl&gt;, ## # WVOC_32_cod &lt;dbl&gt;, WVOC_33_cod &lt;dbl&gt;, WMAT_01_cod &lt;dbl&gt;, WMAT_02_cod &lt;dbl&gt;, ## # WMAT_03_cod &lt;dbl&gt;, WMAT_04_cod &lt;dbl&gt;, WMAT_05_cod &lt;dbl&gt;, WMAT_06_cod &lt;dbl&gt;, ## # WMAT_07_cod &lt;dbl&gt;, WMAT_08_cod &lt;dbl&gt;, WMAT_09_cod &lt;dbl&gt;, WMAT_10_cod &lt;dbl&gt;, ## # WMAT_11_cod &lt;dbl&gt;, WMAT_12_cod &lt;dbl&gt;, WMAT_13_cod &lt;dbl&gt;, WMAT_14_cod &lt;dbl&gt;, ## # WMAT_15_cod &lt;dbl&gt;, WMAT_16_cod &lt;dbl&gt;, WMAT_17_cod &lt;dbl&gt;, WMAT_18_cod &lt;dbl&gt;, ## # WMAT_19_cod &lt;dbl&gt;, WMAT_20_cod &lt;dbl&gt;, WMAT_21_cod &lt;dbl&gt;, WMAT_22_cod &lt;dbl&gt;, ## # WMAT_23_cod &lt;dbl&gt;, WMAT_24_cod &lt;dbl&gt;, WMAT_25_cod &lt;dbl&gt;, WMAT_26_cod &lt;dbl&gt;, ## # bfbs_01_cod &lt;dbl&gt;, bfbs_03_cod &lt;dbl&gt;, bfbs_04_cod &lt;dbl&gt;, bfbs_10_cod &lt;dbl&gt;, ## # bfbs_12_cod &lt;dbl&gt;, bfbs_14_cod &lt;dbl&gt;, bfbs_17_cod &lt;dbl&gt;, bfbs_23_cod &lt;dbl&gt;, ## # lkns_01_cod &lt;dbl&gt;, lkns_02_cod &lt;dbl&gt;, lkns_03_cod &lt;dbl&gt;, lkns_04_cod &lt;dbl&gt;, ## # lkns_05_cod &lt;dbl&gt;, lkns_06_cod &lt;dbl&gt;, lkns_07_cod &lt;dbl&gt;, lkns_08_cod &lt;dbl&gt;, ## # lkns_09_cod &lt;dbl&gt;, lkns_10_cod &lt;dbl&gt;, lkns_11_cod &lt;dbl&gt; 2.2.2.3 Modificar y añadir variables # DF original DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Modificar variable reemplazando valor DF_name %&gt;% mutate(PPV_DECLARED = PPV_DECLARED/100) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 0.99 ## 2 5 95041 2 21 6 90 PPV_Cond1 0.99 ## 3 6 74594 2 29 6 10 PPV_Cond1 0.99 ## 4 15 72903 2 27 7 75 PPV_Cond1 0.01 ## 5 16 21260 1 29 5 35 PPV_Cond1 0.24 ## 6 18 50315 2 28 6 14 PPV_Cond1 0.99 ## 7 19 21774 2 27 4 2 PPV_Cond1 0.99 ## 8 20 20881 2 55 6 89 PPV_Cond1 0.99 ## 9 21 39751 2 28 6 6 PPV_Cond1 0.99 ## 10 22 99384 1 46 5 0 PPV_Cond1 0.01 ## # … with 93 more rows # Añadir variable DF_name %&gt;% mutate(PPV_DECLARED_PCT = PPV_DECLARED/100) ## # A tibble: 103 x 9 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED_PCT &lt;dbl&gt; # Añadir variable destruyendo el resto del DF DF_name %&gt;% transmute(PPV_DECLARED_PCT = PPV_DECLARED/100) ## # A tibble: 103 x 1 ## PPV_DECLARED_PCT ## &lt;dbl&gt; ## 1 0.99 ## 2 0.99 ## 3 0.99 ## 4 0.01 ## 5 0.24 ## 6 0.99 ## 7 0.99 ## 8 0.99 ## 9 0.99 ## 10 0.01 ## # … with 93 more rows # Limpiar nombres DF_name %&gt;% janitor::clean_names() ## # A tibble: 103 x 8 ## x1 id genero edad educacion follow_up condition ppv_declared ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.2.2.4 Resúmenes agrupados La combinación de verbos group_by() y summarise() es una de las más usadas. Con esta podemos calcular promedios, medianas, etc. por condición de manera sencilla. # Resumen DF_name %&gt;% summarise(Promedio_PPV = mean(PPV_DECLARED), N = n()) ## # A tibble: 1 x 2 ## Promedio_PPV N ## &lt;dbl&gt; &lt;int&gt; ## 1 68.5 103 # Resumen agrupado DF_name %&gt;% group_by(Genero) %&gt;% summarise(Promedio_PPV = mean(PPV_DECLARED), N = n()) ## # A tibble: 2 x 3 ## Genero Promedio_PPV N ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 66.4 40 ## 2 2 69.9 63 # Resumen agrupando por multiples variables, y calculando varias cosas DF_name %&gt;% group_by(Genero, condition) %&gt;% summarise(promedio_PPV = mean(PPV_DECLARED), mediana_PPV = median(PPV_DECLARED), SD = sd(PPV_DECLARED), N = n()) ## # A tibble: 8 x 6 ## # Groups: Genero [2] ## Genero condition promedio_PPV mediana_PPV SD N ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 PPV_Cond1 63.8 88 43.1 9 ## 2 1 PPV_Cond2 51 46 10.3 13 ## 3 1 PPV_Cond3 75.6 80 32.5 5 ## 4 1 PPV_Cond4 80.1 92 19.4 13 ## 5 2 PPV_Cond1 74 99 43.0 19 ## 6 2 PPV_Cond2 49.4 46 16.3 8 ## 7 2 PPV_Cond3 69.2 98.5 38.9 16 ## 8 2 PPV_Cond4 74.7 90 27.3 20 2.2.3 Ejercicios - verbos dplyr Usando la base df_wide, haz las siguientes cosas, una a una: Filtra el DF para quedarnos solo con edades entre 18 y 50 años Ordena los datos por genero y edad, esta última decreciente Selecciona las columnas para quedarnos solo con ID, variables demograficas, y respuestas crudas (raw) Crea una nueva variable que sea niv_edu_porc, en la que calcules cual es el porcentaje de nivel educativo al que han llegado relativo al máximo de la base de datos (nivel educativo persona / nivel educativo maximo; en porcentaje) Ahora combina el resultado de todas las operaciones anteriores en un DF Calcula el promedio y desviación típica de edad para cada género df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) 2.2.4 Verbos avanzados y otras criaturas indómitas 2.2.4.1 Wide to long Empecemos con un ejemplo muy sencillo. 3 participantes, 2 items. # Creamos un DF df_simple_wide = data.frame(ID = c(&quot;Participante1&quot;, &quot;Participante2&quot;, &quot;Participante3&quot;), Item1 = c(22, 33, 44), Item2 = c(88, 99, 77)) df_simple_wide ## ID Item1 Item2 ## 1 Participante1 22 88 ## 2 Participante2 33 99 ## 3 Participante3 44 77 # Wide to long df_simple_long = df_simple_wide %&gt;% gather(Item, Response, Item1:Item2) df_simple_long ## ID Item Response ## 1 Participante1 Item1 22 ## 2 Participante2 Item1 33 ## 3 Participante3 Item1 44 ## 4 Participante1 Item2 88 ## 5 Participante2 Item2 99 ## 6 Participante3 Item2 77 Ahora pasemos a un ejemplo mas complejo. Tenemos las puntuaciones a los 11 items de la lipkus numeracy scale de 232 participantes, ademas de datos demográficos. # Leemos documento en formato WIDE df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) %&gt;% # Seleccionamos solo algunas de las filas select(ID, dem_genero, dem_edad, dem_nivedu, matches(&quot;lkns_[0-9]{2}_raw&quot;)) df_wide ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;dbl&gt;, lkns_07_raw &lt;chr&gt;, lkns_08_raw &lt;dbl&gt;, ## # lkns_09_raw &lt;dbl&gt;, lkns_10_raw &lt;dbl&gt;, lkns_11_raw &lt;dbl&gt; # Wide to long df_wide %&gt;% gather(Item, Response, lkns_01_raw:lkns_11_raw) ## # A tibble: 2,552 x 6 ## ID dem_genero dem_edad dem_nivedu Item Response ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 lkns_01_raw 500 ## 2 2 0 67 2 lkns_01_raw 0 ## 3 3 0 24 4 lkns_01_raw 700 ## 4 4 0 30 4 lkns_01_raw 500 ## 5 5 0 38 3 lkns_01_raw 6 ## 6 6 0 45 4 lkns_01_raw 40 ## 7 7 1 58 3 lkns_01_raw 0 ## 8 8 1 47 4 lkns_01_raw 500 ## 9 9 1 52 3 lkns_01_raw 600 ## 10 10 1 49 4 lkns_01_raw 600 ## # … with 2,542 more rows df_wide %&gt;% gather(Item, Response, 5:15) ## # A tibble: 2,552 x 6 ## ID dem_genero dem_edad dem_nivedu Item Response ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 lkns_01_raw 500 ## 2 2 0 67 2 lkns_01_raw 0 ## 3 3 0 24 4 lkns_01_raw 700 ## 4 4 0 30 4 lkns_01_raw 500 ## 5 5 0 38 3 lkns_01_raw 6 ## 6 6 0 45 4 lkns_01_raw 40 ## 7 7 1 58 3 lkns_01_raw 0 ## 8 8 1 47 4 lkns_01_raw 500 ## 9 9 1 52 3 lkns_01_raw 600 ## 10 10 1 49 4 lkns_01_raw 600 ## # … with 2,542 more rows df_long = df_wide %&gt;% gather(Item, Response, matches(&quot;lkns&quot;)) DT::datatable(df_long) 2.2.4.2 Long to wide Retomamos el ejemplo simple de antes: # Long to wide simple df_simple_long %&gt;% spread(Item, Response) ## ID Item1 Item2 ## 1 Participante1 22 88 ## 2 Participante2 33 99 ## 3 Participante3 44 77 Y lo mismo con el ejemplo mas complejo: # Long to wide df_long %&gt;% spread(Item, Response) ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;chr&gt;, lkns_07_raw &lt;chr&gt;, lkns_08_raw &lt;chr&gt;, ## # lkns_09_raw &lt;chr&gt;, lkns_10_raw &lt;chr&gt;, lkns_11_raw &lt;chr&gt; 2.2.4.2.1 ¿Para que sirve tener los datos en formato long? DF_plot = df_long %&gt;% mutate(Response_num = as.numeric(Response)) DF_plot %&gt;% drop_na(Response_num) %&gt;% ggplot(aes(Item, Response_num, color = Item)) + geom_jitter(alpha = .5) + geom_violin(alpha = .4) + scale_y_log10() + coord_flip() DF_plot %&gt;% filter(is.na(Response_num)) %&gt;% ggplot(aes(Item, Response, color = Item)) + geom_jitter(alpha = .5, height = .2) + facet_wrap(~ Item, scales = &quot;free&quot;) 2.2.4.3 Separate, omit, ifelse, case_when, tipos de variables… # Base original name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) # Separate DF_name %&gt;% separate(condition, c(&quot;primer_chunk&quot;, &quot;segundo_chunk&quot;), sep = &quot;_&quot;) ## # A tibble: 103 x 9 ## X1 ID Genero Edad Educacion FollowUP primer_chunk segundo_chunk ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV Cond1 ## 2 5 95041 2 21 6 90 PPV Cond1 ## 3 6 74594 2 29 6 10 PPV Cond1 ## 4 15 72903 2 27 7 75 PPV Cond1 ## 5 16 21260 1 29 5 35 PPV Cond1 ## 6 18 50315 2 28 6 14 PPV Cond1 ## 7 19 21774 2 27 4 2 PPV Cond1 ## 8 20 20881 2 55 6 89 PPV Cond1 ## 9 21 39751 2 28 6 6 PPV Cond1 ## 10 22 99384 1 46 5 0 PPV Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; # Separate in rows DF_name %&gt;% separate_rows(condition, sep = &quot;_&quot;) ## # A tibble: 206 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV 99 ## 2 4 41904 1 47 8 80 Cond1 99 ## 3 5 95041 2 21 6 90 PPV 99 ## 4 5 95041 2 21 6 90 Cond1 99 ## 5 6 74594 2 29 6 10 PPV 99 ## 6 6 74594 2 29 6 10 Cond1 99 ## 7 15 72903 2 27 7 75 PPV 1 ## 8 15 72903 2 27 7 75 Cond1 1 ## 9 16 21260 1 29 5 35 PPV 24 ## 10 16 21260 1 29 5 35 Cond1 24 ## # … with 196 more rows # Drop NAs DF_name %&gt;% drop_na(PPV_DECLARED) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # If else DF_name %&gt;% mutate(Genero = ifelse(Genero == 1, &quot;Hombre&quot;, &quot;Mujer&quot;)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 Hombre 47 8 80 PPV_Cond1 99 ## 2 5 95041 Mujer 21 6 90 PPV_Cond1 99 ## 3 6 74594 Mujer 29 6 10 PPV_Cond1 99 ## 4 15 72903 Mujer 27 7 75 PPV_Cond1 1 ## 5 16 21260 Hombre 29 5 35 PPV_Cond1 24 ## 6 18 50315 Mujer 28 6 14 PPV_Cond1 99 ## 7 19 21774 Mujer 27 4 2 PPV_Cond1 99 ## 8 20 20881 Mujer 55 6 89 PPV_Cond1 99 ## 9 21 39751 Mujer 28 6 6 PPV_Cond1 99 ## 10 22 99384 Hombre 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Case when DF_name %&gt;% mutate(Genero = case_when( Genero == 1 ~ &quot;Hombre&quot;, Genero == 2 ~ &quot;Mujer&quot;, TRUE ~ &quot;Otros&quot;)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 Hombre 47 8 80 PPV_Cond1 99 ## 2 5 95041 Mujer 21 6 90 PPV_Cond1 99 ## 3 6 74594 Mujer 29 6 10 PPV_Cond1 99 ## 4 15 72903 Mujer 27 7 75 PPV_Cond1 1 ## 5 16 21260 Hombre 29 5 35 PPV_Cond1 24 ## 6 18 50315 Mujer 28 6 14 PPV_Cond1 99 ## 7 19 21774 Mujer 27 4 2 PPV_Cond1 99 ## 8 20 20881 Mujer 55 6 89 PPV_Cond1 99 ## 9 21 39751 Mujer 28 6 6 PPV_Cond1 99 ## 10 22 99384 Hombre 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Unite DF_separated = DF_name %&gt;% separate(condition, c(&quot;primer_chunk&quot;, &quot;segundo_chunk&quot;), sep = &quot;_&quot;) DF_separated %&gt;% unite(condition, c(primer_chunk, segundo_chunk), sep = &quot;_&quot;) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Pull DF_name %&gt;% pull(PPV_DECLARED) %&gt;% mean(.) ## [1] 68.52427 2.2.4.4 Regular expressions Basic Regular Expressions Cheatsheet SOURCE: https://xkcd.com/208/ DF_regexp = DF_name %&gt;% select(-X1); DF_regexp ## # A tibble: 103 x 7 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 1 47 8 80 PPV_Cond1 99 ## 2 95041 2 21 6 90 PPV_Cond1 99 ## 3 74594 2 29 6 10 PPV_Cond1 99 ## 4 72903 2 27 7 75 PPV_Cond1 1 ## 5 21260 1 29 5 35 PPV_Cond1 24 ## 6 50315 2 28 6 14 PPV_Cond1 99 ## 7 21774 2 27 4 2 PPV_Cond1 99 ## 8 20881 2 55 6 89 PPV_Cond1 99 ## 9 39751 2 28 6 6 PPV_Cond1 99 ## 10 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Regexp DF_regexp %&gt;% mutate(condition = gsub(&quot;PPV_&quot;, &quot;&quot;, condition)) %&gt;% mutate(condition_N = gsub(&quot;.*([[:digit:]]$)&quot;, &quot;\\\\1&quot;, condition)) ## # A tibble: 103 x 8 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED condition_N ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 41904 1 47 8 80 Cond1 99 1 ## 2 95041 2 21 6 90 Cond1 99 1 ## 3 74594 2 29 6 10 Cond1 99 1 ## 4 72903 2 27 7 75 Cond1 1 1 ## 5 21260 1 29 5 35 Cond1 24 1 ## 6 50315 2 28 6 14 Cond1 99 1 ## 7 21774 2 27 4 2 Cond1 99 1 ## 8 20881 2 55 6 89 Cond1 99 1 ## 9 39751 2 28 6 6 Cond1 99 1 ## 10 99384 1 46 5 0 Cond1 1 1 ## # … with 93 more rows read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) %&gt;% # Seleccionamos solo algunas de las filas select(ID, dem_genero, dem_edad, dem_nivedu, matches(&quot;lkns_[0-9]{2}_raw&quot;)) ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;dbl&gt;, lkns_07_raw &lt;chr&gt;, lkns_08_raw &lt;dbl&gt;, ## # lkns_09_raw &lt;dbl&gt;, lkns_10_raw &lt;dbl&gt;, lkns_11_raw &lt;dbl&gt; Una aplicación Shiny para ayudar a construir Regular Expressions: regexplain::regex_gadget() 2.2.5 Ejercicios - verbos avanzados dplyr Trabajaremos con los datos procesados del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base final en formato wide (archivo: /outputs/data/sa-prepared.csv). Cambia el orden de las variables para que ID sea la primera columna. Transforma la base a formato long. Crea un nuevo DF (DF_split) donde crees una variable llamada social_adaptation_split con la median split para la variable Social.Adaptation. La mitad superior se llamará high_social_adaptation y la mitad inferior low_social_adaptation. Asegúrate que no hay valores NA. El resultado final debería ser: Ahora volvemos a usar con los datos brutos (sa-raw-anonymised.csv) del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al.  En estos datos se muestran las puntuaciones crudas (e.g. WMAT_01_raw) y ya codificadas/corregidas (WMAT_01_cod) para los ítems de varias pruebas. Con los datos de los ítems de cada prueba, necesitamos calcular el puntaje para cada participante. Empezaremos con la prueba de Matrices de WAIS (WMAT_). Extrae la suma para cada participante de los ítems WMAT_*_cod. Hay al menos dos estrategias posibles: Selecciona las columnas relevantes y haz la suma de columnas Convierte a long, filtra para quedarte con las filas correspondientes a la prueba relevante, y haz una suma agrupada df_wide_raw = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) 2.3 Combinar bases de datos 2.3.1 Bind # Importar CSVs DF1 = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;, &quot;01.csv&quot;)) DF2 = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;, &quot;02.csv&quot;)) # Bind DFs añadiendo las *filas* de DF2 a DF1 DF1 %&gt;% bind_rows(DF2) ## # A tibble: 800 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 790 more rows # Bind DFs añadiendo las *columnas* de DF2 a DF1 # bind_cols renombra automaticamente los nombres de las columnas para que no haya coincidencias DF1 %&gt;% bind_cols(DF2) ## # A tibble: 400 x 18 ## Sex...1 Priming...2 trialN...3 Block...4 Adjective...5 Valence...6 Answer...7 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 male Collective 1 we ofensivo negative yes ## 2 male Collective 2 we resentido negative no ## 3 male Collective 3 we ego�sta negative yes ## 4 male Collective 4 we indiscreto negative yes ## 5 male Collective 5 we sumiso negative yes ## 6 male Collective 6 we agradable positive yes ## 7 male Collective 7 we clasista negative yes ## 8 male Collective 8 we altruista positive yes ## 9 male Collective 9 we ansioso negative yes ## 10 male Collective 10 we presumido negative yes ## # … with 390 more rows, and 11 more variables: Arrow...8 &lt;chr&gt;, rT...9 &lt;dbl&gt;, ## # Sex...10 &lt;chr&gt;, Priming...11 &lt;chr&gt;, trialN...12 &lt;dbl&gt;, Block...13 &lt;chr&gt;, ## # Adjective...14 &lt;chr&gt;, Valence...15 &lt;chr&gt;, Answer...16 &lt;chr&gt;, ## # Arrow...17 &lt;chr&gt;, rT...18 &lt;dbl&gt; 2.3.2 Joins El paquete {dplyr} tiene funciones que permiten trabajar combinando, filtrando, etc. distintos dataframes. Podéis ver más detalle y algunas ilustraciones fantásticas (como la de abajo; inner_join()) en el capítulo relational data de r4ds. SOURCE: https://r4ds.had.co.nz/relational-data.html#mutating-joins En https://github.com/gadenbuie/tidyexplain se pueden ver animaciones mostrando estas operaciones. Tipos de Join Estas operaciones tendrán la forma: DF_x %&gt;% WHATEVER_join(DF_y) Mutating joins: inner_join(): preserva pares de observaciones de de DF_x y de DF_y con claves iguales left_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales right_join(): preserva las observaciones de DF_y, añadiendo las de DF_x con claves iguales full_join(): preserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales Filtering joins: semi_join(): preserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y anti_join(): preserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y Nesting joins: nest_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales 2.3.2.1 Mutating joins Importamos datos Tenemos los siguientes dataframes: DF_IDs: Variables demográficas de participantes DF_results: Resultados en variables de interés de participantes DF_BAD: Grupo de participantes “selectos” # Importar CSVs para los joins DF_IDs = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-IDs.csv&quot;)) DF_results = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-results.csv&quot;)) DF_BAD = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-BAD.csv&quot;)) # DT::datatable(DF_IDs) # DT::datatable(DF_results) # DT::datatable(DF_BAD) 2.3.2.1.1 Inner join Preserva pares de observaciones de de DF_x y de DF_y con claves iguales. SOURCE: https://github.com/gadenbuie/tidyexplain DF_inner_joined = DF_IDs %&gt;% inner_join(DF_results) #nrow(DF_inner_joined) DT::datatable(DF_inner_joined) 2.3.2.1.2 Left join Preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales. SOURCE: https://github.com/gadenbuie/tidyexplain DF_left_joined = DF_IDs %&gt;% left_join(DF_results) #nrow(DF_left_joined) DT::datatable(DF_left_joined) 2.3.2.1.3 Full join Preserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales. SOURCE: https://github.com/gadenbuie/tidyexplain DF_full_joined = DF_IDs %&gt;% full_join(DF_results) #nrow(DF_full_joined) DT::datatable(DF_full_joined) 2.3.2.2 Filtering joins 2.3.2.2.1 Anti join Preserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y. SOURCE: https://github.com/gadenbuie/tidyexplain # AVOID the people present in DF_BAD DF_anti_joined = DF_IDs %&gt;% anti_join(DF_BAD, by = &quot;ID&quot;) %&gt;% left_join(DF_results) DT::datatable(DF_anti_joined) 2.3.2.2.2 Semi join Preserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y. SOURCE: https://github.com/gadenbuie/tidyexplain # INCLUDE ONLY the people present in DF_BAD DF_semi_joined = DF_IDs %&gt;% semi_join(DF_BAD, by = &quot;ID&quot;) %&gt;% left_join(DF_results) DT::datatable(DF_semi_joined) 2.3.2.3 Nesting joins DF_nest_joined = DF_IDs %&gt;% nest_join(DF_results, by = &quot;ID&quot;) DT::datatable(DF_nest_joined) 2.3.3 Ejercicios JOINS Con los DFs de abajo, haz las siguientes operaciones: DF_IDs = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-IDs2.csv&quot;)) DF_results = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-results.csv&quot;)) DF_BAD = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-BAD.csv&quot;)) Une los datos demográficos con los resultados A la base resultante, quítale los sujetos descartados de DF_BAD Crea una nueva base con datos demográficos y resultados para los sujetos descartados Comprueba si el promedio para Crystallized Intelligence de los participantes descartados difiere de la de los no descartados Haz una gráfica donde se puedan ver las diferencias En el ejercicio 3 de verbos avanzados creaste un DF llamado DF_split con la median split a partir de la variable Social.Adaptation. Uno ese DF al DF_long que habías creado en el ejercicio 2 de la misma sección. El DF final se vera así: Haz un plot donde se vea la distribución para todas las variables de resultados de los dos niveles de social_adaptation_split. El plot que vimos en el tema anterior tiene el problema de que los datos de tuberculosis son en números absolutos. Serias capaz de convertir estos a % de la población, como se ve en el plot de abajo? 2.4 Más allá de la manipulación 2.4.1 Fast and Frugal trees Hay un paquete fantástico de Nathaniel Phillips llamado {FFTrees}. Este permite crear, visualizar y evaluar fast-and-frugal decision trees DF_wide = read.csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv&quot;) %&gt;% mutate(Anxious.Attachment = round(Anxious.Attachment, 2)) median_social_adaptation = DF_wide %&gt;% pull(Social.Adaptation) %&gt;% median(., na.rm = TRUE) DF_split = DF_wide %&gt;% mutate(high_social_adaptation = case_when( Social.Adaptation &gt;= median_social_adaptation ~ TRUE, Social.Adaptation &lt; median_social_adaptation ~ FALSE)) %&gt;% select(-ID, -Social.Adaptation) %&gt;% drop_na() sa.fft &lt;- FFTrees(formula = high_social_adaptation ~., data = DF_split) # Plotear el arbol de decision plot(sa.fft, main = &quot;Social adaptation&quot;, decision.labels = c(&quot;Low&quot;, &quot;High&quot;)) # Describe el algoritmo sa.fft$inwords ## NULL 2.4.2 Machine learning Con el paquete {caret} podemos usar alguno de los 238 distintos métodos de machine learning. Por ejemplo, Backprop: # ensure the results are repeatable set.seed(7) DF_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv&quot;) %&gt;% janitor::clean_names() %&gt;% as.data.frame() median_social_adaptation = DF_wide %&gt;% pull(social_adaptation) %&gt;% median(., na.rm = TRUE) DB_x = DF_wide %&gt;% mutate(high_social_adaptation = as.factor( case_when( social_adaptation &gt;= median_social_adaptation ~ &quot;high&quot;, social_adaptation &lt; median_social_adaptation ~ &quot;low&quot;))) %&gt;% select(-id, -social_adaptation) %&gt;% drop_na() %&gt;% select(high_social_adaptation, everything()) # calculate correlation matrix correlationMatrix &lt;- cor(DB_x[,2:ncol(DB_x)]) # print(correlationMatrix) # find attributes that are highly corrected (ideally &gt;0.75) highlyCorrelated &lt;- findCorrelation(correlationMatrix, cutoff = 0.25) # print(highlyCorrelated) DB_final = DB_x %&gt;% select(all_of(highlyCorrelated)) %&gt;% select(high_social_adaptation, everything()) %&gt;% as.data.frame() # prepare training scheme control &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 10, repeats = 3) # train the model model &lt;- train(high_social_adaptation ~ ., data = DB_final, method = &quot;lvq&quot;, preProcess = &quot;scale&quot;, trControl = control) # estimate variable importance importance &lt;- varImp(model, scale = FALSE) # print(importance) # plot importance plot(importance) # define the control using a random forest selection function control &lt;- rfeControl(functions = rfFuncs, method = &quot;cv&quot;, number = 10) # run the RFE algorithm results &lt;- rfe(DB_final[,2:ncol(DB_final)], DB_final[,1], sizes = c(1:ncol(DB_final)), rfeControl = control) # summarize the results print(results) ## ## Recursive feature selection ## ## Outer resampling method: Cross-Validated (10 fold) ## ## Resampling performance over subset size: ## ## Variables Accuracy Kappa AccuracySD KappaSD Selected ## 1 0.5444 0.06947 0.04637 0.09913 ## 2 0.5877 0.16723 0.08935 0.17367 ## 3 0.6537 0.30008 0.07950 0.15638 ## 4 0.6299 0.25436 0.05316 0.10521 ## 5 0.6535 0.30535 0.06075 0.11840 ## 6 0.6578 0.31455 0.03172 0.06010 * ## ## The top 5 variables (out of 6): ## stress, internal_locus, crystallized_intelligence, fluid_intelligence, age # list the chosen features predictors(results) ## [1] &quot;stress&quot; &quot;internal_locus&quot; ## [3] &quot;crystallized_intelligence&quot; &quot;fluid_intelligence&quot; ## [5] &quot;age&quot; &quot;sex&quot; # plot the results plot(results, type = c(&quot;g&quot;, &quot;o&quot;)) 2.5 Datasets interesantes En los siguientes repositorios podréis encontrar datasets interesantes para jugar. fivethirtyeight Our World in Data TidyTuesday Bibliografía Cheatsheets RStudio Cheatsheet dplyr data-carpentry-week lesson_joins R4ds - Joins Tidyexplain "],["análisis-de-datos-exploratorio.html", "Capítulo 3 Análisis de datos exploratorio 3.1 Visualizando distribuciones 3.2 Covariación 3.3 Ejercicios finales Bibliografía", " Capítulo 3 Análisis de datos exploratorio Paquetes para este capítulo if (!require(&#39;dplyr&#39;)) install.packages(&#39;dplyr&#39;); library(&#39;dplyr&#39;) if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) if (!require(&#39;haven&#39;)) install.packages(&#39;haven&#39;); library(&#39;haven&#39;) if (!require(&#39;inspectdf&#39;)) install.packages(&#39;inspectdf&#39;); library(&#39;inspectdf&#39;) if (!require(&#39;tidyr&#39;)) install.packages(&#39;tidyr&#39;); library(&#39;tidyr&#39;) VER: R 4 data science - exploratory data analysis 3.1 Visualizando distribuciones 3.1.1 Variables categóricas ggplot(gapminder, aes(continent)) + geom_bar() gapminder %&gt;% count(continent) ## # A tibble: 5 x 2 ## continent n ## &lt;fct&gt; &lt;int&gt; ## 1 Africa 624 ## 2 Americas 300 ## 3 Asia 396 ## 4 Europe 360 ## 5 Oceania 24 3.1.2 Variables continuas ggplot(gapminder, aes(lifeExp)) + geom_histogram(binwidth = 1) gapminder %&gt;% count(lifeExp) ## # A tibble: 1,626 x 2 ## lifeExp n ## &lt;dbl&gt; &lt;int&gt; ## 1 23.6 1 ## 2 28.8 1 ## 3 30 1 ## 4 30.0 1 ## 5 30.3 1 ## 6 30.3 1 ## 7 31.2 1 ## 8 31.3 1 ## 9 31.6 1 ## 10 32.0 1 ## # … with 1,616 more rows gapminder %&gt;% count(cut_width(lifeExp, 10)) ## # A tibble: 7 x 2 ## `cut_width(lifeExp, 10)` n ## &lt;fct&gt; &lt;int&gt; ## 1 [15,25] 1 ## 2 (25,35] 32 ## 3 (35,45] 273 ## 4 (45,55] 348 ## 5 (55,65] 329 ## 6 (65,75] 548 ## 7 (75,85] 173 ggplot(gapminder, aes(lifeExp)) + geom_freqpoly(binwidth = 2) 3.1.3 Ejercicio variables individuales Usando el DF mpg, visualiza la distribucion de las variables manufacturer, class, trans, hwy y cty 3.1.4 Visualizando datasets completos Cuando nos llega una nueva base de datos, una de las primeras cosas que haremos será familiarizarnos con los datos. Cómo se distribuyen, cual es la relación entre distintas variables, etc. # Wide to long d &lt;- gather(gapminder) %&gt;% filter(value != 999) %&gt;% # Si existiera algun codigo para missing values, filtrar mutate(value_NUM = as.numeric(value)) # Plot numeric variables d %&gt;% drop_na(value_NUM) %&gt;% ggplot(aes(value_NUM)) + facet_wrap(~ key, scales = &quot;free&quot;) + geom_histogram(bins = 15) #+ scale_x_log10() # Plot non-numeric variables d %&gt;% drop_na(value) %&gt;% filter(is.na(value_NUM)) %&gt;% ggplot(aes(value)) + facet_wrap(~ key, scales = &quot;free&quot;) + geom_bar() + coord_flip() 3.1.4.1 inspectdf gapminder %&gt;% inspectdf::inspect_na() ## # A tibble: 6 x 3 ## col_name cnt pcnt ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 country 0 0 ## 2 continent 0 0 ## 3 year 0 0 ## 4 lifeExp 0 0 ## 5 pop 0 0 ## 6 gdpPercap 0 0 gapminder %&gt;% inspectdf::inspect_na() %&gt;% show_plot + coord_flip() gapminder_cat &lt;- gapminder %&gt;% inspectdf::inspect_cat() gapminder_cat %&gt;% inspectdf::show_plot() gapminder_num &lt;- gapminder %&gt;% inspectdf::inspect_num() gapminder_num %&gt;% inspectdf::show_plot() 3.2 Covariación 3.2.1 Variable categórica y continua Podemos contar el numero de elementos por nivel de la variable o ver densidad, etc. ggplot(gapminder, aes(lifeExp, colour = continent)) + geom_freqpoly(binwidth = 2) # Lo mismo pero usando stat(count) ggplot(gapminder, aes(lifeExp, stat(count), colour = continent)) + geom_freqpoly(binwidth = 2) # En stat() podemos usar combinaciones de funciones ggplot(gapminder, aes(lifeExp, stat(density/max(density)), colour = continent)) + geom_freqpoly(binwidth = 2) Podemos ver boxplots para cada nivel de la variable categórica: ggplot(gapminder, aes(continent, lifeExp)) + geom_boxplot() ggplot(gapminder, aes(reorder(x = continent, X = lifeExp, FUN = median), lifeExp)) + geom_boxplot() # Que feo ha quedado el titulo del eje x ggplot(gapminder, aes(reorder(x = continent, X = lifeExp, FUN = median), lifeExp)) + geom_boxplot() + labs(x = &quot;Continente&quot;) Y podemos usar geom_density_ridges() para combinar puntos con distribuciones: ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) ¿Qué estamos viendo exáctamente arriba? Hay un punto por cada pais, y por cada año, lo que da lugar aalgo bien dificil de interpretar. Podemos ver los datos únicamente del último año: gapminder %&gt;% group_by(year) %&gt;% summarise(n()) ## # A tibble: 12 x 2 ## year `n()` ## &lt;int&gt; &lt;int&gt; ## 1 1952 142 ## 2 1957 142 ## 3 1962 142 ## 4 1967 142 ## 5 1972 142 ## 6 1977 142 ## 7 1982 142 ## 8 1987 142 ## 9 1992 142 ## 10 1997 142 ## 11 2002 142 ## 12 2007 142 ggplot(gapminder %&gt;% filter(year == 2007), aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) Me pregunto si será muy evidente la diferencia entre los extremos en la base de datos, 1952 y 2007: A = ggplot(gapminder %&gt;% filter(year == 1952), aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;1952&quot;) B = ggplot(gapminder %&gt;% filter(year == 2007), aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;2007&quot;) cowplot::plot_grid(A, B) Finalmente, podemos ver el avance por país de una manera más directa: # METODO 1: Asumimos que el valor máximo corresponde al más actualizado DF_gapminder_max_min = gapminder %&gt;% group_by(continent, country) %&gt;% summarise(lifeExp = max(lifeExp) - min(lifeExp)) ggplot(DF_gapminder_max_min, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Diferencia entre max y min por país&quot;) # METODO 2: Calculamos maximo - mínimo para cada país DF_last_year = gapminder %&gt;% filter(year == max(year)) %&gt;% select(country, continent, lifeExp) %&gt;% rename(lifeExp_max = lifeExp) DF_first_year = gapminder %&gt;% filter(year == min(year)) %&gt;% select(country, continent, lifeExp) %&gt;% rename(lifeExp_min = lifeExp) DF_last_first = DF_last_year %&gt;% full_join(DF_first_year, by = c(&quot;country&quot;, &quot;continent&quot;)) %&gt;% mutate(DIFF = lifeExp_max - lifeExp_min) # gather(max_min, value, lifeExp_max:lifeExp_min) ggplot(DF_last_first, aes(DIFF, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Diferencia entre 2007 y 1952 por pais&quot;) 3.2.2 Ejercicio covariacion 1 Mira el plot donde mostramos la diferencia entre los extremos en la base de datos, 1952 y 2007 con dos gráficas, una al lado de la otra. Ves algún problema? Trata de resolver el problema en las escalas. El resultado final deberia ser: 3.2.3 Dos variables categóricas ggplot(diamonds, aes(cut, color)) + geom_count() diamonds %&gt;% count(color, cut) ## # A tibble: 35 x 3 ## color cut n ## &lt;ord&gt; &lt;ord&gt; &lt;int&gt; ## 1 D Fair 163 ## 2 D Good 662 ## 3 D Very Good 1513 ## 4 D Premium 1603 ## 5 D Ideal 2834 ## 6 E Fair 224 ## 7 E Good 933 ## 8 E Very Good 2400 ## 9 E Premium 2337 ## 10 E Ideal 3903 ## # … with 25 more rows diamonds %&gt;% count(color, cut) %&gt;% ggplot(aes(color, cut, fill = n)) + geom_tile() 3.2.4 Dos variables continuas ggplot(gapminder, aes(lifeExp, gdpPercap)) + geom_point() ggplot(gapminder, aes(lifeExp, gdpPercap, color = continent)) + geom_point(alpha = 1 / 2) + scale_y_log10() ggplot(gapminder, aes(lifeExp, gdpPercap)) + geom_hex() ggplot(gapminder, aes(lifeExp, gdpPercap)) + geom_boxplot(mapping = aes(group = cut_width(lifeExp, 10))) + scale_y_log10() 3.2.5 Ejercicio covariación 2 Usando el DF mpg, visualiza la covariación entre: manufacturer y hwy class y hwy hwy y cty 3.3 Ejercicios finales 3.3.1 Ejercicio exploración base nueva Usando la base del paper Cancer Screening Risk Literacy of Physicians in Training, haz un primer análisis exploratorio que incluya: histogramas de todas las variables numéricas y no-numéricas scatterplots de la relación entre comprensión y numeracy, y entre comprensión y screenbeliefs Bibliografía Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ "],["trabajo-con-rmarkdown-para-reportes-reproducibles.html", "Capítulo 4 Trabajo con RMarkdown para reportes reproducibles Dependencias 4.1 Que es la reproducibilidad 4.2 Proyectos de R-Studio 4.3 Control de cambios con Git y Github 4.4 RMarkdown, openscience y análisis reproducibles 4.5 Sintaxis, chunks de código, tipos de archivo 4.6 De los datos al reporte final: Una historia de amor con R 4.7 Avanzado 4.8 Mas allá de Rmarkdown 4.9 Varios Bibliografía", " Capítulo 4 Trabajo con RMarkdown para reportes reproducibles if (!require(&#39;afex&#39;)) install.packages(&#39;afex&#39;); library(&#39;afex&#39;) if (!require(&#39;correlation&#39;)) install.packages(&quot;correlation&quot;); library(&#39;correlation&#39;) if (!require(&#39;corrr&#39;)) install.packages(&#39;corrr&#39;); library(&#39;corrr&#39;) if (!require(&#39;ggraph&#39;)) install.packages(&#39;ggraph&#39;); library(&#39;ggraph&#39;) if (!require(&#39;gtsummary&#39;)) install.packages(&#39;gtsummary&#39;); library(&#39;gtsummary&#39;) if (!require(&#39;knitr&#39;)) install.packages(&#39;knitr&#39;); library(&#39;knitr&#39;) if (!require(&#39;remotes&#39;)) install.packages(&#39;remotes&#39;); library(&#39;remotes&#39;) if (!require(&#39;renv&#39;)) install.packages(&quot;renv&quot;); library(&#39;renv&#39;) if (!require(&#39;rticles&#39;)) install.packages(&#39;rticles&#39;); library(&#39;rticles&#39;) if (!require(&#39;see&#39;)) install.packages(&quot;see&quot;); library(&#39;see&#39;) if (!require(&#39;stargazer&#39;)) install.packages(&#39;stargazer&#39;); library(&#39;stargazer&#39;) if (!require(&#39;grateful&#39;)) remotes::install_github(&quot;Pakillo/grateful&quot;); library(&#39;grateful&#39;) if (!require(&#39;papaja&#39;)) remotes::install_github(&quot;crsh/papaja&quot;); library(&#39;papaja&#39;) if (!require(&#39;report&#39;)) remotes::install_github(&quot;easystats/report&quot;); library(&#39;report&#39;) Dependencias Instalar Git Windows: https://happygitwithr.com/install-git.html#install-git-windows “Adjusting your PATH environment,” selecciona “Git from the command line and also from 3rd-party software” Mac: https://happygitwithr.com/install-git.html#macos Linux: https://happygitwithr.com/install-git.html#linux Instalar latex: if (!require(&#39;tinytex&#39;)) install.packages(&#39;tinytex&#39;); library(&#39;tinytex&#39;) # Instalar distribución latex automáticamente (llevará un rato) tinytex::install_tinytex() 4.1 Que es la reproducibilidad La crisis de replicación (replication crisis) se inició con un paper que trató de replicar los resultados de 100 investigaciones clásicas. Esta crisis ha generado un movimiento muy interesante dentro de las Ciencias Sociales y la Psicología en particular. Cada vez es más común aplicar algunos principios de buenas prácticas como compartir materiales, datos y scripts de análisis, para que tanto los revisores como otros investigadores puedan entender, reanalizar, etc. nuestras investigaciones. Hay algunas organizaciones que han surgido para tratar de mejorar la colaboración, transparencia, y manera de trabajar: Psychological Science Accelerator Peer Reviewer’s Openness Initiative (PRO) Open Science Foundation Y algunas prácticas y maneras de publicar “nuevas,” se están haciendo cada vez más imprescindibles: Registered reports Preregistration En este capítulo vamos a ver algunos pasos fundamentales para tender un workflow que permita y ayude a la reproducibilidad. 4.2 Proyectos de R-Studio El primer paso empieza por crear un proyecto de RStudio. Al usar proyectos, simplificamos varias cosas, haciendo automáticamente más fácil compartir nuestro trabajo con otras personas. Podéis leer algo más sobre esto aquí. 4.3 Control de cambios con Git y Github Un segundo elemento que nos va a ayudar a trabajar en equipo, y a evitar problemas en proyectos relativamente complejos es el uso de un sistema de control de versiones como Git. Los proyectos de RStudio hacen especialmente sencillo usar Git, click, click, click… SOURCE: https://xkcd.com/1597/ Algunas referencias útiles: OhshitGit website Git in practice happygitwithr En esta sección podemos ver algunos comandos básicos asociados a workflows bien sencillos. 4.3.1 Github github.com es una plataforma web muy popular donde almacenar proyectos de programación. Muchos de los paquetes de R, el mismo RStudio, etc, tienen repositorios abiertos en Github. Una de las ventajas fundamentales de usar Github es que esta plataforma integra algunas herramientas para hacer más sencillo el control de versiones, como el pull request, que nos permite combinar ramas de proyectos sin apenas problemas. SOURCE: https://github.githubassets.com/images/modules/open_graph/github-octocat.png Github tiene un programa especial para estudiantes: https://education.github.com/ 4.3.1.1 Seguir repositorios Algo maravilloso de Github es que muchos de los paquetes que usamos se desarrollan abiertamente en la plataforma, lo que nos permite poder seguir su desarrollo, abrir Issues cuando encontramos algun problema, etc. Por ejemplo, ¿recuerdan el paquete esquisse? Recientemente salió la versión 2.0 que usamos en la primera sesión? Si queremos mantenernos al dia sobre algun paquete, recibir notificaciones cuando salen nuevas versiones, o simplemente marcarlo con una estrellita para no olvidarnos de su existencia, Github nos puede ayudar: SOURCE: www.github.com 4.3.2 Clonar un repositorio existente Algo que podemos hacer con todos los repositorios de Github es clonarlos localmente: En RStudio: File &gt; New Project &gt; Version Control &gt; Git Pega en “repository URL” la URL del repo GitHub (ver imagen de abajo). Será algo similar a https://github.com/VUESTRO_NOMBRE_DE USUARIO/NOMBRE_REPO.git SOURCE: www.github.com 4.3.3 Crear Git y asociar a Github repo Versión simple En www.github.com: Creamos repositorio nuevo Initialize this repository with a README Clonar repositorio Usando el terminal Para prepararnos para usar Git y Github tenemos que hacer lo siguiente: Crear local git repo: usethis::use_git() (cuando creamos un repositorio Git localmente, se crea una carpeta oculta llamada .git) Crear Github Token: usethis::browse_github_token() Insertar token en .Renvirom: usethis::edit_r_environ() Crear Github repo: usethis::use_github() Empujar el repositorio local a Github: git push --set-upstream origin master 4.3.4 Ejercicio Git-Github Haz lo siguiente: Crea un proyecto de RStudio Abre una cuenta en Github! o haz login Sigue los pasos de arriba para crear un repositorio publico y asociarlo a un repositorio local 4.3.5 Workflow Hay diferentes filosofias sobre cual es la mejor manera de trabajar con Git. En este post por Vincent Driessen podeis ver una explicación bien detallada, complementada con imagenes como la que se ve a continuación. SOURCE: https://nvie.com/posts/a-successful-git-branching-model/ El modelo básico implica la existencia de dos ramas. Una master (“producción”), que siempre debe funcionar, y una develop (para desarrollo), donde experimentamos, rompemos cosas, etc. Podeis ver un manual super completo llamado Happy Git and GitHub for the useR elaborado por Jenny Bryan, Jim Hester, entre otros. 4.3.5.1 Modelo básico En RStudio podemos trabajar gráficamente, como se ve abajo, o usando el Terminal: Usando el entorno gráfico, o el terminal Empezamos en la rama master: Pull : nos aseguramos que nuestro repositorio local esta actualizado git pull Branch : Creamos nueva rama llamada development git checkout -b development Hacemos cambios en nuestros scripts Commit : Commiteamos los cambios Añadimos archivos: git add foo.txt Hacemos el commit: git commit --message \"A commit message\" Push : subimos la rama a Github git push origin development Pull request (En Github): Compare &amp; Pull request 2 branches, Pull request Pull : nos aseguramos que nuestro repositorio local esta actualizado git pull 4.3.5.2 Pull request en 3 + 1 sencillos pasos Después de hacer el push de arriba, al entrar en nuestro repositorio deberíamos ver algo parecido a lo siguiente (si no lo vemos, ir a branches). Lo más dificl será hacer click en los botones verdes adecuados: Paso 1. Compare &amp; pull request Paso 2. Create pull request Paso 3. Merge pull request y confirmar Borrar rama antigua 4.3.6 Ejercicio Nuestro primer commit Usando el proyecto de RStudio de antes, crea una rama nueva llamada development Crea un nuevo archivo en formato .Rmd: Haz un commit de ese archivo y subelo (push) a Github (asegurate que esta allá!). No olvides hacer un pull! Ahora haz cambios en el archivo, commitealos, súbelos, y sincroniza tu repo local 4.3.6.1 Feature branch Para la versión más razonable deberiamos tener partir con las siguientes ramas: master development Queremos implementar un nuevo feature o arreglar algun problema: Creamos nueva rama (localmente feature_x) git checkout -b feature_x Hacemos cambios Vemos que cambios hay: git status, o las diferencias exactas git diff Commiteamos los cambios: Añadimos archivos: git add foo.txt Hacemos el commit: git commit --message \"A commit message\" Ahora viene lo bueno… opción sencilla: 3a. Subimos la rama a Github, donde podremos hacer un Pull request: - git push origin feature_x - Si todo ha ido bien, borramos la rama feature_x: git branch -d feature_x La opción menos sencilla: 3b. Si no esperamos conflictos - mergeamos rama a developmentm para poder probar que todo funciona bien. git checkout development git pull origin development --ff-only git merge feature_x git push origin development 4.3.6.2 Stash Hemos hecho algunos cambios pero no queremos hacer commit: git stash Recuperamos los cambios git checkout rama_en_la_que_recuperar_cambios git stash apply Queremos destruir el stash git stash drop 4.4 RMarkdown, openscience y análisis reproducibles RMarkdown es un tipo de archivo que nos permite combinar texto formateado con código y resultados en un mismo documento (HTML, PDF, WORD…). Aprovechando la potencia de este tipo de archivo, algunas personas han creado paquetes para preparar artículos en formato APA, o con las plantillas de decenas de editoriales. 4.5 Sintaxis, chunks de código, tipos de archivo La sintáxis básica de RMarkdown es sorprendentemente sencilla, como se puede ver más abajo. Eso si, lo que hay detrás es toda la potencia de latex, así que el cielo es el límite. Y como no, tenemos mucha ayuda: R Markdown cheatsheet R Markdown: The Definitive Guide Web oficial de Rmarkdown dentro de RStudio Resumiendo, tienes tres elementos básicos: 4.5.1 Cabecera YAML Cuando creas un documento .Rmd nuevo verás algo similar a lo siguiente en las primeras lineas: --- title: &quot;Untitled&quot; author: &quot;G&quot; date: &quot;6/1/2019&quot; output: pdf_document --- Esta es la cabecera YAML, en la cual se le pueden pasar parámetros para añadir un índice, cambiar formato, y muchas otras cosas. 4.5.2 Rmarkdown En el resto del documento (con la excepción de los chunks de código), el formato que usaremos será Rmarkdown. Su sintaxis es muy sencilla pero nada tolerante. Podéis ver las bases en la R Markdown cheatsheet. IMPORTANTE. Si algo no funciona como esperas: Añade saltos de linea entre párrafos. Añade dos espacios al final de las líneas. Añade un espacio después de #: MAL: #Título grande BIEN: # Título grande 4.5.3 Chunks de código Los chunks de código están delimitados por: En su interior, puedes usar código R como si estuvieras en un script de R normal. En la cabecera puedes añadir opciones. Hay una cantidad apabullante de opciones. Por ejemplo, en el siguiente chunk: {r nombre_chunk, eval=TRUE, include=TRUE, fig.height=10, fig.width=12, message=FALSE, warning=FALSE, cache=TRUE, results='asis'} eval=TRUE: Muestra el código include=TRUE: Corre el código fig.height=10: altura de los plots (en inches) fig.width=12: ancho de los plots (en inches) message=FALSE: NO muestres mensajes warning=FALSE: NO muestres warnings cache=TRUE: cachea el output del plot results='asis': muestra el output tal cual (importante cuando el output es en latex/pdf) Haciendo click en la herramienta de la derecha puedes controlar varios parámetros esenciales. TRUCO: Si tienes un chunk al principio llamado setup, cada vez que reinicies RStudio y ejecutes código en cualquier parte de tu documento, ese bloque se ejecutara automaticamente. Esto es ideal para poner tus librerias, lectura de datos… 4.5.4 Ejercicio básico RMarkdown Volvamos al archivo .Rmd que creamos antes. Hagamos lo siguiente: Dale formato de artículo científico, creando las siguientes secciones: Title Abstract Introducción Materials and Methods Participants Materials Results Experiment 1 Experiment 2 Discussion Bibliography Pon texto de relleno dentro de cada sección. Para ello puedes usar la función stri_rand_lipsum() del paquete {stringi}. Renderiza tu documento en formato PDF. Pull, Commit, Push, Pull… 4.5.5 Herramientas básicas para investigadoras/es De manera relativamente sencilla podemos incluir tablas bonitas en los reportes. 4.5.5.1 Descriptivos gtsummary::tbl_summary(gapminder %&gt;% select(-country), by = continent, missing = &quot;ifany&quot;) %&gt;% gtsummary::add_n() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #mziicjnlgx .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mziicjnlgx .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mziicjnlgx .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mziicjnlgx .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #mziicjnlgx .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mziicjnlgx .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mziicjnlgx .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mziicjnlgx .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mziicjnlgx .gt_column_spanner_outer:first-child { padding-left: 0; } #mziicjnlgx .gt_column_spanner_outer:last-child { padding-right: 0; } #mziicjnlgx .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #mziicjnlgx .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #mziicjnlgx .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mziicjnlgx .gt_from_md > :first-child { margin-top: 0; } #mziicjnlgx .gt_from_md > :last-child { margin-bottom: 0; } #mziicjnlgx .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mziicjnlgx .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #mziicjnlgx .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mziicjnlgx .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #mziicjnlgx .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mziicjnlgx .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mziicjnlgx .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mziicjnlgx .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mziicjnlgx .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mziicjnlgx .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #mziicjnlgx .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mziicjnlgx .gt_sourcenote { font-size: 90%; padding: 4px; } #mziicjnlgx .gt_left { text-align: left; } #mziicjnlgx .gt_center { text-align: center; } #mziicjnlgx .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mziicjnlgx .gt_font_normal { font-weight: normal; } #mziicjnlgx .gt_font_bold { font-weight: bold; } #mziicjnlgx .gt_font_italic { font-style: italic; } #mziicjnlgx .gt_super { font-size: 65%; } #mziicjnlgx .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N Africa, N = 6241 Americas, N = 3001 Asia, N = 3961 Europe, N = 3601 Oceania, N = 241 year 1,704 1,980 (1,966, 1,993) 1,980 (1,966, 1,993) 1,980 (1,966, 1,993) 1,980 (1,966, 1,993) 1,980 (1,966, 1,993) lifeExp 1,704 48 (42, 54) 67 (58, 72) 62 (51, 70) 72 (70, 75) 74 (71, 78) pop 1,704 4,579,311 (1,342,075, 10,801,490) 6,227,510 (2,962,359, 18,340,309) 14,530,830 (3,844,393, 46,300,348) 8,551,125 (4,331,500, 21,802,867) 6,403,492 (3,199,212, 14,351,625) gdpPercap 1,704 1,192 (761, 2,377) 5,466 (3,428, 7,830) 2,647 (1,057, 8,549) 12,082 (7,213, 20,461) 17,983 (14,142, 22,214) 1 Median (IQR) # table_combined_vive = gtsummary::tbl_merge(list(T_female, T_male), tab_spanner = list(&quot;Female&quot;, &quot;Male&quot;)) # gt::gtsave(gtsummary::as_gt(table_combined_vive), file = &quot;outputs/table-combined-vive.png&quot;) 4.5.5.2 Correlaciones 4.5.5.2.1 Test de correlación # https://github.com/easystats/easystats corr_test = cor.test(iris$Sepal.Width, iris$Sepal.Length, method = &quot;spearman&quot;) report(corr_test) ## Effect sizes were labelled following Funder&#39;s (2019) recommendations. ## ## The Spearman&#39;s rank correlation rho between iris$Sepal.Width and iris$Sepal.Length is negative, significant and small (rho = -0.17, S = 6.56e+05, p &lt; .05) table_easystats = report::report(corr_test) knitr::kable(table_easystats) Parameter1 Parameter2 rho S p Method iris\\(Sepal.Width |iris\\)Sepal.Length -0.17 6.56e+05 0.041 Spearman’s rank correlation rho mtcars %&gt;% correlation(partial = TRUE) %&gt;% plot() 4.5.5.2.2 Tabla de correlaciones # https://paulvanderlaken.com/2018/09/10/simpler-correlation-analysis-in-r-using-tidyverse-principles/ table_correlations &lt;- iris %&gt;% correlation::correlation() # report() %&gt;% # table_long(full = TRUE) # Cambiamos todos los NA por &quot;&quot; table_clean = table_correlations %&gt;% mutate_if(is.character, ~replace(., is.na(.), &quot;&quot;)) # Mostramos la tabla bonita (función kable del paquete {knitr}) knitr::kable(table_clean) Parameter1 Parameter2 r CI CI_low CI_high t df_error p Method n_Obs Sepal.Length Sepal.Width -0.1175698 0.95 -0.2726932 0.0435116 -1.440287 148 0.1518983 Pearson correlation 150 Sepal.Length Petal.Length 0.8717538 0.95 0.8270363 0.9055080 21.646019 148 0.0000000 Pearson correlation 150 Sepal.Length Petal.Width 0.8179411 0.95 0.7568971 0.8648361 17.296454 148 0.0000000 Pearson correlation 150 Sepal.Width Petal.Length -0.4284401 0.95 -0.5508771 -0.2879499 -5.768449 148 0.0000001 Pearson correlation 150 Sepal.Width Petal.Width -0.3661259 0.95 -0.4972130 -0.2186966 -4.786461 148 0.0000081 Pearson correlation 150 Petal.Length Petal.Width 0.9628654 0.95 0.9490525 0.9729853 43.387237 148 0.0000000 Pearson correlation 150 4.5.5.3 LM model_lm &lt;- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) summary_lm = summary(model_lm) # papaja::apa_print.summary.lm(summary_lm)$table table_lm = papaja::apa_print(model_lm)$table knitr::kable(table_lm) predictor estimate ci statistic p.value Intercept 4.58 \\([4.36\\), \\(4.80]\\) 40.89 &lt; .001 Petal Length 0.44 \\([0.31\\), \\(0.57]\\) 6.74 &lt; .001 Petal Width -1.24 \\([-1.67\\), \\(-0.81]\\) -5.65 &lt; .001 Petal Length \\(\\times\\) Petal Width 0.19 \\([0.12\\), \\(0.25]\\) 5.62 &lt; .001 report(model_lm) ## We fitted a linear model (estimated using OLS) to predict Sepal.Length with Petal.Length and Petal.Width (formula: Sepal.Length ~ Petal.Length * Petal.Width). The model explains a significant and substantial proportion of variance (R2 = 0.81, F(3, 146) = 204.54, p &lt; .001, adj. R2 = 0.80). The model&#39;s intercept, corresponding to Petal.Length = 0 and Petal.Width = 0, is at 4.58 (95% CI [4.36, 4.80], t(146) = 40.89, p &lt; .001). Within this model: ## ## - The effect of Petal.Length is significantly positive (beta = 0.44, 95% CI [0.31, 0.57], t(146) = 6.74, p &lt; .001; Std. beta = 1.42, 95% CI [1.14, 1.71]) ## - The effect of Petal.Width is significantly negative (beta = -1.24, 95% CI [-1.67, -0.81], t(146) = -5.65, p &lt; .001; Std. beta = -0.49, 95% CI [-0.76, -0.21]) ## - The interaction effect of Petal.Width on Petal.Length is significantly positive (beta = 0.19, 95% CI [0.12, 0.25], t(146) = 5.62, p &lt; .001; Std. beta = 0.31, 95% CI [0.20, 0.41]) ## ## Standardized parameters were obtained by fitting the model on a standardized version of the dataset. table_easystats = report::report(model_lm) knitr::kable(table_easystats) Parameter Coefficient CI CI_low CI_high t df_error p Std_Coefficient Std_Coefficient_CI_low Std_Coefficient_CI_high Fit 1 (Intercept) 4.58 [ 4.36, 4.80] 40.89 &lt; .001 -0.29 [-0.42, -0.17] 4.58 [ 4.36, 4.80] 40.89 &lt; .001 2 Petal.Length 0.44 [ 0.31, 0.57] 6.74 &lt; .001 1.42 [ 1.14, 1.71] 0.44 [ 0.31, 0.57] 6.74 &lt; .001 3 Petal.Width -1.24 [-1.67, -0.81] -5.65 &lt; .001 -0.49 [-0.76, -0.21] -1.24 [-1.67, -0.81] -5.65 &lt; .001 4 Petal.Length * Petal.Width 0.19 [ 0.12, 0.25] 5.62 &lt; .001 0.31 [ 0.20, 0.41] 0.19 [ 0.12, 0.25] 5.62 &lt; .001 5 NA 6 AIC 130.70 7 BIC 145.75 8 R2 0.81 9 R2 (adj.) 0.80 11 Sigma 0.37 Usando el paquete {stargazer} podemos mostrar una tabla de resultados: stargazer::stargazer(model_lm, heather = FALSE, type = &quot;html&quot;) Dependent variable: Sepal.Length Petal.Length 0.442*** (0.066) Petal.Width -1.239*** (0.219) Petal.Length:Petal.Width 0.189*** (0.034) Constant 4.577*** (0.112) Observations 150 R2 0.808 Adjusted R2 0.804 Residual Std. Error 0.367 (df = 146) F Statistic 204.544*** (df = 3; 146) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 FALSE 4.5.5.4 Anova Ver paquete {afex} data(obk.long, package = &quot;afex&quot;) head(obk.long) ## id treatment gender age phase hour value ## 1 1 control M -4.75 pre 1 1 ## 2 1 control M -4.75 pre 2 2 ## 3 1 control M -4.75 pre 3 4 ## 4 1 control M -4.75 pre 4 2 ## 5 1 control M -4.75 pre 5 1 ## 6 1 control M -4.75 post 1 3 # estimate mixed ANOVA on the full design: model = afex::aov_ez(&quot;id&quot;, &quot;value&quot;, obk.long, between = c(&quot;treatment&quot;, &quot;gender&quot;), within = c(&quot;phase&quot;, &quot;hour&quot;), observed = &quot;gender&quot;) table_afex = papaja::apa_print(model)$table knitr::kable(table_afex) Effect F df1 df2 MSE p ges 1 Treatment 3.94 2 10 22.81 .055 .278 2 Gender 3.66 1 10 22.81 .085 .152 4 Phase 16.13 1.60 15.99 5.02 &lt; .001 .217 8 Hour 16.69 1.84 18.41 3.39 &lt; .001 .183 3 Treatment \\(\\times\\) Gender 2.86 2 10 22.81 .104 .218 5 Treatment \\(\\times\\) Phase 4.85 3.20 15.99 5.02 .013 .143 6 Gender \\(\\times\\) Phase 0.28 1.60 15.99 5.02 .709 .005 9 Treatment \\(\\times\\) Hour 0.09 3.68 18.41 3.39 .979 .002 10 Gender \\(\\times\\) Hour 0.45 1.84 18.41 3.39 .628 .006 12 Phase \\(\\times\\) Hour 1.18 3.60 35.96 2.67 .335 .024 7 Treatment \\(\\times\\) Gender \\(\\times\\) Phase 0.64 3.20 15.99 5.02 .612 .021 11 Treatment \\(\\times\\) Gender \\(\\times\\) Hour 0.62 3.68 18.41 3.39 .641 .016 13 Treatment \\(\\times\\) Phase \\(\\times\\) Hour 0.35 7.19 35.96 2.67 .930 .014 14 Gender \\(\\times\\) Phase \\(\\times\\) Hour 0.93 3.60 35.96 2.67 .449 .019 15 Treatment \\(\\times\\) Gender \\(\\times\\) Phase \\(\\times\\) Hour 0.74 7.19 35.96 2.67 .646 .029 data &lt;- iris data$Cat1 &lt;- rep(c(&quot;X&quot;, &quot;X&quot;, &quot;Y&quot;), length.out = nrow(data)) data$Cat2 &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), length.out = nrow(data)) model_aov &lt;- aov(Sepal.Length ~ Species * Cat1 * Cat2, data = data) report::report(model_aov) ## The ANOVA (formula: Sepal.Length ~ Species * Cat1 * Cat2) suggests that: ## ## - The main effect of Species is significant and large (F(2, 138) = 115.28, p &lt; .001; Eta2 (partial) = 0.63, 90% CI [0.55, 0.69]) ## - The main effect of Cat1 is not significant and very small (F(1, 138) = 9.59e-03, p = 0.922; Eta2 (partial) = 6.95e-05, 90% CI [0.00, 6.47e-03]) ## - The main effect of Cat2 is not significant and very small (F(1, 138) = 6.08e-03, p = 0.938; Eta2 (partial) = 4.40e-05, 90% CI [0.00, 3.12e-03]) ## - The interaction between Species and Cat1 is not significant and very small (F(2, 138) = 0.51, p = 0.604; Eta2 (partial) = 7.28e-03, 90% CI [0.00, 0.04]) ## - The interaction between Species and Cat2 is not significant and small (F(2, 138) = 0.94, p = 0.394; Eta2 (partial) = 0.01, 90% CI [0.00, 0.05]) ## - The interaction between Cat1 and Cat2 is not significant and very small (F(1, 138) = 0.91, p = 0.341; Eta2 (partial) = 6.58e-03, 90% CI [0.00, 0.05]) ## - The interaction between Species, Cat1 and Cat2 is not significant and very small (F(2, 138) = 0.13, p = 0.875; Eta2 (partial) = 1.93e-03, 90% CI [0.00, 0.01]) ## ## Effect sizes were labelled following Field&#39;s (2013) recommendations. report::report(model_aov) ## The ANOVA (formula: Sepal.Length ~ Species * Cat1 * Cat2) suggests that: ## ## - The main effect of Species is significant and large (F(2, 138) = 115.28, p &lt; .001; Eta2 (partial) = 0.63, 90% CI [0.55, 0.69]) ## - The main effect of Cat1 is not significant and very small (F(1, 138) = 9.59e-03, p = 0.922; Eta2 (partial) = 6.95e-05, 90% CI [0.00, 6.47e-03]) ## - The main effect of Cat2 is not significant and very small (F(1, 138) = 6.08e-03, p = 0.938; Eta2 (partial) = 4.40e-05, 90% CI [0.00, 3.12e-03]) ## - The interaction between Species and Cat1 is not significant and very small (F(2, 138) = 0.51, p = 0.604; Eta2 (partial) = 7.28e-03, 90% CI [0.00, 0.04]) ## - The interaction between Species and Cat2 is not significant and small (F(2, 138) = 0.94, p = 0.394; Eta2 (partial) = 0.01, 90% CI [0.00, 0.05]) ## - The interaction between Cat1 and Cat2 is not significant and very small (F(1, 138) = 0.91, p = 0.341; Eta2 (partial) = 6.58e-03, 90% CI [0.00, 0.05]) ## - The interaction between Species, Cat1 and Cat2 is not significant and very small (F(2, 138) = 0.13, p = 0.875; Eta2 (partial) = 1.93e-03, 90% CI [0.00, 0.01]) ## ## Effect sizes were labelled following Field&#39;s (2013) recommendations. table_aov = papaja::apa_print(model_aov)$table knitr::kable(table_aov) Effect F df1 df2 MSE p ges Species 115.28 2 138 0.27 &lt; .001 .626 Cat1 0.01 1 138 0.27 .922 .000 Cat2 0.01 1 138 0.27 .938 .000 Species \\(\\times\\) Cat1 0.51 2 138 0.27 .604 .007 Species \\(\\times\\) Cat2 0.94 2 138 0.27 .394 .013 Cat1 \\(\\times\\) Cat2 0.91 1 138 0.27 .341 .007 Species \\(\\times\\) Cat1 \\(\\times\\) Cat2 0.13 2 138 0.27 .875 .002 4.5.6 Otros Para evitar problemas con los paths de los archivos, usar here::here() Para evitar problemas con instalación de Latex: if (!require(&#39;tinytex&#39;)) install.packages(&#39;tinytex&#39;); library(&#39;tinytex&#39;) tinytex::install_tinytex() Corregir ortografía en Rmarkdown (F7) https://github.com/ropensci/spelling#readme 4.5.6.1 Usar bibliografía Bibliografía en Rmarkdown https://blog.rstudio.com/2020/11/09/rstudio-1-4-preview-citations/ https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html https://www.r-bloggers.com/bibliography-with-knitr-cite-your-references-and-packages/ 4.5.6.2 Citar los paquetes que usamos ¿Debemos citar los paquetes que usamos? Respuesta corta, si Respuesta larga, la mayoría de los paquetes grateful::cite_packages(all.pkg = FALSE, out.format = &quot;rmd&quot;, out.dir = &quot;dev&quot;) 4.5.7 Ejercicio avanzado Bajad la base de Cancer Screening Risk Literacy of Physicians in Training: https://osf.io/qn9a2/ y el preprint del artículo: En el documento .Rmd de antes: Cread algo parecido a la tabla de correlaciones (Tabla 3) que se ve en el artículo. Tratad de emular el tipo de análisis que se ve en la Tabla 4. 4.6 De los datos al reporte final: Una historia de amor con R Preparar artículos en formato APA remotes::install_github(&quot;crsh/papaja&quot;) # Create new R Markdown file rmarkdown::draft( here::here(&quot;data&quot;, &quot;output&quot;, &quot;mymanuscript.Rmd&quot;), &quot;apa6&quot;, package = &quot;papaja&quot;, create_dir = FALSE, edit = FALSE) # Render manuscript rmarkdown::render( here::here(&quot;data&quot;, &quot;output&quot;, &quot;mymanuscript.Rmd&quot;), quiet = TRUE, clean = TRUE) Y no olvidemos el paquete {rticles}, que contiene plantillas de decenas de editoriales 4.7 Avanzado 4.7.1 Manejo de dependencias Usando un sistema de manejo de dependencias renv Estos sistemas crean un snapshot de las librerías usadas actualmente. El estándar actual para hacer esto es packrat: Instalamos renv: install.packages(\"remotes\") remotes::install_github(\"rstudio/renv\") Inicializamos el entorno local de un nuevo proyecto, con una librería privada de R renv::init() Trabajamos en el proyecto, instalando los paquetes que necesitemos Guardamos el estado de las librerías usadas en el proyecto en un lockfile (llamado renv.lock), renv::snapshot() Restauramos el estado de las librerías a partir del lockfile generado por renv::snapshot(). renv::restore() 4.7.2 Alternativas para integrar manejo de dependencias y control de cambios {workflowr} # install.packages(&quot;workflowr&quot;) 4.8 Mas allá de Rmarkdown Aplicaciones web interactivas con R: Shiny 4.9 Varios 4.9.1 Shortcuts! Alt+SHIFT+K: Ver shortcuts! CTRL+SHIFT+M: Pipe CTRL+SHIFT+A: Reformat code CTRL+I: Reindent lines 4.9.2 Estilo Es importante ser consistente en la manera de escribir código. Habitualmente se recomienda seguir una guía de estilo. Por ejemplo, Hadley Wickham’s Style guide o la guia de estilo del tidyverse. 4.9.3 Algunos paquetes interesantes Descargar datos suplementarios de papers publicados usando DOI https://github.com/easystats/easystats https://usethis.r-lib.org/ https://github.com/karthik/holepunch Bibliografía Guia de estilo del tidyverse Hadley Wickham’s Style guide Happy Git and GitHub for the useR packrat {workflowr} Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Yihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html Mas cosas sobre reproducibilidad: Reproducibility project: Psychology Many labs 2 "],["reporte-final.html", "Capítulo 5 Reporte final 5.1 Base de datos a usar 5.2 Paso a paso 5.3 Hint 5.4 Nota final", " Capítulo 5 Reporte final El objetivo evaluable de este workshop es escribir CONJUNTAMENTE un mini-paper (tan sólo título, abstract, método y resultados) en inglés, en formato APA usando {papaja} o algún formato de {rticles}. 5.1 Base de datos a usar SOURCE: https://twitter.com/richarddmorey/status/690680901760606209 Usaremos la base de datos https://osf.io/qn9a2/ asociada al paper Cancer screening risk literacy of physicians in training: An experimental study de Petrova et al. En ese paper podréis ver que hay 1 experimento. Vuestra tarea será crear conjuntamente un paper en Rmarkdown (PDF) donde hagáis un reanálisis de los datos de ese paper. Cada uno de vosotros elegirá un subconjunto de variables y un análisis, e incluirá un “Experimento” dentro del paper conjunto, mostrando y describiendo sus resultados. 5.2 Paso a paso Tendréis que seguir los siguientes pasos para completar el trabajo: Paso 1: Crear un Repositorio en Github Paso 2: Clonar el repositorio localmente en un computador Paso 3: Crear una rama development y trabajar conjuntamente en la preparación de datos (importar, renombrar, seleccionar variables…) Paso 4: Usando {papaja}, o alguna de las plantillas de {rticles} cread juntos (en un solo computador) un documento Rmd e incluid la estructura (secciones) del paper Title Abstract: describir brevemente que se hace Introduction Materials and Methods Participants Materials Results Experiment 1 Experiment 2 Experiment 3 Discussion Paso 5: Cada uno clonara el repositorio localmente en su computador, creará su rama propia y, en la sección adecuada (e.g. Experiment 2), completará las tareas de abajo (commit y push cambios a la rama propia de Github al finalizar). NO borrar la rama propia de Github: Describir el análisis realizado Tabla APA con descriptivos de las variables seleccionadas Descripción de resultados en formato APA Tabla de resultados APA Plot APA que represente adecuadamente estos resultados Paso 6: Combinar los cambios de las 3 ramas individuales en development Paso 7: Cada uno debería revisar el paper final, corregir fallos y combinarlos en la rama development Paso 8: Mover los cambios a master y celebrar! 5.3 Hint En la carpeta Data and results de https://osf.io/qn9a2/ hay varios archivos que os ayudarán a entender cuales son las variables de interés. Analysis script R1.sps: script de SPSS usado para los análisis del paper Variables R1.sps: descripción de variables … Es muy recomendable ubicar las variables de interés, y renombrarlas para que sean fácilmente reconocibles. 5.4 Nota final La nota final se definirá de la siguiente manera: Paper final: 60% Tarea individual: 40% El formato, el estilo, y los acabados tienen que ser con el estándar de calidad esperado en un paper científico. Se evaluará específicamente lo siguiente: Paper final (60% total): (90%) El paper tiene que ser reproducible: El profesor descargará el repositorio completo en un computador sin ninguna librería instalada y kniteara el archivo .Rmd del paper. La expectativa es que todo funcione, y que el paper que se cree automáticamente sea idéntico al entregado por los alumnos. (10%) Calidad general de la redacción, ausencia de errores gramaticales y ortográficos graves. Tarea individual (40% total): (20%) Describir el análisis realizado (20%) Tabla APA con descriptivos de las variables seleccionadas (20%) Descripción de resultados en formato APA (20%) Tabla de resultados APA (20%) Plot APA que represente adecuadamente estos resultados La historia completa de commits de todas las ramas (master, development, y las 3 individuales) deberá estar disponible. "],["paquetes-usados.html", "Paquetes usados References", " Paquetes usados En la documentación y ejercicios de este workshop se usaron los paquetes que se pueden ver abajo. Este listado se creó automáticamente usando {grateful}: base (R Core Team 2019) knitr (Xie 2014) stargazer (Hlavac 2018) rticles (Allaire et al. 2019) renv (Ushey 2019) remotes (Hester et al. 2019) papaja (Aust and Barth 2018) easystats (Lüdecke and Makowski 2019) estimate (Makowski and Lüdecke 2019b) see (Lüdecke et al. 2019) report (Makowski et al. 2019) correlation (Makowski 2019) parameters (Makowski and Lüdecke 2019a) bayestestR (Makowski, Ben-Shachar, and Lüdecke 2019) performance (Lüdecke, Makowski, and Waggoner 2019) insight (Lüdecke, Waggoner, and Makowski 2019) corrr (Jackson, Cimentada, and Ruiz 2019) afex (Singmann et al. 2019) lme4 (Bates et al. 2015) Matrix (Bates and Maechler 2019) hexbin (Carr et al. 2019) FFTrees (Phillips et al. 2018) caret (Jed Wing et al. 2019) lattice (Sarkar 2008) janitor (Firke 2019) gsheet (Conway 2016) DT (Xie, Cheng, and Tan 2019) writexl (Ooms 2018) readODS (Schutten et al. 2018) here (Müller 2017) haven (Wickham and Miller 2019) readxl (Wickham and Bryan 2019) plotly (Sievert 2018) ggridges (Wilke 2018) ggthemes (Arnold 2019) gganimate (Pedersen and Robinson 2019) gapminder (Bryan 2017) esquisse (Meyer and Perrier 2019) cowplot (Wilke 2019) forcats (Wickham 2019a) stringr (Wickham 2019b) dplyr (Wickham et al. 2019) purrr (Henry and Wickham 2019) readr (Wickham, Hester, and Francois 2018) tidyr (Wickham and Henry 2019) tibble (Müller and Wickham 2019) ggplot2 (Wickham 2016) tidyverse (Wickham 2017) References Allaire, JJ, Yihui Xie, R Foundation, Hadley Wickham, Journal of Statistical Software, Ramnath Vaidyanathan, Association for Computing Machinery, et al. 2019. Rticles: Article Formats for r Markdown. https://github.com/rstudio/rticles. Arnold, Jeffrey B. 2019. Ggthemes: Extra Themes, Scales and Geoms for ’Ggplot2’. https://CRAN.R-project.org/package=ggthemes. Aust, Frederik, and Marius Barth. 2018. papaja: Create APA Manuscripts with R Markdown. https://github.com/crsh/papaja. Bates, Douglas, and Martin Maechler. 2019. Matrix: Sparse and Dense Matrix Classes and Methods. https://CRAN.R-project.org/package=Matrix. Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01. Bryan, Jennifer. 2017. Gapminder: Data from Gapminder. https://CRAN.R-project.org/package=gapminder. Carr, Dan, ported by Nicholas Lewin-Koh, Martin Maechler, and contains copies of lattice functions written by Deepayan Sarkar. 2019. Hexbin: Hexagonal Binning Routines. https://CRAN.R-project.org/package=hexbin. Conway, Max. 2016. Gsheet: Download Google Sheets Using Just the URL. https://CRAN.R-project.org/package=gsheet. Firke, Sam. 2019. Janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor. Henry, Lionel, and Hadley Wickham. 2019. Purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr. Hester, Jim, Gábor Csárdi, Hadley Wickham, Winston Chang, Martin Morgan, and Dan Tenenbaum. 2019. Remotes: R Package Installation from Remote Repositories, Including ’GitHub’. https://CRAN.R-project.org/package=remotes. Hlavac, Marek. 2018. Stargazer: Well-Formatted Regression and Summary Statistics Tables. Bratislava, Slovakia: Central European Labour Studies Institute (CELSI). https://CRAN.R-project.org/package=stargazer. Jackson, Simon, Jorge Cimentada, and Edgar Ruiz. 2019. Corrr: Correlations in r. https://CRAN.R-project.org/package=corrr. Jed Wing, Max Kuhn. Contributions from, Steve Weston, Andre Williams, Chris Keefer, Allan Engelhardt, Tony Cooper, Zachary Mayer, et al. 2019. Caret: Classification and Regression Training. https://CRAN.R-project.org/package=caret. Lüdecke, Daniel, and Dominique Makowski. 2019. Easystats: Jump in the Easyverse. https://github.com/easystats/easystats. Lüdecke, Daniel, Dominique Makowski, and Philip Waggoner. 2019. Performance: Assessment of Regression Models Performance. https://easystats.github.io/performance/. Lüdecke, Daniel, Dominique Makowski, Philip Waggoner, and Mattan S. Ben-Shachar. 2019. See: Visualisation Toolbox for ’Easystats’ and Extra Geoms, Themes and Color Palettes for ’Ggplot2’. https://easystats.github.io/see/. Lüdecke, Daniel, Philip Waggoner, and Dominique Makowski. 2019. “Insight: A Unified Interface to Access Information from Model Objects in r.” Journal of Open Source Software 4 (38): 1412. https://doi.org/10.21105/joss.01412. Makowski, Dominique. 2019. Correlation: Easy Peasy Correlations. https://github.com/easystats/correlation. Makowski, Dominique, Mattan S. Ben-Shachar, and Daniel Lüdecke. 2019. “Understand and Describe Bayesian Models and Posterior Distributions Using bayestestR.” CRAN. https://doi.org/10.5281/zenodo.2556486. Makowski, Dominique, and Daniel Lüdecke. 2019a. “Describe and Understand Your Model’s Parameters.” CRAN. https://github.com/easystats/parameters. ———. 2019b. Estimate: Estimate Effects, Contrasts and Means. https://github.com/easystats/estimate. Makowski, Dominique, Lüdecke, and Daniel. 2019. “The Report Package for r: Ensuring the Use of Best Practices for Results Reporting.” CRAN. https://github.com/easystats/report. Meyer, Fanny, and Victor Perrier. 2019. Esquisse: Explore and Visualize Your Data Interactively. https://CRAN.R-project.org/package=esquisse. Müller, Kirill. 2017. Here: A Simpler Way to Find Your Files. https://CRAN.R-project.org/package=here. Müller, Kirill, and Hadley Wickham. 2019. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble. Ooms, Jeroen. 2018. Writexl: Export Data Frames to Excel ’Xlsx’ Format. https://CRAN.R-project.org/package=writexl. Pedersen, Thomas Lin, and David Robinson. 2019. Gganimate: A Grammar of Animated Graphics. https://CRAN.R-project.org/package=gganimate. Phillips, Nathaniel, Hansjoerg Neth, Jan Woike, and Wolfgang Gaissmaer. 2018. FFTrees: Generate, Visualise, and Evaluate Fast-and-Frugal Decision Trees. https://CRAN.R-project.org/package=FFTrees. R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Sarkar, Deepayan. 2008. Lattice: Multivariate Data Visualization with r. New York: Springer. http://lmdvr.r-forge.r-project.org. Schutten, Gerrit-Jan, Chung-hong Chan, Thomas J. Leeper, and other contributors. 2018. readODS: Read and Write ODS Files. https://CRAN.R-project.org/package=readODS. Sievert, Carson. 2018. Plotly for r. https://plotly-r.com. Singmann, Henrik, Ben Bolker, Jake Westfall, Frederik Aust, and Mattan S. Ben-Shachar. 2019. Afex: Analysis of Factorial Experiments. https://CRAN.R-project.org/package=afex. Ushey, Kevin. 2019. Renv: Project Environments for r. https://github.com/rstudio/renv. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. ———. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse. ———. 2019a. Forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats. ———. 2019b. Stringr: Simple, Consistent Wrappers for Common String Operations. https://CRAN.R-project.org/package=stringr. Wickham, Hadley, and Jennifer Bryan. 2019. Readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl. Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr. Wickham, Hadley, and Lionel Henry. 2019. Tidyr: Easily Tidy Data with ’Spread()’ and ’Gather()’ Functions. https://CRAN.R-project.org/package=tidyr. Wickham, Hadley, Jim Hester, and Romain Francois. 2018. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr. Wickham, Hadley, and Evan Miller. 2019. Haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven. Wilke, Claus O. 2018. Ggridges: Ridgeline Plots in ’Ggplot2’. https://CRAN.R-project.org/package=ggridges. ———. 2019. Cowplot: Streamlined Plot Theme and Plot Annotations for ’Ggplot2’. https://CRAN.R-project.org/package=cowplot. Xie, Yihui. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. ———. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. ———. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. Xie, Yihui, Joe Cheng, and Xianying Tan. 2019. DT: A Wrapper of the JavaScript Library ’DataTables’. https://CRAN.R-project.org/package=DT. "]]
