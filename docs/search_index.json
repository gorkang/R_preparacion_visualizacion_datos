[["index.html", "R para preparación y visualización de datos Doctorado en Neurociencia Social y Cognición Introducción Objetivos Como empezar Bibliografía", " R para preparación y visualización de datos Doctorado en Neurociencia Social y Cognición Gorka Navarrete, ORCID: 0000-0001-7678-8656 Introducción El seminario estará centrado en el uso de R para la preparación y visualización de datos, además de la generación de reportes reproducibles. R es un lenguaje de programación abierto, con una gran comunidad orientada al trabajo, visualización y modelado de datos en contextos científicos y técnicos. Nos introduciremos de manera práctica a R, resolviendo problemas que encontramos habitualmente durante el quehacer científico, focalizándonos en el trabajo abierto, colaborativo y reproducible. Objetivos Dar las herramientas básicas a los alumnos para que puedan trabajar de manera autónoma con R y RStudio para el proceso de importación, transformación, visualización y reporte de datos. Al finalizar el curso los alumnos serán capaces de: Importar archivos de datos, transformar los datos, crear nuevas variables. Realizar análisis de datos exploratorios, visualizar distribuciones y comparar grupos. Generar reportes reproducibles con RMarkdown. Como empezar Si ya has completado los pasos indicados en Preparando nuesto sistema, puedes lanzar el siguiente código en tu ordenador para descargar los materiales del curso: if (!require(&#39;usethis&#39;)) install.packages(&#39;usethis&#39;); library(&#39;usethis&#39;) usethis::use_course(&quot;gorkang/R_preparacion_visualizacion_datos&quot;) Sigue las instrucciones que aparecen en la Consola para tener un nuevo proyecto de RStudio con todos los materiales del curso. El codigo anterior creará una carpeta llamada R_preparacion_visualizacion_datos-master. Dentro de esa carpeta tendrás un archivo llamado R_preparacion_visualizacion_datos.Rproj que te permitirá abrir el proyecto de RStudio del workshop. La carpeta R_preparacion_visualizacion_datos-master contiene varias cosas. Las mas importantes son: Carpeta _book: puedes abrir book/index.html en tu navegador para ver el “libro” de este curso Carpeta Rmd: En esa carpeta esta el codigo fuente de los capitulos del libro Carpeta data: Cuando usemos archivos de datos, vendrán de aquí Bibliografía Bryan, J., &amp; Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/ Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ Wickham, H. (2014). Advanced r. Chapman and Hall/CRC. https://adv-r.hadley.nz/ Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Yihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html "],["preparando-sistema.html", "Preparando nuestro sistema 0.1 Empezando en A-B-C 0.2 Algo más sobre la instalación de paquetes Bibliografía", " Preparando nuestro sistema 0.1 Empezando en A-B-C Para poder iniciar el workshop necesitamos tener R y RStudio instalados, además de algunas librerías. Para tener un sistema funcional, completa los pasos A, B y C. Si ya tienes R y Rstudio instalados (recientemente), puedes pasar directamente al paso (C). (A) Instalar R R, es un lenguaje de programación especializado en el computación estadística y visualización de datos. Es recomendable tener instalada la última versión de R. Puedes usar uno de los enlaces siguientes: Windows: Descargar e instalar R para Windows Mac: Descargar e instalar R para Mac Ubuntu Linux: más detalles en la web de R. En un terminal: sudo apt-get install r-base (B) Instalar RStudio RStudio es un entorno integrado de desarrollo (IDE) para la programación R. Descargar e instalar RStudio. Una vez descargado e instalado, abre RStudio. Deberías ver algo parecido a lo siguiente: (C) Paquetes para el workshop Usaremos un buen numero de paquetes en el workshop. Hay algunos meta-paquetes que simplifican la instalación de múltiples paquetes (e.g. pacman, pak, …), pero en este caso vamos a usar una versión casera. Copia y pega el código de abajo y ejecútalo [tecla ENTER] en la consola de RStudio. El proceso de instalación requiere Internet y tardará un buen rato. list_of_packages = c(&quot;bookdown&quot;, &quot;corrplot&quot;, &quot;cowplot&quot;, &quot;esquisse&quot;, &quot;gapminder&quot;, &quot;ggpubr&quot;, &quot;ggridges&quot;, &quot;ggthemes&quot;, &quot;hrbrthemes&quot;, &quot;inspectdf&quot;, &quot;janitor&quot;, &quot;knitr&quot;, &quot;plotly&quot;, &quot;psych&quot;, &quot;remotes&quot;, &quot;stringr&quot;, &quot;tictoc&quot;, &quot;tidyverse&quot;, &quot;usethis&quot;, &quot;yarrr&quot;) new_packages &lt;- list_of_packages[!(list_of_packages %in% installed.packages()[,&quot;Package&quot;])] if (length(new_packages)) install.packages(new_packages, dependencies = TRUE) 0.2 Algo más sobre la instalación de paquetes Los paquetes de R son una colección de funciones, datos y documentación que amplían las capacidades básicas de R. En 2019 el numero de paquetes en R-cran ha superado los 14,000 (ver este buscador de paquetes). Gran parte de las funciones y paquetes que utilizaremos en este workshop se encuentran contenidas en el meta-paquete “tidyverse” (este es un paquete de paquetes). Ya lo instalamos en (C), pero si quisieras instalarlo solo tendrías que ejecutar la siguiente linea en la consola de RStudio ((1) en la imagen de arriba): install.packages(\"tidyverse\") Para instalar otro paquete diferente de “tidyverse,” remplaza su nombre entre comillas dentro de la función: install.packages(\"NOMBRE_DE_PAQUETE\"). Una vez instalado un paquete, no es necesario volver hacerlo, a menos que reinstales R. 0.2.1 Cargar paquetes Las funciones, datos y documentación dentro de nuestros paquetes no podrán ser utilizadas hasta que se carguen en R (en realidad también pueden ser llamadas usando su referencia absoluta ::, por ejemplo: dplyr::tibble(columna = 1). La estructura de lo anterior es: nombre_paquete::nombre_de_funcion(parametros)). Una vez instalados, para cargar los paquetes se usa la función library(): library(tidyverse) 0.2.2 Todo en uno El siguiente código simplifica lo anterior. Comprueba que el paquete esta instalado; Si no se encuentra instalado, lo instala. Finalmente lo carga. if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) Para instalar múltiples paquetes, podemos repetir la linea de mas arriba tantas veces como sea necesaria, o usar una versión algo mas sofisticada como el código del apartado (C): if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse') if (!require('bookdown')) install.packages('bookdown'); library('bookdown') ... 0.2.3 Instalar paquetes de Github En ocasiones querremos instalar directamente la versión en desarrollo del paquete desde Github. Para eso podemos usar la función install_github del paquete remotes. Por ejemplo, para instalar el paquete {renv} desde su repositorio de Github: if (!require('remotes')) install.packages('remotes'); library('remotes') remotes::install_github(\"rstudio/renv\") Bibliografía Algunos de los manuales que vamos a usar para el workshop son los siguientes: Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Bryan, J., &amp; Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/ "],["introducción-a-r-y-visualización-de-datos.html", "Capítulo 1 Introducción a R y visualización de datos 1.1 Introducción: porque la visualización de datos es importante 1.2 Por qué R? 1.3 Visualización de datos con ggplot2 1.4 Visualización interactiva 1.5 Ejercicios Bibliografía", " Capítulo 1 Introducción a R y visualización de datos Paquetes para este capítulo if (!require(&#39;cowplot&#39;)) install.packages(&#39;cowplot&#39;); library(&#39;cowplot&#39;) if (!require(&#39;esquisse&#39;)) install.packages(&#39;esquisse&#39;); library(&#39;esquisse&#39;) if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;gganimate&#39;)) install.packages(&#39;gganimate&#39;); library(&#39;gganimate&#39;) if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) if (!require(&#39;ggthemes&#39;)) install.packages(&#39;ggthemes&#39;); library(&#39;ggthemes&#39;) if (!require(&#39;ggridges&#39;)) install.packages(&#39;ggridges&#39;); library(&#39;ggridges&#39;) if (!require(&#39;hrbrthemes&#39;)) install.packages(&#39;hrbrthemes&#39;); library(&#39;hrbrthemes&#39;) if (!require(&#39;plotly&#39;)) install.packages(&#39;plotly&#39;); library(&#39;plotly&#39;) if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) # if (!require(&#39;gganimate&#39;)) devtools::install_github(&#39;thomasp85/gganimate&#39;); library(&#39;gganimate&#39;) 1.1 Introducción: porque la visualización de datos es importante “These 13 datasets (the Datasaurus, plus 12 others) each have the same summary statistics (x/y mean, x/y standard deviation, and Pearson’s correlation) to two decimal places, while being drastically different in appearance.” (Matejka, J., &amp; Fitzmaurice, G., 2017) SOURCE: https://www.autodeskresearch.com/publications/samestats 1.1.1 Porque la visualización de datos es importante - ejemplo del mundo real Este ejemplo viene de un experimento que realizamos junto con Carlos Santamaría hace algún tiempo. Presentamos una tarea sobre cálculo de probabilidades en un contexto real. Nuestros participantes estaban entrando a un examen para convertirse en trabajadores del estado. La historia real tiene algunos matices, pero simplificando, digamos que la materia para el examen eran unos 80 temas. Las personas generalmente no podían estudiar con profundidad todos los temas (o sabían que esa no era la estrategia óptima), así que se concentraban en un subconjunto de esos temas (e.g. 30 de 80). En el examen, se seleccionaban al azar 5 de estos temas, y las personas tenían que elegir uno de ellos para desarrollar. Abajo se puede ver como cambia la probabilidad de que uno de los temas estudiados aparezca dentro de los 5 seleccionados al azar. Con 30 temas estudiados (de los 80 totales), la probabilidad de que uno de ellos salga en la prueba es del 91%. Si estudiáramos 47, subiríamos a una probabilidad del 99%. En el experimento le preguntamos a las personas por la probabilidad de que les aparezca alguno de los temas que han estudiado en la prueba. Comparamos las siguientes dos preguntas: ¿Cuál es la probabilidad de que salga uno de los temas que has estudiado? ¿Cuál es la probabilidad de que no salga ninguno de los temas que has estudiado? Miramos el error promedio en función de la pregunta (cuanto se han alejado de la probabilidad correcta), y vemos que nuestra manipulación ha tenido un efecto considerable: if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) # Leemos datos DF = read_csv( here::here(&quot;data&quot;, &quot;files&quot;, &quot;01-visualizacion-importante.csv&quot;)) %&gt;% mutate(Question = as.factor( case_when(Question_p_of == 1 ~ &quot;p (salga uno)&quot;, Question_p_of == 0 ~ &quot;p (no salga ninguno)&quot;))) # Promedio por condicion DF %&gt;% group_by(Question) %&gt;% summarise(Error_promedio = mean(Error), SD = sd(Error, na.rm = TRUE), N = n()) ## # A tibble: 2 x 4 ## Question Error_promedio SD N ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 p (no salga ninguno) 4.02 35.8 31 ## 2 p (salga uno) -30.7 20.0 31 Hay una diferencia notable entre condiciones. Pasamos de un error promedio del -30.7% a tan solo 4%, simplemente cambiando la pregunta. Hagamos un sencillo análisis de regresión para ver si la diferencia es significativa, y cuanta varianza explica nuestro modelo. # Modelo de regresion modelo_regresion = lm(Error ~ Question, DF) # Resultados summary(modelo_regresion) ## ## Call: ## lm(formula = Error ~ Question, data = DF) ## ## Residuals: ## Min 1Q Median 3Q Max ## -53.516 -15.758 -2.758 25.984 70.742 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.016 5.212 0.771 0.444 ## Questionp (salga uno) -34.758 7.370 -4.716 1.48e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 29.02 on 60 degrees of freedom ## Multiple R-squared: 0.2704, Adjusted R-squared: 0.2583 ## F-statistic: 22.24 on 1 and 60 DF, p-value: 1.479e-05 # Histograma de los residuos hist(modelo_regresion$residuals) # Supuesto de normalidad de residuales shapiro.test(modelo_regresion$residuals) ## ## Shapiro-Wilk normality test ## ## data: modelo_regresion$residuals ## W = 0.96215, p-value = 0.0532 Todo es hermoso. Tenemos un efecto claramente significativo de la pregunta (y con un R2-ajustado de .258, no está nada mal), y además, nuestro modelo no incumple el supuesto de normalidad de residuos (por los pelos!). Preparamos un plot con promedios y barras con error standard para nuestro paper: # Plot para publicación plot_inicial = ggplot(DF, aes(Question, Error, fill = Question)) + stat_summary( fun.y = mean, geom = &quot;point&quot;, size = 4, color = &quot;darkgrey&quot;) + stat_summary(geom = &quot;errorbar&quot;, fun.data = mean_se, position = &quot;dodge&quot;, color = &quot;black&quot;, width = .2) + scale_y_continuous(limits = c(-50, 50), breaks = seq(-50, 50, 10)) + theme_minimal(base_size = 12) + theme(legend.position = &quot;none&quot;) plot_inicial Estamos listos para escribir nuestro paper. Solo por curiosidad, veamos boxplots de los dos grupos. Mmmm… hay algo extraño: # Boxplots por condición ggplot(DF, aes(Question, Error, color = Question, group = Question)) + geom_boxplot(alpha = .5) + theme_minimal() + scale_y_continuous(limits = c(-50, 50), breaks = seq(-50, 50, 10)) + labs(x = &quot;What is the probability of x?&quot;) Volvemos a extraer descriptivos… pero esta vez incluimos la mediana. # Promedio y mediana por condicion DF %&gt;% group_by(Question) %&gt;% summarise(Error_promedio = mean(Error), Error_mediana = median(Error), SD = sd(Error, na.rm = TRUE), N = n()) ## # A tibble: 2 x 5 ## Question Error_promedio Error_mediana SD N ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 p (no salga ninguno) 4.02 25 35.8 31 ## 2 p (salga uno) -30.7 -37 20.0 31 Que esta pasando? Veamos las respuestas de todos los participantes, junto con la distribución de los datos, más la media y mediana por condición. plot_final = ggplot(DF, aes(Question, Error, color = Question, group = Question)) + geom_jitter(size = 2) + geom_violin(alpha = .2) + stat_summary( fun.y = median, geom = &quot;point&quot;, size = 3, color = &quot;black&quot;, shape = 0) + stat_summary( fun.y = mean, geom = &quot;point&quot;, size = 3, color = &quot;darkgrey&quot;, shape = 1) + theme_minimal() + scale_y_continuous(limits = c(-50, 50), breaks = seq(-50, 50, 10)) + labs(x = &quot;What is the probability of x?&quot;) plot_final TLDR: La manera en la visualizamos la información determina las conclusiones a las que llegamos. # Visualizamos el grafico inicial y el final, uno al lado del otro cowplot::plot_grid(plot_inicial, plot_final) Moraleja: es importante mostrar los datos individuales y/o la distribución de los datos SOURCE: https://www.autodeskresearch.com/publications/samestats 1.2 Por qué R? R es uno de los programas para data science mas populares, especialmente usado en la academia. El numero de paquetes que ofrecen funcionalidades de todo tipo no ha dejado de crecer. En 2019 el numero de paquetes en R-cran ha superado los 14,000, y el ritmo de crecimiento nos acerca a la singularidad… ;) SOURCE: https://gist.github.com/daroczig/3cf06d6db4be2bbe3368 Además de lo anterior, R es un programa de código abierto (esencial para poder hacer buena ciencia), con una comunidad de usuarios muy acogedora. Sus funciones de visualización son muy potentes (ver la r-graph-gallery para algunos ejemplos), siendo usadas como herramienta principal en algunos medios como la BBC. Con R puedes recoger datos interactivamente con shiny, preparar datos (o extraerlos de paginas web con rvest o RSelenium), visualizar datos estáticos con ggplot, animarlos con gganimate, visualizarlos con interactivamente con plotly o shiny. Puedes también analizar los datos con todas las técnicas imaginables, desde anovas con afex a modelos mixtos con lmer y/o afex, pasando por meta-análisis con metafor, SEM, Path analysis, mediación, con lavaan, análisis Bayesianos con brms o bayesfactor, y un larguísimo etc. Puedes llevar tus visualizaciones y análisis a reportes automáticos en múltiples formatos (pdf, html, docx) con Rmarkdown, crear libros como este con bookdown, páginas web con blogdown, e incluso papers completamente reproducibles (preparación y análisis de datos) en formato APA con papaja. 1.2.1 Bienvenida al tidyverse El tidyverse es un conjunto de paquetes que nos permitirán hacer de manera (habitualmente) intuitiva muchas tareas de preparación y visualización de datos. 1.2.1.1 Tidyverse vs Base R Muchas de las funciones que existen en el Tidyverse tienen un equivalente en base-R (la instalación por defecto de R). El Tidyverse tiene ventajas y desventajas. La ventaja fundamental es que el código resulta (habitualmente) más fácil de leer, los nombres de las funciones son mas intuitivos, y las maneras de hacer las cosas tienen a ser consistentes. La desventaja fundamental es que incrementamos el numero de dependencias (paquetes) de nuestro código. Veamos un ejemplo extraído de aqui. La misma operación con base-R o con tidyverse: Filter rows with conditions evaluated within groups: iris flowers with maximum “Petal.Width” for each “Species” 1.2.1.1.1 Tidyverse iris %&gt;% group_by(Species) %&gt;% filter(Petal.Width == max(Petal.Width)) ## # A tibble: 5 x 5 ## # Groups: Species [3] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5 3.5 1.6 0.6 setosa ## 2 5.9 3.2 4.8 1.8 versicolor ## 3 6.3 3.3 6 2.5 virginica ## 4 7.2 3.6 6.1 2.5 virginica ## 5 6.7 3.3 5.7 2.5 virginica 1.2.1.1.2 Base-R # First operate in the data.frame by group (split-apply) widest_petals &lt;- by(iris, INDICES = iris$Species, FUN = function(x){ x[x$Petal.Width == max(x$Petal.Width), ] }) # Then combine the results into a data.frame do.call(rbind, widest_petals) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## setosa 5.0 3.5 1.6 0.6 setosa ## versicolor 5.9 3.2 4.8 1.8 versicolor ## virginica.101 6.3 3.3 6.0 2.5 virginica ## virginica.110 7.2 3.6 6.1 2.5 virginica ## virginica.145 6.7 3.3 5.7 2.5 virginica 1.2.2 Antes de empezar Programar (tras la fase de euforia inicial) es muy difícil. Todos necesitamos ayuda. Contar con una comunidad robusta con la que compartir, preguntar, contribuir, ayuda muchísimo. SOURCE: http://www.keywordbasket.com/ZWZlY3RvIGR1bm5pbmcta3J1Z2Vy/ Hay algunos recursos que resultan muy útiles: Comunidad de usuarios de Rstudio Twiter!. Por ejemplo: #TidyTuesday (@thomas_mock) @dataandme @rivaquiroga @RLadiesSantiago Webs como R bloggers Y otros que son más que imprescindibles. Nadie sabe como los antiguos podían programar antes de la llegada de Stackoverflow: Google: text size ggplot Stack overflow!!! 1.2.3 R para visualización de datos ggplot2 es el paquete por excelencia para visualización de datos. Su potencia va asociada a un nivel de complejidad considerable, hasta el punto que hay Cheat sheets oficiales, Cheat sheets buscables, y decenas de miles de preguntas en Stack Overflow. 1.2.3.1 Primeros pasos - con training wheels Para empezar a usar ggplot sin tener que preocuparnos de su complejidad, podemos usar la función esquisse:::esquisser() del paquete esquisse. Esta nos permite usar la potencia de ggplot para explorar una base de datos de manera muy sencilla. SOURCE: https://www.williamrchase.com/slides/intro_r_anthropology_2018#93 La manera fácil (1, 2, 3), usando esquisse: # 1) Asegurate que hemos instalado el paquete esquisse if (!require(&#39;esquisse&#39;)) install.packages(&#39;esquisse&#39;); library(&#39;esquisse&#39;) # 2) Carga el dataframe que desees. En este caso, &quot;iris&quot; data(iris) # 3) Lanza el wizard esquisser esquisse:::esquisser() 1.2.3.2 Aprendamos con Garrick Garrick Aden-Buie (@grrrck) ha creado una excelente introducción a ggplot2 y la gramática de gráficos. Vamos a usarla para familiarizarnos con algunas de las funcionalidades de ggplot. Antes de LANZAR LA PRESENTACION introducción a ggplot2 y la gramática de gráficos, asegúrate que tienes instalados los paquetes tidyverse y gapminder, y crea el DF pop_simple usando el código de abajo. if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) tidy_pop &lt;- gapminder %&gt;% filter(country %in% c(&quot;Canada&quot;, &quot;China&quot;, &quot;United States&quot;), year &gt;= 1997) %&gt;% select(country, year, pop) %&gt;% mutate(pop = pop / 10^6) 1.3 Visualización de datos con ggplot2 1.3.1 Primeros pasos En esta sección vamos a ver algunos de los componentes que usaremos cuando visualicemos datos. Los ingredientes esenciales son: Aesthetic mappings (aes): Variables, colores, rellenos, formas, … Geoms (geom_): puntos, lineas, boxplots, … Facets (facet_): facet_wrap() y facet_grid() Transformaciones estadísticas: stat_summary, ..prop.., … SOURCE: https://skillgaze.com/2017/10/31/understanding-different-visualization-layers-of-ggplot/ Muchos de los ejemplos que usamos en esta sección vienen de R for data science: 1.3.2 Aesthetic mappings En aes() vamos a indicar las variables que queremos en los ejes x e y, el color de los puntos o lineas, el relleno de las barras, la forma de los puntos, el tipo de linea, la agrupación de los datos, etc. x: x = gdpPercap y: y = lifeExp color: color = continent; color = “red”; color = “#FAA627” fill: fill = continent; fill = “red”; fill = “#FAA627” alpha: alpha = continent; alpha = 0.2 size: size = continent; size = 5 shape: shape = continent; shape = 0 ver codigo de las distintas formas linetype: linetype = continent; linetype = “dashed” group: group = continent # x = gdpPercap, y = lifeExp ggplot(data = gapminder, mapping = aes(x = gdpPercap, y = lifeExp)) + geom_point() # x = lifeExp, y = gdpPercap ggplot(data = gapminder, mapping = aes(x = lifeExp, y = gdpPercap)) + geom_point() 1.3.2.1 Color, alpha, size Para elegir paletas de colores: colorbrewer Codigo HEX de colores # Grafico inicial ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() # Color &quot;rojo&quot; para los puntos ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(color = &quot;red&quot;) # Color en funcion de la variable &#39;continent&#39; ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() # Color en funcion de la variable &#39;continent&#39; + size ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2)) + geom_point() # Color en funcion de la variable &#39;continent&#39; + size + alpha ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2, alpha = .1)) + geom_point() Imagina que queremos asignar colores manualmente. ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(color = c(&quot;red&quot;, &quot;grey&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;black&quot;)) # Error: Aesthetics must be either length 1 or the same as the data (1704): colour Tenemos que indicar que el color depende de ‘class,’ y después usar scale_color_manual() ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() + scale_color_manual(values = c(&quot;red&quot;, &quot;grey&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;black&quot;)) 1.3.2.2 Shape Códigos para las distintas formas: SOURCE: https://r4ds.had.co.nz/data-visualisation.html#aesthetic-mappings ggplot(gapminder, aes(gdpPercap, lifeExp, shape = continent)) + geom_point() 1.3.2.3 Linetype Códigos para los distintos estilos de linea: SOURCE: http://sape.inf.usi.ch/quick-reference/ggplot2/linetype ggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) + stat_summary(fun.y = mean, geom = &quot;line&quot;) 1.3.3 Geoms Una de las cosas más difíciles (inicialmente) cuando nos enfrentamos a unos datos nuevos es elegir el método más efectivo para visualizar los datos. Hay varios recursos interesantes sobre cómo elegir una gráfica. En esta sección veremos distintos tipos de geoms_(). 1.3.3.1 geom_point y geom_jitter # Points ggplot(mpg, aes(displ, hwy)) + geom_point() # Jitter Points ggplot(mpg, aes(displ, hwy)) + geom_jitter() 1.3.3.2 geom_smooth # Linea de tendencia (default loess) ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() + geom_smooth() # Usamos lm ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point() + geom_smooth(method = &quot;lm&quot;) # Un smooth por cada clase ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point() + geom_smooth() # Coloreamos puntos pero mantenemos un solo smooth ggplot(gapminder, aes(gdpPercap, lifeExp)) + geom_point(aes(color = continent)) + geom_smooth() Hagamos una pausa para hacer algunos ejercicios usando diferentes geoms, colores… 1.3.3.3 geom_boxplot y geom_violin # Boxplot base ggplot(gapminder, aes(continent, lifeExp)) + geom_boxplot(alpha = .2) # Boxplot con fill ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_boxplot(alpha = .2) # Violins ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) # Combinamos ambos ggplot(gapminder, aes(continent, lifeExp)) + geom_boxplot(alpha = .2) + geom_violin(alpha = .2, aes(fill = continent)) 1.3.3.4 geom_histogram # Histogram - variable continua ggplot(gapminder, aes(lifeExp)) + geom_histogram() # Histogram - variable categorica ggplot(gapminder, aes(continent)) + geom_histogram(stat = &quot;count&quot;) # Histogram - variable categorica, con fill y alpha ggplot(gapminder, aes(continent, fill = continent, alpha = .2)) + geom_histogram(stat = &quot;count&quot;) 1.3.3.5 geom_dotplot # Dotplot ggplot(mpg, aes(manufacturer)) + geom_dotplot() + coord_flip() 1.3.3.6 geom_density # Density ggplot(gapminder, aes(lifeExp)) + geom_density() # Density with fill ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density() # Density with fill and alpha ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(alpha = .2) # Density - position stack ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(position = &quot;stack&quot;, alpha = .2) # Density - position fill ggplot(gapminder, aes(lifeExp, fill = continent)) + geom_density(position = &quot;fill&quot;, alpha = .2) 1.3.3.7 geom_density_ridges # geom_density_ridges ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(alpha = .2) # geom_density_ridges junto con raincloud points y histograma ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.7, scale = 0.9) 1.3.4 Facets Hay dos funciones para facet_grid y facet_wrap. facet_grid(~ variable) nos devuelve una matriz simétrica de gráficas. facet_wrap(~ variable) nos devuelve tantas facetas como niveles de la variable. 1.3.4.1 facet_grid # Plot inicial ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .2) + facet_grid(~ continent) + guides(alpha = FALSE, color = FALSE) # Cambiamos ejes ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .2) + facet_grid(continent ~ .) + guides(alpha = FALSE, color = FALSE) # Añadimos una segunda variable ggplot(gapminder, aes(gdpPercap, lifeExp, color = country)) + geom_line(alpha = .2) + facet_grid(continent ~ pop &gt; 5000000) + guides(alpha = FALSE, color = FALSE) 1.3.4.2 facet_wrap # Plot base ggplot(gapminder, aes(year, lifeExp, color = continent)) + geom_line(alpha = .2) + facet_wrap( ~ continent) + guides(alpha = FALSE, color = FALSE) # Una sola fila ggplot(gapminder, aes(year, lifeExp, color = continent)) + geom_line(alpha = .2) + facet_wrap( ~ continent, nrow = 1) + guides(alpha = FALSE, color = FALSE) # 5 filas ggplot(gapminder, aes(year, lifeExp, color = continent)) + geom_line(alpha = .2) + facet_wrap(continent ~ gdpPercap &gt; 4000, nrow = 5) + guides(alpha = FALSE, color = FALSE) 1.3.5 Transformaciones estadísticas VER: https://r4ds.had.co.nz/data-visualisation.html#statistical-transformations 1.3.5.1 Proporciones # Gráfico inicial ggplot(gapminder, aes(continent)) + geom_bar() # Proporciones ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() 1.3.5.2 stat_summary # Mediana, máximo y mínimo ggplot(gapminder, aes(continent, lifeExp)) + stat_summary( fun.ymin = min, fun.ymax = max, fun.y = median) # Media y media ± sd ggplot(gapminder, aes(continent, lifeExp)) + stat_summary( fun.ymin = function(x) mean(x) - sd(x), fun.ymax = function(x) mean(x) + sd(x), fun.y = mean) 1.3.5.3 Promedios por grupo # Plot inicial ggplot(mpg) + geom_jitter(aes(x = class, y = hwy), width = 0.2) + theme_minimal() # Añadimos promedio por grupo (?) ggplot(mpg) + geom_jitter(aes(x = class, y = hwy), width = 0.2) + stat_summary(aes(x = class, y = hwy), fun = mean) + theme_minimal() # Version &quot;refinada&quot; ggplot(mpg) + geom_jitter(aes(x = class, y = hwy), width = 0.2) + stat_summary(aes(x = class, y = hwy), fun = mean, color = &quot;red&quot;, geom = &quot;point&quot;, size = 4, alpha = .7) + theme_minimal() # More things! ggplot(mpg) + geom_jitter(aes(x = class, y = hwy), width = 0.2) + stat_summary(aes(x = class, y = hwy), fun = mean, color = &quot;red&quot;, geom = &quot;point&quot;, size = 4, alpha = .7) + stat_summary(aes(x = class, y = hwy), fun = median, color = &quot;green&quot;, geom = &quot;point&quot;, shape = &quot;triangle&quot;, size = 4, alpha = .7) + theme_minimal() Ejemplos más complejos # Usando lineas ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .6, size = 4) + # geom_line(alpha = .3, size = 1) + stat_summary(fun.y = mean, geom = &quot;line&quot;, size = 1, alpha = .3) # Gapminder ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + stat_summary(data = gapminder %&gt;% group_by(continent) %&gt;% summarise(gdpPercap = mean(gdpPercap), lifeExp = mean(lifeExp)), fun.y = mean, geom = &quot;point&quot;, size = 4) # Iris ggplot(iris, aes(Petal.Length, Petal.Width, color = Species)) + geom_point(alpha = .4) + stat_summary(data = iris %&gt;% group_by(Species) %&gt;% summarise(Petal.Length = mean(Petal.Length), Petal.Width = mean(Petal.Width)), fun.y = mean, geom = &quot;point&quot;, size = 4) Hagamos una pausa para hacer algunos ejercicios con transformaciones estadísticas 1.3.6 Personalización de gráficas 1.3.6.1 Coords # Gráfico inicial ggplot(gapminder, aes(continent)) + geom_bar() # coord_flip() ggplot(gapminder, aes(continent)) + geom_bar() + coord_flip() # coord_polar() ggplot(gapminder, aes(continent)) + geom_bar() + coord_polar() 1.3.6.2 Scales # Grafico inicial ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) # Añadimos breaks en eje y ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) # Separador de miles y breaks en x ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + hrbrthemes::scale_x_comma(breaks = seq(0, 100000, 10000)) # Formato de $ ($M) ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_continuous(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;), breaks = seq(0, 100000, 20000)) # Escala log ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;)) # Invertimos escala ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_reverse() # No mostramos el texto de los breaks de x ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_reverse() + theme(axis.text.x = element_blank()) # Proporciones ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() # % ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() + scale_y_continuous(labels = scales::percent) 1.3.6.3 Colors and fill scales # Plot inicial ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) # Relleno usando paleta blues ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + geom_violin(alpha = .2) + scale_fill_brewer(palette = &quot;Blues&quot;) # Color grey ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) + geom_point() + scale_color_grey(start = 0.2, end = 0.8, na.value = &quot;red&quot;) # Gradient ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) + geom_point() + scale_color_gradient(low = &quot;red&quot;, high = &quot;blue&quot;) # Gradient con un numero predefinidos de una paleta ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) + geom_point() + scale_colour_gradientn(colours = terrain.colors(3)) 1.3.6.4 Combinando gráficas plot1 = ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + geom_point(alpha = .1) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;)) + theme(legend.position = &quot;top&quot;) plot2 = ggplot(gapminder, aes(continent, ..prop.., group = 1)) + geom_bar() + scale_y_continuous(labels = scales::percent) + coord_flip() cowplot::plot_grid(plot2, plot1, rel_widths = c(.3, 0.7)) # SOURCE: https://stackoverflow.com/questions/8545035/scatterplot-with-marginal-histograms-in-ggplot2/56440634#56440634 if (!require(&#39;cowplot&#39;)) install.packages(&#39;cowplot&#39;); library(&#39;cowplot&#39;) # Set up scatterplot scatterplot &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) + geom_point(size = 3, alpha = 0.6) + guides(color = FALSE) + theme(plot.margin = margin()) # Define marginal histogram marginal_distribution &lt;- function(x, var, group) { ggplot(x, aes_string(x = var, fill = group)) + geom_histogram(bins = 30, alpha = 0.4, position = &quot;identity&quot;) + # geom_density(alpha = 0.4, size = 0.1) + guides(fill = FALSE) + theme_void() + theme(plot.margin = margin()) } # Set up marginal histograms x_hist &lt;- marginal_distribution(iris, &quot;Sepal.Length&quot;, &quot;Species&quot;) y_hist &lt;- marginal_distribution(iris, &quot;Sepal.Width&quot;, &quot;Species&quot;) + coord_flip() # Align histograms with scatterplot aligned_x_hist &lt;- align_plots(x_hist, scatterplot, align = &quot;v&quot;)[[1]] aligned_y_hist &lt;- align_plots(y_hist, scatterplot, align = &quot;h&quot;)[[1]] # Arrange plots plot_grid( aligned_x_hist , NULL , scatterplot , aligned_y_hist , ncol = 2 , nrow = 2 , rel_heights = c(0.2, 1) , rel_widths = c(1, 0.2)) 1.3.6.5 Usando estilos https://ggplot2.tidyverse.org/reference/ggtheme.html https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) # Create a base graph p &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) + geom_point() + labs(title = &#39;A ggplot simple graph&#39;, subtitle = &#39;Simple tweaks to improve plots, or not&#39;, x = &#39;&#39;, y = &#39;&#39;, caption = &#39;https://github.com/gorkang / @gorkang&#39;) + theme_gray() # This is the default. Needed here because of the Bookdown theme p Usando el tema fivethirtyeight # if (!require(&#39;hrbrthemes&#39;)) install.packages(&#39;hrbrthemes&#39;); library(&#39;hrbrthemes&#39;) if (!require(&#39;ggthemes&#39;)) install.packages(&#39;ggthemes&#39;); library(&#39;ggthemes&#39;) p + ggthemes::scale_color_fivethirtyeight() + ggthemes::theme_fivethirtyeight() Usando el tema economist p + ggthemes::scale_color_economist() + ggthemes::theme_economist() Hagamos una pausa para hacer algunos ejercicios usando temas, paletas… 1.4 Visualización interactiva 1.4.0.1 Gráficas interactivas if (!require(&#39;plotly&#39;)) install.packages(&#39;plotly&#39;); library(&#39;plotly&#39;) plotly::ggplotly( ggplot(gapminder %&gt;% filter(year == 2007), aes(gdpPercap, lifeExp, color = continent, size = country)) + geom_point(alpha = .3, point = 2) + scale_y_continuous(breaks = seq(0, 100, 5)) + scale_x_log10(labels = scales::dollar_format(prefix=&quot;$&quot;, suffix = &quot;M&quot;)) + theme(legend.position = &quot;none&quot;) ) 1.4.0.2 Animando gráficas if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;gganimate&#39;)) devtools::install_github(&#39;thomasp85/gganimate&#39;); library(&#39;gganimate&#39;) #sudo apt-get install ffmpeg p = ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) + geom_point(alpha = 0.7, show.legend = FALSE) + scale_colour_manual(values = country_colors) + scale_size(range = c(2, 12)) + scale_x_log10() + facet_wrap(~continent) + # Here comes the gganimate specific bits labs(title = &#39;Year: {frame_time}&#39;, x = &#39;GDP per capita&#39;, y = &#39;life expectancy&#39;) + transition_time(year) + ease_aes(&#39;linear&#39;) animate(p, renderer = ffmpeg_renderer()) 1.5 Ejercicios 1.5.1 Ejercicios con Geoms, colores… Usando el df mpg, Crea los 6 plots que se pueden ver más abajo. Aquí tienes el plot base, para hacer mas fácil la tarea: ggplot(mpg, aes(displ, hwy)) + geom_point() + theme_grey() Además de generar uno a uno los 6 plots, serías capaz de generar la figura que se ve abajo? Esto es, un plot que incluye los 6 plots juntos. Con el DF diamonds, crea el siguiente plot: El plot del panel (A) tiene varios problemas (los años no son enteros o factores, los casos no se muestran con un separador de miles, la leyenda esta a la derecha ocupado un espacio precioso, etc.). Trata de resolverlos e intenta llegar al resultado que se ve en el panel (B). Usa el df table1 del paquete {tidyr}? 1.5.2 Sintaxis aes() Alguna de estas gráficas dará un error? Sin correr el código, sabrías decir cuál de ellas? Hay varias soluciones posibles, ¿Cuales serían?. ggplot(mpg, mapping = aes(displ, hwy, color = class)) + geom_point() + stat_summary(fun.y = mean, geom = &quot;line&quot;, linetype = &quot;dashed&quot;) ggplot(mpg, mapping = aes(displ, hwy, color = class, linetype = class)) + geom_point() + stat_summary(fun.y = mean, geom = &quot;line&quot;) ggplot(mpg, mapping = aes(displ, hwy, color = class)) + geom_point() + stat_summary(fun.y = mean, geom = &quot;line&quot;, linetype = class) 1.5.3 Temas 6a. Serías capaz de reproducir este gráfico, usando el df diamonds y el theme_economist? 6b. Serías capaz de reproducir este gráfico, usando el df gapminder y la paleta Accent? 1.5.4 Transformaciones estadísticas Cuando al plot A trato de añadirle lineas con me aparece algo como lo de B. plotA = ggplot(mpg, aes(displ, hwy, color = class)) + geom_point() + theme(legend.position = &quot;bottom&quot;) plotB = ggplot(mpg, aes(displ, hwy, color = class)) + geom_point() + geom_line() + theme(legend.position = &quot;bottom&quot;) cowplot::plot_grid(plotA, plotB, labels = c(&quot;A&quot;, &quot;B&quot;)) Pero en realidad yo quiero algo como esto. ¿Podrías reproducirlo? Podrías crear este gráfico? Mostramos mediana ± sd para cada país, organizado por continente. Bibliografía Matejka, J., &amp; Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM. https://bbc.github.io/rcookbook/ https://github.com/bbc/bbplot https://github.com/dreamRs/esquisse Garrick Aden-Buie. A Gentle Guide to the Grammar of Graphics with ggplot2: https://github.com/gadenbuie/gentle-ggplot2 Michael Toth. You Need to Start Branding Your Graphs. Here’s How, with ggplot!: https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html Claus Wilke: https://wilkelab.org/practicalgg/ Thomas Lin Pedersen: Part 1: https://www.youtube.com/watch?v=h29g21z0a68 Part 2: https://www.youtube.com/watch?v=0m4yywqNPVY "],["preparación-y-transformación-de-datos.html", "Capítulo 2 Preparación y transformación de datos 2.1 Importar y exportar datos 2.2 Preparación y transformación de datos 2.3 Combinar bases de datos 2.4 Más allá de la manipulación 2.5 Datasets interesantes Bibliografía", " Capítulo 2 Preparación y transformación de datos En este capítulo vamos a aprender a importar y exportar todo tipo de archivos, ademas de pasar de una base de datos no especialmente amigable, a una base de datos tidy, esto es, siguiendo algunas reglas bien sencillas que harán más fácil trabajar con los datos. Paquetes para este capítulo if (!require(&quot;tidyverse&quot;)) install.packages(&quot;tidyverse&quot;); library(&quot;tidyverse&quot;) if (!require(&quot;readxl&quot;)) install.packages(&quot;readxl&quot;); library(&quot;readxl&quot;) if (!require(&quot;haven&quot;)) install.packages(&quot;haven&quot;); library(&quot;haven&quot;) if (!require(&quot;here&quot;)) install.packages(&quot;here&quot;); library(&quot;here&quot;) if (!require(&quot;readODS&quot;)) install.packages(&quot;readODS&quot;); library(&quot;readODS&quot;) if (!require(&quot;writexl&quot;)) install.packages(&quot;writexl&quot;); library(&quot;writexl&quot;) if (!require(&quot;DT&quot;)) install.packages(&quot;DT&quot;); library(&quot;DT&quot;) if (!require(&quot;gsheet&quot;)) install.packages(&quot;gsheet&quot;); library(&quot;gsheet&quot;) if (!require(&quot;janitor&quot;)) install.packages(&quot;janitor&quot;); library(&quot;janitor&quot;) if (!require(&#39;caret&#39;)) install.packages(&quot;caret&quot;, dependencies = c(&quot;Depends&quot;, &quot;Suggests&quot;)); library(&#39;caret&#39;) if (!require(&#39;FFTrees&#39;)) install.packages(&#39;FFTrees&#39;); library(&#39;FFTrees&#39;) 2.1 Importar y exportar datos Podemos ver las funciones de esta sección y como usarlas en la Cheatsheet importar datos 2.1.1 Importar un solo archivo Vamos a ver con más detalle los archivos CSV (comma separated values). Las funciones para importar archivos excel, Libreoffice, SPSS, etc. tienen parámetros muy similares. 2.1.1.1 Archivos CSV Usaremos las siguientes funciones del paquete readr: readr::read_csv(): valores separados por coma (“,”) readr::read_csv2(): valores separados por punto y coma (“;”) readr::read_delim( , delim = \"|\"): valores separados por un delimitador arbitrario # Cargamos libreria if (!require(&quot;readr&quot;)) install.packages(&quot;readr&quot;); library(&quot;readr&quot;) # Version simple DF_name = read_csv(&quot;data/files/02-read-csv.csv&quot;) # Version avanzada name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.1.2 Otros tipos de archivos 2.1.1.2.1 Archivos excel if (!require(&quot;readxl&quot;)) install.packages(&quot;readxl&quot;); library(&quot;readxl&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-xlsx.xlsx&quot;) readxl::read_excel(name_of_file) ## # A tibble: 103 x 8 ## ...1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.1.2.2 Archivos SPSS if (!require(&quot;haven&quot;)) install.packages(&quot;haven&quot;); library(&quot;haven&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-sav.sav&quot;) haven::read_sav(name_of_file) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.1.2.3 Archivos Libreoffice if (!require(&quot;readODS&quot;)) install.packages(&quot;readODS&quot;); library(&quot;readODS&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-ods.ods&quot;) df_ODS = readODS::read_ods(name_of_file) # Vemos las primeras filas head(df_ODS) ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 2.1.1.2.4 Google sheets Para poder leer una gsheet debemos antes crear un enlace para compartirla: \"Share\" -&gt; \"Get shareable link\" if (!require(&quot;gsheet&quot;)) install.packages(&quot;gsheet&quot;); library(&quot;gsheet&quot;) name_of_sheet = &quot;1jjb91j2X13_JKDAeIwrKIdNv0rcseMdteSqb0ZMVOig/edit#gid=807114896&quot; gsheet::gsheet2tbl(name_of_sheet) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.1.2 Ejercicios - Importar datos En el repositorio R para preparación y visualización de datos - DNSC - UAI de la Open Science Foundation podrás ver una carpeta llamada Capitulo 2. Importa los archivos que ahí aparecen: 02-extralines-1.xlsx 02-extralines-2.xlsx 02-extralines-3.xlsx 02-spanish.csv 2.1.3 Importar múltiples archivos En ocasiones tenemos múltiples archivos en una carpeta (e.g. uno por participante) y queremos combinarlos todos en un solo DF. if (!require(&quot;purrr&quot;)) install.packages(&quot;purrr&quot;); library(&quot;purrr&quot;) if (!require(&quot;readr&quot;)) install.packages(&quot;readr&quot;); library(&quot;readr&quot;) if (!require(&quot;readxl&quot;)) install.packages(&quot;readxl&quot;); library(&quot;readxl&quot;) Importamos los archivos que están en la carpeta data/files/02-CSVs # Directorio donde se encuentran los archivos name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) # Listamos los archivos a leer files &lt;- list.files(name_of_folder, full.names = TRUE) # Leemos todos los archivos, combinandolos en un dataframe full &lt;- map_df(files, read_csv) full ## # A tibble: 1,600 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,590 more rows 2.1.3.1 Incluir nombres de archivos Incluimos nombres de archivo en una columna: name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) files &lt;- list.files(name_of_folder, full.names = TRUE) %&gt;% set_names(basename(.)) full2 &lt;- map_df(files, read_csv, .id = &quot;file&quot;) full2 ## # A tibble: 1,600 x 10 ## file Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 01.csv male Collecti… 1 we ofensivo negati… yes left 623 ## 2 01.csv male Collecti… 2 we resentido negati… no right 1235 ## 3 01.csv male Collecti… 3 we ego�sta negati… yes left 335 ## 4 01.csv male Collecti… 4 we indiscre… negati… yes left 355 ## 5 01.csv male Collecti… 5 we sumiso negati… yes left 618 ## 6 01.csv male Collecti… 6 we agradable positi… yes left 328 ## 7 01.csv male Collecti… 7 we clasista negati… yes left 348 ## 8 01.csv male Collecti… 8 we altruista positi… yes left 1620 ## 9 01.csv male Collecti… 9 we ansioso negati… yes left 346 ## 10 01.csv male Collecti… 10 we presumido negati… yes left 778 ## # … with 1,590 more rows 2.1.3.2 Con parametros Añadimos parametros a la funcion de lectura. En este caso, definimos el tipo de columna esperado con la función col_types(). Con esto nos aseguraremos que si alguno de los archivos tiene el tipo de datos “incorrecto,” aparecerán warnings en la importación: name_of_folder = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;) files &lt;- list.files(name_of_folder, full.names = TRUE) full &lt;- map_df(files, read_csv, col_types = cols( Sex = col_factor(), Priming = col_character(), trialN = col_integer(), Block = col_character(), Adjective = col_character(), Valence = col_factor(), Answer = col_character(), Arrow = col_character(), rT = col_double())) full ## # A tibble: 1,600 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,590 more rows 2.1.4 Ejercicios - Importar múltiples archivos Cuando más arriba importamos los archivos que están en la carpeta data/files/02-CSVs, ¿qué archivos importamos exáctamente? ¿Ves algún problema en lo que hicimos? El resultado final deberia ser así: ## # A tibble: 1,200 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,190 more rows Leed los archivos .xlsx de la carpeta data/files/02-XLSs, combinándolos en un único DF. El resultado final debería ser como se ve a continuación: ## # A tibble: 1,200 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 1,190 more rows 2.1.5 Exportar datos 2.1.5.1 Archivos CSV # Versión simple write_csv(DF_name, &quot;data/files/02-write-csv.csv&quot;) # Versión avanzada name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-csv.csv&quot;) write_csv(DF_name, name_of_file) 2.1.5.2 Otros Archivos if (!require(&quot;writexl&quot;)) install.packages(&quot;writexl&quot;); library(&quot;writexl&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-xlsx.xlsx&quot;) writexl::write_xlsx(DF_name, name_of_file) if (!require(&quot;haven&quot;)) install.packages(&quot;haven&quot;); library(&quot;haven&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-sav.sav&quot;) haven::write_sav(DF_name, name_of_file) if (!require(&quot;readODS&quot;)) install.packages(&quot;readODS&quot;); library(&quot;readODS&quot;) name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-write-ods.ods&quot;) readODS::write_ods(DF_name, name_of_file) 2.2 Preparación y transformación de datos Para la preparación y transformación de datos usaremos fundamentalmente dplyr. Hay otros paquetes más rápidos como data.table. Si trabajas con datos gigantescos (millones de filas), sin duda notarás la diferencia. La desventaja es que la sintaxis es (habitualmente) algo más difícil. 2.2.1 Tidy data Existen tres sencillas reglas que definen la Tidy data: Cada variable tiene su columna propia Cada observacion tiene su fila propia Cada valor tiene su celda propia Las ventajas fundamentales son: Uso de una manera consistente de trabajar, que se alinea con el tidyverse Facilidad para trabajar con la logica vectorizada Por ejemplo. De manera muy sencilla y rápida podemos crear una nueva columna realizando algún cómputo arbitrario con los valores de otra columna. if (!require(&quot;tidyverse&quot;)) install.packages(&quot;tidyverse&quot;); library(&quot;tidyverse&quot;) # Compute rate per 100,000 table1 %&gt;% mutate(rate_per_100K = cases / population * 100000) ## # A tibble: 6 x 5 ## country year cases population rate_per_100K ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 3.73 ## 2 Afghanistan 2000 2666 20595360 12.9 ## 3 Brazil 1999 37737 172006362 21.9 ## 4 Brazil 2000 80488 174504898 46.1 ## 5 China 1999 212258 1272915272 16.7 ## 6 China 2000 213766 1280428583 16.7 O contar el número de casos por valor de una variable. # Compute cases per year table1 %&gt;% count(year, wt = cases) ## # A tibble: 2 x 2 ## year n ## &lt;int&gt; &lt;int&gt; ## 1 1999 250740 ## 2 2000 296920 Y, como no, ggplot funciona con datos tidy, en formato long. # Visualise changes over time if (!require(&quot;tidyverse&quot;)) install.packages(&quot;tidyverse&quot;); library(&quot;tidyverse&quot;) ggplot(table1, aes(as.factor(year), cases)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country)) 2.2.2 Verbos dplyr Usaremos {dplyr}, un paquete muy potente para la manipulación de datos. Su sintaxis, además, es bastante intuitiva (¡son verbos en inglés!). Usando pipes %&gt;% (CONTROL + SHIFT + M) podemos enlazar operaciones de transformación de datos de manera muy sencilla (una vez nos aprendamos los verbos). Verbos esenciales: filter(): filtrar filas arrange(): ordenar filas select(): seleccionar columnas rename(): renombrar columnas mutate(): crear columnas, modificar columnas, etc. Podemos ver mas detalle y ejemplos en la Cheatsheet de dplyr. Tabla resumen dplyr 2.2.2.1 Filtrar y ordenar filas # DF original name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Filtrar DF_name %&gt;% filter(Educacion &gt; 8) ## # A tibble: 3 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 157 12207 1 26 9 57 PPV_Cond2 45 ## 2 287 60873 1 72 10 51 PPV_Cond3 99 ## 3 381 64486 2 19 9 80 PPV_Cond4 92 # Ordenar DF_name %&gt;% arrange(Educacion, desc(Genero)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 350 20439 2 41 1 81 PPV_Cond4 92 ## 2 399 81379 1 36 1 90 PPV_Cond4 92 ## 3 42 20361 2 37 2 60 PPV_Cond1 1 ## 4 364 19201 2 21 2 67 PPV_Cond4 10 ## 5 412 60292 1 28 2 90 PPV_Cond4 80 ## 6 44 92735 2 30 3 95 PPV_Cond1 99 ## 7 135 32344 2 34 3 81 PPV_Cond2 46 ## 8 299 33562 2 35 3 95 PPV_Cond3 99 ## 9 333 29837 2 28 3 80 PPV_Cond4 60 ## 10 361 57804 2 40 3 30 PPV_Cond4 90 ## # … with 93 more rows 2.2.2.2 Seleccionar, ordenar y renombrar columnas # Seleccionar columnas DF_name %&gt;% select(Genero, Edad) ## # A tibble: 103 x 2 ## Genero Edad ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 47 ## 2 2 21 ## 3 2 29 ## 4 2 27 ## 5 1 29 ## 6 2 28 ## 7 2 27 ## 8 2 55 ## 9 2 28 ## 10 1 46 ## # … with 93 more rows # Eliminar columnas DF_name %&gt;% select(-X1) ## # A tibble: 103 x 7 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 1 47 8 80 PPV_Cond1 99 ## 2 95041 2 21 6 90 PPV_Cond1 99 ## 3 74594 2 29 6 10 PPV_Cond1 99 ## 4 72903 2 27 7 75 PPV_Cond1 1 ## 5 21260 1 29 5 35 PPV_Cond1 24 ## 6 50315 2 28 6 14 PPV_Cond1 99 ## 7 21774 2 27 4 2 PPV_Cond1 99 ## 8 20881 2 55 6 89 PPV_Cond1 99 ## 9 39751 2 28 6 6 PPV_Cond1 99 ## 10 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Ordenar y eliminar columnas DF_name %&gt;% select(ID, Edad, Genero, everything(), -X1) ## # A tibble: 103 x 7 ## ID Edad Genero Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 47 1 8 80 PPV_Cond1 99 ## 2 95041 21 2 6 90 PPV_Cond1 99 ## 3 74594 29 2 6 10 PPV_Cond1 99 ## 4 72903 27 2 7 75 PPV_Cond1 1 ## 5 21260 29 1 5 35 PPV_Cond1 24 ## 6 50315 28 2 6 14 PPV_Cond1 99 ## 7 21774 27 2 4 2 PPV_Cond1 99 ## 8 20881 55 2 6 89 PPV_Cond1 99 ## 9 39751 28 2 6 6 PPV_Cond1 99 ## 10 99384 46 1 5 0 PPV_Cond1 1 ## # … with 93 more rows # Renombrar columnas DF_name %&gt;% rename(Identificador = ID, Sexo = Genero) ## # A tibble: 103 x 8 ## X1 Identificador Sexo Edad Educacion FollowUP condition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 ## 2 5 95041 2 21 6 90 PPV_Cond1 ## 3 6 74594 2 29 6 10 PPV_Cond1 ## 4 15 72903 2 27 7 75 PPV_Cond1 ## 5 16 21260 1 29 5 35 PPV_Cond1 ## 6 18 50315 2 28 6 14 PPV_Cond1 ## 7 19 21774 2 27 4 2 PPV_Cond1 ## 8 20 20881 2 55 6 89 PPV_Cond1 ## 9 21 39751 2 28 6 6 PPV_Cond1 ## 10 22 99384 1 46 5 0 PPV_Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; # Renombrar usando la posicion (DANGER!) DF_name %&gt;% rename(Identificador = 2) ## # A tibble: 103 x 8 ## X1 Identificador Genero Edad Educacion FollowUP condition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 ## 2 5 95041 2 21 6 90 PPV_Cond1 ## 3 6 74594 2 29 6 10 PPV_Cond1 ## 4 15 72903 2 27 7 75 PPV_Cond1 ## 5 16 21260 1 29 5 35 PPV_Cond1 ## 6 18 50315 2 28 6 14 PPV_Cond1 ## 7 19 21774 2 27 4 2 PPV_Cond1 ## 8 20 20881 2 55 6 89 PPV_Cond1 ## 9 21 39751 2 28 6 6 PPV_Cond1 ## 10 22 99384 1 46 5 0 PPV_Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; # Renombrar usando vectores oldnames = c(&quot;ID&quot;,&quot;Genero&quot;) newnames = c(&quot;Identificador&quot;,&quot;Sexo&quot;) DF_name %&gt;% rename_at(vars(oldnames), ~ newnames) ## # A tibble: 103 x 8 ## X1 Identificador Sexo Edad Educacion FollowUP condition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 ## 2 5 95041 2 21 6 90 PPV_Cond1 ## 3 6 74594 2 29 6 10 PPV_Cond1 ## 4 15 72903 2 27 7 75 PPV_Cond1 ## 5 16 21260 1 29 5 35 PPV_Cond1 ## 6 18 50315 2 28 6 14 PPV_Cond1 ## 7 19 21774 2 27 4 2 PPV_Cond1 ## 8 20 20881 2 55 6 89 PPV_Cond1 ## 9 21 39751 2 28 6 6 PPV_Cond1 ## 10 22 99384 1 46 5 0 PPV_Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; 2.2.2.2.1 Selección avanzada con select_helpers() El everything() que usamos dentro de select() más arriba es uno de los select_helpers() existentes. Estos permiten realizar operaciones de selección de variables de manera más sencilla. select_helpers() starts_with(): Empieza con un prefijo (e.g. starts_with(\")) ends_with(): Ends with a suffix contains(): Contains a literal string matches(): Matches a regular expression num_range(): Matches a numerical range like x01, x02, x03 one_of(): Matches variable names in a character vector everything(): Matches all variables last_col(): Select last variable, possibly with an offset Trabajaremos con los datos del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base RAW en formato wide. # DF original df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) cat(names(df_wide)) ## ID dem_genero dem_edad dem_nivedu WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod WVOC_06_cod WVOC_07_cod WVOC_08_cod WVOC_09_cod WVOC_10_cod WVOC_11_cod WVOC_12_cod WVOC_13_cod WVOC_14_cod WVOC_15_cod WVOC_16_cod WVOC_17_cod WVOC_18_cod WVOC_19_cod WVOC_20_cod WVOC_21_cod WVOC_22_cod WVOC_23_cod WVOC_24_cod WVOC_25_cod WVOC_26_cod WVOC_27_cod WVOC_28_cod WVOC_29_cod WVOC_30_cod WVOC_31_cod WVOC_32_cod WVOC_33_cod WVOC_TOTAL WVOC_TOTAL_STD WMAT_01_cod WMAT_01_raw WMAT_02_cod WMAT_02_raw WMAT_03_cod WMAT_03_raw WMAT_04_cod WMAT_04_raw WMAT_05_cod WMAT_05_raw WMAT_06_cod WMAT_06_raw WMAT_07_cod WMAT_07_raw WMAT_08_cod WMAT_08_raw WMAT_09_cod WMAT_09_raw WMAT_10_cod WMAT_10_raw WMAT_11_cod WMAT_11_raw WMAT_12_cod WMAT_12_raw WMAT_13_cod WMAT_13_raw WMAT_14_cod WMAT_14_raw WMAT_15_cod WMAT_15_raw WMAT_16_cod WMAT_16_raw WMAT_17_cod WMAT_17_raw WMAT_18_cod WMAT_18_raw WMAT_19_cod WMAT_19_raw WMAT_20_cod WMAT_20_raw WMAT_21_cod WMAT_21_raw WMAT_22_cod WMAT_22_raw WMAT_23_cod WMAT_23_raw WMAT_24_cod WMAT_24_raw WMAT_25_cod WMAT_25_raw WMAT_26_cod WMAT_26_raw WMAT_A WMAT_B WMAT_C wmat_total wmat_total_std bfbs_01_cod bfbs_01_conf bfbs_01_raw bfbs_03_cod bfbs_03_conf bfbs_03_raw bfbs_04_cod bfbs_04_conf bfbs_04_raw bfbs_10_cod bfbs_10_conf bfbs_10_raw bfbs_12_cod bfbs_12_conf bfbs_12_raw bfbs_14_cod bfbs_14_conf bfbs_14_raw bfbs_17_cod bfbs_17_conf bfbs_17_raw bfbs_23_cod bfbs_23_conf bfbs_23_raw bfbs_conf_total bfbs_cong_conf bfbs_cong_total bfbs_creib_conf bfbs_creib_total bfbs_incong_conf bfbs_incon_total bfbs_increib_conf bfbs_increib_total bfbs_invalid_conf bfbs_invalid_total bfbs_total bfbs_valid_conf bfbs_valid_total EA_01_raw EA_02_raw EA_03_raw EA_04_raw EA_05_raw EA_06_raw EA_07_raw EA_08_raw EA_09_raw EA_10_raw EA_11_raw EA_12_raw EA_13_raw EA_14_raw EA_15_raw EA_16_raw EA_17_raw EA_18_raw EA_19_raw EA_20_raw EA_21_raw EA_22_raw EA_23_raw EA_24_raw EA_azar_TOTAL EA_control_interno_TOTAL EA_otros_poderosos_TOTAL EAR_01_raw EAR_02_raw EAR_03_raw EAR_04_raw EAR_05_raw EAR_06_raw EAR_07_raw EAR_08_raw EAR_09_raw EAR_10_raw EAR_TOTAL ECRRS_ansiedad_TOTAL ECRRS_evitacion_TOTAL ECRRS_madre_01_raw ECRRS_madre_02_raw ECRRS_madre_03_raw ECRRS_madre_04_raw ECRRS_madre_05_raw ECRRS_madre_06_raw ECRRS_madre_07_raw ECRRS_madre_08_raw ECRRS_madre_09_raw ECRRS_madre_ansiedad_TOTAL ECRRS_madre_evitacion_TOTAL ECRRS_mejoramig_01_raw ECRRS_mejoramig_02_raw ECRRS_mejoramig_03_raw ECRRS_mejoramig_04_raw ECRRS_mejoramig_05_raw ECRRS_mejoramig_06_raw ECRRS_mejoramig_07_raw ECRRS_mejoramig_08_raw ECRRS_mejoramig_09_raw ECRRS_mejoramigo_ansiedad_TOTAL ECRRS_mejoramigo_evitacion_TOTAL ECRRS_padre_01_raw ECRRS_padre_02_raw ECRRS_padre_03_raw ECRRS_padre_04_raw ECRRS_padre_05_raw ECRRS_padre_06_raw ECRRS_padre_07_raw ECRRS_padre_08_raw ECRRS_padre_09_raw ECRRS_padre_ansiedad_TOTAL ECRRS_padre_evitacion_TOTAL ECRRS_pareja_01_raw ECRRS_pareja_02_raw ECRRS_pareja_03_raw ECRRS_pareja_04_raw ECRRS_pareja_05_raw ECRRS_pareja_06_raw ECRRS_pareja_07_raw ECRRS_pareja_08_raw ECRRS_pareja_09_raw ECRRS_pareja_ansiedad_TOTAL ECRRS_pareja_evitacion_TOTAL GHQ_01 GHQ_02 GHQ_03 GHQ_04 GHQ_05 GHQ_06 GHQ_07 GHQ_08 GHQ_09 GHQ_10 GHQ_11 GHQ_12 GHQ_autoestima_TOTAL GHQ_estres_TOTAL GHQ_exito_afrontamiento_TOTAL GHQ_TOTAL wdig_dir_total wdig_inv_total WDIGSIMB_TOTAL wdig_total wdig_total_std lkns_01_cod lkns_01_raw lkns_02_cod lkns_02_raw lkns_03_cod lkns_03_raw lkns_04_cod lkns_04_raw lkns_05_cod lkns_05_raw lkns_06_cod lkns_06_raw lkns_07_cod lkns_07_raw lkns_08_cod lkns_08_raw lkns_09_cod lkns_09_raw lkns_10_cod lkns_10_raw lkns_11_cod lkns_11_raw lkns_total SASS_01_raw SASS_02_raw SASS_03_raw SASS_04_raw SASS_05_raw SASS_06_raw SASS_07_raw SASS_08_raw SASS_09_raw SASS_10_raw SASS_11_raw SASS_12_raw SASS_13_raw SASS_14_raw SASS_15_raw SASS_16_raw SASS_17_raw SASS_18_raw SASS_19_raw SASS_20_raw SASS_21_raw SASS_TOTAL SASS_trabajo bayes_all_accuracy bayes_all_confidence bayes_pictorial_qualitative_accuracy bayes_pictorial_quantitative_accuracy bayes_text_qualitative_accuracy bayes_text_quantitative_accuracy # Seleccionamos variables que contienen la cadena de texto &quot;dem&quot; df_wide %&gt;% select(contains(&quot;dem&quot;)) ## # A tibble: 232 x 3 ## dem_genero dem_edad dem_nivedu ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 38 4 ## 2 0 67 2 ## 3 0 24 4 ## 4 0 30 4 ## 5 0 38 3 ## 6 0 45 4 ## 7 1 58 3 ## 8 1 47 4 ## 9 1 52 3 ## 10 1 49 4 ## # … with 222 more rows # Seleccionamos variables que acacan con la cadena de texto &quot;cod&quot; df_wide %&gt;% select(ID, ends_with(&quot;cod&quot;)) ## # A tibble: 232 x 79 ## ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 2 2 1 2 ## 2 2 2 2 2 1 0 ## 3 3 2 2 2 1 2 ## 4 4 2 1 1 1 2 ## 5 5 2 2 1 1 0 ## 6 6 1 1 2 1 2 ## 7 7 1 0 2 1 0 ## 8 8 2 2 2 1 2 ## 9 9 2 2 2 2 2 ## 10 10 2 2 2 2 2 ## # … with 222 more rows, and 73 more variables: WVOC_06_cod &lt;dbl&gt;, ## # WVOC_07_cod &lt;dbl&gt;, WVOC_08_cod &lt;dbl&gt;, WVOC_09_cod &lt;dbl&gt;, ## # WVOC_10_cod &lt;dbl&gt;, WVOC_11_cod &lt;dbl&gt;, WVOC_12_cod &lt;dbl&gt;, ## # WVOC_13_cod &lt;dbl&gt;, WVOC_14_cod &lt;dbl&gt;, WVOC_15_cod &lt;dbl&gt;, ## # WVOC_16_cod &lt;dbl&gt;, WVOC_17_cod &lt;dbl&gt;, WVOC_18_cod &lt;dbl&gt;, ## # WVOC_19_cod &lt;dbl&gt;, WVOC_20_cod &lt;dbl&gt;, WVOC_21_cod &lt;dbl&gt;, ## # WVOC_22_cod &lt;dbl&gt;, WVOC_23_cod &lt;dbl&gt;, WVOC_24_cod &lt;dbl&gt;, ## # WVOC_25_cod &lt;dbl&gt;, WVOC_26_cod &lt;dbl&gt;, WVOC_27_cod &lt;dbl&gt;, ## # WVOC_28_cod &lt;dbl&gt;, WVOC_29_cod &lt;dbl&gt;, WVOC_30_cod &lt;dbl&gt;, ## # WVOC_31_cod &lt;dbl&gt;, WVOC_32_cod &lt;dbl&gt;, WVOC_33_cod &lt;dbl&gt;, ## # WMAT_01_cod &lt;dbl&gt;, WMAT_02_cod &lt;dbl&gt;, WMAT_03_cod &lt;dbl&gt;, ## # WMAT_04_cod &lt;dbl&gt;, WMAT_05_cod &lt;dbl&gt;, WMAT_06_cod &lt;dbl&gt;, ## # WMAT_07_cod &lt;dbl&gt;, WMAT_08_cod &lt;dbl&gt;, WMAT_09_cod &lt;dbl&gt;, ## # WMAT_10_cod &lt;dbl&gt;, WMAT_11_cod &lt;dbl&gt;, WMAT_12_cod &lt;dbl&gt;, ## # WMAT_13_cod &lt;dbl&gt;, WMAT_14_cod &lt;dbl&gt;, WMAT_15_cod &lt;dbl&gt;, ## # WMAT_16_cod &lt;dbl&gt;, WMAT_17_cod &lt;dbl&gt;, WMAT_18_cod &lt;dbl&gt;, ## # WMAT_19_cod &lt;dbl&gt;, WMAT_20_cod &lt;dbl&gt;, WMAT_21_cod &lt;dbl&gt;, ## # WMAT_22_cod &lt;dbl&gt;, WMAT_23_cod &lt;dbl&gt;, WMAT_24_cod &lt;dbl&gt;, ## # WMAT_25_cod &lt;dbl&gt;, WMAT_26_cod &lt;dbl&gt;, bfbs_01_cod &lt;dbl&gt;, ## # bfbs_03_cod &lt;dbl&gt;, bfbs_04_cod &lt;dbl&gt;, bfbs_10_cod &lt;dbl&gt;, ## # bfbs_12_cod &lt;dbl&gt;, bfbs_14_cod &lt;dbl&gt;, bfbs_17_cod &lt;dbl&gt;, ## # bfbs_23_cod &lt;dbl&gt;, lkns_01_cod &lt;dbl&gt;, lkns_02_cod &lt;dbl&gt;, ## # lkns_03_cod &lt;dbl&gt;, lkns_04_cod &lt;dbl&gt;, lkns_05_cod &lt;dbl&gt;, ## # lkns_06_cod &lt;dbl&gt;, lkns_07_cod &lt;dbl&gt;, lkns_08_cod &lt;dbl&gt;, ## # lkns_09_cod &lt;dbl&gt;, lkns_10_cod &lt;dbl&gt;, lkns_11_cod &lt;dbl&gt; # Lo mismo, pero usando expresiones regulares df_wide %&gt;% select(ID, matches(&quot;cod$&quot;)) ## # A tibble: 232 x 79 ## ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 2 2 1 2 ## 2 2 2 2 2 1 0 ## 3 3 2 2 2 1 2 ## 4 4 2 1 1 1 2 ## 5 5 2 2 1 1 0 ## 6 6 1 1 2 1 2 ## 7 7 1 0 2 1 0 ## 8 8 2 2 2 1 2 ## 9 9 2 2 2 2 2 ## 10 10 2 2 2 2 2 ## # … with 222 more rows, and 73 more variables: WVOC_06_cod &lt;dbl&gt;, ## # WVOC_07_cod &lt;dbl&gt;, WVOC_08_cod &lt;dbl&gt;, WVOC_09_cod &lt;dbl&gt;, ## # WVOC_10_cod &lt;dbl&gt;, WVOC_11_cod &lt;dbl&gt;, WVOC_12_cod &lt;dbl&gt;, ## # WVOC_13_cod &lt;dbl&gt;, WVOC_14_cod &lt;dbl&gt;, WVOC_15_cod &lt;dbl&gt;, ## # WVOC_16_cod &lt;dbl&gt;, WVOC_17_cod &lt;dbl&gt;, WVOC_18_cod &lt;dbl&gt;, ## # WVOC_19_cod &lt;dbl&gt;, WVOC_20_cod &lt;dbl&gt;, WVOC_21_cod &lt;dbl&gt;, ## # WVOC_22_cod &lt;dbl&gt;, WVOC_23_cod &lt;dbl&gt;, WVOC_24_cod &lt;dbl&gt;, ## # WVOC_25_cod &lt;dbl&gt;, WVOC_26_cod &lt;dbl&gt;, WVOC_27_cod &lt;dbl&gt;, ## # WVOC_28_cod &lt;dbl&gt;, WVOC_29_cod &lt;dbl&gt;, WVOC_30_cod &lt;dbl&gt;, ## # WVOC_31_cod &lt;dbl&gt;, WVOC_32_cod &lt;dbl&gt;, WVOC_33_cod &lt;dbl&gt;, ## # WMAT_01_cod &lt;dbl&gt;, WMAT_02_cod &lt;dbl&gt;, WMAT_03_cod &lt;dbl&gt;, ## # WMAT_04_cod &lt;dbl&gt;, WMAT_05_cod &lt;dbl&gt;, WMAT_06_cod &lt;dbl&gt;, ## # WMAT_07_cod &lt;dbl&gt;, WMAT_08_cod &lt;dbl&gt;, WMAT_09_cod &lt;dbl&gt;, ## # WMAT_10_cod &lt;dbl&gt;, WMAT_11_cod &lt;dbl&gt;, WMAT_12_cod &lt;dbl&gt;, ## # WMAT_13_cod &lt;dbl&gt;, WMAT_14_cod &lt;dbl&gt;, WMAT_15_cod &lt;dbl&gt;, ## # WMAT_16_cod &lt;dbl&gt;, WMAT_17_cod &lt;dbl&gt;, WMAT_18_cod &lt;dbl&gt;, ## # WMAT_19_cod &lt;dbl&gt;, WMAT_20_cod &lt;dbl&gt;, WMAT_21_cod &lt;dbl&gt;, ## # WMAT_22_cod &lt;dbl&gt;, WMAT_23_cod &lt;dbl&gt;, WMAT_24_cod &lt;dbl&gt;, ## # WMAT_25_cod &lt;dbl&gt;, WMAT_26_cod &lt;dbl&gt;, bfbs_01_cod &lt;dbl&gt;, ## # bfbs_03_cod &lt;dbl&gt;, bfbs_04_cod &lt;dbl&gt;, bfbs_10_cod &lt;dbl&gt;, ## # bfbs_12_cod &lt;dbl&gt;, bfbs_14_cod &lt;dbl&gt;, bfbs_17_cod &lt;dbl&gt;, ## # bfbs_23_cod &lt;dbl&gt;, lkns_01_cod &lt;dbl&gt;, lkns_02_cod &lt;dbl&gt;, ## # lkns_03_cod &lt;dbl&gt;, lkns_04_cod &lt;dbl&gt;, lkns_05_cod &lt;dbl&gt;, ## # lkns_06_cod &lt;dbl&gt;, lkns_07_cod &lt;dbl&gt;, lkns_08_cod &lt;dbl&gt;, ## # lkns_09_cod &lt;dbl&gt;, lkns_10_cod &lt;dbl&gt;, lkns_11_cod &lt;dbl&gt; 2.2.2.3 Modificar y añadir variables # DF original DF_name ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Modificar variable reemplazando valor DF_name %&gt;% mutate(PPV_DECLARED = PPV_DECLARED/100) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 0.99 ## 2 5 95041 2 21 6 90 PPV_Cond1 0.99 ## 3 6 74594 2 29 6 10 PPV_Cond1 0.99 ## 4 15 72903 2 27 7 75 PPV_Cond1 0.01 ## 5 16 21260 1 29 5 35 PPV_Cond1 0.24 ## 6 18 50315 2 28 6 14 PPV_Cond1 0.99 ## 7 19 21774 2 27 4 2 PPV_Cond1 0.99 ## 8 20 20881 2 55 6 89 PPV_Cond1 0.99 ## 9 21 39751 2 28 6 6 PPV_Cond1 0.99 ## 10 22 99384 1 46 5 0 PPV_Cond1 0.01 ## # … with 93 more rows # Añadir variable DF_name %&gt;% mutate(PPV_DECLARED_PCT = PPV_DECLARED/100) ## # A tibble: 103 x 9 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED_PCT &lt;dbl&gt; # Añadir variable destruyendo el resto del DF DF_name %&gt;% transmute(PPV_DECLARED_PCT = PPV_DECLARED/100) ## # A tibble: 103 x 1 ## PPV_DECLARED_PCT ## &lt;dbl&gt; ## 1 0.99 ## 2 0.99 ## 3 0.99 ## 4 0.01 ## 5 0.24 ## 6 0.99 ## 7 0.99 ## 8 0.99 ## 9 0.99 ## 10 0.01 ## # … with 93 more rows # Limpiar nombres if (!require(&quot;janitor&quot;)) install.packages(&quot;janitor&quot;); library(&quot;janitor&quot;) DF_name %&gt;% janitor::clean_names() ## # A tibble: 103 x 8 ## x1 id genero edad educacion follow_up condition ppv_declared ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows 2.2.2.4 Resúmenes agrupados La combinación de verbos group_by() y summarise() es una de las más usadas. Con esta podemos calcular promedios, medianas, etc. por condición de manera sencilla. # Resumen DF_name %&gt;% summarise(Promedio_PPV = mean(PPV_DECLARED), N = n()) ## # A tibble: 1 x 2 ## Promedio_PPV N ## &lt;dbl&gt; &lt;int&gt; ## 1 68.5 103 # Resumen agrupado DF_name %&gt;% group_by(Genero) %&gt;% summarise(Promedio_PPV = mean(PPV_DECLARED), N = n()) ## # A tibble: 2 x 3 ## Genero Promedio_PPV N ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 66.4 40 ## 2 2 69.9 63 # Resumen agrupando por multiples variables, y calculando varias cosas DF_name %&gt;% group_by(Genero, condition) %&gt;% summarise(promedio_PPV = mean(PPV_DECLARED), mediana_PPV = median(PPV_DECLARED), SD = sd(PPV_DECLARED), N = n()) ## # A tibble: 8 x 6 ## # Groups: Genero [2] ## Genero condition promedio_PPV mediana_PPV SD N ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 PPV_Cond1 63.8 88 43.1 9 ## 2 1 PPV_Cond2 51 46 10.3 13 ## 3 1 PPV_Cond3 75.6 80 32.5 5 ## 4 1 PPV_Cond4 80.1 92 19.4 13 ## 5 2 PPV_Cond1 74 99 43.0 19 ## 6 2 PPV_Cond2 49.4 46 16.3 8 ## 7 2 PPV_Cond3 69.2 98.5 38.9 16 ## 8 2 PPV_Cond4 74.7 90 27.3 20 2.2.3 Ejercicios - verbos dplyr Usando la base df_wide, haz las siguientes cosas, una a una: Filtra el DF para quedarnos solo con edades entre 18 y 50 años Ordena los datos por genero y edad, esta última decreciente Selecciona las columnas para quedarnos solo con ID, variables demograficas, y respuestas crudas (raw) Crea una nueva variable que sea niv_edu_porc, en la que calcules cual es el porcentaje de nivel educativo al que han llegado relativo al máximo de la base de datos (nivel educativo persona / nivel educativo maximo; en porcentaje) Ahora combina el resultado de todas las operaciones anteriores en un DF Calcula el promedio y desviación típica de edad para cada género df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) 2.2.4 Verbos avanzados y otras criaturas indómitas 2.2.4.1 Wide to long Empecemos con un ejemplo muy sencillo. 3 participantes, 2 items. # Creamos un DF df_simple_wide = data.frame(ID = c(&quot;Participante1&quot;, &quot;Participante2&quot;, &quot;Participante3&quot;), Item1 = c(22, 33, 44), Item2 = c(88, 99, 77)) df_simple_wide ## ID Item1 Item2 ## 1 Participante1 22 88 ## 2 Participante2 33 99 ## 3 Participante3 44 77 # Wide to long df_simple_long = df_simple_wide %&gt;% gather(Item, Response, Item1:Item2) df_simple_long ## ID Item Response ## 1 Participante1 Item1 22 ## 2 Participante2 Item1 33 ## 3 Participante3 Item1 44 ## 4 Participante1 Item2 88 ## 5 Participante2 Item2 99 ## 6 Participante3 Item2 77 Ahora pasemos a un ejemplo mas complejo. Tenemos las puntuaciones a los 11 items de la lipkus numeracy scale de 232 participantes, ademas de datos demográficos. # Leemos documento en formato WIDE df_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) %&gt;% # Seleccionamos solo algunas de las filas select(ID, dem_genero, dem_edad, dem_nivedu, matches(&quot;lkns_[0-9]{2}_raw&quot;)) df_wide ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;dbl&gt;, lkns_07_raw &lt;chr&gt;, ## # lkns_08_raw &lt;dbl&gt;, lkns_09_raw &lt;dbl&gt;, lkns_10_raw &lt;dbl&gt;, ## # lkns_11_raw &lt;dbl&gt; # Wide to long df_wide %&gt;% gather(Item, Response, lkns_01_raw:lkns_11_raw) ## # A tibble: 2,552 x 6 ## ID dem_genero dem_edad dem_nivedu Item Response ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 lkns_01_raw 500 ## 2 2 0 67 2 lkns_01_raw 0 ## 3 3 0 24 4 lkns_01_raw 700 ## 4 4 0 30 4 lkns_01_raw 500 ## 5 5 0 38 3 lkns_01_raw 6 ## 6 6 0 45 4 lkns_01_raw 40 ## 7 7 1 58 3 lkns_01_raw 0 ## 8 8 1 47 4 lkns_01_raw 500 ## 9 9 1 52 3 lkns_01_raw 600 ## 10 10 1 49 4 lkns_01_raw 600 ## # … with 2,542 more rows df_wide %&gt;% gather(Item, Response, 5:15) ## # A tibble: 2,552 x 6 ## ID dem_genero dem_edad dem_nivedu Item Response ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 lkns_01_raw 500 ## 2 2 0 67 2 lkns_01_raw 0 ## 3 3 0 24 4 lkns_01_raw 700 ## 4 4 0 30 4 lkns_01_raw 500 ## 5 5 0 38 3 lkns_01_raw 6 ## 6 6 0 45 4 lkns_01_raw 40 ## 7 7 1 58 3 lkns_01_raw 0 ## 8 8 1 47 4 lkns_01_raw 500 ## 9 9 1 52 3 lkns_01_raw 600 ## 10 10 1 49 4 lkns_01_raw 600 ## # … with 2,542 more rows df_long = df_wide %&gt;% gather(Item, Response, matches(&quot;lkns&quot;)) DT::datatable(df_long) 2.2.4.2 Long to wide Retomamos el ejemplo simple de antes: # Long to wide simple df_simple_long %&gt;% spread(Item, Response) ## ID Item1 Item2 ## 1 Participante1 22 88 ## 2 Participante2 33 99 ## 3 Participante3 44 77 Y lo mismo con el ejemplo mas complejo: # Long to wide df_long %&gt;% spread(Item, Response) ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;chr&gt;, lkns_07_raw &lt;chr&gt;, ## # lkns_08_raw &lt;chr&gt;, lkns_09_raw &lt;chr&gt;, lkns_10_raw &lt;chr&gt;, ## # lkns_11_raw &lt;chr&gt; 2.2.4.2.1 ¿Para que sirve tener los datos en formato long? DF_plot = df_long %&gt;% mutate(Response_num = as.numeric(Response)) DF_plot %&gt;% drop_na(Response_num) %&gt;% ggplot(aes(Item, Response_num, color = Item)) + geom_jitter(alpha = .5) + geom_violin(alpha = .4) + scale_y_log10() + coord_flip() DF_plot %&gt;% filter(is.na(Response_num)) %&gt;% ggplot(aes(Item, Response, color = Item)) + geom_jitter(alpha = .5, height = .2) + facet_wrap(~ Item, scales = &quot;free&quot;) 2.2.4.3 Separate, omit, ifelse, case_when, tipos de variables… # Base original name_of_file = here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-read-csv.csv&quot;) DF_name = read_csv(name_of_file) # Separate DF_name %&gt;% separate(condition, c(&quot;primer_chunk&quot;, &quot;segundo_chunk&quot;), sep = &quot;_&quot;) ## # A tibble: 103 x 9 ## X1 ID Genero Edad Educacion FollowUP primer_chunk segundo_chunk ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 4 41904 1 47 8 80 PPV Cond1 ## 2 5 95041 2 21 6 90 PPV Cond1 ## 3 6 74594 2 29 6 10 PPV Cond1 ## 4 15 72903 2 27 7 75 PPV Cond1 ## 5 16 21260 1 29 5 35 PPV Cond1 ## 6 18 50315 2 28 6 14 PPV Cond1 ## 7 19 21774 2 27 4 2 PPV Cond1 ## 8 20 20881 2 55 6 89 PPV Cond1 ## 9 21 39751 2 28 6 6 PPV Cond1 ## 10 22 99384 1 46 5 0 PPV Cond1 ## # … with 93 more rows, and 1 more variable: PPV_DECLARED &lt;dbl&gt; # Separate in rows DF_name %&gt;% separate_rows(condition, sep = &quot;_&quot;) ## # A tibble: 206 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV 99 ## 2 4 41904 1 47 8 80 Cond1 99 ## 3 5 95041 2 21 6 90 PPV 99 ## 4 5 95041 2 21 6 90 Cond1 99 ## 5 6 74594 2 29 6 10 PPV 99 ## 6 6 74594 2 29 6 10 Cond1 99 ## 7 15 72903 2 27 7 75 PPV 1 ## 8 15 72903 2 27 7 75 Cond1 1 ## 9 16 21260 1 29 5 35 PPV 24 ## 10 16 21260 1 29 5 35 Cond1 24 ## # … with 196 more rows # Drop NAs DF_name %&gt;% drop_na(PPV_DECLARED) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # If else DF_name %&gt;% mutate(Genero = ifelse(Genero == 1, &quot;Hombre&quot;, &quot;Mujer&quot;)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 Hombre 47 8 80 PPV_Cond1 99 ## 2 5 95041 Mujer 21 6 90 PPV_Cond1 99 ## 3 6 74594 Mujer 29 6 10 PPV_Cond1 99 ## 4 15 72903 Mujer 27 7 75 PPV_Cond1 1 ## 5 16 21260 Hombre 29 5 35 PPV_Cond1 24 ## 6 18 50315 Mujer 28 6 14 PPV_Cond1 99 ## 7 19 21774 Mujer 27 4 2 PPV_Cond1 99 ## 8 20 20881 Mujer 55 6 89 PPV_Cond1 99 ## 9 21 39751 Mujer 28 6 6 PPV_Cond1 99 ## 10 22 99384 Hombre 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Case when DF_name %&gt;% mutate(Genero = case_when( Genero == 1 ~ &quot;Hombre&quot;, Genero == 2 ~ &quot;Mujer&quot;, TRUE ~ &quot;Otros&quot;)) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 Hombre 47 8 80 PPV_Cond1 99 ## 2 5 95041 Mujer 21 6 90 PPV_Cond1 99 ## 3 6 74594 Mujer 29 6 10 PPV_Cond1 99 ## 4 15 72903 Mujer 27 7 75 PPV_Cond1 1 ## 5 16 21260 Hombre 29 5 35 PPV_Cond1 24 ## 6 18 50315 Mujer 28 6 14 PPV_Cond1 99 ## 7 19 21774 Mujer 27 4 2 PPV_Cond1 99 ## 8 20 20881 Mujer 55 6 89 PPV_Cond1 99 ## 9 21 39751 Mujer 28 6 6 PPV_Cond1 99 ## 10 22 99384 Hombre 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Unite DF_separated = DF_name %&gt;% separate(condition, c(&quot;primer_chunk&quot;, &quot;segundo_chunk&quot;), sep = &quot;_&quot;) DF_separated %&gt;% unite(condition, c(primer_chunk, segundo_chunk), sep = &quot;_&quot;) ## # A tibble: 103 x 8 ## X1 ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 41904 1 47 8 80 PPV_Cond1 99 ## 2 5 95041 2 21 6 90 PPV_Cond1 99 ## 3 6 74594 2 29 6 10 PPV_Cond1 99 ## 4 15 72903 2 27 7 75 PPV_Cond1 1 ## 5 16 21260 1 29 5 35 PPV_Cond1 24 ## 6 18 50315 2 28 6 14 PPV_Cond1 99 ## 7 19 21774 2 27 4 2 PPV_Cond1 99 ## 8 20 20881 2 55 6 89 PPV_Cond1 99 ## 9 21 39751 2 28 6 6 PPV_Cond1 99 ## 10 22 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Pull DF_name %&gt;% pull(PPV_DECLARED) %&gt;% mean(.) ## [1] 68.52427 2.2.4.4 Regular expressions Basic Regular Expressions Cheatsheet SOURCE: https://xkcd.com/208/ DF_regexp = DF_name %&gt;% select(-X1); DF_regexp ## # A tibble: 103 x 7 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 41904 1 47 8 80 PPV_Cond1 99 ## 2 95041 2 21 6 90 PPV_Cond1 99 ## 3 74594 2 29 6 10 PPV_Cond1 99 ## 4 72903 2 27 7 75 PPV_Cond1 1 ## 5 21260 1 29 5 35 PPV_Cond1 24 ## 6 50315 2 28 6 14 PPV_Cond1 99 ## 7 21774 2 27 4 2 PPV_Cond1 99 ## 8 20881 2 55 6 89 PPV_Cond1 99 ## 9 39751 2 28 6 6 PPV_Cond1 99 ## 10 99384 1 46 5 0 PPV_Cond1 1 ## # … with 93 more rows # Regexp DF_regexp %&gt;% mutate(condition = gsub(&quot;PPV_&quot;, &quot;&quot;, condition)) %&gt;% mutate(condition_N = gsub(&quot;.*([[:digit:]]$)&quot;, &quot;\\\\1&quot;, condition)) ## # A tibble: 103 x 8 ## ID Genero Edad Educacion FollowUP condition PPV_DECLARED condition_N ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 41904 1 47 8 80 Cond1 99 1 ## 2 95041 2 21 6 90 Cond1 99 1 ## 3 74594 2 29 6 10 Cond1 99 1 ## 4 72903 2 27 7 75 Cond1 1 1 ## 5 21260 1 29 5 35 Cond1 24 1 ## 6 50315 2 28 6 14 Cond1 99 1 ## 7 21774 2 27 4 2 Cond1 99 1 ## 8 20881 2 55 6 89 Cond1 99 1 ## 9 39751 2 28 6 6 Cond1 99 1 ## 10 99384 1 46 5 0 Cond1 1 1 ## # … with 93 more rows read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) %&gt;% # Seleccionamos solo algunas de las filas select(ID, dem_genero, dem_edad, dem_nivedu, matches(&quot;lkns_[0-9]{2}_raw&quot;)) ## # A tibble: 232 x 15 ## ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 38 4 500 10 10 ## 2 2 0 67 2 0 0 0 ## 3 3 0 24 4 700 100 0.1 ## 4 4 0 30 4 500 30 1 ## 5 5 0 38 3 6 2 3 ## 6 6 0 45 4 40 200 2 ## 7 7 1 58 3 0 0 0 ## 8 8 1 47 4 500 100 0.1 ## 9 9 1 52 3 600 1 1 ## 10 10 1 49 4 600 500 70 ## # … with 222 more rows, and 8 more variables: lkns_04_raw &lt;chr&gt;, ## # lkns_05_raw &lt;chr&gt;, lkns_06_raw &lt;dbl&gt;, lkns_07_raw &lt;chr&gt;, ## # lkns_08_raw &lt;dbl&gt;, lkns_09_raw &lt;dbl&gt;, lkns_10_raw &lt;dbl&gt;, ## # lkns_11_raw &lt;dbl&gt; Una aplicación Shiny para ayudar a construir Regular Expressions: devtools::install_github(&quot;gadenbuie/regexplain&quot;) regexplain::regex_gadget() 2.2.5 Ejercicios - verbos avanzados dplyr Trabajaremos con los datos procesados del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base final en formato wide (archivo: /outputs/data/sa-prepared.csv). Cambia el orden de las variables para que ID sea la primera columna. Transforma la base a formato long. Crea un nuevo DF (DF_split) donde crees una variable llamada social_adaptation_split con la median split para la variable Social.Adaptation. La mitad superior se llamará high_social_adaptation y la mitad inferior low_social_adaptation. Asegúrate que no hay valores NA. El resultado final debería ser: Ahora volvemos a usar con los datos brutos (sa-raw-anonymised.csv) del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al.  En estos datos se muestran las puntuaciones crudas (e.g. WMAT_01_raw) y ya codificadas/corregidas (WMAT_01_cod) para los ítems de varias pruebas. Con los datos de los ítems de cada prueba, necesitamos calcular el puntaje para cada participante. Empezaremos con la prueba de Matrices de WAIS (WMAT_). Extrae la suma para cada participante de los ítems WMAT_*_cod. Hay al menos dos estrategias posibles: Selecciona las columnas relevantes y haz la suma de columnas Convierte a long, filtra para quedarte con las filas correspondientes a la prueba relevante, y haz una suma agrupada if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) df_wide_raw = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv&quot;) 2.3 Combinar bases de datos 2.3.1 Bind # Importar CSVs DF1 = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;, &quot;01.csv&quot;)) DF2 = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-CSVs&quot;, &quot;02.csv&quot;)) # Bind DFs añadiendo las *filas* de DF2 a DF1 DF1 %&gt;% bind_rows(DF2) ## # A tibble: 800 x 9 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 male Collective 1 we ofensivo negative yes left 623 ## 2 male Collective 2 we resentido negative no right 1235 ## 3 male Collective 3 we ego�sta negative yes left 335 ## 4 male Collective 4 we indiscreto negative yes left 355 ## 5 male Collective 5 we sumiso negative yes left 618 ## 6 male Collective 6 we agradable positive yes left 328 ## 7 male Collective 7 we clasista negative yes left 348 ## 8 male Collective 8 we altruista positive yes left 1620 ## 9 male Collective 9 we ansioso negative yes left 346 ## 10 male Collective 10 we presumido negative yes left 778 ## # … with 790 more rows # Bind DFs añadiendo las *columnas* de DF2 a DF1 # bind_cols renombra automaticamente los nombres de las columnas para que no haya coincidencias DF1 %&gt;% bind_cols(DF2) ## # A tibble: 400 x 18 ## Sex Priming trialN Block Adjective Valence Answer Arrow rT Sex1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 male Collec… 1 we ofensivo negati… yes left 623 male ## 2 male Collec… 2 we resentido negati… no right 1235 male ## 3 male Collec… 3 we ego�sta negati… yes left 335 male ## 4 male Collec… 4 we indiscre… negati… yes left 355 male ## 5 male Collec… 5 we sumiso negati… yes left 618 male ## 6 male Collec… 6 we agradable positi… yes left 328 male ## 7 male Collec… 7 we clasista negati… yes left 348 male ## 8 male Collec… 8 we altruista positi… yes left 1620 male ## 9 male Collec… 9 we ansioso negati… yes left 346 male ## 10 male Collec… 10 we presumido negati… yes left 778 male ## # … with 390 more rows, and 8 more variables: Priming1 &lt;chr&gt;, ## # trialN1 &lt;dbl&gt;, Block1 &lt;chr&gt;, Adjective1 &lt;chr&gt;, Valence1 &lt;chr&gt;, ## # Answer1 &lt;chr&gt;, Arrow1 &lt;chr&gt;, rT1 &lt;dbl&gt; 2.3.2 Joins El paquete {dplyr} tiene funciones que permiten trabajar combinando, filtrando, etc. distintos dataframes. Podéis ver más detalle y algunas ilustraciones fantásticas (como la de abajo; inner_join()) en el capítulo relational data de r4ds. SOURCE: https://r4ds.had.co.nz/relational-data.html#mutating-joins En https://github.com/gadenbuie/tidyexplain se pueden ver animaciones mostrando estas operaciones. Tipos de Join Estas operaciones tendrán la forma: DF_x %&gt;% WHATEVER_join(DF_y) Mutating joins: inner_join(): preserva pares de observaciones de de DF_x y de DF_y con claves iguales left_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales right_join(): preserva las observaciones de DF_y, añadiendo las de DF_x con claves iguales full_join(): preserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales Filtering joins: semi_join(): preserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y anti_join(): preserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y Nesting joins: nest_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales 2.3.2.1 Mutating joins Importamos datos Tenemos los siguientes dataframes: DF_IDs: Variables demográficas de participantes DF_results: Resultados en variables de interés de participantes DF_BAD: Grupo de participantes “selectos” # Importar CSVs para los joins DF_IDs = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-IDs.csv&quot;)) DF_results = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-results.csv&quot;)) DF_BAD = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-BAD.csv&quot;)) # DT::datatable(DF_IDs) # DT::datatable(DF_results) # DT::datatable(DF_BAD) 2.3.2.1.1 Inner join Preserva pares de observaciones de de DF_x y de DF_y con claves iguales. SOURCE: https://github.com/gadenbuie/tidyexplain DF_inner_joined = DF_IDs %&gt;% inner_join(DF_results) #nrow(DF_inner_joined) DT::datatable(DF_inner_joined) 2.3.2.1.2 Left join Preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales. SOURCE: https://github.com/gadenbuie/tidyexplain DF_left_joined = DF_IDs %&gt;% left_join(DF_results) #nrow(DF_left_joined) DT::datatable(DF_left_joined) 2.3.2.1.3 Full join Preserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales. SOURCE: https://github.com/gadenbuie/tidyexplain DF_full_joined = DF_IDs %&gt;% full_join(DF_results) #nrow(DF_full_joined) DT::datatable(DF_full_joined) 2.3.2.2 Filtering joins 2.3.2.2.1 Anti join Preserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y. SOURCE: https://github.com/gadenbuie/tidyexplain # AVOID the people present in DF_BAD DF_anti_joined = DF_IDs %&gt;% anti_join(DF_BAD, by = &quot;ID&quot;) %&gt;% left_join(DF_results) DT::datatable(DF_anti_joined) 2.3.2.2.2 Semi join Preserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y. SOURCE: https://github.com/gadenbuie/tidyexplain # INCLUDE ONLY the people present in DF_BAD DF_semi_joined = DF_IDs %&gt;% semi_join(DF_BAD, by = &quot;ID&quot;) %&gt;% left_join(DF_results) DT::datatable(DF_semi_joined) 2.3.2.3 Nesting joins DF_nest_joined = DF_IDs %&gt;% nest_join(DF_results, by = &quot;ID&quot;) DT::datatable(DF_nest_joined) 2.3.3 Ejercicios JOINS Con los DFs de abajo, haz las siguientes operaciones: DF_IDs = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-IDs2.csv&quot;)) DF_results = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-results.csv&quot;)) DF_BAD = read_csv(here::here(&quot;data&quot;, &quot;files&quot;, &quot;02-join-BAD.csv&quot;)) Une los datos demográficos con los resultados A la base resultante, quítale los sujetos descartados de DF_BAD Crea una nueva base con datos demográficos y resultados para los sujetos descartados Comprueba si el promedio para Crystallized Intelligence de los participantes descartados difiere de la de los no descartados Haz una gráfica donde se puedan ver las diferencias En el ejercicio 3 de verbos avanzados creaste un DF llamado DF_split con la median split a partir de la variable Social.Adaptation. Uno ese DF al DF_long que habías creado en el ejercicio 2 de la misma sección. El DF final se vera así: Haz un plot donde se vea la distribución para todas las variables de resultados de los dos niveles de social_adaptation_split. El plot que vimos en el tema anterior tiene el problema de que los datos de tuberculosis son en números absolutos. Serias capaz de convertir estos a % de la población, como se ve en el plot de abajo? 2.4 Más allá de la manipulación 2.4.1 Fast and Frugal trees Hay un paquete fantástico de Nathaniel Phillips llamado {FFTrees}. Este permite crear, visualizar y evaluar fast-and-frugal decision trees if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) if (!require(&#39;FFTrees&#39;)) install.packages(&#39;FFTrees&#39;); library(&#39;FFTrees&#39;) DF_wide = read.csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv&quot;) %&gt;% mutate(Anxious.Attachment = round(Anxious.Attachment, 2)) median_social_adaptation = DF_wide %&gt;% pull(Social.Adaptation) %&gt;% median(., na.rm = TRUE) DF_split = DF_wide %&gt;% mutate(high_social_adaptation = case_when( Social.Adaptation &gt;= median_social_adaptation ~ TRUE, Social.Adaptation &lt; median_social_adaptation ~ FALSE)) %&gt;% select(-ID, -Social.Adaptation) %&gt;% drop_na() sa.fft &lt;- FFTrees(formula = high_social_adaptation ~., data = DF_split) # Plotear el arbol de decision plot(sa.fft, main = &quot;Social adaptation&quot;, decision.labels = c(&quot;Low&quot;, &quot;High&quot;)) # Describe el algoritmo sa.fft$inwords ## [1] &quot;If Self.Esteem &lt;= 26, decide False&quot; ## [2] &quot;If Stress &gt; 5, decide False&quot; ## [3] &quot;If Crystallized.Intelligence &gt; 6, decide True&quot; ## [4] &quot;If Numeracy &lt;= 1, decide False, otherwise, decide True&quot; 2.4.2 Machine learning Con el paquete {caret} podemos usar alguno de los 238 distintos métodos de machine learning. Por ejemplo, Backprop: # ensure the results are repeatable set.seed(7) # load the library if (!require(&#39;caret&#39;)) install.packages(&quot;caret&quot;, dependencies = c(&quot;Depends&quot;, &quot;Suggests&quot;)); library(&#39;caret&#39;) # if (!require(&#39;mlbench&#39;)) install.packages(&quot;mlbench&quot;); library(&#39;mlbench&#39;) DF_wide = read_csv(&quot;https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv&quot;) %&gt;% janitor::clean_names() %&gt;% as.data.frame() DB_x = DF_wide %&gt;% mutate(high_social_adaptation = as.factor( case_when( social_adaptation &gt;= median_social_adaptation ~ &quot;high&quot;, social_adaptation &lt; median_social_adaptation ~ &quot;low&quot;))) %&gt;% select(-id, -social_adaptation) %&gt;% drop_na() %&gt;% select(high_social_adaptation, everything()) # calculate correlation matrix correlationMatrix &lt;- cor(DB_x[,2:ncol(DB_x)]) # print(correlationMatrix) # find attributes that are highly corrected (ideally &gt;0.75) highlyCorrelated &lt;- findCorrelation(correlationMatrix, cutoff = 0.25) # print(highlyCorrelated) DB_final = DB_x %&gt;% select(highlyCorrelated) %&gt;% select(high_social_adaptation, everything()) %&gt;% as.data.frame() # prepare training scheme control &lt;- trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=3) # train the model model &lt;- train(high_social_adaptation ~ ., data = DB_final, method=&quot;lvq&quot;, preProcess=&quot;scale&quot;, trControl=control) # estimate variable importance importance &lt;- varImp(model, scale=FALSE) # print(importance) # plot importance plot(importance) # define the control using a random forest selection function control &lt;- rfeControl(functions=rfFuncs, method=&quot;cv&quot;, number=10) # run the RFE algorithm results &lt;- rfe(DB_final[,2:ncol(DB_final)], DB_final[,1], sizes=c(1:ncol(DB_final)), rfeControl=control) # summarize the results print(results) ## ## Recursive feature selection ## ## Outer resampling method: Cross-Validated (10 fold) ## ## Resampling performance over subset size: ## ## Variables Accuracy Kappa AccuracySD KappaSD Selected ## 1 0.5626 0.1135 0.09383 0.1883 ## 2 0.5768 0.1483 0.06622 0.1315 ## 3 0.6755 0.3451 0.07775 0.1592 * ## 4 0.6483 0.2921 0.07217 0.1462 ## 5 0.6431 0.2836 0.10321 0.2057 ## 6 0.6435 0.2851 0.09605 0.1911 ## ## The top 3 variables (out of 3): ## internal_locus, stress, crystallized_intelligence # list the chosen features predictors(results) ## [1] &quot;internal_locus&quot; &quot;stress&quot; ## [3] &quot;crystallized_intelligence&quot; # plot the results plot(results, type=c(&quot;g&quot;, &quot;o&quot;)) 2.5 Datasets interesantes En los siguientes repositorios podréis encontrar datasets interesantes para jugar. fivethirtyeight Our World in Data TidyTuesday Bibliografía Cheatsheets RStudio Cheatsheet dplyr data-carpentry-week lesson_joins R4ds - Joins Tidyexplain "],["análisis-de-datos-exploratorio.html", "Capítulo 3 Análisis de datos exploratorio 3.1 Visualizando distribuciones 3.2 Covariación 3.3 Ejercicios finales Bibliografía", " Capítulo 3 Análisis de datos exploratorio Paquetes para este capítulo if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;hexbin&#39;)) install.packages(&#39;hexbin&#39;); library(&#39;hexbin&#39;) if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) VER: R 4 data science - exploratory data analysis 3.1 Visualizando distribuciones 3.1.1 Variables categóricas ggplot(gapminder, aes(continent)) + geom_bar() gapminder %&gt;% count(continent) ## # A tibble: 5 x 2 ## continent n ## &lt;fct&gt; &lt;int&gt; ## 1 Africa 624 ## 2 Americas 300 ## 3 Asia 396 ## 4 Europe 360 ## 5 Oceania 24 3.1.2 Variables continuas ggplot(gapminder, aes(lifeExp)) + geom_histogram(binwidth = 1) gapminder %&gt;% count(lifeExp) ## # A tibble: 1,626 x 2 ## lifeExp n ## &lt;dbl&gt; &lt;int&gt; ## 1 23.6 1 ## 2 28.8 1 ## 3 30 1 ## 4 30.0 1 ## 5 30.3 1 ## 6 30.3 1 ## 7 31.2 1 ## 8 31.3 1 ## 9 31.6 1 ## 10 32.0 1 ## # … with 1,616 more rows gapminder %&gt;% count(cut_width(lifeExp, 10)) ## # A tibble: 7 x 2 ## `cut_width(lifeExp, 10)` n ## &lt;fct&gt; &lt;int&gt; ## 1 [15,25] 1 ## 2 (25,35] 32 ## 3 (35,45] 273 ## 4 (45,55] 348 ## 5 (55,65] 329 ## 6 (65,75] 548 ## 7 (75,85] 173 ggplot(gapminder, aes(lifeExp)) + geom_freqpoly(binwidth = 2) 3.1.3 Ejercicio variables individuales Usando el DF mpg, visualiza la distribucion de las variables manufacturer, class, trans, hwy y cty 3.1.4 Visualizando datasets completos Cuando nos llega una nueva base de datos, una de las primeras cosas que haremos será familiarizarnos con los datos. Cómo se distribuyen, cual es la relación entre distintas variables, etc. if (!require(&#39;dplyr&#39;)) install.packages(&#39;dplyr&#39;); library(&#39;dplyr&#39;) if (!require(&#39;tidyr&#39;)) install.packages(&#39;tidyr&#39;); library(&#39;tidyr&#39;) if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) # Wide to long d &lt;- gather(gapminder) %&gt;% filter(value != 999) %&gt;% # Si existiera algun codigo para missing values, filtrar mutate(value_NUM = as.numeric(value)) # Plot numeric variables d %&gt;% drop_na(value_NUM) %&gt;% ggplot(aes(value_NUM)) + facet_wrap(~ key, scales = &quot;free&quot;) + geom_histogram(bins = 15) #+ scale_x_log10() # Plot non-numeric variables d %&gt;% drop_na(value) %&gt;% filter(is.na(value_NUM)) %&gt;% ggplot(aes(value)) + facet_wrap(~ key, scales = &quot;free&quot;) + geom_bar() + coord_flip() 3.1.4.1 inspectdf if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;inspectdf&#39;)) install.packages(&#39;inspectdf&#39;); library(&#39;inspectdf&#39;) if (!require(&#39;dplyr&#39;)) install.packages(&#39;dplyr&#39;); library(&#39;dplyr&#39;) if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) gapminder %&gt;% inspect_na ## # A tibble: 6 x 3 ## col_name cnt pcnt ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 country 0 0 ## 2 continent 0 0 ## 3 year 0 0 ## 4 lifeExp 0 0 ## 5 pop 0 0 ## 6 gdpPercap 0 0 gapminder %&gt;% inspect_na %&gt;% show_plot + coord_flip() gapminder_cat &lt;- gapminder %&gt;% inspect_cat() gapminder_cat %&gt;% show_plot() gapminder_num &lt;- gapminder %&gt;% inspect_num() gapminder_num %&gt;% show_plot() 3.1.4.2 Datos perdidos if (!require(&#39;gapminder&#39;)) install.packages(&#39;gapminder&#39;); library(&#39;gapminder&#39;) if (!require(&#39;inspectdf&#39;)) install.packages(&#39;inspectdf&#39;); library(&#39;inspectdf&#39;) if (!require(&#39;dplyr&#39;)) install.packages(&#39;dplyr&#39;); library(&#39;dplyr&#39;) if (!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(&#39;ggplot2&#39;) if (!require(&#39;naniar&#39;)) install.packages(&#39;naniar&#39;); library(&#39;naniar&#39;) gapminder %&gt;% inspect_na ## # A tibble: 6 x 3 ## col_name cnt pcnt ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 country 0 0 ## 2 continent 0 0 ## 3 year 0 0 ## 4 lifeExp 0 0 ## 5 pop 0 0 ## 6 gdpPercap 0 0 gapminder %&gt;% inspect_na %&gt;% show_plot + coord_flip() gapminder_cat &lt;- gapminder %&gt;% inspect_cat() gapminder_cat %&gt;% show_plot() gapminder_num &lt;- gapminder %&gt;% inspect_num() gapminder_num %&gt;% show_plot() # naniar::gg_miss_upset(gapminder) 3.2 Covariación 3.2.1 Variable categórica y continua Podemos contar el numero de elementos por nivel de la variable o ver densidad, etc. ggplot(gapminder, aes(lifeExp, colour = continent)) + geom_freqpoly(binwidth = 2) # Lo mismo pero usando stat(count) ggplot(gapminder, aes(lifeExp, stat(count), colour = continent)) + geom_freqpoly(binwidth = 2) # En stat() podemos usar combinaciones de funciones ggplot(gapminder, aes(lifeExp, stat(density/max(density)), colour = continent)) + geom_freqpoly(binwidth = 2) Podemos ver boxplots para cada nivel de la variable categórica: ggplot(gapminder, aes(continent, lifeExp)) + geom_boxplot() ggplot(gapminder, aes(reorder(x = continent, X = lifeExp, FUN = median), lifeExp)) + geom_boxplot() # Que feo ha quedado el titulo del eje x ggplot(gapminder, aes(reorder(x = continent, X = lifeExp, FUN = median), lifeExp)) + geom_boxplot() + labs(x = &quot;Continente&quot;) Y podemos usar geom_density_ridges() para combinar puntos con distribuciones: ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) ¿Qué estamos viendo exáctamente arriba? Hay un punto por cada pais, y por cada año, lo que da lugar aalgo bien dificil de interpretar. Podemos ver los datos únicamente del último año: gapminder %&gt;% group_by(year) %&gt;% summarise(n()) ## # A tibble: 12 x 2 ## year `n()` ## &lt;int&gt; &lt;int&gt; ## 1 1952 142 ## 2 1957 142 ## 3 1962 142 ## 4 1967 142 ## 5 1972 142 ## 6 1977 142 ## 7 1982 142 ## 8 1987 142 ## 9 1992 142 ## 10 1997 142 ## 11 2002 142 ## 12 2007 142 ggplot(gapminder %&gt;% filter(year == 2007), aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) Me pregunto si será muy evidente la diferencia entre los extremos en la base de datos, 1952 y 2007: A = ggplot(gapminder %&gt;% filter(year == 1952), aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;1952&quot;) B = ggplot(gapminder %&gt;% filter(year == 2007), aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;2007&quot;) cowplot::plot_grid(A, B) Finalmente, podemos ver el avance por país de una manera más directa: # METODO 1: Asumimos que el valor máximo corresponde al más actualizado DF_gapminder_max_min = gapminder %&gt;% group_by(continent, country) %&gt;% summarise(lifeExp = max(lifeExp) - min(lifeExp)) ggplot(DF_gapminder_max_min, aes(lifeExp, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Diferencia entre max y min por país&quot;) # METODO 2: Calculamos maximo - mínimo para cada país DF_last_year = gapminder %&gt;% filter(year == max(year)) %&gt;% select(country, continent, lifeExp) %&gt;% rename(lifeExp_max = lifeExp) DF_first_year = gapminder %&gt;% filter(year == min(year)) %&gt;% select(country, continent, lifeExp) %&gt;% rename(lifeExp_min = lifeExp) DF_last_first = DF_last_year %&gt;% full_join(DF_first_year, by = c(&quot;country&quot;, &quot;continent&quot;)) %&gt;% mutate(DIFF = lifeExp_max - lifeExp_min) # gather(max_min, value, lifeExp_max:lifeExp_min) ggplot(DF_last_first, aes(DIFF, continent, fill = continent)) + ggridges::geom_density_ridges(stat = &quot;binline&quot;, bins = 20, scale = 0.95, draw_baseline = FALSE, alpha = .3) + ggridges::geom_density_ridges(jittered_points = TRUE, position = &quot;raincloud&quot;, alpha = 0.5, scale = 0.9) + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Diferencia entre 2007 y 1952 por pais&quot;) 3.2.2 Ejercicio covariacion 1 Mira el plot donde mostramos la diferencia entre los extremos en la base de datos, 1952 y 2007 con dos gráficas, una al lado de la otra. Ves algún problema? Trata de resolver el problema en las escalas. El resultado final deberia ser: 3.2.3 Dos variables categóricas ggplot(diamonds, aes(cut, color)) + geom_count() diamonds %&gt;% count(color, cut) ## # A tibble: 35 x 3 ## color cut n ## &lt;ord&gt; &lt;ord&gt; &lt;int&gt; ## 1 D Fair 163 ## 2 D Good 662 ## 3 D Very Good 1513 ## 4 D Premium 1603 ## 5 D Ideal 2834 ## 6 E Fair 224 ## 7 E Good 933 ## 8 E Very Good 2400 ## 9 E Premium 2337 ## 10 E Ideal 3903 ## # … with 25 more rows diamonds %&gt;% count(color, cut) %&gt;% ggplot(aes(color, cut, fill = n)) + geom_tile() 3.2.4 Dos variables continuas ggplot(gapminder, aes(lifeExp, gdpPercap)) + geom_point() ggplot(gapminder, aes(lifeExp, gdpPercap, color = continent)) + geom_point(alpha = 1 / 2) + scale_y_log10() if (!require(&#39;hexbin&#39;)) install.packages(&#39;hexbin&#39;); library(&#39;hexbin&#39;) ggplot(gapminder, aes(lifeExp, gdpPercap)) + geom_hex() ggplot(gapminder, aes(lifeExp, gdpPercap)) + geom_boxplot(mapping = aes(group = cut_width(lifeExp, 10))) + scale_y_log10() 3.2.5 Ejercicio covariación 2 Usando el DF mpg, visualiza la covariación entre: manufacturer y hwy class y hwy hwy y cty 3.3 Ejercicios finales 3.3.1 Ejercicio exploración base nueva Usando la base del paper Cancer Screening Risk Literacy of Physicians in Training, haz un primer análisis exploratorio que incluya: histogramas de todas las variables numéricas y no-numéricas scatterplots de la relación entre comprensión y numeracy, y entre comprensión y screenbeliefs Bibliografía Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/ "],["trabajo-con-rmarkdown-para-reportes-reproducibles.html", "Capítulo 4 Trabajo con RMarkdown para reportes reproducibles Dependencias 4.1 Que es la reproducibilidad 4.2 Proyectos de R-Studio 4.3 Control de cambios con Git y Github 4.4 RMarkdown, openscience y análisis reproducibles 4.5 Sintaxis, chunks de código, tipos de archivo 4.6 De los datos al reporte final: Una historia de amor con R 4.7 Avanzado 4.8 Mas allá de Rmarkdown 4.9 Varios Bibliografía", " Capítulo 4 Trabajo con RMarkdown para reportes reproducibles if (!require(&#39;afex&#39;)) install.packages(&#39;afex&#39;); library(&#39;afex&#39;) if (!require(&#39;corrr&#39;)) install.packages(&#39;corrr&#39;); library(&#39;corrr&#39;) if (!require(&#39;easystats&#39;)) remotes::install_github(&quot;easystats/easystats&quot;); library(&#39;easystats&#39;) if (!require(&#39;correlation&#39;)) remotes::install_github(&quot;easystats/correlation&quot;); library(&#39;correlation&#39;) if (!require(&#39;report&#39;)) remotes::install_github(&quot;easystats/report&quot;); library(&#39;report&#39;) if (!require(&#39;see&#39;)) remotes::install_github(&quot;easystats/see&quot;); library(&#39;see&#39;) if (!require(&#39;papaja&#39;)) remotes::install_github(&quot;crsh/papaja&quot;); library(&#39;papaja&#39;) if (!require(&#39;remotes&#39;)) install.packages(&#39;remotes&#39;); library(&#39;remotes&#39;) if (!require(&#39;renv&#39;)) remotes::install_github(&quot;rstudio/renv&quot;); library(&#39;renv&#39;) if (!require(&#39;rticles&#39;)) install.packages(&#39;rticles&#39;); library(&#39;rticles&#39;) if (!require(&#39;stargazer&#39;)) install.packages(&#39;stargazer&#39;); library(&#39;stargazer&#39;) if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) Dependencias Instalar Git Windows: https://happygitwithr.com/install-git.html#install-git-windows “Adjusting your PATH environment,” selecciona “Git from the command line and also from 3rd-party software” Mac: https://happygitwithr.com/install-git.html#macos Linux: https://happygitwithr.com/install-git.html#linux Instalar latex: if (!require(&#39;tinytex&#39;)) install.packages(&#39;tinytex&#39;); library(&#39;tinytex&#39;) # Instalar distribución latex automáticamente (llevará un rato) tinytex::install_tinytex() 4.1 Que es la reproducibilidad La crisis de replicación (replication crisis) se inició con un paper que trató de replicar los resultados de 100 investigaciones clásicas. Esta crisis ha generado un movimiento muy interesante dentro de las Ciencias Sociales y la Psicología en particular. Cada vez es más común aplicar algunos principios de buenas prácticas como compartir materiales, datos y scripts de análisis, para que tanto los revisores como otros investigadores puedan entender, reanalizar, etc. nuestras investigaciones. Hay algunas organizaciones que han surgido para tratar de mejorar la colaboración, transparencia, y manera de trabajar: Psychological Science Accelerator Peer Reviewer’s Openness Initiative (PRO) Open Science Foundation Y algunas prácticas y maneras de publicar “nuevas,” se están haciendo cada vez más imprescindibles: Registered reports Preregistration En este capítulo vamos a ver algunos pasos fundamentales para tender un workflow que permita y ayude a la reproducibilidad. 4.2 Proyectos de R-Studio El primer paso empieza por crear un proyecto de RStudio. Al usar proyectos, simplificamos varias cosas, haciendo automáticamente más fácil compartir nuestro trabajo con otras personas. Podéis leer algo más sobre esto aquí. 4.3 Control de cambios con Git y Github Un segundo elemento que nos va a ayudar a trabajar en equipo, y a evitar problemas en proyectos relativamente complejos es el uso de un sistema de control de versiones como Git. Los proyectos de RStudio hacen especialmente sencillo usar Git, click, click, click… SOURCE: https://xkcd.com/1597/ Algunas referencias útiles: OhshitGit website Git in practice happygitwithr En esta sección podemos ver algunos comandos básicos asociados a workflows bien sencillos. 4.3.1 Github github.com es una plataforma web muy popular donde almacenar proyectos de programación. Muchos de los paquetes de R, el mismo RStudio, etc, tienen repositorios abiertos en Github. Una de las ventajas fundamentales de usar Github es que esta plataforma integra algunas herramientas para hacer más sencillo el control de versiones, como el pull request, que nos permite combinar ramas de proyectos sin apenas problemas. SOURCE: https://github.githubassets.com/images/modules/open_graph/github-octocat.png Github tiene un programa especial para estudiantes: https://education.github.com/ 4.3.1.1 Seguir repositorios Algo maravilloso de Github es que muchos de los paquetes que usamos se desarrollan abiertamente en la plataforma, lo que nos permite poder seguir su desarrollo, abrir Issues cuando encontramos algun problema, etc. Por ejemplo, ¿recuerdan el paquete esquisse? Recientemente salió la versión 2.0 que usamos en la primera sesión? Si queremos mantenernos al dia sobre algun paquete, recibir notificaciones cuando salen nuevas versiones, o simplemente marcarlo con una estrellita para no olvidarnos de su existencia, Github nos puede ayudar: SOURCE: www.github.com 4.3.2 Clonar un repositorio existente Algo que podemos hacer con todos los repositorios de Github es clonarlos localmente: En RStudio: File &gt; New Project &gt; Version Control &gt; Git Pega en “repository URL” la URL del repo GitHub (ver imagen de abajo). Será algo similar a https://github.com/VUESTRO_NOMBRE_DE USUARIO/NOMBRE_REPO.git SOURCE: www.github.com 4.3.3 Crear Git y asociar a Github repo Versión simple En www.github.com: Creamos repositorio nuevo Initialize this repository with a README Clonar repositorio Usando el terminal Para prepararnos para usar Git y Github tenemos que hacer lo siguiente: Crear local git repo: usethis::use_git() (cuando creamos un repositorio Git localmente, se crea una carpeta oculta llamada .git) Crear Github Token: usethis::browse_github_token() Insertar token en .Renvirom: usethis::edit_r_environ() Crear Github repo: usethis::use_github() Empujar el repositorio local a Github: git push --set-upstream origin master 4.3.4 Ejercicio Git-Github Haz lo siguiente: Crea un proyecto de RStudio Abre una cuenta en Github! o haz login Sigue los pasos de arriba para crear un repositorio publico y asociarlo a un repositorio local 4.3.5 Workflow Hay diferentes filosofias sobre cual es la mejor manera de trabajar con Git. En este post por Vincent Driessen podeis ver una explicación bien detallada, complementada con imagenes como la que se ve a continuación. SOURCE: https://nvie.com/posts/a-successful-git-branching-model/ El modelo básico implica la existencia de dos ramas. Una master (“producción”), que siempre debe funcionar, y una develop (para desarrollo), donde experimentamos, rompemos cosas, etc. Podeis ver un manual super completo llamado Happy Git and GitHub for the useR elaborado por Jenny Bryan, Jim Hester, entre otros. 4.3.5.1 Modelo básico En RStudio podemos trabajar gráficamente, como se ve abajo, o usando el Terminal: Usando el entorno gráfico, o el terminal Empezamos en la rama master: Pull : nos aseguramos que nuestro repositorio local esta actualizado git pull Branch : Creamos nueva rama llamada development git checkout -b development Hacemos cambios en nuestros scripts Commit : Commiteamos los cambios Añadimos archivos: git add foo.txt Hacemos el commit: git commit --message \"A commit message\" Push : subimos la rama a Github git push origin development Pull request (En Github): Compare &amp; Pull request 2 branches, Pull request Pull : nos aseguramos que nuestro repositorio local esta actualizado git pull 4.3.5.2 Pull request en 3 + 1 sencillos pasos Después de hacer el push de arriba, al entrar en nuestro repositorio deberíamos ver algo parecido a lo siguiente (si no lo vemos, ir a branches). Lo más dificl será hacer click en los botones verdes adecuados: Paso 1. Compare &amp; pull request Paso 2. Create pull request Paso 3. Merge pull request y confirmar Borrar rama antigua 4.3.6 Ejercicio Nuestro primer commit Usando el proyecto de RStudio de antes, crea una rama nueva llamada development Crea un nuevo archivo en formato .Rmd: Haz un commit de ese archivo y subelo (push) a Github (asegurate que esta allá!). No olvides hacer un pull! Ahora haz cambios en el archivo, commitealos, súbelos, y sincroniza tu repo local 4.3.6.1 Feature branch Para la versión más razonable deberiamos tener partir con las siguientes ramas: master development Queremos implementar un nuevo feature o arreglar algun problema: Creamos nueva rama (localmente feature_x) git checkout -b feature_x Hacemos cambios Vemos que cambios hay: git status, o las diferencias exactas git diff Commiteamos los cambios: Añadimos archivos: git add foo.txt Hacemos el commit: git commit --message \"A commit message\" Ahora viene lo bueno… opción sencilla: 3a. Subimos la rama a Github, donde podremos hacer un Pull request: - git push origin feature_x - Si todo ha ido bien, borramos la rama feature_x: git branch -d feature_x La opción menos sencilla: 3b. Si no esperamos conflictos - mergeamos rama a developmentm para poder probar que todo funciona bien. git checkout development git pull origin development --ff-only git merge feature_x git push origin development 4.3.6.2 Stash Hemos hecho algunos cambios pero no queremos hacer commit: git stash Recuperamos los cambios git checkout rama_en_la_que_recuperar_cambios git stash apply Queremos destruir el stash git stash drop 4.4 RMarkdown, openscience y análisis reproducibles RMarkdown es un tipo de archivo que nos permite combinar texto formateado con código y resultados en un mismo documento (HTML, PDF, WORD…). Aprovechando la potencia de este tipo de archivo, algunas personas han creado paquetes para preparar artículos en formato APA, o con las plantillas de decenas de editoriales. 4.5 Sintaxis, chunks de código, tipos de archivo La sintáxis básica de RMarkdown es sorprendentemente sencilla, como se puede ver más abajo. Eso si, lo que hay detrás es toda la potencia de latex, así que el cielo es el límite. Y como no, tenemos mucha ayuda: R Markdown cheatsheet R Markdown: The Definitive Guide Web oficial de Rmarkdown dentro de RStudio Resumiendo, tienes tres elementos básicos: 4.5.1 Cabecera YAML Cuando creas un documento .Rmd nuevo verás algo similar a lo siguiente en las primeras lineas: --- title: &quot;Untitled&quot; author: &quot;G&quot; date: &quot;6/1/2019&quot; output: pdf_document --- Esta es la cabecera YAML, en la cual se le pueden pasar parámetros para añadir un índice, cambiar formato, y muchas otras cosas. 4.5.2 Rmarkdown En el resto del documento (con la excepción de los chunks de código), el formato que usaremos será Rmarkdown. Su sintaxis es muy sencilla pero nada tolerante. Podéis ver las bases en la R Markdown cheatsheet. IMPORTANTE. Si algo no funciona como esperas: Añade saltos de linea entre párrafos. Añade dos espacios al final de las líneas. Añade un espacio después de #: MAL: #Título grande BIEN: # Título grande 4.5.3 Chunks de código Los chunks de código están delimitados por: En su interior, puedes usar código R como si estuvieras en un script de R normal. En la cabecera puedes añadir opciones. Hay una cantidad apabullante de opciones. Por ejemplo, en el siguiente chunk: {r nombre_chunk, eval=TRUE, include=TRUE, fig.height=10, fig.width=12, message=FALSE, warning=FALSE, cache=TRUE, results='asis'} eval=TRUE: Muestra el código include=TRUE: Corre el código fig.height=10: altura de los plots (en inches) fig.width=12: ancho de los plots (en inches) message=FALSE: NO muestres mensajes warning=FALSE: NO muestres warnings cache=TRUE: cachea el output del plot results='asis': muestra el output tal cual (importante cuando el output es en latex/pdf) Haciendo click en la herramienta de la derecha puedes controlar varios parámetros esenciales. TRUCO: Si tienes un chunk al principio llamado setup, cada vez que reinicies RStudio y ejecutes código en cualquier parte de tu documento, ese bloque se ejecutara automaticamente. Esto es ideal para poner tus librerias, lectura de datos… 4.5.4 Ejercicio básico RMarkdown Volvamos al archivo .Rmd que creamos antes. Hagamos lo siguiente: Dale formato de artículo científico, creando las siguientes secciones: Title Abstract Introducción Materials and Methods Participants Materials Results Experiment 1 Experiment 2 Discussion Bibliography Pon texto de relleno dentro de cada sección. Para ello puedes usar la función stri_rand_lipsum() del paquete {stringi}. Renderiza tu documento en formato PDF. Pull, Commit, Push, Pull… 4.5.5 Herramientas básicas para investigadoras/es De manera relativamente sencilla podemos incluir tablas bonitas en los reportes. if (!require(&#39;corrr&#39;)) install.packages(&#39;corrr&#39;); library(&#39;corrr&#39;) if (!require(&#39;correlation&#39;)) remotes::install_github(&quot;easystats/correlation&quot;); library(&#39;correlation&#39;) if (!require(&#39;knitr&#39;)) install.packages(&#39;knitr&#39;); library(&#39;knitr&#39;) if (!require(&#39;papaja&#39;)) remotes::install_github(&quot;crsh/papaja&quot;); library(&#39;papaja&#39;) if (!require(&#39;report&#39;)) remotes::install_github(&quot;easystats/report&quot;); library(&#39;report&#39;) if (!require(&#39;stargazer&#39;)) install.packages(&#39;stargazer&#39;); library(&#39;stargazer&#39;) if (!require(&#39;tidyverse&#39;)) install.packages(&#39;tidyverse&#39;); library(&#39;tidyverse&#39;) 4.5.5.1 Descriptivos gtsummary::tbl_summary(gapminder %&gt;% select(-country), by = continent, missing = &quot;ifany&quot;) %&gt;% gtsummary::add_n() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #lbjfgfpbtx .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #lbjfgfpbtx .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lbjfgfpbtx .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lbjfgfpbtx .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 4px; border-top-color: #FFFFFF; border-top-width: 0; } #lbjfgfpbtx .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lbjfgfpbtx .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #lbjfgfpbtx .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #lbjfgfpbtx .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #lbjfgfpbtx .gt_column_spanner_outer:first-child { padding-left: 0; } #lbjfgfpbtx .gt_column_spanner_outer:last-child { padding-right: 0; } #lbjfgfpbtx .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; overflow-x: hidden; display: inline-block; width: 100%; } #lbjfgfpbtx .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #lbjfgfpbtx .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #lbjfgfpbtx .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #lbjfgfpbtx .gt_from_md > :first-child { margin-top: 0; } #lbjfgfpbtx .gt_from_md > :last-child { margin-bottom: 0; } #lbjfgfpbtx .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #lbjfgfpbtx .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #lbjfgfpbtx .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lbjfgfpbtx .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #lbjfgfpbtx .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #lbjfgfpbtx .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #lbjfgfpbtx .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #lbjfgfpbtx .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lbjfgfpbtx .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #lbjfgfpbtx .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #lbjfgfpbtx .gt_sourcenote { font-size: 90%; padding: 4px; } #lbjfgfpbtx .gt_left { text-align: left; } #lbjfgfpbtx .gt_center { text-align: center; } #lbjfgfpbtx .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lbjfgfpbtx .gt_font_normal { font-weight: normal; } #lbjfgfpbtx .gt_font_bold { font-weight: bold; } #lbjfgfpbtx .gt_font_italic { font-style: italic; } #lbjfgfpbtx .gt_super { font-size: 65%; } #lbjfgfpbtx .gt_footnote_marks { font-style: italic; font-size: 65%; } Characteristic N Africa, N = 6241 Americas, N = 3001 Asia, N = 3961 Europe, N = 3601 Oceania, N = 241 year 1704 1980 (1966, 1993) 1980 (1966, 1993) 1980 (1966, 1993) 1980 (1966, 1993) 1980 (1966, 1993) lifeExp 1704 48 (42, 54) 67 (58, 72) 62 (51, 70) 72 (70, 75) 74 (71, 78) pop 1704 4579311 (1342075, 10801490) 6227510 (2962359, 18340309) 14530830 (3844393, 46300348) 8551125 (4331500, 21802867) 6403492 (3199212, 14351625) gdpPercap 1704 1192 (761, 2377) 5466 (3428, 7830) 2647 (1057, 8549) 12082 (7213, 20461) 17983 (14142, 22214) 1 Statistics presented: median (IQR) # table_combined_vive = gtsummary::tbl_merge(list(T_female, T_male), tab_spanner = list(&quot;Female&quot;, &quot;Male&quot;)) # gt::gtsave(gtsummary::as_gt(table_combined_vive), file = &quot;outputs/table-combined-vive.png&quot;) 4.5.5.2 Correlaciones 4.5.5.2.1 Test de correlación # https://github.com/easystats/easystats corr_test = cor.test(iris$Sepal.Width, iris$Sepal.Length, method = &quot;spearman&quot;) report(corr_test) ## The Spearman&#39;s rank correlation rho between iris$Sepal.Width and iris$Sepal.Length is negative, significant and small (rho = -0.17, S = 6.56e+05, p &lt; .05). table_easystats = report(corr_test) %&gt;% table_long() knitr::kable(table_easystats) Parameter1 Parameter2 rho S p Method iris\\(Sepal.Width |iris\\)Sepal.Length -0.1667777 656283.3 0.041368 Spearman library(see) # for plotting library(ggraph) # needs to be loaded mtcars %&gt;% correlation(partial = TRUE) %&gt;% plot() 4.5.5.2.2 Tabla de correlaciones # https://paulvanderlaken.com/2018/09/10/simpler-correlation-analysis-in-r-using-tidyverse-principles/ table_correlations &lt;- iris %&gt;% correlation() # report() %&gt;% # table_long(full = TRUE) # Cambiamos todos los NA por &quot;&quot; table_clean = table_correlations %&gt;% mutate_if(is.character, ~replace(., is.na(.), &quot;&quot;)) # Mostramos la tabla bonita (función kable del paquete {knitr}) knitr::kable(table_clean) Parameter1 Parameter2 r CI_low CI_high t df p Method n_Obs Sepal.Length Sepal.Width -0.1175698 -0.2726932 0.0435116 -1.440287 148 0.1518983 Pearson 150 Sepal.Length Petal.Length 0.8717538 0.8270363 0.9055080 21.646019 148 0.0000000 Pearson 150 Sepal.Length Petal.Width 0.8179411 0.7568971 0.8648361 17.296454 148 0.0000000 Pearson 150 Sepal.Width Petal.Length -0.4284401 -0.5508771 -0.2879499 -5.768449 148 0.0000001 Pearson 150 Sepal.Width Petal.Width -0.3661259 -0.4972130 -0.2186966 -4.786461 148 0.0000081 Pearson 150 Petal.Length Petal.Width 0.9628654 0.9490525 0.9729853 43.387237 148 0.0000000 Pearson 150 4.5.5.3 LM model_lm &lt;- lm(Sepal.Length ~ Petal.Length * Petal.Width, data = iris) summary_lm = summary(model_lm) # papaja::apa_print.summary.lm(summary_lm)$table table_lm = papaja::apa_print.lm(model_lm)$table knitr::kable(table_lm) predictor estimate ci statistic p.value Intercept 4.58 \\([4.36\\), \\(4.80]\\) 40.89 &lt; .001 Petal Length 0.44 \\([0.31\\), \\(0.57]\\) 6.74 &lt; .001 Petal Width -1.24 \\([-1.67\\), \\(-0.81]\\) -5.65 &lt; .001 Petal Length \\(\\times\\) Petal Width 0.19 \\([0.12\\), \\(0.25]\\) 5.62 &lt; .001 report(model_lm, standardize = &quot;robust&quot;) ## We fitted a linear model (estimated using OLS) to predict Sepal.Length with Petal.Length and Petal.Width (formula = Sepal.Length ~ Petal.Length * Petal.Width). Parameters were standardized using the robust method. Effect sizes were labelled following Funder&#39;s (2019) recommendations. ## ## The model explains a significant and substantial proportion of variance (R2 = 0.81, F(3, 146) = 204.54, p &lt; .001, adj. R2 = 0.80). The model&#39;s intercept, corresponding to Sepal.Length = 0, Petal.Length = 0 and Petal.Width = 0, is at 4.58 (SE = 0.11, 95% CI [4.36, 4.80], p &lt; .001). Within this model: ## ## - The effect of Petal.Length is positive and can be considered as very large and significant (beta = 0.44, SE = 0.07, std. beta = 1.42, p &lt; .001). ## - The effect of Petal.Width is negative and can be considered as medium and significant (beta = -1.24, SE = 0.22, std. beta = -0.49, p &lt; .001). ## - The effect of Petal.Length:Petal.Width is positive and can be considered as small and significant (beta = 0.19, SE = 0.03, std. beta = 0.31, p &lt; .001). report(model_lm, standardize = &quot;robust&quot;) %&gt;% text_short() ## We fitted a linear model to predict Sepal.Length with Petal.Length and Petal.Width.The model&#39;s explanatory power is substantial (R2 = 0.81, adj. R2 = 0.80). The model&#39;s intercept is at 4.58. Within this model: ## ## - The effect of Petal.Length is positive and can be considered as very large and significant (beta = 0.44, std. beta = 1.42, p &lt; .001). ## - The effect of Petal.Width is negative and can be considered as medium and significant (beta = -1.24, std. beta = -0.49, p &lt; .001). ## - The effect of Petal.Length:Petal.Width is positive and can be considered as small and significant (beta = 0.19, std. beta = 0.31, p &lt; .001). table_easystats = report(model_lm, standardize = &quot;robust&quot;) %&gt;% table_long() knitr::kable(table_easystats) Parameter Coefficient SE CI_low.x CI_high.x t df_error p Std_Coefficient CI CI_low.y CI_high.y Fit (Intercept) 4.5771709 0.1119521 4.3559149 4.7984269 40.885096 146 0e+00 -0.2931027 0.95 -0.4185674 -0.1676380 NA Petal.Length 0.4416762 0.0655094 0.3122070 0.5711453 6.742182 146 0e+00 1.4237590 0.95 1.1418281 1.7056900 NA Petal.Width -1.2393154 0.2193702 -1.6728668 -0.8057640 -5.649424 146 1e-07 -0.4884181 0.95 -0.7626706 -0.2141656 NA Petal.Length:Petal.Width 0.1885887 0.0335720 0.1222389 0.2549386 5.617443 146 1e-07 0.3064497 0.95 0.1986336 0.4142658 NA NA NA NA NA NA NA NA NA NA NA NA NA NA AIC NA NA NA NA NA NA NA NA NA NA NA 130.6951836 BIC NA NA NA NA NA NA NA NA NA NA NA 145.7483600 R2 NA NA NA NA NA NA NA NA NA NA NA 0.8078020 R2 (adj.) NA NA NA NA NA NA NA NA NA NA NA 0.8038527 RMSE NA NA NA NA NA NA NA NA NA NA NA 0.3618154 Usando el paquete {stargazer} podemos mostrar una tabla de resultados: stargazer::stargazer(model_lm, heather = FALSE, type = &quot;html&quot;) Dependent variable: Sepal.Length Petal.Length 0.442*** (0.066) Petal.Width -1.239*** (0.219) Petal.Length:Petal.Width 0.189*** (0.034) Constant 4.577*** (0.112) Observations 150 R2 0.808 Adjusted R2 0.804 Residual Std. Error 0.367 (df = 146) F Statistic 204.544*** (df = 3; 146) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 FALSE 4.5.5.4 Anova Ver paquete {afex} if (!require(&#39;afex&#39;)) install.packages(&#39;afex&#39;); library(&#39;afex&#39;) data(obk.long, package = &quot;afex&quot;) head(obk.long) ## id treatment gender age phase hour value ## 1 1 control M -4.75 pre 1 1 ## 2 1 control M -4.75 pre 2 2 ## 3 1 control M -4.75 pre 3 4 ## 4 1 control M -4.75 pre 4 2 ## 5 1 control M -4.75 pre 5 1 ## 6 1 control M -4.75 post 1 3 # estimate mixed ANOVA on the full design: model = aov_ez(&quot;id&quot;, &quot;value&quot;, obk.long, between = c(&quot;treatment&quot;, &quot;gender&quot;), within = c(&quot;phase&quot;, &quot;hour&quot;), observed = &quot;gender&quot;) table_afex = papaja::apa_print.aov(model)$table knitr::kable(table_afex) Effect F df1 df2 MSE p ges 1 Treatment 3.94 2 10 22.81 .055 .278 2 Gender 3.66 1 10 22.81 .085 .152 4 Phase 16.13 1.6 15.99 5.02 &lt; .001 .217 8 Hour 16.69 1.84 18.41 3.39 &lt; .001 .183 3 Treatment \\(\\times\\) Gender 2.86 2 10 22.81 .104 .218 5 Treatment \\(\\times\\) Phase 4.85 3.2 15.99 5.02 .013 .143 6 Gender \\(\\times\\) Phase 0.28 1.6 15.99 5.02 .709 .005 9 Treatment \\(\\times\\) Hour 0.09 3.68 18.41 3.39 .979 .002 10 Gender \\(\\times\\) Hour 0.45 1.84 18.41 3.39 .628 .006 12 Phase \\(\\times\\) Hour 1.18 3.6 35.96 2.67 .335 .024 7 Treatment \\(\\times\\) Gender \\(\\times\\) Phase 0.64 3.2 15.99 5.02 .612 .021 11 Treatment \\(\\times\\) Gender \\(\\times\\) Hour 0.62 3.68 18.41 3.39 .641 .016 13 Treatment \\(\\times\\) Phase \\(\\times\\) Hour 0.35 7.19 35.96 2.67 .930 .014 14 Gender \\(\\times\\) Phase \\(\\times\\) Hour 0.93 3.6 35.96 2.67 .449 .019 15 Treatment \\(\\times\\) Gender \\(\\times\\) Phase \\(\\times\\) Hour 0.74 7.19 35.96 2.67 .646 .029 data &lt;- iris data$Cat1 &lt;- rep(c(&quot;X&quot;, &quot;X&quot;, &quot;Y&quot;), length.out = nrow(data)) data$Cat2 &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), length.out = nrow(data)) model_aov &lt;- aov(Sepal.Length ~ Species * Cat1 * Cat2, data=data) report(model_aov) ## The ANOVA suggests that: ## ## - The main effect of Species is significant (F(2, 138) = 115.28, p &lt; .001) and can be considered as large (partial omega squared = 0.60). ## - The main effect of Cat1 is not significant (F(1, 138) = 0.01, p = 0.922) and can be considered as very small (partial omega squared = -0.01). ## - The main effect of Cat2 is not significant (F(1, 138) = 0.01, p = 0.938) and can be considered as very small (partial omega squared = -0.01). ## - The interaction between Species and Cat1 is not significant (F(2, 138) = 0.51, p = 0.604) and can be considered as very small (partial omega squared = -0.01). ## - The interaction between Species and Cat2 is not significant (F(2, 138) = 0.94, p = 0.394) and can be considered as very small (partial omega squared = -8.42e-04). ## - The interaction between Cat1 and Cat2 is not significant (F(1, 138) = 0.91, p = 0.341) and can be considered as very small (partial omega squared = -5.69e-04). ## - The interaction between Species, Cat1 and Cat2 is not significant (F(2, 138) = 0.13, p = 0.875) and can be considered as very small (partial omega squared = -0.01). report(model_aov) %&gt;% table_long() ## Parameter | Sum_Squares | df | Mean_Square | F | p | Omega_Sq_partial ## ------------------------------------------------------------------------------------------ ## Species | 63.21 | 2 | 31.61 | 115.28 | 3.66e-30 | 0.60 ## Cat1 | 0.00 | 1 | 0.00 | 0.01 | 0.92 | -0.01 ## Cat2 | 0.00 | 1 | 0.00 | 0.01 | 0.94 | -0.01 ## Species:Cat1 | 0.28 | 2 | 0.14 | 0.51 | 0.60 | -0.01 ## Species:Cat2 | 0.51 | 2 | 0.26 | 0.94 | 0.39 | -8.42e-04 ## Cat1:Cat2 | 0.25 | 1 | 0.25 | 0.91 | 0.34 | -5.69e-04 ## Species:Cat1:Cat2 | 0.07 | 2 | 0.04 | 0.13 | 0.87 | -0.01 ## Residuals | 37.84 | 138 | 0.27 | | | table_aov = papaja::apa_print.aov(model_aov)$table knitr::kable(table_aov) Effect F df1 df2 MSE p ges Species 115.28 2 138 0.27 &lt; .001 .626 Cat1 0.01 1 138 0.27 .922 .000 Cat2 0.01 1 138 0.27 .938 .000 Species \\(\\times\\) Cat1 0.51 2 138 0.27 .604 .007 Species \\(\\times\\) Cat2 0.94 2 138 0.27 .394 .013 Cat1 \\(\\times\\) Cat2 0.91 1 138 0.27 .341 .007 Species \\(\\times\\) Cat1 \\(\\times\\) Cat2 0.13 2 138 0.27 .875 .002 4.5.6 Otros Para evitar problemas con los paths de los archivos, usar here::here() Para evitar problemas con instalación de Latex: if (!require(&#39;tinytex&#39;)) install.packages(&#39;tinytex&#39;); library(&#39;tinytex&#39;) tinytex::install_tinytex() Corregir ortografía en Rmarkdown (F7) https://github.com/ropensci/spelling#readme 4.5.6.1 Usar bibliografía Bibliografía en Rmarkdown https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html https://www.r-bloggers.com/bibliography-with-knitr-cite-your-references-and-packages/ 4.5.6.2 Citar los paquetes que usamos ¿Debemos citar los paquetes que usamos? Respuesta corta, si Respuesta larga, la mayoría de los paquetes remotes::install_github(&quot;Pakillo/grateful&quot;) grateful::cite_packages(all.pkg = FALSE, out.format = &quot;rmd&quot;, out.dir = &quot;dev&quot;) 4.5.7 Ejercicio avanzado Bajad la base de Cancer Screening Risk Literacy of Physicians in Training: https://osf.io/qn9a2/ y el preprint del artículo: En el documento .Rmd de antes: Cread algo parecido a la tabla de correlaciones (Tabla 3) que se ve en el artículo. Tratad de emular el tipo de análisis que se ve en la Tabla 4. 4.6 De los datos al reporte final: Una historia de amor con R Preparar artículos en formato APA devtools::install_github(&quot;crsh/papaja&quot;) # Create new R Markdown file rmarkdown::draft( here::here(&quot;data&quot;, &quot;output&quot;, &quot;mymanuscript.Rmd&quot;), &quot;apa6&quot;, package = &quot;papaja&quot;, create_dir = FALSE, edit = FALSE) # Render manuscript rmarkdown::render( here::here(&quot;data&quot;, &quot;output&quot;, &quot;mymanuscript.Rmd&quot;), quiet = TRUE, clean = TRUE) Y no olvidemos el paquete {rticles}, que contiene plantillas de decenas de editoriales 4.7 Avanzado 4.7.1 Manejo de dependencias Usando un sistema de manejo de dependencias renv Estos sistemas crean un snapshot de las librerías usadas actualmente. El estándar actual para hacer esto es packrat: Instalamos renv: install.packages(\"remotes\") remotes::install_github(\"rstudio/renv\") Inicializamos el entorno local de un nuevo proyecto, con una librería privada de R renv::init() Trabajamos en el proyecto, instalando los paquetes que necesitemos Guardamos el estado de las librerías usadas en el proyecto en un lockfile (llamado renv.lock), renv::snapshot() Restauramos el estado de las librerías a partir del lockfile generado por renv::snapshot(). renv::restore() 4.7.2 Alternativas para integrar manejo de dependencias y control de cambios {workflowr} # install.packages(&quot;workflowr&quot;) 4.8 Mas allá de Rmarkdown Aplicaciones web interactivas con R: Shiny 4.9 Varios 4.9.1 Shortcuts! Alt+SHIFT+K: Ver shortcuts! CTRL+SHIFT+M: Pipe CTRL+SHIFT+A: Reformat code CTRL+I: Reindent lines 4.9.2 Estilo Es importante ser consistente en la manera de escribir código. Habitualmente se recomienda seguir una guía de estilo. Por ejemplo, Hadley Wickham’s Style guide o la guia de estilo del tidyverse. 4.9.3 Algunos paquetes interesantes Descargar datos suplementarios de papers publicados usando DOI https://github.com/easystats/easystats https://usethis.r-lib.org/ https://github.com/karthik/holepunch Bibliografía Guia de estilo del tidyverse Hadley Wickham’s Style guide Happy Git and GitHub for the useR packrat {workflowr} Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/ Yihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html Mas cosas sobre reproducibilidad: Reproducibility project: Psychology Many labs 2 "],["reporte-final.html", "Capítulo 5 Reporte final 5.1 Base de datos a usar 5.2 Paso a paso 5.3 Hint 5.4 Nota final", " Capítulo 5 Reporte final El objetivo evaluable de este workshop es escribir CONJUNTAMENTE un mini-paper (tan sólo título, abstract, método y resultados) en inglés, en formato APA usando {papaja} o algún formato de {rticles}. 5.1 Base de datos a usar SOURCE: https://twitter.com/richarddmorey/status/690680901760606209 Usaremos la base de datos https://osf.io/qn9a2/ asociada al paper Cancer screening risk literacy of physicians in training: An experimental study de Petrova et al. En ese paper podréis ver que hay 1 experimento. Vuestra tarea será crear conjuntamente un paper en Rmarkdown (PDF) donde hagáis un reanálisis de los datos de ese paper. Cada uno de vosotros elegirá un subconjunto de variables y un análisis, e incluirá un “Experimento” dentro del paper conjunto, mostrando y describiendo sus resultados. 5.2 Paso a paso Tendréis que seguir los siguientes pasos para completar el trabajo: Paso 1: Crear un Repositorio en Github Paso 2: Clonar el repositorio localmente en un computador Paso 3: Crear una rama development y trabajar conjuntamente en la preparación de datos (importar, renombrar, seleccionar variables…) Paso 4: Usando {papaja}, o alguna de las plantillas de {rticles} cread juntos (en un solo computador) un documento Rmd e incluid la estructura (secciones) del paper Title Abstract: describir brevemente que se hace Introduction Materials and Methods Participants Materials Results Experiment 1 Experiment 2 Experiment 3 Discussion Paso 5: Cada uno clonara el repositorio localmente en su computador, creará su rama propia y, en la sección adecuada (e.g. Experiment 2), completará las tareas de abajo (commit y push cambios a la rama propia de Github al finalizar). NO borrar la rama propia de Github: Describir el análisis realizado Tabla APA con descriptivos de las variables seleccionadas Descripción de resultados en formato APA Tabla de resultados APA Plot APA que represente adecuadamente estos resultados Paso 6: Combinar los cambios de las 3 ramas individuales en development Paso 7: Cada uno debería revisar el paper final, corregir fallos y combinarlos en la rama development Paso 8: Mover los cambios a master y celebrar! 5.3 Hint En la carpeta Data and results de https://osf.io/qn9a2/ hay varios archivos que os ayudarán a entender cuales son las variables de interés. Analysis script R1.sps: script de SPSS usado para los análisis del paper Variables R1.sps: descripción de variables … Es muy recomendable ubicar las variables de interés, y renombrarlas para que sean fácilmente reconocibles. 5.4 Nota final La nota final se definirá de la siguiente manera: Paper final: 60% Tarea individual: 40% El formato, el estilo, y los acabados tienen que ser con el estándar de calidad esperado en un paper científico. Se evaluará específicamente lo siguiente: Paper final (60% total): (90%) El paper tiene que ser reproducible: El profesor descargará el repositorio completo en un computador sin ninguna librería instalada y kniteara el archivo .Rmd del paper. La expectativa es que todo funcione, y que el paper que se cree automáticamente sea idéntico al entregado por los alumnos. (10%) Calidad general de la redacción, ausencia de errores gramaticales y ortográficos graves. Tarea individual (40% total): (20%) Describir el análisis realizado (20%) Tabla APA con descriptivos de las variables seleccionadas (20%) Descripción de resultados en formato APA (20%) Tabla de resultados APA (20%) Plot APA que represente adecuadamente estos resultados La historia completa de commits de todas las ramas (master, development, y las 3 individuales) deberá estar disponible. "],["paquetes-usados.html", "Paquetes usados References", " Paquetes usados En la documentación y ejercicios de este workshop se usaron los paquetes que se pueden ver abajo. Este listado se creó automáticamente usando {grateful}: base (R Core Team 2019) knitr (Xie 2014) stargazer (Hlavac 2018) rticles (Allaire et al. 2019) renv (Ushey 2019) remotes (Hester et al. 2019) papaja (Aust and Barth 2018) easystats (Lüdecke and Makowski 2019) estimate (Makowski and Lüdecke 2019b) see (Lüdecke et al. 2019) report (Makowski et al. 2019) correlation (Makowski 2019) parameters (Makowski and Lüdecke 2019a) bayestestR (Makowski, Ben-Shachar, and Lüdecke 2019) performance (Lüdecke, Makowski, and Waggoner 2019) insight (Lüdecke, Waggoner, and Makowski 2019) corrr (Jackson, Cimentada, and Ruiz 2019) afex (Singmann et al. 2019) lme4 (Bates et al. 2015) Matrix (Bates and Maechler 2019) hexbin (Carr et al. 2019) FFTrees (Phillips et al. 2018) caret (Jed Wing et al. 2019) lattice (Sarkar 2008) janitor (Firke 2019) gsheet (Conway 2016) DT (Xie, Cheng, and Tan 2019) writexl (Ooms 2018) readODS (Schutten et al. 2018) here (Müller 2017) haven (Wickham and Miller 2019) readxl (Wickham and Bryan 2019) plotly (Sievert 2018) hrbrthemes (Rudis 2019) ggridges (Wilke 2018) ggthemes (Arnold 2019) gganimate (Pedersen and Robinson 2019) gapminder (Bryan 2017) esquisse (Meyer and Perrier 2019) cowplot (Wilke 2019) forcats (Wickham 2019a) stringr (Wickham 2019b) dplyr (Wickham et al. 2019) purrr (Henry and Wickham 2019) readr (Wickham, Hester, and Francois 2018) tidyr (Wickham and Henry 2019) tibble (Müller and Wickham 2019) ggplot2 (Wickham 2016) tidyverse (Wickham 2017) References Allaire, JJ, Yihui Xie, R Foundation, Hadley Wickham, Journal of Statistical Software, Ramnath Vaidyanathan, Association for Computing Machinery, et al. 2019. Rticles: Article Formats for r Markdown. https://github.com/rstudio/rticles. Arnold, Jeffrey B. 2019. Ggthemes: Extra Themes, Scales and Geoms for ’Ggplot2’. https://CRAN.R-project.org/package=ggthemes. Aust, Frederik, and Marius Barth. 2018. papaja: Create APA Manuscripts with R Markdown. https://github.com/crsh/papaja. Bates, Douglas, and Martin Maechler. 2019. Matrix: Sparse and Dense Matrix Classes and Methods. https://CRAN.R-project.org/package=Matrix. Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01. Bryan, Jennifer. 2017. Gapminder: Data from Gapminder. https://CRAN.R-project.org/package=gapminder. Carr, Dan, ported by Nicholas Lewin-Koh, Martin Maechler, and contains copies of lattice functions written by Deepayan Sarkar. 2019. Hexbin: Hexagonal Binning Routines. https://CRAN.R-project.org/package=hexbin. Conway, Max. 2016. Gsheet: Download Google Sheets Using Just the URL. https://CRAN.R-project.org/package=gsheet. Firke, Sam. 2019. Janitor: Simple Tools for Examining and Cleaning Dirty Data. https://CRAN.R-project.org/package=janitor. Henry, Lionel, and Hadley Wickham. 2019. Purrr: Functional Programming Tools. https://CRAN.R-project.org/package=purrr. Hester, Jim, Gábor Csárdi, Hadley Wickham, Winston Chang, Martin Morgan, and Dan Tenenbaum. 2019. Remotes: R Package Installation from Remote Repositories, Including ’GitHub’. https://CRAN.R-project.org/package=remotes. Hlavac, Marek. 2018. Stargazer: Well-Formatted Regression and Summary Statistics Tables. Bratislava, Slovakia: Central European Labour Studies Institute (CELSI). https://CRAN.R-project.org/package=stargazer. Jackson, Simon, Jorge Cimentada, and Edgar Ruiz. 2019. Corrr: Correlations in r. https://CRAN.R-project.org/package=corrr. Jed Wing, Max Kuhn. Contributions from, Steve Weston, Andre Williams, Chris Keefer, Allan Engelhardt, Tony Cooper, Zachary Mayer, et al. 2019. Caret: Classification and Regression Training. https://CRAN.R-project.org/package=caret. Lüdecke, Daniel, and Dominique Makowski. 2019. Easystats: Jump in the Easyverse. https://github.com/easystats/easystats. Lüdecke, Daniel, Dominique Makowski, and Philip Waggoner. 2019. Performance: Assessment of Regression Models Performance. https://easystats.github.io/performance/. Lüdecke, Daniel, Dominique Makowski, Philip Waggoner, and Mattan S. Ben-Shachar. 2019. See: Visualisation Toolbox for ’Easystats’ and Extra Geoms, Themes and Color Palettes for ’Ggplot2’. https://easystats.github.io/see/. Lüdecke, Daniel, Philip Waggoner, and Dominique Makowski. 2019. “Insight: A Unified Interface to Access Information from Model Objects in r.” Journal of Open Source Software 4 (38): 1412. https://doi.org/10.21105/joss.01412. Makowski, Dominique. 2019. Correlation: Easy Peasy Correlations. https://github.com/easystats/correlation. Makowski, Dominique, Mattan S. Ben-Shachar, and Daniel Lüdecke. 2019. “Understand and Describe Bayesian Models and Posterior Distributions Using bayestestR.” CRAN. https://doi.org/10.5281/zenodo.2556486. Makowski, Dominique, and Daniel Lüdecke. 2019a. “Describe and Understand Your Model’s Parameters.” CRAN. https://github.com/easystats/parameters. ———. 2019b. Estimate: Estimate Effects, Contrasts and Means. https://github.com/easystats/estimate. Makowski, Dominique, Lüdecke, and Daniel. 2019. “The Report Package for r: Ensuring the Use of Best Practices for Results Reporting.” CRAN. https://github.com/easystats/report. Meyer, Fanny, and Victor Perrier. 2019. Esquisse: Explore and Visualize Your Data Interactively. https://CRAN.R-project.org/package=esquisse. Müller, Kirill. 2017. Here: A Simpler Way to Find Your Files. https://CRAN.R-project.org/package=here. Müller, Kirill, and Hadley Wickham. 2019. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble. Ooms, Jeroen. 2018. Writexl: Export Data Frames to Excel ’Xlsx’ Format. https://CRAN.R-project.org/package=writexl. Pedersen, Thomas Lin, and David Robinson. 2019. Gganimate: A Grammar of Animated Graphics. https://CRAN.R-project.org/package=gganimate. Phillips, Nathaniel, Hansjoerg Neth, Jan Woike, and Wolfgang Gaissmaer. 2018. FFTrees: Generate, Visualise, and Evaluate Fast-and-Frugal Decision Trees. https://CRAN.R-project.org/package=FFTrees. R Core Team. 2019. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. Rudis, Bob. 2019. Hrbrthemes: Additional Themes, Theme Components and Utilities for ’Ggplot2’. https://CRAN.R-project.org/package=hrbrthemes. Sarkar, Deepayan. 2008. Lattice: Multivariate Data Visualization with r. New York: Springer. http://lmdvr.r-forge.r-project.org. Schutten, Gerrit-Jan, Chung-hong Chan, Thomas J. Leeper, and other contributors. 2018. readODS: Read and Write ODS Files. https://CRAN.R-project.org/package=readODS. Sievert, Carson. 2018. Plotly for r. https://plotly-r.com. Singmann, Henrik, Ben Bolker, Jake Westfall, Frederik Aust, and Mattan S. Ben-Shachar. 2019. Afex: Analysis of Factorial Experiments. https://CRAN.R-project.org/package=afex. Ushey, Kevin. 2019. Renv: Project Environments for r. https://github.com/rstudio/renv. Wickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org. ———. 2017. Tidyverse: Easily Install and Load the ’Tidyverse’. https://CRAN.R-project.org/package=tidyverse. ———. 2019a. Forcats: Tools for Working with Categorical Variables (Factors). https://CRAN.R-project.org/package=forcats. ———. 2019b. Stringr: Simple, Consistent Wrappers for Common String Operations. https://CRAN.R-project.org/package=stringr. Wickham, Hadley, and Jennifer Bryan. 2019. Readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl. Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr. Wickham, Hadley, and Lionel Henry. 2019. Tidyr: Easily Tidy Data with ’Spread()’ and ’Gather()’ Functions. https://CRAN.R-project.org/package=tidyr. Wickham, Hadley, Jim Hester, and Romain Francois. 2018. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr. Wickham, Hadley, and Evan Miller. 2019. Haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven. Wilke, Claus O. 2018. Ggridges: Ridgeline Plots in ’Ggplot2’. https://CRAN.R-project.org/package=ggridges. ———. 2019. Cowplot: Streamlined Plot Theme and Plot Annotations for ’Ggplot2’. https://CRAN.R-project.org/package=cowplot. Xie, Yihui. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. ———. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. ———. 2014. “Knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595. Xie, Yihui, Joe Cheng, and Xianying Tan. 2019. DT: A Wrapper of the JavaScript Library ’DataTables’. https://CRAN.R-project.org/package=DT. "]]
