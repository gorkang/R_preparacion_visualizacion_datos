[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R para preparación y visualización de datos",
    "section": "",
    "text": "Introducción\nEl objetivo de este seminario es aprender a usar R para preparar y visualizar datos, además de generar reportes reproducibles. Está pensado para alumnos de postgrado con conocimientos básicos de programación.\nTambién conoceremos jsPsychR, un conjunto de herramientas creado por miembros del CSCN para ayudar a crear paradigmas experimentales con jsPsych, simular participantes, y estandarizar el proceso de preparación y análisis de datos.\nR es un lenguaje de programación abierto, con una gran comunidad, orientado al trabajo, visualización y modelado de datos en contextos científicos y técnicos. Nos introduciremos de manera práctica a R, resolviendo problemas que encontramos habitualmente durante el quehacer científico, focalizándonos en el trabajo abierto, colaborativo y reproducible.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#objetivos",
    "href": "index.html#objetivos",
    "title": "R para preparación y visualización de datos",
    "section": "Objetivos",
    "text": "Objetivos\nDar las herramientas básicas a los alumnos para que puedan trabajar de manera autónoma con R y RStudio para el proceso de importación, transformación, visualización y reporte de datos.\nAl finalizar el curso deberíamos ser capaces de:\n\nImportar archivos de datos, transformar los datos, crear nuevas variables.\nRealizar análisis de datos exploratorios, visualizar distribuciones y comparar grupos.\nGenerar reportes reproducibles con Quarto/RMarkdown\nCrear paradigmas experimentales y un pipeline completo para la preparación de datos con jsPsychR.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#como-empezar",
    "href": "index.html#como-empezar",
    "title": "R para preparación y visualización de datos",
    "section": "Como empezar",
    "text": "Como empezar\nSi ya has completado los pasos A-B-C y otras dependencias a instalar indicados en preparando nuestro sistema, puedes lanzar el siguiente código en tu ordenador para descargar los materiales del curso:\n\nif (!require('usethis')) install.packages('usethis'); library('usethis')\nusethis::use_course(\"gorkang/R_preparacion_visualizacion_datos\")\n\nSigue las instrucciones que aparecen en la Consola para tener un nuevo proyecto de RStudio con todos los materiales del curso. El código anterior creará una carpeta llamada R_preparacion_visualizacion_datos-master.\nLa carpeta R_preparacion_visualizacion_datos-master contiene varias cosas. Las mas importantes son:\n\nR_preparacion_visualizacion_datos.Rproj: para abrir el proyecto de RStudio del curso. Ábrelo siempre usando este archivo.\nCarpeta docs: puedes abrir docs/index.html en tu navegador para ver el “libro” de este curso. Alternativamente, puedes consultar una version online del libro\nCarpeta qmd: En esa carpeta esta el código fuente de los capítulos del libro\nCarpeta data: Cuando usemos archivos de datos, vendrán de aquí\n\n\n\n\n\n\n\nEn ocasiones encontraras un recuadro como este. En la versión online del libro, si haces click sobre el, aparecerá una pista sobre como resolver el ejercicio.\n\n\n\n\n\n¡No hagas click sin antes haber intentado resolver el ejercicio sin ayuda!",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#bibliografía",
    "href": "index.html#bibliografía",
    "title": "R para preparación y visualización de datos",
    "section": "Bibliografía",
    "text": "Bibliografía\nBryan, J., & Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/\nWickham, H. (2014). Advanced r. Chapman and Hall/CRC. https://adv-r.hadley.nz/\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nYihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "qmd/00-configuracion-sistema.html",
    "href": "qmd/00-configuracion-sistema.html",
    "title": "Preparando nuestro sistema",
    "section": "",
    "text": "Empezando en A-B-C\nPara poder iniciar el workshop necesitamos tener R y RStudio instalados, además de algunas librerías. Para tener un sistema funcional, completa los pasos A, B y C. Si ya tienes R y Rstudio instalados (recientemente), puedes pasar directamente al paso (C).",
    "crumbs": [
      "Preparando nuestro sistema"
    ]
  },
  {
    "objectID": "qmd/00-configuracion-sistema.html#empezando-en-a-b-c",
    "href": "qmd/00-configuracion-sistema.html#empezando-en-a-b-c",
    "title": "Preparando nuestro sistema",
    "section": "",
    "text": "(A) Instalar R\nR, es un lenguaje de programación especializado en la computación estadística y visualización de datos. Es recomendable tener instalada la última versión de R (necesitarás al menos la versión 4.2). Puedes usar uno de los enlaces siguientes:\n\nWindows: Descargar e instalar R para Windows\nMac: Descargar e instalar R para Mac\nUbuntu Linux: más detalles en la web de R.\nEn un terminal: sudo apt install r-base\n\n(B) Instalar RStudio\nRStudio es un entorno integrado de desarrollo (IDE) para la programación R.\n\n\nDescargar e instalar RStudio.\nUna vez descargado e instalado, abre RStudio. Deberías ver algo parecido a lo siguiente:\n\n\n\n\n\n\n\n\n\n\nSi encuentras un error de instalación en ubuntu, tendrás que instalar RStudio manualmente:\n\nsudo dpkg -i rstudio-[VERSION_NUMBER]-amd64.deb\nsudo apt --fix-broken install\n\n\n\n(C) Paquetes para el workshop\nPara instalar los paquetes del workshop, ejecuta el código de más abajo (sección sombreada en gris claro) en la consola de RStudio.\nEn este gif puedes ver como hacerlo:\n\n\n\n\n\n\n\n\nCopia y pega el código de abajo en la consola de RStudio y ejecútalo [tecla ENTER]:\n\nif (!require('rlang')) install.packages('rlang'); library('rlang')\nrlang::check_installed(\n  pkg = c(\"afex\", \"broom.mixed\", \"correlation\", \"corrr\", \"cowplot\", \"dplyr\", \"DT\", \"esquisse\",\n          \"gapminder\", \"geomtextpath\", \"ggplot2\", \"ggrain\", \"ggraph\", \"ggridges\", \"ggthemes\", \n          \"ggtext\", \"googlesheets4\", \"grateful\", \"gtsummary\", \n          \"haven\", \"here\", \"hexbin\", \"inspectdf\", \"janitor\", \"knitr\", \"lme4\", \n          \"papaja\", \"parameters\", \"performance\", \"plotly\", \"purrr\", \n          \"quarto\", \"readODS\", \"readr\", \"readxl\", \"remotes\", \"renv\", \"report\", \n          \"rticles\", \"see\", \"sjPlot\", \"stargazer\", \"tidyr\", \"usethis\", \"writexl\"), \n  reason = \"to run the initial setup\")\n\n\n\n\n\n\n\nSi falla el codigo de arriba, puedes intentar esto\n\n\n\n\n\n\nif (!require('pak')) install.packages('pak'); library('pak')\n\npak::pak(\n  pkg = c(\"afex\", \"broom.mixed\", \"correlation\", \"corrr\", \"cowplot\", \"dplyr\", \"DT\", \"esquisse\",\n          \"gapminder\", \"geomtextpath\", \"ggplot2\", \"ggrain\", \"ggraph\", \"ggridges\", \"ggthemes\", \n          \"ggtext\", \"googlesheets4\", \"grateful\", \"gtsummary\", \n          \"haven\", \"here\", \"hexbin\", \"inspectdf\", \"janitor\", \"knitr\", \"lme4\", \n          \"papaja\", \"parameters\", \"performance\", \"plotly\", \"purrr\", \n          \"quarto\", \"readODS\", \"readr\", \"readxl\", \"remotes\", \"renv\", \"report\", \n          \"rticles\", \"see\", \"sjPlot\", \"stargazer\", \"tidyr\", \"usethis\", \"writexl\"))\n\n\n\n\nOtros paquetes que necesitaremos. Para que corran estas líneas tenemos que haber completado el paso previo.\n\nif (!require('remotes')) install.packages('remotes'); remotes::install_github('gorkang/jsPsychAdmin')\nif (!require('regexplain')) remotes::install_github(\"gadenbuie/regexplain\"); library('regexplain')\n\nUsaremos un buen número de paquetes en el workshop. El proceso de instalación requiere Internet y tardará un buen rato (en algunos sistemas puede llegar a 1 hora).\nHay algunos meta-paquetes que simplifican la instalación de múltiples paquetes (e.g. pacman, pak, renv, …), pero dejaremos eso para más adelante.\nOtras dependencias a instalar\nInstalar Quarto\nQuarto es un sistema de publicación de código abierto que funciona con diferentes lenguajes de programación como R o python. Lo usaremos a partir del capítulo 6.\nDescarga e instala Quarto\nInstalar latex\nPara generar pdf’s necesitaremos tener instalado Latex. tinytex nos ayudará a simplificar el proceso:\n\nif (!require('tinytex')) install.packages('tinytex'); library('tinytex')\ntinytex::install_tinytex() # Llevará un buen rato\n\nDocker\nNecesitaremos Docker para simular datos de participantes online.\nInstala Docker en:\n\n\nLinux\n\n\nMac\n\nWindows\n\nAdicionalmente:\n\nWindows: Update wsl (in a command prompt): wsl - update\n\nUbuntu:\n\nEn un terminal: sudo apt install libssl-dev libcurl4-openssl-dev libxml2-dev docker\n\nSi los monos hacen su trabajo pero no aparecen los csv’s, asegúrate que el usuario docker tiene acceso al directorio ~/Downloads\n\n\n\nPara más detalles, puedes consultar jsPsychMonkeys setup\nGit\nVer instrucciones para Windows, Mac y Linux.\n  Importante: en el paso Adjusting your PATH environment en en Windows, selecciona Git from the command line and also from 3rd-party software",
    "crumbs": [
      "Preparando nuestro sistema"
    ]
  },
  {
    "objectID": "qmd/00-configuracion-sistema.html#algo-más-sobre-la-instalación-de-paquetes",
    "href": "qmd/00-configuracion-sistema.html#algo-más-sobre-la-instalación-de-paquetes",
    "title": "Preparando nuestro sistema",
    "section": "Algo más sobre la instalación de paquetes",
    "text": "Algo más sobre la instalación de paquetes\nLos paquetes de R son una colección de funciones, datos y documentación que amplían las capacidades básicas de R.\nGran parte de las funciones y paquetes que utilizaremos en este workshop se encuentran contenidas en el meta-paquete tidyverse (este es un paquete de paquetes). No lo instalamos en (C), pero si quisieras instalarlo solo tendrías que ejecutar la siguiente linea en la consola de RStudio:\n\ninstall.packages(\"tidyverse\")\n\nPara instalar otro paquete diferente de “tidyverse”, remplaza su nombre entre comillas dentro de la función:\n\ninstall.packages(\"NOMBRE_DE_PAQUETE\")\n\nUna vez instalado un paquete, no es necesario volver hacerlo, a menos que reinstales R.\nCargar paquetes\nLas funciones, datos y documentación dentro de nuestros paquetes no podrán ser utilizadas hasta que se carguen en R. Una vez instalados, para cargar los paquetes se usa la función library():\n\nlibrary(ggplot2)  \n\nEn realidad las funciones también pueden ser llamadas usando su referencia absoluta ::, sin necesidad de cargarlas antes. Por ejemplo: dplyr::tibble(columna = 1). En general: nombre_paquete::nombre_de_funcion(parametros)).\nTodo en uno\nEl siguiente código simplifica lo anterior. Comprueba que el paquete esta instalado; Si no se encuentra instalado, lo instala. Finalmente lo carga.\n\nif (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')  \n\nPara instalar múltiples paquetes, podemos repetir la linea de mas arriba tantas veces como sea necesario, o usar una versión algo más sofisticada como el código del apartado (C):\n\nif (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')\nif (!require('bookdown')) install.packages('bookdown'); library('bookdown')\n\nAl principio de cada capítulo, verás una sección llamada Paquetes para este capítulo. Si pegas el contenido de esa sección en un script de R al empezar cada capítulo, te asegurarás de tener disponibles todas las funciones que usaremos.\nInstalar paquetes de Github\nEn ocasiones querremos instalar directamente la versión en desarrollo del paquete desde Github. Para eso podemos usar la función install_github() del paquete remotes. Por ejemplo, para instalar el paquete {BayesianReasoning} desde su repositorio de Github:\n\nif (!require('remotes')) install.packages('remotes'); library('remotes')\nremotes::install_github(\"gorkang/jsPsychMaker\")",
    "crumbs": [
      "Preparando nuestro sistema"
    ]
  },
  {
    "objectID": "qmd/00-configuracion-sistema.html#bibliografía",
    "href": "qmd/00-configuracion-sistema.html#bibliografía",
    "title": "Preparando nuestro sistema",
    "section": "Bibliografía",
    "text": "Bibliografía\nAlgunos de los manuales que vamos a usar para el workshop son los siguientes:\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nBryan, J., & Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/",
    "crumbs": [
      "Preparando nuestro sistema"
    ]
  },
  {
    "objectID": "qmd/01-introduccion.html",
    "href": "qmd/01-introduccion.html",
    "title": "\n1  Introducción a R\n",
    "section": "",
    "text": "1.1 Introducción: ¿por qué la visualización de datos es importante?\n“These 13 datasets (the Datasaurus, plus 12 others) each have the same summary statistics (x/y mean, x/y standard deviation, and Pearson’s correlation) to two decimal places, while being drastically different in appearance.” (Matejka, J., & Fitzmaurice, G., 2017).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a R</span>"
    ]
  },
  {
    "objectID": "qmd/01-introduccion.html#introducción-por-qué-la-visualización-de-datos-es-importante",
    "href": "qmd/01-introduccion.html#introducción-por-qué-la-visualización-de-datos-es-importante",
    "title": "\n1  Introducción a R\n",
    "section": "",
    "text": "SOURCE: https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\n1.1.1 Ejemplo del mundo real: ¿cuantos temas deberia estudiar?\nEste ejemplo viene de un experimento que realizamos junto con Carlos Santamaría hace algún tiempo. Presentamos una tarea sobre cálculo de probabilidades a personas que estaban entrando a un examen para convertirse en trabajadores del estado.\nSimplificando algo, digamos que la materia para el examen eran 80 temas. No es posible estudiar con profundidad todos los temas, así que los opositores se concentraban en un subconjunto de esos temas (e.g. 30 de 80). Al empezar el examen, se seleccionaban al azar 5 de los 80 temas, y cada persona elegía uno de ellos para desarrollar.\nAbajo se puede ver como cambia la probabilidad de que uno de los temas estudiados aparezca dentro de los 5 seleccionados al azar. Con 30 de los 80 temas estudiados, la probabilidad de que uno de ellos salga en la prueba es del 91%. Si estudiáramos 47, subiríamos a una probabilidad del 99%.\n\n\n\n\n\n\nLa esencia del dilema al que se enfrentan los opositores se puede condensar en este gráfico. La ganancia (en probabilidad de que salga un tema estudiado) va disminuyendo con cada tema adicional, hasta llegar a un punto en el que es negligible. El problema es que esto es muy poco intuitivo…\n\n\n\n\n\n\n En el experimento le preguntamos a los participantes por la probabilidad de que les apareciera alguno de los temas estudiados en la prueba. Comparamos las siguientes dos preguntas:\n\n¿Cuál es la probabilidad de que salga uno de los temas que has estudiado?\n\n¿Cuál es la probabilidad de que no salga ninguno de los temas que has estudiado?\n\nMiramos el error promedio en función de la pregunta (cuanto se han alejado de la probabilidad correcta), y vimos que nuestra manipulación había tenido un efecto considerable:\n\n\n\n\nQuestion\nError_promedio\nSD\nN\n\n\n\np (salga uno)\n-30.741936\n20.01494\n31\n\n\np (no salga ninguno)\n4.016129\n35.82469\n31\n\n\n\n\n\n\nHay una diferencia notable entre condiciones. Pasamos de un error promedio del -30.7% a tan solo 4%, simplemente cambiando la pregunta. Hagamos un sencillo análisis de regresión para ver si la diferencia es significativa, y cuanta varianza explica nuestro modelo.\n\n\n\n\n \nError\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n4.02\n-6.41 – 14.44\n0.444\n\n\nQuestion [p (salga uno)]\n-34.76\n-49.50 – -20.02\n&lt;0.001\n\n\nObservations\n62\n\n\nR2 / R2 adjusted\n0.270 / 0.258\n\n\n\n\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  modelo_regresion$residuals\n#&gt; W = 0.96215, p-value = 0.0532\n\n\n\n\n\n\n\n\nTodo es hermoso. Tenemos un efecto claramente significativo de la pregunta (y con un R2-ajustado de .258, no está nada mal), y además, nuestro modelo no incumple el supuesto de normalidad de residuos (¡por los pelos!).\n\n\n\n\n\n\nNota importante sobre las pruebas de normalidad. Hack click para leerme.\n\n\n\n\n\nLas pruebas de normalidad son muy sensibles al tamaño de la muestra. Como el tamaño de la muestra es pequeño en este caso, no es esperable que el resultado sea significativo.\n\n\n\nPreparamos un plot con promedios y barras con error standard para nuestro paper.\n\n\n\n\n\n\n\n\nEstamos listos para escribir el paper. Preparemos la tabla con descriptivos…\n\n\n\n\nQuestion\nError_promedio\nSD\nN\n\n\n\np (salga uno)\n-30.741936\n20.01494\n31\n\n\np (no salga ninguno)\n4.016129\n35.82469\n31\n\n\n\n\n\n\nEs curioso que la desviación estándar sea mayor en el grupo con menos error promedio… Visualicemos las respuestas de todos los participantes, junto con la distribución de los datos.\n\n\n\n\n\n\n\n\nComo se puede apreciar en la gráfica, cuando usamos la pregunta ¿Cuál es la probabilidad de que no salga ninguno de los temas que has estudiado? no estamos reduciendo el error, sino convirtiendo una distribución de respuestas unimodal en bimodal.\n\nTLDR: La manera en la visualizamos la información determina las conclusiones a las que llegamos. En una sola gráfica:\n\n\n\n\n\n\n\n\nMoraleja: es importante mostrar los datos individuales y/o la distribución de los datos\n\n\nSOURCE: https://www.research.autodesk.com/publications/same-stats-different-graphs/",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a R</span>"
    ]
  },
  {
    "objectID": "qmd/01-introduccion.html#por-qué-r",
    "href": "qmd/01-introduccion.html#por-qué-r",
    "title": "\n1  Introducción a R\n",
    "section": "\n1.2 ¿Por qué R?",
    "text": "1.2 ¿Por qué R?\n\n\n\nR es uno de los programas para data science mas populares, especialmente usado en la academia. El numero de paquetes que ofrecen funcionalidades de todo tipo no ha dejado de crecer. En 2024 el numero de paquetes en R-cran ha superado los 25,000, y el ritmo de crecimiento nos acerca a la singularidad… ;)\n\n\n\n\n\n\nSOURCE: https://gist.github.com/daroczig/3cf06d6db4be2bbe3368\n\n\nAdemás de lo anterior, R es un programa de código abierto (algo esencial para poder hacer ciencia reproducible), con una comunidad de usuarios muy acogedora, y con un importante foco en la inclusividad.\nLa importancia de la comunidad es difícil de apreciar. Por ejemplo, es relativamente habitual que uno abra un issue en Github pidiendo una nueva característica en un paquete, y que los creadores la implementen (e.g. correlation, gtsummary, rorcid), que uno reporte un error y lo corrijan (e.g. sjPlot, gtsummary), recibir correcciones y mejoras en tus repositorios (e.g. html2latex, 2019-Chile), o poder contribuir a repositorios de otros (e.g. jsPsych, gtsummary).\nSus funciones de visualización son muy potentes (ver la r-graph-gallery para algunos ejemplos), siendo usadas como herramienta principal en medios como la BBC.\n\n\nSOURCE: BBC\n\n\nNo menos importante, hay una gran cantidad de cursos, tutoriales, presentaciones y libros de una calidad excelente, con los que podemos aprender de manera autónoma. Por ejemplo:\n\npsyTeachR team at the University of Glasgow\nA Gentle Guide to the Grammar of Graphics with ggplot2\nresulumit.com Rmd workshop\nR for Data Science\nAdvanced R\n\n\nPara ver una compilación de libros disponibles (&gt; 300): Big Book of R",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a R</span>"
    ]
  },
  {
    "objectID": "qmd/01-introduccion.html#para-qué-sirve-r",
    "href": "qmd/01-introduccion.html#para-qué-sirve-r",
    "title": "\n1  Introducción a R\n",
    "section": "\n1.3 ¿Para qué sirve R?",
    "text": "1.3 ¿Para qué sirve R?\nCon R puedes recoger datos interactivamente con shiny, preparar datos (o extraerlos de paginas web con rvest o RSelenium), visualizar datos estáticos con ggplot, animarlos con gganimate, visualizarlos con interactivamente con plotly o shiny.\nPuedes también analizar los datos con todas las técnicas imaginables, desde anovas con afex a modelos mixtos con lmer y/o afex, pasando por meta-análisis con metafor, SEM, Path analysis, mediación, con lavaan, análisis Bayesianos con brms o bayesfactor, y un larguísimo etc.\nPuedes llevar tus visualizaciones y análisis a reportes automáticos en múltiples formatos (pdf, html, docx) con Rmarkdown, o quarto, crear libros como este con bookdown, páginas web con blogdown o distill, e incluso papers completamente reproducibles (preparación y análisis de datos) en formato APA con papaja.\n\n\n1.3.1 Bienvenida al tidyverse\n\n\n\nEl tidyverse es un conjunto de paquetes que nos permitirán hacer de manera (habitualmente) intuitiva muchas tareas de preparación y visualización de datos.\n\n1.3.1.1 Tidyverse vs Base R\nMuchas de las funciones que existen en el Tidyverse tienen un equivalente en base-R (la instalación por defecto de R). El Tidyverse tiene ventajas y desventajas. La ventaja fundamental es que el código resulta (habitualmente) más fácil de leer, los nombres de las funciones son más intuitivos, y la forma de hacer las cosas tiene a ser consistente. La desventaja fundamental es que incrementamos el numero de dependencias (paquetes) de nuestro código.\nVeamos un ejemplo extraído de aquí.\n\nLa misma operación con base-R o con tidyverse:\nFilter rows with conditions evaluated within groups: iris flowers with maximum “Petal.Width” for each “Species”\nTidyverse\n\n  result1 = iris |&gt; \n    group_by(Species) |&gt; \n    filter(Petal.Width == max(Petal.Width))\n\nBase-R\n\n  # First operate in the data.frame by group (split-apply)\n  widest_petals &lt;- by(iris, \n                      INDICES = iris$Species, \n                      FUN = function(x){\n                        x[x$Petal.Width == max(x$Petal.Width), ] \n                      })\n  \n  # Then combine the results into a data.frame\n  result2 = do.call(rbind, widest_petals)\n\n\n\nwaldo::compare(result1, result2, ignore_attr = TRUE)\n#&gt; ✔ No differences\n\nresult1\n#&gt; # A tibble: 5 × 5\n#&gt; # Groups:   Species [3]\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n#&gt;          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;     \n#&gt; 1          5           3.5          1.6         0.6 setosa    \n#&gt; 2          5.9         3.2          4.8         1.8 versicolor\n#&gt; 3          6.3         3.3          6           2.5 virginica \n#&gt; 4          7.2         3.6          6.1         2.5 virginica \n#&gt; 5          6.7         3.3          5.7         2.5 virginica\n\n\n1.3.2 Antes de empezar\nProgramar es como tener un superpoder. Pero llegar adquirir ese superpoder es muy difícil. Todos necesitamos ayuda. Contar con una comunidad robusta con la que compartir, preguntar, contribuir, hace el proceso más agradable, y aumenta tus probabilidades de éxito.\nInicialmente “programaremos” usando la técnica conocida como Copy and paste programming, y poco a poco aprenderemos a descomponer el código, adaptarlo a nuestras necesidades, hasta que en algún momento lleguemos a escribir código propio. Este manual os debería servir de referencia para las primeras fases. Familiarizaros con su estructura, y acostumbraros a copiar, pegar y correr el código que aparece en los recuadros grises.\n\n\nSOURCE: http://www.keywordbasket.com/ZWZlY3RvIGR1bm5pbmcta3J1Z2Vy/\n\n\n\n1.3.3 Recursos adicionales\nHay algunos recursos que son imprescindibles. Nadie sabe como los antiguos podían programar antes de la llegada de Stackoverflow:\n\nStack overflow\nGoogle: avoid scientific notation R: options(scipen=999)\n\nY otros recursos que resultan muy útiles:\n\nComunidad de usuarios de Rstudio\n\nMastodon! Por ejemplo:\n\n\n @thomas_mock (#TidyTuesday)\n\n\n @rivaquiroga\n\n\n @RLadiesGlobal\n\n @coolbutuseless\n\n\nWebs como R bloggers",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a R</span>"
    ]
  },
  {
    "objectID": "qmd/01-introduccion.html#bibliografía",
    "href": "qmd/01-introduccion.html#bibliografía",
    "title": "\n1  Introducción a R\n",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nMatejka, J., & Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM.\nhttps://bbc.github.io/rcookbook/\nhttps://github.com/bbc/bbplot\nBig Book or R : https://www.bigbookofr.com/index.html",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a R</span>"
    ]
  },
  {
    "objectID": "qmd/02-visualizacion-basica.html",
    "href": "qmd/02-visualizacion-basica.html",
    "title": "\n2  Introducción a la visualización de datos\n",
    "section": "",
    "text": "2.1 R para visualización de datos\nggplot2 es el paquete por excelencia para visualización de datos. Su potencia va asociada a un nivel de complejidad considerable, hasta el punto que hay Cheat sheets oficiales, Cheat sheets buscables, y decenas de miles de preguntas en Stack Overflow.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la visualización de datos</span>"
    ]
  },
  {
    "objectID": "qmd/02-visualizacion-basica.html#r-para-visualización-de-datos",
    "href": "qmd/02-visualizacion-basica.html#r-para-visualización-de-datos",
    "title": "\n2  Introducción a la visualización de datos\n",
    "section": "",
    "text": "2.1.1 Primeros pasos - con training wheels\nPara empezar a trabajar con ggplot sin tener que preocuparnos de su complejidad, podemos usar la función esquisse:::esquisser() del paquete esquisse. Esta nos permite usar la potencia de ggplot para explorar una base de datos de manera muy sencilla.\n\n\nSOURCE: https://github.com/will-r-chase/blog/blob/master/static/slides/slide_img/esquisse.gif\n\n\nLa manera fácil (1, 2, 3), usando esquisse:\n\n\n# 1) Asegúrate que hemos instalado el paquete esquisse\n  if (!require('esquisse')) install.packages('esquisse'); library('esquisse')\n\n# 2) Lanza el wizard esquisser  \n  esquisse:::esquisser(iris)\n\n# 3) Crea el gráfico que quieras, exporta el código...\n\n\n2.1.2 Aprendamos con Garrick\nGarrick Aden-Buie ( @grrrck) ha creado una excelente introducción a ggplot2 y la gramática de gráficos. Os recomiendo revisarla para familiarizaros con las funcionalidades de ggplot.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la visualización de datos</span>"
    ]
  },
  {
    "objectID": "qmd/02-visualizacion-basica.html#visualización-de-datos-con-ggplot2",
    "href": "qmd/02-visualizacion-basica.html#visualización-de-datos-con-ggplot2",
    "title": "\n2  Introducción a la visualización de datos\n",
    "section": "\n2.2 Visualización de datos con ggplot2",
    "text": "2.2 Visualización de datos con ggplot2\n\n2.2.1 Componentes de una gráfica\nEn esta sección vamos a ver algunos de los componentes que usaremos cuando visualicemos datos. Muchos de los ejemplos que usaremos vienen de R for data science.\n\n\n\n\n\n\nIngredientes esenciales de una gráfica\n\n\n\n\n\nAesthetic mappings (aes): Variables, colores, rellenos, formas, …\n\nGeoms (geom_): puntos, líneas, boxplots, …\n\nFacets (facet_): paneles con diferentes gráficos para cada nivel de una variable categórica, …\n\nTransformaciones estadísticas: calcular promedios, barras de error, …\n\n\n\nSOURCE: https://skillgaze.com/2017/10/31/understanding-different-visualization-layers-of-ggplot/\n\n\n\n\n2.2.2 Mi primera gráfica en A-B-C\nPara crear una gráfica con ggplot, tenemos que:\n\nindicar donde están nuestros datos y que mostraremos en los ejes x e y\n\nañadir la o las geometrías (geoms) que queramos\n\nUsaremos + para sumar instrucciones, con una lógica de capas superpuestas.\nPor ejemplo:\n\nIndicamos los datos y coordenadas: ggplot(data = mpg, aes(x = displ, y = hwy))\nAñadimos el geom de puntos para mostrar la relación entre x e y: + geom_point()\nAñadimos un segundo geom para trazar una línea de tendencia: + geom_smooth()\n\n\n\n\n\n\n\n\n\nEl código de la gráfica final sería el siguiente. Si respetamos el orden de las variables, podemos simplificar nuestro código, evitando el data =, x = e y =:\n\n\n# Los datos están en mpg. Queremos ver la relación entre las variables `displ` y `hwy`\n# Usamos geom_point para mostrar puntos \n# Usamos geom_smooth para dibujar linea de tendencia\n\nggplot(mpg, aes(displ, hwy)) +\n  geom_point() + \n  geom_smooth()\n\n\n\n\n\n\n\n\n2.2.3 Aesthetic mappings\nEn aes() vamos a indicar las variables que queremos en los ejes x e y, el color de los puntos o líneas, el relleno de las barras, la forma de los puntos, el tipo de linea, la agrupación de los datos, etc.\n\n\n\n\n\n\nParámetros estéticos\n\n\n\n\n\nx: x = gdpPercap\n\ny: y = lifeExp\n\ncolor: color = continent; color = “red”; color = “#FAA627”\n\nfill: fill = continent; fill = “red”; fill = “#FAA627”\n\nalpha: alpha = continent; alpha = 0.2\n\nsize: size = continent; size = 5\n\nshape: shape = continent; shape = 0 ver codigo de las distintas formas\n\n\nlinetype: linetype = continent; linetype = “dashed”\n\ngroup: group = continent\n\n\n\nVeamos algunos de los parámetros…\n\n2.2.3.1 x-y\nAlgo esencial es decirle a ggplot qué queremos mostrar en los ejes x e y de nuestra gráfica.\nEmpezaremos usando los datos de gapminder Vamos a ver qué variables tenemos en el data frame:\n\n\n\n\n\n\nError: object ‘gapminder’ not found\n\n\n\n\n\nSi te aparece el error: Error: object 'gapminder' not found, asegurate de hacer los pasos indicados en el recuadro Paquetes para este capítulo arriba. \n\n\n\n\ngapminder\n#&gt; # A tibble: 1,704 × 6\n#&gt;   country     continent  year lifeExp      pop gdpPercap\n#&gt;   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia       1952    28.8  8425333      779.\n#&gt; 2 Afghanistan Asia       1957    30.3  9240934      821.\n#&gt; 3 Afghanistan Asia       1962    32.0 10267083      853.\n#&gt; 4 Afghanistan Asia       1967    34.0 11537966      836.\n#&gt; 5 Afghanistan Asia       1972    36.1 13079460      740.\n#&gt; 6 Afghanistan Asia       1977    38.4 14880372      786.\n#&gt; # ℹ 1,698 more rows\n\nVisualizamos la relación entre gdpPercap (eje x), y lifeExp (eje y):\n\nggplot(gapminder, aes(gdpPercap, lifeExp)) + \n  geom_point()\n\n\n\n\n\n\n\nDentro de aes(), el primer parámetro se refiere al eje x y el segundo al eje y. Si cambiamos el orden del código de arriba, podemos ver de nuevo la relación entre lifeExp y gdpPercap, con los ejes invertidos.\n\n\n  ggplot(gapminder, aes(lifeExp, gdpPercap)) + \n    geom_point()\n\n\n\n\n\n\n\nEjercicio\nUsando gapminder, ¿podrías crear un gráfico de gdp per cápita por población como éste?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\ndentro de aes() tenemos que poner gdpPercap y pop\n\n\n\n\n2.2.3.2 Color, alpha, size\nPara asignar colores podemos usar nombres de colores en inglés, o algo llamado código HEX:\n\nEscribe colors() en la Consola de RStudio (aparecerá un listado con &gt; 600 colores)\nVer el código HEX de los colores\n\n\nEmpecemos a cambiar parámetros de nuestro gráfico inicial:\n\n  # Gráfico inicial\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point()\n\n\n\n\n\n\n\nColor “rojo” para los puntos con color = \"red\".\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point(color = \"red\")\n\n\n\n\n\n\n\nColor en función de la variable ‘continent’. Al usar un nombre de variable, tenemos que ponerlo dentro de aes().\n\n\n\n\n\n\nError: object ‘continent’ not found\n\n\n\n\n\n\ncontinent es una columna de gapminder, no un color. Siempre que usemos nombres de variables, tienen que estar dentro de aes()\n\n\n\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + \n    geom_point()\n\n\n\n\n\n\n\nColor en función de la variable ‘continent’. Cambiamos el tamaño de los puntos a 2.\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2)) + \n    geom_point()\n\n\n\n\n\n\n\nColor en función de la variable ‘continent’. Cambiamos el tamaño de los puntos a 2. Añadimos transparencia usando el parámetro ‘alpha’.\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, \n                        color = continent, \n                        size = 2, \n                        alpha = .1)) + \n    geom_point()\n\n\n\n\n\n\n\nEjercicios\nUsando como base el plot siguiente (GDP x población):\nggplot(gapminder, aes(gdpPercap, pop)) + \n    geom_point()\n¿Podrías hacer lo siguiente?:\n\nColorear los puntos por continente\nTamaño del punto 4\nAlpha 0.5\n\n\n\n\n\n\n\n\n\nCada uno de los siguientes gráficos tiene un error. ¿Sabrías corregirlos?\n\nggplot(gapminder, aes(gdpPercap, pop), color = continent) + \n    geom_point(size = 4, alpha = .5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\ncolor = continent debe ir dentro de aes()\n\n\n\n\nggplot(gapminder, aes(gdpPercap, pop, color = \"blue\")) + \n    geom_point(size = 4, alpha = .5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\ncolor = “blue” debe ir fuera de aes()\n\n\n\n\n\n2.2.3.3 Shape\n\n\n\n\n\n\nCódigos para las distintas formas\n\n\n\n\n\nSOURCE: https://r4ds.had.co.nz/data-visualisation.html#aesthetic-mappings\n\n\n\nEn este ejemplo usamos la variable continent para asignar una forma diferente a cada uno de los continentes.\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, shape = continent)) + \n    geom_point() \n\n\n\n\n\n\n\n\n2.2.3.4 Linetype\n\n\n\n\n\n\nCódigos para los distintos estilos de linea\n\n\n\n\n\nSOURCE: http://sape.inf.usi.ch/quick-reference/ggplot2/linetype\n\n\n\nPodemos definir directamente el tipo de línea que queremos en geom_line():\n\n\n  ggplot(gapminder, aes(year, lifeExp, color = continent)) + \n    stat_summary(fun = mean, geom = \"line\", linetype = \"dashed\")\n\n\n\n\n\n\n\nO que el tipo de línea dependa de una variable:\n\n\n  ggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) + \n    stat_summary(fun = mean, geom = \"line\") \n\n\n\n\n\n\n\n\n2.2.4 Geoms\nUna de las cosas más difíciles cuando nos enfrentamos a nuevos datos es elegir el método más efectivo para visualizarlos. Hay varios recursos interesantes sobre cómo elegir una gráfica. Personalmente, para encontrar inspiración, la r graph gallery me parece un recurso fantástico.\nEn esta sección veremos distintos tipos de geometría, o geoms_().\n\n\n\n\n\n\n\nAlgunos tipos de geoms\n\n\n\nPara una lista exhaustiva ver el manual de ggplot2.\n\n\nSOURCE: https://nbisweden.github.io/RaukR-2019/ggplot/presentation/ggplot_presentation_assets/geoms.png\n\n\n\n\n\n2.2.4.1 geom_point y geom_jitter\nSi queremos un gráfico de dispersión o scatterplot, podemos usar el geom_point()\n\n  ggplot(mpg, aes(displ, hwy)) + \n    geom_point()\n\n\n\n\n\n\n\nEn algunos casos, tenemos muchos puntos que se superponen. Si usamos geom_jitter() la posición de los puntos cambia levemente de manera aleatoria para evitar superposiciones. Con las propiedades ´width´ y ´height´ podemos controlar el desplazamiento horizontal y vertical máximo.\n\n  ggplot(mpg, aes(displ, hwy)) + \n    geom_jitter()\n\n\n\n\n\n\n\n\n2.2.4.2 geom_smooth\nPodemos añadir líneas de tendencia con geom_smooth(). El method por defecto es loess, pero podemos usar otros métodos (e.g. geom_smooth(method = \"lm\") para usar una regresión lineal).\nRecuerda que las funciones que usamos (todo lo que contiene () e.g. geom_smooth()) tienen parámetros, que son instrucciones adicionales que nos permiten modificar como se comportan. Para ver que opciones tenemos, podemos ver la ayuda de las funciones : ?geom_smooth(), o poner el cursor encima y presionar F1 (ayuda).\n\n  \n  # Linea de tendencia (default loess)\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point() +\n    geom_smooth()\n    \n\n\n\n\n\n\n\nUsamos “lm”.\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point() +\n    geom_smooth(method = \"lm\")\n \n\n\n\n\n\n\n\nUn smooth por cada color (continent).\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + \n    geom_point() +\n    geom_smooth()\n \n\n\n\n\n\n\n\nColoreamos puntos pero mantenemos un solo smooth introduciendo el parámetro aes(color = continent) dentro de geom_point().\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point(aes(color = continent)) +\n    geom_smooth()\n\n    \n\n\n\n\n\n\n\nEjercicios\nUsando como base el siguiente plot:\n  ggplot(gapminder, aes(gdpPercap, lifeExp, shape = continent)) + \n    geom_point()\n\nColorea los puntos por continente\nMuestra una línea de tendencia por continente (sin el intervalo de confianza)\nHaz que el tipo de línea cambie por continente\nAñade transparencia a los puntos para que las líneas destaquen\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\n\nparámetro color\n\ngeom geom_smooth, parámetro se\n\nparámetro linetype\n\nparámetro alpha dentro de geom_point\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAhora vamos a usar el data frame mpg. Empieza con este plot:\n\n\nggplot(mpg, aes(displ, hwy)) + \n  geom_point() +\n  theme_grey()\n\n\n\n\n\n\n\nFinalmente, intenta crear los siguientes 6 plots. Te recomiendo avanzar en orden alfabètico.\nPara conseguirlo vamos a tener que usar parámetros como group, color o linetype, pensando muy bien si los tenemos que poner en el aes() general, o en un aes() dentro de geoms específicos:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolución. No me mires hasta haberlo intentado mucho!\n\n\n\n\n\n\n\ngeom geom_smooth, parámetro se\n\n\ngroup = drv dentro de aes()\n\nparámetro color dentro del aes() general\n\nparámetro color dentro del geom\n\nparámetro linetype\n\nx2 geom_point\n\n\n\n\n\n\n\n\n2.2.4.3 geom_boxplot y geom_violin\nPodemos crear diagramas de cajas (boxplots) con geom_boxplot o violines con geom_violin para visualizar como cambian los datos por grupo.\nBoxplot con relleno (parámetro fill).\n\n\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + \n    geom_boxplot(alpha = .2)\n\n\n\n\n\n\n\nLos violin plots nos permiten ver la distribución de los datos. Podemos usar el parámetro draw_quantiles para dibujar quantiles, por ejemplo, el percentil 50 (la mediana). Si queremos mostrar los percentiles 25, 50 y 75, tenemos que usar draw_quantiles = c(.25, .5, .75).\n\n\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + \n    geom_violin(alpha = .2, draw_quantiles = .5)\n\n\n\n\n\n\n\nPodemos combinar geom_violin con geom_jitter para mostrar las observaciones individuales. Si usamos height = 0 y width = .2, los puntos mostraran el valor exacto de lifeExp, y se dispersarán algo en el eje horizontal.\n\n\n  ggplot(gapminder, aes(continent, lifeExp)) + \n    geom_violin(alpha = .2, aes(fill = continent), draw_quantiles = .5) +\n    geom_jitter(alpha = .1, height = 0, width = .2)\n\n\n\n\n\n\n\n\n2.2.4.4 geom_histogram y geom_bar\nCuando queremos visualizar la distribución de variables continuas, podemos usar histogramas (geom_histogram()). Como puedes ver, ahora solo le pasamos una variable a aes() (el eje y muestra el número de observaciones, y es calculado por ggplot).\n\n  ggplot(gapminder, aes(lifeExp)) + \n    geom_histogram()\n\n\n\n\n\n\n\nSi tenemos variables categóricas, usamos geom_bar(). Podemos usar guides(fill = \"none\") para que desaparezca la leyenda asociada al color, porque los nombres de cada categoría ya aparecen en el eje x:\n\n  ggplot(gapminder, aes(continent, fill = continent)) +\n    geom_bar(alpha = .6) +\n    guides(fill = \"none\")\n\n\n\n\n\n\n\n\n2.2.4.5 geom_density\nPara visualizar distribuciones cuando tenemos muchos datos, podemos usar geom_density(). Eso sí, recuerda que con pocos datos, los gráficos de densidad nos dan una falsa seguridad sobre la forma de nuestra distribución.\nUsamos el parámetro alpha = .2 para añadir transparencia y ver todas las distribuciones. Puedes probar cambiando su valor a 1, para ver que ocurre (alpha puede tener valores de 0 a 1).\n\n  ggplot(gapminder, aes(lifeExp, fill = continent)) + \n      geom_density(alpha = .2)\n\n\n\n\n\n\n\nEjercicio\nAñadiendo un parámetro a la gráfica de arriba, podemos transformarla en las versiones de abajo. ¿Podrías hacerlo? (recuerda que poniéndote encima de geom_density() y tecleando F1 puedes ver la ayuda de la función).\nggplot(gapminder, aes(lifeExp, fill = continent)) + \n      geom_density(alpha = .2)\n\n\n\n\n\n\nSolución\n\n\n\n\n\nposition = \"stack\" y position = \"fill\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.4.6 geom_density_ridges\nUno de mis geoms favoritos para comparar distribuciones es geom_density_ridges:\n\n  ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + \n    ggridges::geom_density_ridges(alpha = .2)\n\n\n\n\n\n\n\nEspecialmente porque podemos incluir en el mismo gráfico información sobre distribuciones y puntos individuales.\n\nggplot(gapminder, aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.7,\n    scale = 0.9,\n    quantile_lines = TRUE,\n    quantile_fun = mean\n  ) +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(n.breaks = 10) +\n  labs(caption = \"vertical lines represent the mean lifeExp per continent\")\n\n\n\n\n\n\n\nEjercicios\nUsando como base el plot de la sección geom_histogram():\n  ggplot(gapminder, aes(lifeExp)) + \n    geom_histogram()\n\nColorea los histogramas por continente\nSabrías hacer que no se amontonen unos continentes sobre otros? Necesitarás añadir transparencia para ver todos los datos\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\ngeom_histogram(position = \"identity\", alpha = .3).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.5 Personalización básica\nUna gráfica necesita elementos como el título, ejes con nombres informativos, etc. Usaremos la función labs() para incluir o editar lo siguiente:\n\n\ntitle: título de la gráfica\n\n\nsubtitle: subtítulo\n\n\ncaption: pie de gráfica (abajo a la derecha)\n\n\ntag: etiqueta de la gráfica (arriba a la izquierda)\n\n\nx: eje horizontal\n\n\ny: eje vertical\n\n\nfill: título de leyenda si se usa el parámetro fill\n\n\ncolor: título de leyenda si se usa el parámetro color\n\n\nalt: alt-text, importante para que los lectores de pantalla usados por personas ciegas describan las gráficas\n\nEn el siguiente ejemplo, vamos a personalizar la gráfica del ejercicio anterior:\n\nggplot(gapminder, aes(lifeExp, fill = continent)) + \n  geom_histogram(position = \"identity\", alpha = .3) +\n  labs(title = \"Distribution of life expectancy\",\n       subtitle = \"by continent\", \n       caption = \"Source, the gapminder dataset\",\n       tag = \"a)\",\n       x = \"Life expectancy (in years)\",\n       y = \"Number of observations (countries, years)\", \n       fill = \"Continent\",\n       alt = \"Alt text for the plot. Very useful for blind people\"\n       )\n\n\n\n\n\n\n\nEjercicio\nUsando como base este plot:\n\n   ggplot(mpg, aes(displ, hwy)) + \n    geom_point() +\n    geom_smooth(se = FALSE) +\n    theme_grey()\n\n\n\n\n\n\n\nPersonalízalo añadiendo y modificando:\n\ntítulo\n\nsubtítulo\n\ncaption\n\nejes x e y\n\nPara conseguir esto:\n\n\n\n\n\n\n\n\n\nCon lo que hemos visto en este capítulo, podrás crear una gran cantidad de gráficas. En el siguiente capítulo veremos algunas funcionalidades más avanzadas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la visualización de datos</span>"
    ]
  },
  {
    "objectID": "qmd/02-visualizacion-basica.html#bibliografía",
    "href": "qmd/02-visualizacion-basica.html#bibliografía",
    "title": "\n2  Introducción a la visualización de datos\n",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nMatejka, J., & Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM.\nhttps://bbc.github.io/rcookbook/\nhttps://github.com/bbc/bbplot\nhttps://github.com/dreamRs/esquisse\nGarrick Aden-Buie. A Gentle Guide to the Grammar of Graphics with ggplot2: https://github.com/gadenbuie/gentle-ggplot2\nMichael Toth. You Need to Start Branding Your Graphs. Here’s How, with ggplot!: https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html\nClaus Wilke: https://wilkelab.org/practicalgg/\n\nThomas Lin Pedersen:\n\nPart 1: https://www.youtube.com/watch?v=h29g21z0a68\nPart 2: https://www.youtube.com/watch?v=0m4yywqNPVY\n\n\nBig Book or R : https://www.bigbookofr.com/index.html",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introducción a la visualización de datos</span>"
    ]
  },
  {
    "objectID": "qmd/03-visualizacion-avanzada.html",
    "href": "qmd/03-visualizacion-avanzada.html",
    "title": "\n3  Visualización avanzada\n",
    "section": "",
    "text": "3.1 Facets\nCuando queremos separar en gráficos independientes distintas categorías dentro de nuestros datos, podemos usar facetas. Hay dos funciones para esto, facet_grid() y facet_wrap().",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización avanzada</span>"
    ]
  },
  {
    "objectID": "qmd/03-visualizacion-avanzada.html#facets",
    "href": "qmd/03-visualizacion-avanzada.html#facets",
    "title": "\n3  Visualización avanzada\n",
    "section": "",
    "text": "3.1.1 facet_grid\nfacet_grid(~ variable) nos devuelve una matriz simétrica de gráficas.\n\n \n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n    geom_point(alpha = .2)\n\n\n\n\n\n\n\nUn gráfico para cada continente. Verás que usamos guides(color = \"none\") para que no se vea la leyenda asociada a color. Prueba ejecutar este código con y sin la última línea para ver la diferencia.\n\n \n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n    geom_point(alpha = .2) +\n    facet_grid(~ continent) +\n    guides(color = \"none\")\n\n\n\n\n\n\n\nCambiamos los ejes.\n\n \n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n    geom_point(alpha = .2) +\n    facet_grid(continent ~ .) +\n    guides(color = \"none\")\n  \n\n\n\n\n\n\n\nPodemos añadir una segunda variable (categórica) para tener un gráfico para cada combinación de categorias.\nUn truco muy útil es dicotomizar variables usando condiciones lógicas (e.g. pop &gt; 5000000).\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = country)) +\n    geom_point(alpha = .2) +\n    facet_grid(continent ~ pop &gt; 5000000) + \n    guides(color = \"none\")\n\n\n\n\n\n\n\nSi queremos usar nombres con significado, podemos usar la función ifelse().\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = country)) +\n    geom_point(alpha = .2) +\n    facet_grid(continent ~ ifelse(pop &gt; 5000000, \"Big countries\", \"Small countries\")) + \n    guides(color = \"none\")\n\n\n\n\n\n\n\n\n3.1.2 facet_wrap\nfacet_wrap(~ variable) nos devuelve tantas facetas como niveles de la variable, pudiendo definir el número de filas y columnas que queremos.\n\n  ggplot(gapminder, aes(lifeExp, fill = continent)) +\n    geom_histogram(alpha = .5)\n\n\n\n\n\n\n\nFacetas por continente (en 2 columnas con ncol = 2).\n\n  ggplot(gapminder, aes(lifeExp, fill = continent)) +\n    geom_histogram(alpha = .5) +\n    facet_wrap( ~ continent, ncol = 2) +\n    guides(fill = \"none\")\n\n\n\n\n\n\n\n\n3.1.3 gghighlight con facetas\nCon la función gghighlight() del paquete gghighlight podemos añadir una capa para facilitar la comparación de cada faceta con los datos completos.\n\n\nggplot(gapminder, aes(lifeExp, fill = continent)) +\n  geom_histogram(alpha = .5) +\n  facet_wrap( ~ continent, nrow = 1) +\n  guides(color = \"none\") +\n  gghighlight::gghighlight()\n\n\n\n\n\n\n\nEjercicios\nUsando como base el plot siguiente:\nggplot(mpg, aes(displ, hwy)) +\n  geom_point()\n\nCrea un panel para cada tipo de coche (class) en una rejilla simétrica\nCrea un panel para cada tipo de coche (class), mostrando paneles en 3 filas\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nfacet_grid() permite crear rejillas simétricas de paneles, y el parámetro nrow de facet_wrap() nos ayuda con paneles con números de filas definidos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización avanzada</span>"
    ]
  },
  {
    "objectID": "qmd/03-visualizacion-avanzada.html#transformaciones-estadísticas",
    "href": "qmd/03-visualizacion-avanzada.html#transformaciones-estadísticas",
    "title": "\n3  Visualización avanzada\n",
    "section": "\n3.2 Transformaciones estadísticas",
    "text": "3.2 Transformaciones estadísticas\nggplot2 nos permite hacer transformaciones estadísticas al crear los gráficos. Vamos a ver algunos ejemplos aquí, pero se pueden hacer muchas más cosas. Para más detalles, ver r4ds.\n\n3.2.1 Computaciones con ggplot: stat_summary()\nEn ocasiones queremos visualizar estadísticas descriptivas asociadas a los datos (e.g. promedio, mínimo y máximo por condición), pero como generalmente trabajaremos con data frames en formato long (una observación por fila), no podremos usar los geoms que hemos visto hasta ahora.\nTenemos dos opciones, la primera es preparar nuevos data frames antes de pasar a la visualización. La segunda, realizar la computación directamente con ggplot, usando stat_summary() junto con alguna de las funciones tradicionales para extraer estadísticas descriptivas.\n\n\n\n\n\n\nEjemplos de funciones que podemos usar en los gráficos\n\n\n\n\n\nmin(): mínimo\n\nmax(): máximo\n\nmean(): media\n\nmedian(): mediana\n\nsd(): desviación estándar\n\n\n\nCon stat_summary() podemos usar funciones simples de manera directa. Por ejemplo, si queremos visualizar la mediana de lifeExp para cada continente, podemos hacer lo siguiente:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\n  stat_summary(fun = median) +\n  labs(caption = \"Mediana\")\n\n\n\n\n\n\n\nstat_summary() tiene un buen número de parámetros (F1 sobre la función para ver la ayuda). Por ejemplo, fun.min y fun.max nos permitirán añadir a la gráfica anterior el rango completo de los datos:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\n  stat_summary(\n    fun = median,\n    fun.min = min,\n    fun.max = max\n    ) +\n  labs(caption = \"Mediana y rango (mínimo/máximo) de los datos\")\n\n\n\n\n\n\n\n\nSi queremos usar funciones algo más complejas, la sintaxis es diferente. En este caso mostramos media ± desviación estándar:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\n  stat_summary(\n    fun = median,\n    fun.min = function(x) median(x) - sd(x),\n    fun.max = function(x) median(x) + sd(x)\n    ) +\nlabs(caption = \"Mediana más/menos desviación estándar\")\n\n\n\n\n\n\n\n\n3.2.2 Promedios por grupo\nLo interesante es que podemos añadir estas transformaciones estadísticas como una capa más en los gráficos. Esto es ideal para mostrar los puntos individuales de nuestros datos, algo crítico como vimos en el tema anterior. Así que, a este gráfico inicial…\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\ngeom_jitter()\n\n\n\n\n\n\n\nLe podemos añadir un punto mostrando la mediana por grupo:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\ngeom_jitter() +\nstat_summary(fun = median,\n             geom = \"point\",\n             color = \"red\", size = 3, alpha = .7)\n\n\n\n\n\n\n\nO la mediana más la desviación estándar:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\ngeom_jitter() +\nstat_summary(fun = median,\n             color = \"red\", size = .5, alpha = .7,\n             fun.min = function(x) median(x) - sd(x),\n             fun.max = function(x) median(x) + sd(x))\n\n\n\n\n\n\n\nEjercicios\nCuando al plot A trato de añadirle líneas para cada class, me aparece algo como lo de B, porque tenemos varios puntos en cada nivel de displ.\n\nplotA = ggplot(mpg, aes(displ, hwy, color = class)) +\n  geom_point() +\n  theme(legend.position = \"bottom\")\n\nplotB = ggplot(mpg, aes(displ, hwy, color = class)) +\n  geom_point() +\n  geom_line() +\n  theme(legend.position = \"bottom\")\n\ncowplot::plot_grid(plotA, plotB, labels = c(\"A\", \"B\"))\n\n\n\n\n\n\n\nPero en realidad no quiero que las líneas pasen por todos los puntos, sino que muestren el promedio en cada nivel de displ para cada class de vehículo.\n\n¿Podrías reproducir el gráfico de abajo?\n\n\n\n\n\n\n\nPista\n\n\n\n\n\nTendrás que reemplazar geom_line() por stat_summary(), usando el parámetro geom = \"line\" para indicarle que quieres usar lineas en lugar de puntos.\n\n\n\n\n\n\n\n\n\n\n\n\nUsando como base:\n\nggplot(gapminder, aes(country, lifeExp, color = continent)) +\n  stat_summary(...) +\n  facet_grid(...) +\n  theme(axis.text.x = element_blank(), # Eliminamos etiquetas de nombres de paises del eje x\n        legend.position = \"none\") # Elimina la leyenda\n\n¿Podrías crear este gráfico? Mostramos mediana ± sd para cada país, organizado por continente.\n\n\n\n\n\n\nPista\n\n\n\n\n\nTienes que encontrar los parámetros adecuados para stat_summary() y facet_grid(). Puedes ver ejemplos en:  - computaciones con ggplot: stat_summary()  - Facet_grid.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización avanzada</span>"
    ]
  },
  {
    "objectID": "qmd/03-visualizacion-avanzada.html#personalización-avanzada-de-gráficas",
    "href": "qmd/03-visualizacion-avanzada.html#personalización-avanzada-de-gráficas",
    "title": "\n3  Visualización avanzada\n",
    "section": "\n3.3 Personalización avanzada de gráficas",
    "text": "3.3 Personalización avanzada de gráficas\nHabitualmente, un vez hemos creado la gráfica, querremos personalizar varias cosas, como las escalas, colores, estilos, título, etc.\n\n3.3.1 Coordenadas\nGráfico inicial:\n\n\nggplot(gapminder, aes(continent)) +\n    geom_bar()\n\n\n\n\n\n\n\nUsamos coord_flip() para rotar las coordenadas:\n\n\nggplot(gapminder, aes(continent)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\nO coord_polar() para usar el sistema de coordenadas polar (360º):\n\n\nggplot(gapminder, aes(continent)) +\n  geom_bar() +\n  coord_polar()\n\n\n\n\n\n\n\n\n3.3.2 Scales\nUsaremos las funciones que empiezan por scale_ para multitud de cosas, por ejemplo, cambiar las etiquetas de los ejes x o y:\n\n# Gráfico inicial\nplot_base = ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point(alpha = .1)\nplot_base\n\n\n\n\n\n\n\nDefinimos cuantos breaks queremos en cada eje, y rotamos las etiquetas del eje x:\n\nplot_base +\n  scale_x_continuous(n.breaks = 15, guide = guide_axis(angle = 90)) +\n  scale_y_continuous(n.breaks = 15)\n\n\n\n\n\n\n\nSeparador de miles y breaks en x:\n\n\nplot_base +\n  scale_y_continuous(n.breaks = 15) +\n  scale_x_continuous(n.breaks = 6, labels = scales::comma)\n\n\n\n\n\n\n\nCon scales::dollar_format() le damos formato de $ ($M)\n\n\nplot_base +\n  scale_y_continuous(n.breaks = 15) +\n  scale_x_continuous(n.breaks = 6, \n                     labels = scales::dollar_format(\n                       prefix = \"$\", \n                       suffix = \"M\")\n                     )\n\n\n\n\n\n\n\nEscala logarítmica. Muy útil para mostrar crecimiento exponencial:\n\nplot_base +\n  scale_y_continuous(n.breaks = 15) +\n  scale_x_log10(n.breaks = 4, \n                labels = scales::dollar_format(\n                  prefix = \"$\",\n                  suffix = \"M\")\n                )\n\n\n\n\n\n\n\nInvertimos escala:\n\nplot_base +\n  scale_y_reverse()\n\n\n\n\n\n\n\nNo mostramos el texto ni los ticks de los breaks de x:\n\nplot_base +\n  scale_y_reverse() +\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n\n\n\n\n\n\nPorcentaje:\n\nggplot(gapminder, aes(continent, after_stat(prop), group = 1)) +\n  geom_bar() +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\n3.3.3 Legends\nLa leyenda de las gráficas nos muestra, por defecto, los colores, rellenos, tipos de linea, etc. que hayamos usado. Por ejemplo, abajo nos muestra la leyenda asociada al color.\n\n\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter()\n\n\n\n\n\n\n\nPodemos hacer algunas cosas básicas como cambiar el nombre de la leyenda, o no mostrarla.\nPor ejemplo, usamos labs(color = \"\") o labs(fill = \"\") para cambiar el título de las leyendas asociadas a colores o rellenos:\n\n\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter() +\n  labs(color = \"My new legend\")\n\n\n\n\n\n\n\nPor otro lado, con guides(color = \"none\") hacemos desaparecer la leyenda asociada al color:\n\n\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter() +\n  guides(color = \"none\")\n\n\n\n\n\n\n\nCon theme(legend.position = \"none\") hacemos desaparecer la leyenda completa:\n\n\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nO también podemos definir una nueva ubicación para nuestra leyenda. Con theme(legend.position = \"bottom\") movemos la leyenda abajo:\n\n\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n3.3.3.1 Fancy pants legends\nEn ocasiones podemos simplificar notablemente las gráficas reemplazando la leyenda clásica por algo más moderno.\nPodemos usar el eje secundario (derecho) para mostrar etiquetas. Partimos del gráfico siguiente:\n\nggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) +\n  stat_summary(fun = mean, geom = \"line\")\n\n\n\n\n\n\n\nUsando un poco de vodoo, podemos convertirlo en esto:\n\n\ngapminder_last = gapminder |&gt;\n  group_by(continent) |&gt;\n  filter(year == max(year)) |&gt;\n  summarize(lifeExp = mean(lifeExp))\n\nggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) +\n  stat_summary(fun = mean, geom = \"line\") +\n  scale_y_continuous(\n    limits = c(0, max(gapminder$lifeExp)),\n    expand = c(0,0),\n    sec.axis = dup_axis(\n      breaks = gapminder_last$lifeExp,\n      labels = gapminder_last$continent,\n      name = NULL)) +\n  scale_x_continuous(expand = c(0,0)) +\n  guides(color = \"none\",\n         linetype = \"none\")\n\n\n\n\n\n\n\nOtra estrategia interesante es colocar las etiquetas en el camino de las líneas. Para ello, necesitaremos la función geom_labelsmooth() del paquete {geomtextpath}:\n\n\nggplot(gapminder,\n       aes(year, lifeExp, linetype = continent, color = continent)) +\n  \n  geomtextpath::geom_labelsmooth(\n    aes(label = continent),\n    text_smoothing = 30,\n    method = \"loess\",\n    formula = y ~ x,\n    size = 3,\n    linewidth = 1,\n    boxlinewidth = 0.3\n  ) +\n  \n  scale_x_continuous(expand = c(0, 0)) +\n  guides(color = \"none\",\n         linetype = \"none\")\n\n\n\n\n\n\n\nEjercicio\nEl plot del panel (A) tiene varios problemas:\n\nlos casos no se muestran con un separador de miles\nla leyenda esta a la derecha ocupado un espacio precioso, debería estar abajo\nal gráfico le falta el título, y caption\nla etiqueta del eje x debería ser year en lugar de as.factor(year)\n\n\nUsando el plot base (A):\nggplot(table1, aes(as.factor(year), cases)) + # Usamos as.factor(year) para evitar que se muestren decimales\n  geom_line(aes(group = country), colour = \"grey50\") +\n  geom_point(aes(colour = country)) +\n  scale_x_discrete(expand = c(.05, 0)) # Movemos las etiquetas del eje x hacia los extremos\nTrata de resolver los problemas e intenta llegar al resultado que se ve en el panel (B).\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- Recuerda la funciónscales::comma() que vimos más arriba - theme(legend.position = \"ALGO AQUI\") nos permite mover la leyenda. Si vas la ayuda de theme() y buscas legend.position, encontrarás sus opciones. - Los parámetros de labs() nos permiten añadir títulos, subtítulos, editar los valores de las etiquetas de x e y, añadir caption, etc. \n\n\n\n\n\n\n\n\n\n\n\nSi te sobra tiempo, puedes tratar de reproducir la siguiente versión mejorada…\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\nHemos visto como hacer esto en el primer ejemplo de fancy pants legends \n\n\n\n\n\n\n\n\n\n\n\n\n3.3.4 Colors and fill scales\nLas funciones scale_color_, scale_fill_ nos sirven para hacer cambios globales en los colores o rellenos de las gráficas. Algunos ejemplos:\nPlot inicial:\n\n  # Plot inicial\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) +\n    geom_violin(alpha = .2)\n\n\n\n\n\n\n\nPodemos usar diferentes paletas de colores preexistentes. Una manera de consultar las paletas disponibles es con RColorBrewer::display.brewer.all():\n\n\n  RColorBrewer::display.brewer.all(n = 3, \n                                   type = \"seq\", # Colores secuenciales\n                                   exact.n = FALSE, \n                                   colorblindFriendly = TRUE)\n\n\n\n\n\n\n\nPodemos ver que el parámetro type nos permite seleccionar paletas secuenciales, divergentes y cualitativas. Por ejemplo, type = \"qual\" nos mostrará colores de paletas cualitativas.\nUna vez elegía nuestra paleta, la podemos aplicar con scale_fill_brewer() para fill o con scale_color_brewer_brewer() para color. En este caso usamos la palette = \"Blues\":\n\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) +\n    geom_violin(alpha = .2) +\n    scale_fill_brewer(palette = \"Blues\")\n\n\n\n\n\n\n\nUsamos scale_color_grey() para estala de grises:\n\n  ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) +\n    geom_point() +\n    scale_color_grey(start = 0.2, end = 0.8, na.value = \"red\")\n\n\n\n\n\n\n\nscale_color_gradient() para gradientes:\n\n  ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) +\n    geom_point() +\n    scale_color_gradient(low = \"red\", high = \"blue\")\n\n\n\n\n\n\n\nO scale_colour_gradientn() con un número predeterminado de colores definido por la paleta terrain.colors():\n\n  # Gradient con un numero predefinidos de una paleta\n  ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) +\n    geom_point() +\n    scale_colour_gradientn(colours = terrain.colors(3))\n\n\n\n\n\n\n\nEjercicio\n\nUsando como base este plot, podrías cambiarle la paleta de color para usar una de las paletas cualitativas?\n\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\nVer parámetro type de la ayuda de scale_fill_brewer() \n\n\n\n\n\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) +\n    geom_violin(alpha = .2) +\n    scale_fill_brewer(palette = \"Blues\")\n\n\n\n\n\n\n\nEl gráfico final debería verse así:\n\n\n\n\n\n\n\n\n\nAhora, usando el gráfico de abajo como base, puedes asignar manualmente colores a los continentes?\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n    geom_point() \n\n\n\n\n\n\n\nUn ejemplo de resultado posible es este:\n\n\n\n\n\n\n\n\nNuestra primera idea podría ser asignar colores directamente dentro de geom_point() tal y como se ve abajo. Pero si intentamos asignar colores manualmente a los continentes de este modo, recibimos un error:\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) +\n    geom_point(color = c(\"red\", \"grey\", \"green\", \"purple\", \"black\"))\n  #  Aesthetics must be either length 1 or the same as the data (1704)\n  # ✖ Fix the following mappings: `colour`\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\nTenemos que:\n\nindicar que el color depende de continent dentro de aes()\nusar scale_color_manual(), con el parámetro values para asignar los colores (values = c(\"green\", \"blue\", ...); ver ejemplos en la ayuda de la función) \n\n\n\n\n\n3.3.5 Combinando gráficas\nCon {cowplot} podemos combinar gráficas de manera muy simple. Otro paquete muy interesante es {patchwork}.\n\n\nplot1 = ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point(alpha = .1) +\n  scale_y_continuous(breaks = seq(0, 100, 5)) +\n  scale_x_log10(labels = scales::dollar_format(prefix = \"$\", suffix = \"M\")) +\n  theme(legend.position = \"top\")\n\nplot2 = ggplot(gapminder, aes(continent, ..prop.., group = 1)) +\n  geom_bar() +\n  scale_y_continuous(labels = scales::percent) +\n  coord_flip()\n\ncowplot::plot_grid(plot2, plot1, rel_widths = c(.3, 0.7))\n\n\n\n\n\n\n\nEjercicio\n\nCombina los dos plots del ejercicio anterior, con las siguientes modificaciones:\n\n\nElimina las leyendas asociadas a colores y rellenos\nUsa la paleta “Accent” para los colores y rellenos\n\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- guides(fill = “none”) quita la leyenda asociada a fill… - scale_fill_brewer(palette = “Accent”) asigna la paleta “Accent” a los rellenos (fill)\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.5.1 Combinando múltiples gráficas\nPodemos combinar múltiples gráficas y llegar a hacer cosas mucho más complejas como combinar un scatteplot con un par de histogramas:\n\n\n# Set up scatterplot\nscatterplot &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) +\n  geom_point(size = 3, alpha = 0.6) +\n  guides(color = \"none\") +\n  theme(plot.margin = margin())\n\n\n# Define marginal histogram\nmarginal_distribution &lt;- function(x, var, group) {\n  ggplot(x, aes_string(x = var, fill = group)) +\n    geom_histogram(bins = 30, alpha = 0.4, position = \"identity\") +\n    # geom_density(alpha = 0.4, size = 0.1) +\n    guides(fill = \"none\") +\n    theme_void() +\n    theme(plot.margin = margin())\n}\n\n# Set up marginal histograms\nx_hist &lt;- marginal_distribution(iris, \"Sepal.Length\", \"Species\")\ny_hist &lt;- marginal_distribution(iris, \"Sepal.Width\", \"Species\") +\n  coord_flip()\n\n# Align histograms with scatterplot\naligned_x_hist &lt;- align_plots(x_hist, scatterplot, align = \"v\")[[1]]\naligned_y_hist &lt;- align_plots(y_hist, scatterplot, align = \"h\")[[1]]\n\n\n# Arrange plots\ncowplot::plot_grid(\n  aligned_x_hist, NULL, scatterplot, aligned_y_hist,\n  ncol = 2, nrow = 2,\n  rel_heights = c(0.2, 1), rel_widths = c(1, 0.2)\n  )\n\n\n\n\n\n\n\n\n3.3.6 Estilos\nLos estilos nos permiten personalizar los gráficos de manera muy sencilla, por ejemplo, usando {ggtheme}. Podéis ver un tutorial aquí.\nPrimero creamos un gráfico sobre el que aplicaremos estilos.\n\n\np &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) +\n  geom_point() +\n  labs(title = 'A ggplot simple graph',\n       subtitle = 'Simple tweaks to improve plots, or not',\n       x = '',\n       y = '',\n       caption = 'https://github.com/gorkang / @gorkang') +\n    theme_gray() # This is the default. Needed here because of the Bookdown theme\n\np\n\n\n\n\n\n\n\nUsando el tema fivethirtyeight:\n\n\np +\n  ggthemes::scale_color_fivethirtyeight() +\n  ggthemes::theme_fivethirtyeight(base_size = 10)\n\n\n\n\n\n\n\nUsando el tema economist:\n\n\np +\n  ggthemes::scale_color_economist() +\n  ggthemes::theme_economist(base_size = 10)\n\n\n\n\n\n\n\nEjercicios\n\nSerías capaz de reproducir este gráfico, usando el data frame diamonds y el theme_economist?\n\nGráfica inicial (verás que parecen datos distintos! Si te fijas bien en el eje x de la gráfica que queremos conseguir, entenderás porque):\nggplot(diamonds, aes(price, cut, fill = cut, color = cut, group = cut)) +\n  ggridges::geom_density_ridges(alpha = .6)\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- scale_x_log10() nos permite transformar el eje x a una escala logarítmica - Hay que aplicar un ggthemes::scale_* para cada elemento: color, fill… \n\n\n\n\n\n\n\n\n\n\n\n\n\nSerías capaz de reproducir este gráfico, usando el data frame gapminder y la paleta Accent?\n\nGráfica inicial:\nggplot(gapminder, aes(gdpPercap, continent, fill = continent, color = continent)) +\n  ggridges::geom_density_ridges(alpha = .6)\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- scales::dollar_format() aplicado al parámetro labels de las funciones scale_x_* nos permite darle formato de moneda a las etiquetas de la escala x\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.7 Estilos en textos\nCon {ggtext} podemos incluir estilos en los textos, por ejemplo, en el título de nuestras gráficas.\n\n\n# Ejemplo adaptado de https://wilkelab.org/ggtext/articles/theme_elements.html\nmtcars |&gt;\n  mutate(\n    transmission = ifelse(am == 1, \"automatic\", \"manual\")\n  ) |&gt;\n  ggplot(aes(hp, mpg, color = transmission)) +\n  geom_point(size = 2) +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  scale_color_manual(\n    values = c(automatic = \"#0072B2\", manual = \"#D55E00\"),\n    guide = \"none\"\n  ) +\n  labs(\n    x = \"Horse power\",\n    y = \"Miles per gallon (MPG)\",\n    title = \"Transmission type impacts fuel efficiency\",\n    subtitle = \"MPG is higher for &lt;span style = 'color:#0072B2;'&gt;automatic&lt;/span&gt;\n            than for &lt;span style = 'color:#D55E00;'&gt;manual&lt;/span&gt; transmissions\"\n\n  ) +\n  theme_minimal() +\n  theme(\n    # plot.title.position = \"plot\",\n    plot.subtitle = element_markdown(size = 11, lineheight = 1.2)\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización avanzada</span>"
    ]
  },
  {
    "objectID": "qmd/03-visualizacion-avanzada.html#otras-gráficas",
    "href": "qmd/03-visualizacion-avanzada.html#otras-gráficas",
    "title": "\n3  Visualización avanzada\n",
    "section": "\n3.4 Otras gráficas",
    "text": "3.4 Otras gráficas\n\n3.4.1 Raincloud plots\nUn tipo de gráfica genial para mostrar simultáneamente observaciones individuales, distribuciones, y cambios, es el raincloudplot.\nSe pueden mostrar las distribuciones para todas las variables numéricas de una base de datos.\n\ngapminder |&gt; \n  select(where(is.numeric)) |&gt; \n  pivot_longer(everything()) |&gt; \n  ggplot(aes(name, value, fill = name)) +\n  ggrain::geom_rain(alpha = .5) +\n  theme_minimal(base_size = 10) +\n  guides(fill = 'none', color = 'none') +\n  facet_wrap(~ name, scales = \"free\") +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\nO la relación entre dos condiciones, momentos, etc.\n\n\ngapminder_min_max = gapminder |&gt; filter(year == max(year) | year == min(year)) |&gt; mutate(year = as.factor(year))\n\ngapminder_min_max |&gt; \n  ggplot(aes(year, lifeExp, fill = year, color = year)) +\n  geom_rain(alpha = .6, rain.side = 'f1x1', id.long.var = \"country\", line.args = list(color = \"lightgrey\")) +\n  theme_classic() +\n  scale_fill_manual(values=c(\"dodgerblue\", \"darkorange\")) +\n  scale_color_manual(values=c(\"dodgerblue\", \"darkorange\")) +\n  guides(fill = 'none', color = 'none')\n\n\n\n\n\n\n\n\n3.4.2 Visualización interactiva\nEl paquete {plotly} nos permite crear gráficas con algunos niveles de interactividad usando funciones propias, o modificando gráficas creadas con ggplot.\n\n3.4.2.1 ggplots interactivos con plotly\nScatterplot creado con ggplot donde se puede ver el valor de los puntos, seleccionar áreas, etc.\n\n\nplotly::ggplotly(\n  ggplot(\n    gapminder |&gt; filter(year == 2007),\n    aes(gdpPercap, lifeExp, color = continent, size = country)\n  ) +\n    geom_point(alpha = .3, point = 2) +\n    scale_y_continuous(breaks = seq(0, 100, 5)) +\n    scale_x_log10(labels = scales::dollar_format(prefix = \"$\", suffix = \"M\")) +\n    theme(legend.position = \"none\")\n)\n\n\n\n\n\n\n3.4.3 Surface plots con plotly\nSurface plot creado con plotly donde se muestra la relación entre 3 variables en un entorno interactivo 3D.\n\n\nDF_RAW = structure(c(181, 163, 60, 124, 76, 62, 73, 59, 17, 21, 26, 7, 1, 2, 3,\n                     188, 145, 61, 130, 61, 59, 62, 57, 20, 22, 22, 6, 4, 5, 5,\n                     137, 154, 54, 191, 75, 56, 65, 56, 22, 27, 33, 14, 5, 5, 5,\n                     126, 185, 65, 109, 51, 71, 57, 38, 25, 23, 21, 10, 5, 5, 5,\n                     150, 144, 44, 123, 58, 24, 48, 41, 19, 26, 21, 5, 5, 5, 5,\n                     138, 137, 61, 130, 67, 34, 60, 44, 19, 21, 16, 4, 5, 5, 5,\n                     121, 146, 101, 92, 70, 74, 88, 33, 18, 39, 24, 12, 5, 5, 5,\n                     100, 160, 129, 117, 70, 61, 42, 35, 22, 25, 21, 7, 10, 23, 8,\n                     100, 129, 130, 107, 64, 61, 44, 25, 23, 30, 18, 11, 20, 58, 40,\n                     100, 136, 131, 96, 53, 31, 51, 37, 43, 31, 19, 2, 22, 40, 41,\n                     100, 124, 154, 74, 62, 44, 34, 15, 26, 23, 20, 6, 23, 10, 19,\n                     100, 126, 251, 76, 73, 84, 47, 40, 32, 25, 32, 6, 13, 10, 13,\n                     100, 129, 194, 91, 53, 99, 46, 34, 60, 21, 17, 6, 14, 14, 26,\n                     100, 115, 119, 88, 64, 108, 37, 24, 49, 26, 17, 6, 15, 15, 47),\n                   .Dim = 15:14,\n                   .Dimnames = list(c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \n                                      \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"),\n                                    c(\"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \n                                      \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \n                                      \"2016\", \"2017\", \"2018\", \"2019\")))\n\nDF = DF_RAW\nplot1 = plotly::plot_ly(x = ~ colnames(DF),\n                        y = ~ rownames(DF),\n                        z = ~ DF) |&gt;\n  plotly::add_surface(\n    name = \"3D mesh\",\n    connectgaps = TRUE,\n    hidesurface = TRUE,\n    showscale = FALSE,\n    contours = list(\n      x = list(\n        show = TRUE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      y = list(\n        show = TRUE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      z = list(\n        show = FALSE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = FALSE\n      )\n    )\n  ) |&gt;\n  plotly::add_surface(\n    name = \"surface\",\n    connectgaps = FALSE,\n    contours = list(\n      x = list(\n        show = F,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      y = list(\n        show = F,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      z = list(\n        show = FALSE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = FALSE\n      )\n    )\n  )\n\nif (!knitr::is_latex_output()) plot1\n\n\n\n\n\n\n3.4.4 Animando gráficas con gganimate\n{gganimate} nos permite crear ggplots añadiendo la dimensión temporal\n\n\nif (!require('gganimate')) remotes::install_github('thomasp85/gganimate'); library('gganimate')\n#sudo apt-get install ffmpeg\n\np = ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10() +\n  facet_wrap(~continent) +\n\n  # Here comes the gganimate specific bits\n  labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') +\n  transition_time(year) +\n  ease_aes('linear')\n\n  # Create animated plot\n  animate(p, renderer = ffmpeg_renderer(), \n          height = 6, width = 10, units = \"in\", res = 300)\n\n  # Save plot\n    # anim_save(\"name_file.mp4\", animation = last_animation())\n\nVideo",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización avanzada</span>"
    ]
  },
  {
    "objectID": "qmd/03-visualizacion-avanzada.html#bibliografía",
    "href": "qmd/03-visualizacion-avanzada.html#bibliografía",
    "title": "\n3  Visualización avanzada\n",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nMatejka, J., & Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM.\nhttps://bbc.github.io/rcookbook/\nhttps://github.com/bbc/bbplot\nhttps://github.com/dreamRs/esquisse\nGarrick Aden-Buie. A Gentle Guide to the Grammar of Graphics with ggplot2: https://github.com/gadenbuie/gentle-ggplot2\nMichael Toth. You Need to Start Branding Your Graphs. Here’s How, with ggplot!: https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html\nClaus Wilke: https://wilkelab.org/practicalgg/\n\nThomas Lin Pedersen:\n\nPart 1: https://www.youtube.com/watch?v=h29g21z0a68\nPart 2: https://www.youtube.com/watch?v=0m4yywqNPVY\n\n\nBig Book or R : https://www.bigbookofr.com/index.html",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Visualización avanzada</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html",
    "href": "qmd/04-preparacion-transformacion.html",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "",
    "text": "Paquetes para este capítulo\nComo en cada capítulo, crea un nuevo script de R (CNTRL+ SHIFT + N), guárdalo con el nombre/número del capítulo (i.e. capitulo4.R), copia y pega las líneas de abajo y ejecútalas.\nif (!require('dplyr')) install.packages('dplyr'); library('dplyr')\nif (!require(\"DT\")) install.packages(\"DT\"); library(\"DT\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\"); library(\"ggplot2\")\nif (!require(\"googlesheets4\")) install.packages(\"googlesheets4\"); library(\"googlesheets4\")\nif (!require(\"haven\")) install.packages(\"haven\"); library(\"haven\")\nif (!require(\"here\")) install.packages(\"here\"); library(\"here\")\nif (!require(\"janitor\")) install.packages(\"janitor\"); library(\"janitor\")\nif (!require(\"purrr\")) install.packages(\"purrr\"); library(\"purrr\")\nif (!require('readr')) install.packages('readr'); library('readr')\nif (!require(\"readxl\")) install.packages(\"readxl\"); library(\"readxl\")\nif (!require(\"readODS\")) install.packages(\"readODS\"); library(\"readODS\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\"); library(\"tidyr\")\nif (!require(\"waldo\")) install.packages(\"waldo\"); library(\"waldo\")\nif (!require(\"writexl\")) install.packages(\"writexl\"); library(\"writexl\")\n\nif (!require('regexplain')) remotes::install_github(\"gadenbuie/regexplain\"); library('regexplain')",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#importar-y-exportar-datos",
    "href": "qmd/04-preparacion-transformacion.html#importar-y-exportar-datos",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "\n4.1 Importar y exportar datos",
    "text": "4.1 Importar y exportar datos\nHasta ahora hemos trabajado con data frames como mpg o gaminder, que forman parte de la instalación por defecto de R, o alguno de sus paquetes. Pero habitualmente trabajaremos con datos propios, por lo que necesitaremos leer uno o varios archivos. RStudio tiene un menú para ayudar a importar datos , pero aquí aprenderemos a hacerlo todo en código, para que nuestros scripts sean auto-contenidos.\nPodemos ver algunas de las funciones de esta sección y cómo usarlas en la Cheatsheet importar datos\n\n4.1.1 Importar un solo archivo\nEmpezaremos por la situación básica más común, cómo importar un solo archivo. Vamos a ver con más detalle los archivos CSV (comma separated values). Las funciones para importar archivos Excel, Libreoffice, SPSS, etc. tienen parámetros similares.\n\n4.1.1.1 Archivos CSV\nUsaremos las siguientes funciones del paquete readr:\n\n\n\n\n\n\nFunciones para leer archivos csv\n\n\n\n\n\nreadr::read_csv(): valores separados por coma (“,”)\n\n\nreadr::read_csv2(): valores separados por punto y coma (“;”), típicamente usado en países de habla Hispana\n\n\nreadr::read_delim( , delim = \"|\"): valores separados por un delimitador arbitrario\n\n\n\nLeemos el archivo 02-read-csv.csv de la carpeta data/files/:\n\n\nDF_name = read_csv(\"data/files/02-read-csv.csv\")\n\nSi estamos usando rmarkdown, o similar, es recomendable usar here::here() para evitar problemas con los paths a los archivos.\n\n  \n# En name_of_file almacenamos la ruta completa al archivo\nname_of_file = here::here(\"data/files/02-read-csv.csv\")\n\n# Leemos el archivo que esta en name_of_file\nDF_name = read_csv(name_of_file)\n\nDF_name\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nSi usamos un repositorio online para almacenar los archivos, podemos leer directamente de una URL.\n\n\nURL = \"https://raw.githubusercontent.com/gorkang/R_preparacion_visualizacion_datos/master/data/files/02-read-csv.csv\"\nread_csv(URL)\n\nLa función read_csv() tiene varios parámetros muy útiles como skip o col_types. Con skip podemos saltarnos líneas del inicio del archivo. Con col_types podemos especificar el tipo de datos que contiene cada columna (texto, números, factores…). Al ser explícitos con el tipo de datos evitamos sorpresas, y de paso reducimos el output de la Consola.\n\n  \n# En name_of_file almacenamos la ruta completa al archivo\nname_of_file = here::here(\"data/files/02-read-csv.csv\")\n\n# Leemos el archivo que esta en name_of_file\nread_csv(name_of_file,\n         col_types = cols(\n           .default = col_double(),\n           condition = col_character(),\n           condition2 = col_character()\n           )\n         )\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n\n4.1.1.2 Otros tipos de archivos\nPara otros tipos de archivos simplemente usaremos otras funciones. Por ejemplo, para leer archivos Excel podemos usar read_excel del paquete readxl.\nArchivos excel\n\n\nname_of_file = here::here(\"data/files/02-read-xlsx.xlsx\")\nreadxl::read_excel(name_of_file)\n\nArchivos SPSS\n\n\nname_of_file = here::here(\"data/files/02-read-sav.sav\")\nhaven::read_sav(name_of_file)\n\nArchivos Libreoffice\n\n\nname_of_file = here::here(\"data/files/02-read-ods.ods\")\ndf_ODS = readODS::read_ods(name_of_file)\n\n# Vemos las primeras filas\nhead(df_ODS)\n\nGoogle sheets\nPara poder leer una gsheet debemos:\n\nCrear un enlace para compartirla: \"Share\" -&gt; \"General access\" -&gt; \"Anyone with the link\"\n\nExtraemos el identificador de la google sheet:\n\n\n\nDe https://docs.google.com/spreadsheets/d/1v3cCKaQ3akGEH8Z2Plu7qpq93GNk6Y6v337iI4KyZ2I/edit?usp=sharing\n\nUsaremos: 1v3cCKaQ3akGEH8Z2Plu7qpq93GNk6Y6v337iI4KyZ2I\n\n\n\n\nif (!require(\"googlesheets4\")) install.packages(\"googlesheets4\"); library(\"googlesheets4\")\nname_of_sheet = \"1v3cCKaQ3akGEH8Z2Plu7qpq93GNk6Y6v337iI4KyZ2I\"\ngooglesheets4::read_sheet(name_of_sheet)   \n\nEjercicios - Importar datos\nEn el repositorio R para preparación y visualización de datos - DNSC - UAI de la Open Science Foundation podrás ver una carpeta llamada Capitulo 3. Si no tenéis conexión a Internet, podéis encontrar los archivos en data/files/OSF_files.\nDescarga e importa los archivos que ahí aparecen, asegurándote que los nombres de columna se leen adecuadamente:\n\n\n\n\n\n\nSolución\n\n\n\n\n\nLa función read_excel() tiene parámetros como skip, que permite no leer las primeras n lineas, o sheet, con la que puedes indicar que pestaña leer.\n\n\n\n\n02-extralines-1.xlsx\n02-extralines-2.xlsx\n02-extralines-3.xlsx\n02-spanish.csv\n\n4.1.2 Importar múltiples archivos\nEn ocasiones tenemos múltiples archivos en una carpeta (e.g. uno por participante) y queremos combinarlos todos en un solo DF.\nPor suerte, las funciones como read_csv() admiten un vector con varios archivos.\nPara importar todos los archivos que están en la carpeta data/files/02-CSVs:\n\n\n# Directorio donde se encuentran los archivos\nname_of_folder = here::here(\"data/files/02-CSVs\")\n\n# Listamos los archivos a leer\nfiles &lt;- list.files(name_of_folder, full.names = TRUE)\n\n# Leemos todos los archivos, combinándolos en un data frame\nfull &lt;- read_csv(files)\n\nfull\n#&gt; # A tibble: 1,600 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,594 more rows\n\nLamentablemente, cuando leamos otro tipo de archivos, como archivos .xlsx, no podemos usar la función read_csv(). Veamos una manera de hacer lo mismo, con la que se puede usar cualquier función para leer datos.\nUsaremos map_df(), que aplica la función que queramos a cada uno de los archivos que le indiquemos, de uno en uno:\n\n\n# Directorio donde se encuentran los archivos\nname_of_folder = here::here(\"data/files/02-CSVs\")\n\n# Listamos los archivos a leer\nfiles &lt;- list.files(name_of_folder, full.names = TRUE)\n\n# Leemos todos los archivos de uno en uno, combinándolos en un data frame\nfull &lt;- purrr::map_df(files, read_csv)\n\n# Mostramos lo que contiene full\nfull\n#&gt; # A tibble: 1,600 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,594 more rows\n\n\n4.1.2.1 Incluir nombres de archivos\nHabitualmente será importante saber a que archivo pertenecen los datos que hemos leído.\nPodemos incluir los nombres de archivo en una columna:\n\n\n# Nombre de la carpeta\nname_of_folder = here::here(\"data/files/02-CSVs\")\n\n# Listamos los archivos dentro de esa carpeta\nfiles_simple &lt;- list.files(name_of_folder, full.names = TRUE)\n\n# Asignamos nombres a los elementos del vector\nfiles = files_simple |&gt; set_names(basename(files_simple))\n\n# Con el parámetro .id, almacenamos los nombres en la columna \"file\"\nfull2 &lt;- map_df(files, read_csv, .id = \"file\")\n\n\n4.1.2.2 Con parametros\nAñadimos parámetros a la función de lectura. En este caso, definimos el tipo de columna esperado con la función col_types(). Con esto nos aseguraremos que si alguno de los archivos tiene el tipo de datos “incorrecto”, aparecerán warnings en la importación:\n\n\nname_of_folder = here::here(\"data/files/02-CSVs\")\nfiles &lt;- list.files(name_of_folder, full.names = TRUE)\nfull &lt;- map_df(files, read_csv,\n               # Ponemos los parámetros separados por comas, después de la función\n               col_types = cols(\n                 .default = col_character(), \n                 Sex = col_factor(),\n                 trialN = col_integer(),\n                 Valence = col_factor(),\n                 rT = col_double()\n                 )\n               )\n\nfull\n#&gt; # A tibble: 1,600 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;fct&gt; &lt;chr&gt;       &lt;int&gt; &lt;chr&gt; &lt;chr&gt;      &lt;fct&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,594 more rows\n\nOtra manera de hacer exactamente lo mismo con map_df(). El código es algo más complejo, pero nos da más flexibilidad, y podemos usar las funciones del mismo modo que habitualmente.\n\n\nname_of_folder = here::here(\"data/files/02-CSVs\")\nfiles &lt;- list.files(name_of_folder, full.names = TRUE)\nfull2 &lt;- 1:length(files) |&gt; \n  purrr::map_df(~ {\n    \n    cli::cli_alert_info(\"Reading file {basename(files[.x])}\")\n    read_csv(files[.x], col_types =  cols(.default = col_character(), \n                                          Sex = col_factor(),\n                                          trialN = col_integer(),\n                                          Valence = col_factor(),\n                                          rT = col_double()\n                                          )\n             )\n  })\n\n\n# Comprobamos que no hay diferencias\nwaldo::compare(full, full2)\n#&gt; ✔ No differences\n\nEjercicios - Importar múltiples archivos\n\nCuando más arriba importamos los archivos que están en la carpeta data/files/02-CSVs:\n\n\n¿Qué archivos importamos exactamente?\n\n\n\n\n\n\n\n¿Ves algún problema en lo que hicimos?\n\n\n\n\n\nRevisa el número de filas y el contenido de la variable files.\n\n\n\nEl resultado final debería ser así:\n\n#&gt; # A tibble: 1,200 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,194 more rows\n\n\nLeed los archivos .xlsx de la carpeta data/files/02-XLSs, combinándolos en un único DF. El resultado final debería ser como se ve a continuación:\n\n\n\n\n\n\n\nPista\n\n\n\n\n\nTendréis que usar list.files() usando el parámetro pattern\n\nTe recomiendo abrir los archivos excel para ver su estructura, las pestañas que tienen… ahí te darás cuenta de que necesitas otros parámetros de read_xlsx() como sheet o skip\n\n\n\n\n\n\n#&gt; # A tibble: 1,200 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,194 more rows\n\n\n4.1.3 Limpiar nombres de columnas\nEl paquete {janitor} tiene una función muy útil llamada clean_names() que aplica algunas reglas sencillas para estandarizar los nombres de columnas:\n\n\nDF_name = read_csv(here::here(\"data/files/02-read-csv.csv\"))\nnames(DF_name)\n#&gt; [1] \"...1\"         \"ID\"           \"Genero\"       \"Edad\"        \n#&gt; [5] \"Educacion\"    \"FollowUP\"     \"condition\"    \"condition2\"  \n#&gt; [9] \"PPV_DECLARED\"\n\nDF_names_clean = DF_name |&gt; janitor::clean_names()\nnames(DF_names_clean)\n#&gt; [1] \"x1\"           \"id\"           \"genero\"       \"edad\"        \n#&gt; [5] \"educacion\"    \"follow_up\"    \"condition\"    \"condition2\"  \n#&gt; [9] \"ppv_declared\"\n\n\n4.1.4 Exportar datos\nMuchas veces guardaremos los datos una vez procesados. Esto se puede hacer con la familia de funciones write_*.\nSiguiendo el ejercicio anterior, después de leer los archivos excel de una carpeta y limpiar los nombres de columna, queremos guardar el data frame resultante en la carpeta data_clean (¡es importante asegurarnos que esa carpeta existe!).\n\n4.1.4.1 Archivos CSV\nSi queremos que el archivo guardado sea un csv, usaremos write_csv() del paquete {readr}.\n\n\n# Lo que hicimos antes, leemos todos los archivos excel de un directorio\nname_of_folder = here::here(\"data/files/02-XLSs\")\nfiles &lt;- list.files(name_of_folder, pattern = \"xls\", full.names = TRUE)\nDF_all = map_df(files, read_xlsx, sheet = 2, skip = 5) |&gt; janitor::clean_names()\n\nreadr::write_csv(DF_all, \"data_clean/DF_all.csv\")\n\n\n4.1.4.2 Otros Archivos\nLa función a usar cambiará en función del formato que queramos:\n\n\nxlsx: writexl::write_xlsx()\n\n\nsav: haven::write_sav()\n\n\nods: readODS::write_ods()\n\n\nrds: readr::write_rds()\n\n\n\n\nwritexl::write_xlsx(DF_all, \"data_clean/DF_all.xlsx\")\n\nhaven::write_sav(DF_all, \"data_clean/DF_all.sav\")\n\nreadODS::write_ods(DF_all, \"data_clean/DF_all.ods\")\n\nreadr::write_rds(DF_all, \"data_clean/DF_all.rds\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#preparación-y-transformación-de-datos",
    "href": "qmd/04-preparacion-transformacion.html#preparación-y-transformación-de-datos",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "\n4.2 Preparación y transformación de datos",
    "text": "4.2 Preparación y transformación de datos\nPara la preparación y transformación de datos usaremos fundamentalmente dplyr. Hay otros paquetes más rápidos como data.table. Si trabajas con datos gigantescos (millones de filas), sin duda notarás la diferencia. La desventaja es que la sintaxis es (habitualmente) menos intuitiva.\n\n4.2.1 Tidy data\nExisten tres sencillas reglas que definen la Tidy data:\n\nCada variable tiene su columna propia\nCada observación tiene su fila propia\nCada valor tiene su celda propia\n\nLas ventajas fundamentales son:\n\nUso de una manera consistente de trabajar, que se alinea con el tidyverse\n\nFacilidad para trabajar con la lógica vectorizada\n\n\nPor ejemplo. De manera muy sencilla y rápida podemos crear una nueva columna realizando algún cómputo arbitrario con los valores de otra columna.\n\n\n# Computa ratio por 100,000\ntable1 |&gt; \n  mutate(rate_per_100K = cases / population * 100000)\n#&gt; # A tibble: 6 × 5\n#&gt;   country      year  cases population rate_per_100K\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071          3.73\n#&gt; 2 Afghanistan  2000   2666   20595360         12.9 \n#&gt; 3 Brazil       1999  37737  172006362         21.9 \n#&gt; 4 Brazil       2000  80488  174504898         46.1 \n#&gt; 5 China        1999 212258 1272915272         16.7 \n#&gt; 6 China        2000 213766 1280428583         16.7\n\nO contar el número de casos por valor de una variable.\n\n\n# Cuenta cuantos registros tenemos por año\ntable1 |&gt; \n  count(year)\n#&gt; # A tibble: 2 × 2\n#&gt;    year     n\n#&gt;   &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  1999     3\n#&gt; 2  2000     3\n\n# Cuenta cuantos registros tenemos por año y país\ntable1 |&gt; \n  count(year, country)\n#&gt; # A tibble: 6 × 3\n#&gt;    year country         n\n#&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;int&gt;\n#&gt; 1  1999 Afghanistan     1\n#&gt; 2  1999 Brazil          1\n#&gt; 3  1999 China           1\n#&gt; 4  2000 Afghanistan     1\n#&gt; 5  2000 Brazil          1\n#&gt; 6  2000 China           1\n\nTambién podemos hacer cosas algo más complejas, por ejemplo, aplicar funciones como across o where(is.numeric) para sumar todas las columnas de tipo numérico.\n\n\ntable1 |&gt; \n  mutate(suma_absurda =  rowSums(across(where(is.numeric))))\n#&gt; # A tibble: 6 × 5\n#&gt;   country      year  cases population suma_absurda\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071     19989815\n#&gt; 2 Afghanistan  2000   2666   20595360     20600026\n#&gt; 3 Brazil       1999  37737  172006362    172046098\n#&gt; 4 Brazil       2000  80488  174504898    174587386\n#&gt; 5 China        1999 212258 1272915272   1273129529\n#&gt; 6 China        2000 213766 1280428583   1280644349\n\nY, como no, ggplot funciona con datos tidy, en formato long.\n\n4.2.2 Verbos dplyr\nUsaremos {dplyr}, un paquete muy potente para la manipulación de datos. Su sintaxis, además, es bastante intuitiva (¡son verbos en inglés!).\nUsando pipes |&gt; (CONTROL + SHIFT + M) podemos enlazar operaciones de transformación de datos de manera muy sencilla (una vez nos aprendamos los verbos).\nPodemos ver más detalle y ejemplos en la Cheatsheet de dplyr.\nEn general usaremos la pipe nativa de R (desde la versión 4.1.0) |&gt;, pero en alguna ocasión usaremos %&gt;% (requiere el paquete magrittr).\n\n\n\n\n\n\nVerbos esenciales\n\n\n\n\nfilter(): filtrar filas\n\narrange(): ordenar filas\n\nselect(): seleccionar columnas\n\nrename(): renombrar columnas\n\nmutate(): crear columnas, modificar columnas, etc.\n\n\n\nTabla resumen dplyr\n\n\n\n\n\n\n\n4.2.2.1 Filtrar y ordenar filas\nA partir de los siguientes datos:\n\n\nname_of_file = here::here(\"data/files/02-read-csv.csv\")\nDF_name = read_csv(name_of_file)\nDF_name\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nPodemos usar el verbo filter() para mostrar las filas que cumplan cualquier regla lógica o combinación de reglas (e.g. Genero == 1 & Edad &gt;= 30).\nEn el ejemplo siguiente, nos quedamos con las filas donde el valor de Educación sea mayor de 8:\n\nDF_name |&gt; \n  filter(Educacion &gt; 8)\n#&gt; # A tibble: 3 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1   157 12207      1    26         9       57 PPV_Cond2 100RInt   \n#&gt; 2   287 60873      1    72        10       51 PPV_Cond3 100RAmp   \n#&gt; 3   381 64486      2    19         9       80 PPV_Cond4 100RAmp   \n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nSi queremos usar varias condiciones lógicas, las reparamos de & (AND).\nAquí nos quedamos con las filas donde el valor de Educación sea mayor de 8 Y el Genero sea igual a 1 (fíjate que usamos == para indicar la condición lógica de igualdad):\n\n\nDF_name |&gt; \n  filter(Educacion &gt; 8 & Genero == 1)\n#&gt; # A tibble: 2 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1   157 12207      1    26         9       57 PPV_Cond2 100RInt   \n#&gt; 2   287 60873      1    72        10       51 PPV_Cond3 100RAmp   \n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nTambién podemos ordenar las filas usando arrange() solo o en combinación con desc().\nPor ejemplo, ordenamos a partir de Educación, de menor a mayor:\n\n\nDF_name |&gt; \n  arrange(Educacion, desc(Genero))\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1   350 20439      2    41         1       81 PPV_Cond4 90LAmp    \n#&gt; 2   399 81379      1    36         1       90 PPV_Cond4 90RAmp    \n#&gt; 3    42 20361      2    37         2       60 PPV_Cond1 100LInt   \n#&gt; 4   364 19201      2    21         2       67 PPV_Cond4 90LAmp    \n#&gt; 5   412 60292      1    28         2       90 PPV_Cond4 100LAmp   \n#&gt; 6    44 92735      2    30         3       95 PPV_Cond1 100RInt   \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nSi queremos ordenar a partir de dos o más criterios, simplemente los separamos por coma. Además, si queremos que alguno de ellos sea de manera descendente (por defecto es ascendente), envolvemos el nombre de columna en desc().\nAbajo, ordenamos educación de manera ascendente, y de Género descendente:\n\n\nDF_name |&gt; \n  arrange(Educacion, desc(Genero))\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1   350 20439      2    41         1       81 PPV_Cond4 90LAmp    \n#&gt; 2   399 81379      1    36         1       90 PPV_Cond4 90RAmp    \n#&gt; 3    42 20361      2    37         2       60 PPV_Cond1 100LInt   \n#&gt; 4   364 19201      2    21         2       67 PPV_Cond4 90LAmp    \n#&gt; 5   412 60292      1    28         2       90 PPV_Cond4 100LAmp   \n#&gt; 6    44 92735      2    30         3       95 PPV_Cond1 100RInt   \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n\n4.2.2.2 Seleccionar, ordenar y renombrar columnas\nSeleccionamos las columnas que queremos listando las variables en el orden deseado dentro del verbo select():\n\n\nDF_name |&gt; \n  select(Genero, Edad)\n#&gt; # A tibble: 103 × 2\n#&gt;   Genero  Edad\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      1    47\n#&gt; 2      2    21\n#&gt; 3      2    29\n#&gt; 4      2    27\n#&gt; 5      1    29\n#&gt; 6      2    28\n#&gt; # ℹ 97 more rows\n\nEliminamos columnas precediendo las variables a eliminar con - dentro de select():\n\n\nDF_name |&gt; \n  select(-...1)\n#&gt; # A tibble: 103 × 8\n#&gt;      ID Genero  Edad Educacion FollowUP condition condition2 PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;             &lt;dbl&gt;\n#&gt; 1 41904      1    47         8       80 PPV_Cond1 90LInt               99\n#&gt; 2 95041      2    21         6       90 PPV_Cond1 90RInt               99\n#&gt; 3 74594      2    29         6       10 PPV_Cond1 100LInt              99\n#&gt; 4 72903      2    27         7       75 PPV_Cond1 100RInt               1\n#&gt; 5 21260      1    29         5       35 PPV_Cond1 90LInt               24\n#&gt; 6 50315      2    28         6       14 PPV_Cond1 90RInt               NA\n#&gt; # ℹ 97 more rows\n\nOrdenamos y eliminamos columnas listando las variables en el orden deseado dentro del verbo select() y precediendo las variables a eliminar con -:\n\n\nDF_name |&gt; \n  select(ID, Edad, Genero, everything(), -...1) \n#&gt; # A tibble: 103 × 8\n#&gt;      ID  Edad Genero Educacion FollowUP condition condition2 PPV_DECLARED\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;             &lt;dbl&gt;\n#&gt; 1 41904    47      1         8       80 PPV_Cond1 90LInt               99\n#&gt; 2 95041    21      2         6       90 PPV_Cond1 90RInt               99\n#&gt; 3 74594    29      2         6       10 PPV_Cond1 100LInt              99\n#&gt; 4 72903    27      2         7       75 PPV_Cond1 100RInt               1\n#&gt; 5 21260    29      1         5       35 PPV_Cond1 90LInt               24\n#&gt; 6 50315    28      2         6       14 PPV_Cond1 90RInt               NA\n#&gt; # ℹ 97 more rows\n\nPara renombrar variables usamos el verbo rename(). Es importante recordar que en hay que indicar rename(NOMBRE_NUEVO = NOMBRE_ANTIGUO):\n\n\nDF_name |&gt; \n  rename(Identificador = ID,\n         Sexo = Genero)\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1 Identificador  Sexo  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4         41904     1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5         95041     2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6         74594     2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15         72903     2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16         21260     1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18         50315     2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nEjercicios - verbos dplyr simples\n\nCuenta los registros por año en el data frame mpg\n\nFiltra los datos para quedarnos solo con los del año 1999\nRenombra la variable displ para que se llame “engine displacement”\n\nSi aparece el error Error: unexpected symbol in ..., puedes ver la ayuda de la función ?make.names, o este post\n\n\n\nOrdena los datos (no las columnas) por consumo en ciudad cty y clase de vehículo class\n\nCrea un data frame que no contenga la variable model\n\n\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n - mpg |&gt; count(year)\n- mpg |&gt; filter(year == 1999)\n- mpg |&gt; rename(engine displacement = displ) #ERROR\n- mpg |&gt; rename(engine_displacement = displ) #SOLUCION1\n- mpg |&gt; rename(`engine displacement` = displ) #SOLUCION2\n- mpg |&gt; arrange(cty, class)\n- mpg |&gt; select(-model) \n\n\n\n\n4.2.2.3 Selección avanzada con select_helpers()\nEl everything() que usamos dentro de select() más arriba es uno de los select_helpers() existentes. Estos nos ayudan a realizar operaciones de selección de variables sin necesidad de escribir a mano todas las variables.\n\n\n\n\n\n\nselect_helpers()\n\n\n\n\nstarts_with(): Empieza con un prefijo (e.g. starts_with(“CI_”))\n\nends_with(): Acaba con un sufijo\n\ncontains(): Contiene una cadena de texto específica\n\nmatches(): Matches a regular expression\n\nnum_range(): Matches a numerical range like x01, x02, x03\n\none_of(): Matches variable names in a character vector\n\neverything(): Matches all variables\n\nlast_col(): Select last variable\n\n\n\nTrabajaremos con los datos del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base RAW en formato wide. Leemos la base y mostramos los títulos de las 291 columnas:\n\n\n  df_wide = read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\")  \n  cat(names(df_wide))\n#&gt; ID dem_genero dem_edad dem_nivedu WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod WVOC_06_cod WVOC_07_cod WVOC_08_cod WVOC_09_cod WVOC_10_cod WVOC_11_cod WVOC_12_cod WVOC_13_cod WVOC_14_cod WVOC_15_cod WVOC_16_cod WVOC_17_cod WVOC_18_cod WVOC_19_cod WVOC_20_cod WVOC_21_cod WVOC_22_cod WVOC_23_cod WVOC_24_cod WVOC_25_cod WVOC_26_cod WVOC_27_cod WVOC_28_cod WVOC_29_cod WVOC_30_cod WVOC_31_cod WVOC_32_cod WVOC_33_cod WVOC_TOTAL WVOC_TOTAL_STD WMAT_01_cod WMAT_01_raw WMAT_02_cod WMAT_02_raw WMAT_03_cod WMAT_03_raw WMAT_04_cod WMAT_04_raw WMAT_05_cod WMAT_05_raw WMAT_06_cod WMAT_06_raw WMAT_07_cod WMAT_07_raw WMAT_08_cod WMAT_08_raw WMAT_09_cod WMAT_09_raw WMAT_10_cod WMAT_10_raw WMAT_11_cod WMAT_11_raw WMAT_12_cod WMAT_12_raw WMAT_13_cod WMAT_13_raw WMAT_14_cod WMAT_14_raw WMAT_15_cod WMAT_15_raw WMAT_16_cod WMAT_16_raw WMAT_17_cod WMAT_17_raw WMAT_18_cod WMAT_18_raw WMAT_19_cod WMAT_19_raw WMAT_20_cod WMAT_20_raw WMAT_21_cod WMAT_21_raw WMAT_22_cod WMAT_22_raw WMAT_23_cod WMAT_23_raw WMAT_24_cod WMAT_24_raw WMAT_25_cod WMAT_25_raw WMAT_26_cod WMAT_26_raw WMAT_A WMAT_B WMAT_C wmat_total wmat_total_std bfbs_01_cod bfbs_01_conf bfbs_01_raw bfbs_03_cod bfbs_03_conf bfbs_03_raw bfbs_04_cod bfbs_04_conf bfbs_04_raw bfbs_10_cod bfbs_10_conf bfbs_10_raw bfbs_12_cod bfbs_12_conf bfbs_12_raw bfbs_14_cod bfbs_14_conf bfbs_14_raw bfbs_17_cod bfbs_17_conf bfbs_17_raw bfbs_23_cod bfbs_23_conf bfbs_23_raw bfbs_conf_total bfbs_cong_conf bfbs_cong_total bfbs_creib_conf bfbs_creib_total bfbs_incong_conf bfbs_incon_total bfbs_increib_conf bfbs_increib_total bfbs_invalid_conf bfbs_invalid_total bfbs_total bfbs_valid_conf bfbs_valid_total EA_01_raw EA_02_raw EA_03_raw EA_04_raw EA_05_raw EA_06_raw EA_07_raw EA_08_raw EA_09_raw EA_10_raw EA_11_raw EA_12_raw EA_13_raw EA_14_raw EA_15_raw EA_16_raw EA_17_raw EA_18_raw EA_19_raw EA_20_raw EA_21_raw EA_22_raw EA_23_raw EA_24_raw EA_azar_TOTAL EA_control_interno_TOTAL EA_otros_poderosos_TOTAL EAR_01_raw EAR_02_raw EAR_03_raw EAR_04_raw EAR_05_raw EAR_06_raw EAR_07_raw EAR_08_raw EAR_09_raw EAR_10_raw EAR_TOTAL ECRRS_ansiedad_TOTAL ECRRS_evitacion_TOTAL ECRRS_madre_01_raw ECRRS_madre_02_raw ECRRS_madre_03_raw ECRRS_madre_04_raw ECRRS_madre_05_raw ECRRS_madre_06_raw ECRRS_madre_07_raw ECRRS_madre_08_raw ECRRS_madre_09_raw ECRRS_madre_ansiedad_TOTAL ECRRS_madre_evitacion_TOTAL ECRRS_mejoramig_01_raw ECRRS_mejoramig_02_raw ECRRS_mejoramig_03_raw ECRRS_mejoramig_04_raw ECRRS_mejoramig_05_raw ECRRS_mejoramig_06_raw ECRRS_mejoramig_07_raw ECRRS_mejoramig_08_raw ECRRS_mejoramig_09_raw ECRRS_mejoramigo_ansiedad_TOTAL ECRRS_mejoramigo_evitacion_TOTAL ECRRS_padre_01_raw ECRRS_padre_02_raw ECRRS_padre_03_raw ECRRS_padre_04_raw ECRRS_padre_05_raw ECRRS_padre_06_raw ECRRS_padre_07_raw ECRRS_padre_08_raw ECRRS_padre_09_raw ECRRS_padre_ansiedad_TOTAL ECRRS_padre_evitacion_TOTAL ECRRS_pareja_01_raw ECRRS_pareja_02_raw ECRRS_pareja_03_raw ECRRS_pareja_04_raw ECRRS_pareja_05_raw ECRRS_pareja_06_raw ECRRS_pareja_07_raw ECRRS_pareja_08_raw ECRRS_pareja_09_raw ECRRS_pareja_ansiedad_TOTAL ECRRS_pareja_evitacion_TOTAL GHQ_01 GHQ_02 GHQ_03 GHQ_04 GHQ_05 GHQ_06 GHQ_07 GHQ_08 GHQ_09 GHQ_10 GHQ_11 GHQ_12 GHQ_autoestima_TOTAL GHQ_estres_TOTAL GHQ_exito_afrontamiento_TOTAL GHQ_TOTAL wdig_dir_total wdig_inv_total WDIGSIMB_TOTAL wdig_total wdig_total_std lkns_01_cod lkns_01_raw lkns_02_cod lkns_02_raw lkns_03_cod lkns_03_raw lkns_04_cod lkns_04_raw lkns_05_cod lkns_05_raw lkns_06_cod lkns_06_raw lkns_07_cod lkns_07_raw lkns_08_cod lkns_08_raw lkns_09_cod lkns_09_raw lkns_10_cod lkns_10_raw lkns_11_cod lkns_11_raw lkns_total SASS_01_raw SASS_02_raw SASS_03_raw SASS_04_raw SASS_05_raw SASS_06_raw SASS_07_raw SASS_08_raw SASS_09_raw SASS_10_raw SASS_11_raw SASS_12_raw SASS_13_raw SASS_14_raw SASS_15_raw SASS_16_raw SASS_17_raw SASS_18_raw SASS_19_raw SASS_20_raw SASS_21_raw SASS_TOTAL SASS_trabajo bayes_all_accuracy bayes_all_confidence bayes_pictorial_qualitative_accuracy bayes_pictorial_quantitative_accuracy bayes_text_qualitative_accuracy bayes_text_quantitative_accuracy\n\nCon contains() seleccionamos variables que contienen la cadena de texto dem:\n\n\n  df_wide |&gt; \n    select(contains(\"dem\"))\n#&gt; # A tibble: 232 × 3\n#&gt;   dem_genero dem_edad dem_nivedu\n#&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1          1       38          4\n#&gt; 2          0       67          2\n#&gt; 3          0       24          4\n#&gt; 4          0       30          4\n#&gt; 5          0       38          3\n#&gt; 6          0       45          4\n#&gt; # ℹ 226 more rows\n\nUsando ends_with() seleccionamos variables que acaban con la cadena de texto cod:\n\n\n  df_wide |&gt; \n    select(ID, ends_with(\"cod\"))\n#&gt; # A tibble: 232 × 79\n#&gt;      ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod\n#&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1     1           2           2           2           1           2\n#&gt; 2     2           2           2           2           1           0\n#&gt; 3     3           2           2           2           1           2\n#&gt; 4     4           2           1           1           1           2\n#&gt; 5     5           2           2           1           1           0\n#&gt; 6     6           1           1           2           1           2\n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 73 more variables: WVOC_06_cod &lt;dbl&gt;, WVOC_07_cod &lt;dbl&gt;, …\n\nFinalmente, matches() nos permite usar todo la potencia de las expresiones regulares. En este caso, también le pedimos variables que acaban con la cadena de texto cod:\n\n\n  df_wide |&gt; \n    select(ID, matches(\"cod$\")) # $: fin de la cadena de texto\n#&gt; # A tibble: 232 × 79\n#&gt;      ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod\n#&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1     1           2           2           2           1           2\n#&gt; 2     2           2           2           2           1           0\n#&gt; 3     3           2           2           2           1           2\n#&gt; 4     4           2           1           1           1           2\n#&gt; 5     5           2           2           1           1           0\n#&gt; 6     6           1           1           2           1           2\n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 73 more variables: WVOC_06_cod &lt;dbl&gt;, WVOC_07_cod &lt;dbl&gt;, …\n\n\n4.2.2.4 Modificar y añadir variables\nSeguimos usando verbos de {dplyr}. Para crear nuevas variables o modificarlas reemplazando los valores usaremos mutate(). Dentro de mutate podemos hacer cualquier operación con una o más variables.\nPrimero leemos nuestra base:\n\n\nname_of_file = here::here(\"data/files/02-read-csv.csv\")\nDF_name = read_csv(name_of_file)\nDF_name\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nSi usamos una variable ya existente, en este caso PPV_DECLARED, sus valores se sobrescriben:\n\n\nDF_name |&gt; \n  mutate(PPV_DECLARED = PPV_DECLARED/100)\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nSi usamos una variable no existente (PPV_DECLARED_PCT), la creamos:\n\n\nDF_name |&gt; \n  mutate(PPV_DECLARED_PCT = PPV_DECLARED/100)\n#&gt; # A tibble: 103 × 10\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 2 more variables: PPV_DECLARED &lt;dbl&gt;, PPV_DECLARED_PCT &lt;dbl&gt;\n\n\n4.2.2.5 Resúmenes agrupados\nLa combinación de verbos group_by() y summarise() es una de las más usadas. Con esta podemos calcular promedios, medianas, etc. por condición de manera sencilla.\nsummarise() nos permite ‘resumir’ datos, calculando promedios, medianas, o cualquier otro estadístico de interés. En este caso, vemos el promedio de la variable PPV_DECLARED usando mean(PPV_DECLARED, na.rm = TRUE). El parámetro na.rm = TRUE ignora los valores NA que pueda haber en la base:\n\n\nDF_name |&gt; \n  summarise(Promedio_PPV = mean(PPV_DECLARED, na.rm = TRUE), \n            N = n())\n#&gt; # A tibble: 1 × 2\n#&gt;   Promedio_PPV     N\n#&gt;          &lt;dbl&gt; &lt;int&gt;\n#&gt; 1         68.1   103\n\nSi incluimos group_by() en la pipeline, esos ‘resúmenes’ se mostraran para cada valor de la variable por la que agrupamos:\n\n\nDF_name |&gt; \n  group_by(Genero) |&gt; \n  summarise(Promedio_PPV = mean(PPV_DECLARED, na.rm = TRUE), \n            N = n())\n#&gt; # A tibble: 2 × 3\n#&gt;   Genero Promedio_PPV     N\n#&gt;    &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      1         65.9    40\n#&gt; 2      2         69.4    63\n\nPodemos agrupar por múltiples variables, y calcular tantas cosas como queramos. En ese caso la media, mediana, desviación estándar y el numero de observaciones:\n\n\nDF_name |&gt; \n  group_by(Genero, condition) |&gt; \n  summarise(promedio_PPV = mean(PPV_DECLARED, na.rm = TRUE),\n            mediana_PPV = median(PPV_DECLARED, na.rm = TRUE),\n            SD = sd(PPV_DECLARED, na.rm = TRUE),\n            N = n())\n#&gt; # A tibble: 8 × 6\n#&gt; # Groups:   Genero [2]\n#&gt;   Genero condition promedio_PPV mediana_PPV    SD     N\n#&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      1 PPV_Cond1         63.8          88  43.1     9\n#&gt; 2      1 PPV_Cond2         50.2          46  10.3    13\n#&gt; 3      1 PPV_Cond3         75.6          80  32.5     5\n#&gt; 4      1 PPV_Cond4         79.1          91  20.0    13\n#&gt; 5      2 PPV_Cond1         72.6          99  43.8    19\n#&gt; 6      2 PPV_Cond2         49.4          46  16.3     8\n#&gt; # ℹ 2 more rows\n\nEjercicios - verbos dplyr\n\nUsando la base df_wide (puedes usar el código de abajo), haz las siguientes cosas, una a una:\n\ndf_wide = read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\")  \n\n\nFiltra el DF para quedarnos solo con edades entre 18 y 50 años\n\nOrdena los datos por genero y edad, esta última decreciente\n\nSelecciona las columnas para quedarnos solo con ID, variables demográficas, y respuestas crudas (raw)\n\nCrea una nueva variable llamada niv_edu_porc, en la que calcules el nivel educativo al que han llegado dividido por el máximo de la base de datos, pero en porcentaje (nivel educativo persona / nivel educativo máximo; en porcentaje)\n\n\nAhora combina el resultado de todas las operaciones anteriores en un DF\nCalcula el promedio y desviación típica de edad para cada género\n\n\n\n\n\n\n\nPistas\n\n\n\n\n\n\n\nPaso a paso:\n\n\nfilter(CONDICION1 & CONDICION2) o filter(CONDICION1, CONDICION2)\n\n\narrange() o arrange(desc())\n\n\nselect(starts_with(\"ALGUN_PATRON\")) o select(ends_with(\"ALGUN_PATRON\"))\n\n\nmutate() usando también max()\n\n\n\nDF_resultado = df_wide |&gt; operacion1 |&gt; operation2 |&gt; ...\ngroup_by() |&gt; summarize()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#verbos-avanzados-y-otras-criaturas-indómitas",
    "href": "qmd/04-preparacion-transformacion.html#verbos-avanzados-y-otras-criaturas-indómitas",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "\n4.3 Verbos avanzados y otras criaturas indómitas",
    "text": "4.3 Verbos avanzados y otras criaturas indómitas\n\n4.3.1 Wide to long simple\nEmpecemos con un ejemplo muy sencillo. 2 participantes, cada uno en una condición, y 2 ítems.\n\n\ndf_simple_wide = \n  tibble(\n    ID = c(\"Participante1\", \"Participante2\"),\n    condition = c(\"calor\", \"frio\"),\n    Item1 = c(22, 33),\n    Item2 = c(88, 99)\n    )\n\ndf_simple_wide\n#&gt; # A tibble: 2 × 4\n#&gt;   ID            condition Item1 Item2\n#&gt;   &lt;chr&gt;         &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Participante1 calor        22    88\n#&gt; 2 Participante2 frio         33    99\n\nPasamos esta base de datos ‘ancha’ (una fila por participante), a una base en formato ‘largo’ (una fila por observación) usando la función pivot_longer(). Solo tenemos que indicar el rango de columnas, asignar nombre a la columna donde enviaremos los nombres de las columnas, y asignar nombre a la columna donde estarán los valores:\n\n\ndf_simple_long = df_simple_wide |&gt;\n  pivot_longer(cols = Item1:Item2,\n               names_to = \"Item\",\n               values_to = \"Response\")\n\n\ndf_simple_long\n#&gt; # A tibble: 4 × 4\n#&gt;   ID            condition Item  Response\n#&gt;   &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 Participante1 calor     Item1       22\n#&gt; 2 Participante1 calor     Item2       88\n#&gt; 3 Participante2 frio      Item1       33\n#&gt; 4 Participante2 frio      Item2       99\n\n\n4.3.2 Long to wide simple\nSiguiendo con el ejemplo anterior, podemos devolver la base en formato ‘largo’ a ‘ancho’ de nuevo usando pivot_wider():\n\n\ndf_simple_long |&gt; \n  pivot_wider(names_from = Item, values_from = Response)\n#&gt; # A tibble: 2 × 4\n#&gt;   ID            condition Item1 Item2\n#&gt;   &lt;chr&gt;         &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Participante1 calor        22    88\n#&gt; 2 Participante2 frio         33    99\n\n\n4.3.2.1 ¿Para que sirve tener los datos en formato long?\nHay algunos análisis para los que necesitamos formato long (e.g. anovas, modelos mixtos…), muchas gráficas con ggplot asumen formato long, y varias cosas se simplifican cuando los datos están en formato largo.\nPor ejemplo, si queremos usar resúmenes agrupados para obtener la media, mediana, desviación estándar… por ítem, con el formato WIDE necesitaremos 3 lineas de código para cada ítem que tenga nuestra base (imagina con 100 ítems…). Con el formato long, el código de abajo es suficiente.\n\n# En formato wide podríamos usar cosas como:  \n  # skimr::skim(df_simple_wide)\n\n# Añadir para cada ítem 3 líneas\ndf_simple_wide |&gt;\n  summarise(mean_Item1 = mean(Item1),\n            mean_Item2 = mean(Item2),\n            # ...\n            median_Item1 = median(Item1),\n            median_Item2 = median(Item2),\n            # ...\n            sd_Item1 = sd(Item1),\n            sd_Item2 = sd(Item2),\n            # ...\n            N = n()\n            # NO aparece N por ítem\n            )\n#&gt; # A tibble: 1 × 7\n#&gt;   mean_Item1 mean_Item2 median_Item1 median_Item2 sd_Item1 sd_Item2     N\n#&gt;        &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;\n#&gt; 1       27.5       93.5         27.5         93.5     7.78     7.78     2\n\n# Sirve para 1 ítem o para 10 millones de ítems\ndf_simple_long |&gt;\n  group_by(Item) |&gt;\n  summarise(MEAN = mean(Response),\n            MEDIAN = median(Response),\n            SD = sd(Response),\n            N = n())\n#&gt; # A tibble: 2 × 5\n#&gt;   Item   MEAN MEDIAN    SD     N\n#&gt;   &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Item1  27.5   27.5  7.78     2\n#&gt; 2 Item2  93.5   93.5  7.78     2\n\n\n4.3.3 Wide to long complex\nAhora pasemos a un ejemplo mas complejo. Leemos la base de datos y seleccionamos las puntuaciones a los 11 ítems de la lipkus numeracy scale de 232 participantes, ademas de datos demográficos. Usamos DT::datatable() para visualizar la base de manera interactiva.\n\n\n# Leemos documento en formato WIDE\ndf_wide_complex = read_csv(\n  \"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\"\n) |&gt;\n  # Seleccionamos solo algunas de las filas\n  select(ID,\n         dem_genero,\n         dem_edad,\n         dem_nivedu,\n         matches(\"lkns_[0-9]{2}_raw\"))\n\nDT::datatable(df_wide_complex)\n\n\n\n\n\nDe nuevo, para pasar de formato ‘ancho’ a ‘largo’ completamos los mismos parámetros que antes. Lo único que añadimos es values_transform = list(Response = as.character) para poder incluir en la columna Response tanto valores numéricos como caracteres.\n\n\ndf_long_complex =\n  df_wide_complex |&gt;\n  pivot_longer(\n    cols = lkns_01_raw:lkns_11_raw,\n    names_to = \"Item\",\n    values_to = \"Response\",\n    values_transform = list(Response = as.character)\n  )\n\n# Podemos usar select_helpers!\n  # Reemplaza lkns_01_raw:lkns_11_raw por matches(\"lkns\")\n\n\nDT::datatable(df_long_complex)\n\n\n\n\n\n\n4.3.4 Long to wide complex\nNos sirve el mismo código que con el ejemplo más simple:\n\n\ndf_long_complex |&gt;  \n  pivot_wider(names_from = Item, values_from = Response)\n#&gt; # A tibble: 232 × 15\n#&gt;      ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw\n#&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;      \n#&gt; 1     1          1       38          4 500         10          10         \n#&gt; 2     2          0       67          2 0           0           0          \n#&gt; 3     3          0       24          4 700         100         0.1        \n#&gt; 4     4          0       30          4 500         30          1          \n#&gt; 5     5          0       38          3 6           2           3          \n#&gt; 6     6          0       45          4 40          200         2          \n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 8 more variables: lkns_04_raw &lt;chr&gt;, lkns_05_raw &lt;chr&gt;, …",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#ejercicios---wide-to-long",
    "href": "qmd/04-preparacion-transformacion.html#ejercicios---wide-to-long",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "Ejercicios - wide to long",
    "text": "Ejercicios - wide to long\nDe nuevo trabajaremos con datos del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al., pero esta vez van a ser los datos procesados. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base final en formato wide (Dentro de https://osf.io/egxy5/, ver archivo: /outputs/data/sa-prepared.csv).\nPara simplificar el proceso, puedes importar los datos y limpiar los nombres de variables así:\n\n\nDF_wide = read_csv(\n  \"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv\"\n) |&gt;\n  janitor::clean_names()\n\n\nCambia el orden de las variables para que ID sea la primera columna.\nTransforma la base a formato long (eso sí, mantén las variables demográficas en formato wide).\nAprovechando que tenemos la base en formato long, sabrías hacer una gráfica con un histograma o densidad para cada una de las variables no demográficas?\n\n\n\n\n\n\n\nPistas\n\n\n\n\n\n\nTendrás que usar la función select() y el select helper everything()\npivot_longer(primera_variable:ultima_variable)\nfacet_wrap(~name, scales = \"free\") te ayudara a crear paneles para cada nombre, donde las escalas x/y pueden variar libremente.\n\n\n\n\nEl gráfico final se debería ver así:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#separate-omit-ifelse-case_when-tipos-de-variables",
    "href": "qmd/04-preparacion-transformacion.html#separate-omit-ifelse-case_when-tipos-de-variables",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "\n4.4 Separate, omit, ifelse, case_when, tipos de variables…",
    "text": "4.4 Separate, omit, ifelse, case_when, tipos de variables…\nPara transformaciones algo más complejas, pero muy habituales, usaremos algunos verbos del paquete {tidyr}, y variaciones con {dplyr}\n\n# Base original\nDF_name = read_csv(\"../data/files/02-read-csv.csv\") |&gt; \n  select(-...1, -Educacion, -Edad, -condition2)\n\nDT::datatable(DF_name)\n\n\n\n\n\n\nPodemos separar la columna de condición usando la función separate() y un separador (sep = \"_\"). La separación puede ser en columnas o en filas. En este primer caso, separamos enviando cada parte de condition a una columna distinta:\n\n# Separate\nDF_separated = DF_name |&gt; \n  separate(condition, c(\"primer_chunk\", \"segundo_chunk\"), sep = \"_\")\n\nDF_separated\n#&gt; # A tibble: 103 × 6\n#&gt;      ID Genero FollowUP primer_chunk segundo_chunk PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV          Cond1                   99\n#&gt; 2 95041      2       90 PPV          Cond1                   99\n#&gt; 3 74594      2       10 PPV          Cond1                   99\n#&gt; 4 72903      2       75 PPV          Cond1                    1\n#&gt; 5 21260      1       35 PPV          Cond1                   24\n#&gt; 6 50315      2       14 PPV          Cond1                   NA\n#&gt; # ℹ 97 more rows\n\nTambién podemos enviar cada parte de condition a una fila distinta:\n\n\nDF_name |&gt; \n  separate_rows(condition, sep = \"_\")\n#&gt; # A tibble: 206 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV                 99\n#&gt; 2 41904      1       80 Cond1               99\n#&gt; 3 95041      2       90 PPV                 99\n#&gt; 4 95041      2       90 Cond1               99\n#&gt; 5 74594      2       10 PPV                 99\n#&gt; 6 74594      2       10 Cond1               99\n#&gt; # ℹ 200 more rows\n\nCon unite() podemos hacer lo contrario, unir columnas con un separador definido:\n\n\n# Unite: inversa de separate\nDF_separated |&gt; \n  unite(condition, c(primer_chunk, segundo_chunk), sep = \"_\")\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV_Cond1           99\n#&gt; 2 95041      2       90 PPV_Cond1           99\n#&gt; 3 74594      2       10 PPV_Cond1           99\n#&gt; 4 72903      2       75 PPV_Cond1            1\n#&gt; 5 21260      1       35 PPV_Cond1           24\n#&gt; 6 50315      2       14 PPV_Cond1           NA\n#&gt; # ℹ 97 more rows\n\nSi necesitamos recodificar variables, cambiar valores condicionalmente,… podemos usar ifelse(), case_when() o recode():\nifelse(), si se cumple la condición Genero == 1, asigna el valor “Hombre”, de lo contrario, “Mujer”:\n\n\nDF_name |&gt;\n  mutate(Genero = ifelse(Genero == 1, \"Hombre\", \"Mujer\"))\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904 Hombre       80 PPV_Cond1           99\n#&gt; 2 95041 Mujer        90 PPV_Cond1           99\n#&gt; 3 74594 Mujer        10 PPV_Cond1           99\n#&gt; 4 72903 Mujer        75 PPV_Cond1            1\n#&gt; 5 21260 Hombre       35 PPV_Cond1           24\n#&gt; 6 50315 Mujer        14 PPV_Cond1           NA\n#&gt; # ℹ 97 more rows\n\nCon case_when() podemos establecer varias condiciones lógicas simultáneamente, ademas de un valor por defecto si no se cumple ninguna de ellas. Las condiciones lógicas pueden ser arbitrariamente complejas:\n\n\nDF_name |&gt;\n  mutate(Genero = \n           case_when(\n             Genero == 1 ~ \"Hombre\",\n             Genero == 2 ~ \"Mujer\",\n             Genero == 3 ~ \"No binario\",\n             TRUE ~ NA_character_)\n         )\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904 Hombre       80 PPV_Cond1           99\n#&gt; 2 95041 Mujer        90 PPV_Cond1           99\n#&gt; 3 74594 Mujer        10 PPV_Cond1           99\n#&gt; 4 72903 Mujer        75 PPV_Cond1            1\n#&gt; 5 21260 Hombre       35 PPV_Cond1           24\n#&gt; 6 50315 Mujer        14 PPV_Cond1           NA\n#&gt; # ℹ 97 more rows\n\nFinalmente podemos usar recode(), con una sintaxis tal vez algo más sencilla:\n\n\n  DF_name |&gt; \n  select(Genero) |&gt; \n    \n    # De número a texto\n    mutate(Genero2 = recode(\n      Genero,\n      `1` = \"Hombre\",\n      `2` = \"Mujer\",\n      .default = \"No definido\"\n    )) |&gt;\n    \n    # De texto a número\n    mutate(Genero3 = recode(\n      Genero2,\n      \"Hombre\" = 1,\n      \"Mujer\" = 0,\n      .default = 999\n    ))\n#&gt; # A tibble: 103 × 3\n#&gt;   Genero Genero2 Genero3\n#&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n#&gt; 1      1 Hombre        1\n#&gt; 2      2 Mujer         0\n#&gt; 3      2 Mujer         0\n#&gt; 4      2 Mujer         0\n#&gt; 5      1 Hombre        1\n#&gt; 6      2 Mujer         0\n#&gt; # ℹ 97 more rows\n\nOtras funciones útiles, extraer los valores de una columna con pull() o descartar los NA de una columna con drop_na().\nUsamos pull() para extraer los valores de una columna.\n\nDF_name |&gt; pull(PPV_DECLARED)\n#&gt;   [1] 99 99 99  1 24 NA 99 99 99  1 94 99 88  0  1 99 99 99 70 99  1 99 99  7\n#&gt;  [25] 10 99 99 99 46 45 46 40 NA 46 46 73 46 50 46 45 46 87 46 49 30 46 50 70\n#&gt;  [49] 44 80 99 99 99 99 80 51 99 20 30  1 20  5 30 99 99 99 99 80 98 99 80 59\n#&gt;  [73] 64 16 79 92 92 80 90 60 93 92 28 92 92 77 74 90 10 92 92 92 65 20 92 92\n#&gt;  [97] 92 92 90 92 NA 92 80\n\nCalculamos el promedio de una columna (con pipes).\n\n \nDF_name |&gt; pull(PPV_DECLARED) |&gt; mean()\n#&gt; [1] NA\n\nCalculamos el promedio usando na.rm = TRUE para que la función mean() ignore los NA’s:\n\n\nDF_name |&gt; pull(PPV_DECLARED) |&gt; mean(na.rm = TRUE)\n#&gt; [1] 68.06\n\nCalculamos la media de manera más sencilla, en este caso usando base R. No siempre son necesarias las pipes. Si escribes DF_name$ y presionas el tabulador, aparecerán todas las columnas de esa base:\n\nmean(DF_name$PPV_DECLARED, na.rm = TRUE)\n#&gt; [1] 68.06\n\nEliminamos las filas que tienen valores perdidos en la variable indicada. En este caso pasamos de 103 a 100 observaciones:\n\nDF_name |&gt;  drop_na(PPV_DECLARED)\n#&gt; # A tibble: 100 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV_Cond1           99\n#&gt; 2 95041      2       90 PPV_Cond1           99\n#&gt; 3 74594      2       10 PPV_Cond1           99\n#&gt; 4 72903      2       75 PPV_Cond1            1\n#&gt; 5 21260      1       35 PPV_Cond1           24\n#&gt; 6 21774      2        2 PPV_Cond1           99\n#&gt; # ℹ 94 more rows",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#ejercicios---verbos-avanzados-dplyr",
    "href": "qmd/04-preparacion-transformacion.html#ejercicios---verbos-avanzados-dplyr",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "Ejercicios - verbos avanzados dplyr",
    "text": "Ejercicios - verbos avanzados dplyr\n\nImporta los datos y limpia los nombres de columna:\n\n\n\n\n\n\n\nPara limpiar nombres de columnas automáticamente:\n\n\n\n\n\nclean_names()\n\n\n\n\n\n# Leemos los datos y usamos janitor::clean_names() para limpiar los nombres de las columnas\n DF_wide = \n  read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv\")\n\n\nEn un nuevo DF (DF_split), crea una variable llamada social_adaptation_split con la median split para la variable social_adaptation. La mitad superior se llamará high_social_adaptation y la mitad inferior low_social_adaptation.\n\n\n\n\n\n\n\nSuele ser más facil si dividimos la tarea en varios pasos\n\n\n\n\n\n1. Calculamos mediana 2. Usamos case_when()\n\n\n\n\nAsegúrate que no hay valores NA.\n\n\n\n\n\n\n\nPista\n\n\n\n\n\nLa función drop_na() .\n\n\n\n\nEl resultado final debería ser:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#regular-expressions",
    "href": "qmd/04-preparacion-transformacion.html#regular-expressions",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "\n4.5 Regular expressions",
    "text": "4.5 Regular expressions\nLas expresiones regulares son una herramienta tan potente como difícil de utilizar. Eso si, podemos hacer algunas cosas básicas muy útiles, sin demasiado esfuerzo. Hay cheatsheets (Basic Regular Expressions Cheatsheet) y libros (introduction to Regular Expressions) que nos pueden ayudar a familiarizarnos con ellas.\n\n\n\nSOURCE: https://xkcd.com/208/\n\n\nImagina que tenemos que trabajar con la columna condition2, donde están codificadas 3 variables importantes:\n\n\nDF_regexp = read_csv(here::here(\"data/files/02-read-csv.csv\")) |&gt; \n  select(-...1, -Educacion, -Edad, -condition)\n\nDF_regexp\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition2 PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n#&gt; 1 41904      1       80 90LInt               99\n#&gt; 2 95041      2       90 90RInt               99\n#&gt; 3 74594      2       10 100LInt              99\n#&gt; 4 72903      2       75 100RInt               1\n#&gt; 5 21260      1       35 90LInt               24\n#&gt; 6 50315      2       14 90RInt               NA\n#&gt; # ℹ 97 more rows\n\nCuando no tenemos separadores explícitos como vimos antes con separate(), podemos usar mutate() junto a gsub() y expresiones regulares para extraer, una a una, las condiciones.\nLa función gsub() nos sirve para eliminar partes de una cadena de texto, para extraer un número, etc.:\n\n\nDF_regexp |&gt; \n  mutate(cond_NM = gsub(\"([0-9]{2,3}).*\", \"\\\\1\", condition2),\n         cond_LR = gsub(\"[0-9]{2,3}([LR]).*\", \"\\\\1\", condition2),\n         cond_IA = gsub(\"[0-9]{2,3}[LR](.*)\", \"\\\\1\", condition2))\n#&gt; # A tibble: 103 × 8\n#&gt;      ID Genero FollowUP condition2 PPV_DECLARED cond_NM cond_LR cond_IA\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1 41904      1       80 90LInt               99 90      L       Int    \n#&gt; 2 95041      2       90 90RInt               99 90      R       Int    \n#&gt; 3 74594      2       10 100LInt              99 100     L       Int    \n#&gt; 4 72903      2       75 100RInt               1 100     R       Int    \n#&gt; 5 21260      1       35 90LInt               24 90      L       Int    \n#&gt; 6 50315      2       14 90RInt               NA 90      R       Int    \n#&gt; # ℹ 97 more rows\n\nExtraemos la misma información, de una manera ligeramente distinta, siendo mucho más explícitos sobre la estructura esperada de la columna condition2:\n\n\nDF_regexp |&gt; \n  mutate(cond_NM = gsub(\"^([0-9]{2,3})([LR])(.*)$\", \"\\\\1\", condition2),\n         cond_LR = gsub(\"^([0-9]{2,3})([LR])(.*)$\", \"\\\\2\", condition2),\n         cond_IA = gsub(\"^([0-9]{2,3})([LR])(.*)$\", \"\\\\3\", condition2))\n#&gt; # A tibble: 103 × 8\n#&gt;      ID Genero FollowUP condition2 PPV_DECLARED cond_NM cond_LR cond_IA\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1 41904      1       80 90LInt               99 90      L       Int    \n#&gt; 2 95041      2       90 90RInt               99 90      R       Int    \n#&gt; 3 74594      2       10 100LInt              99 100     L       Int    \n#&gt; 4 72903      2       75 100RInt               1 100     R       Int    \n#&gt; 5 21260      1       35 90LInt               24 90      L       Int    \n#&gt; 6 50315      2       14 90RInt               NA 90      R       Int    \n#&gt; # ℹ 97 more rows\n\nCon select() y matches() seleccionamos columnas usando la siguiente regular expression lkns_[0-9]{2}_raw:\n\n\nlkns_ contiene esta cadena de texto\n\n\n[0-9]{2} a continuación, contiene cualquier dígito del 0 al 9, dos veces.\n\n_rawa continuación, contiene esta cadena de texto\n\n\n\nread_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\") |&gt; \n  # Seleccionamos solo algunas de las filas\n  select(ID, dem_genero, dem_edad, dem_nivedu, matches(\"lkns_[0-9]{2}_raw\"))\n#&gt; # A tibble: 232 × 15\n#&gt;      ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw\n#&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1     1          1       38          4         500          10        10  \n#&gt; 2     2          0       67          2           0           0         0  \n#&gt; 3     3          0       24          4         700         100         0.1\n#&gt; 4     4          0       30          4         500          30         1  \n#&gt; 5     5          0       38          3           6           2         3  \n#&gt; 6     6          0       45          4          40         200         2  \n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 8 more variables: lkns_04_raw &lt;chr&gt;, lkns_05_raw &lt;chr&gt;, …\n\n\n\n4.5.1 Ayuda con regular expressions\nEs muy fácil cometer errores cuando usamos expresiones regulares. Algunas recomendaciones:\n\nSolo usar expresiones regulares cuando sea necesario\nUsar expresiones regulares lo más explícitas y definidas posible\nVerificar que están funcionando bien!\n\n\n\nSOURCE: https://xkcd.com/1171/\n\nHay una aplicación Shiny muy útil que nos ayudará a construir Regular Expressions:\n\n\nregexplain::regexplain_gadget()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#ejercicios---calcular-puntajes-de-escalas-usando-regular-expressions",
    "href": "qmd/04-preparacion-transformacion.html#ejercicios---calcular-puntajes-de-escalas-usando-regular-expressions",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "Ejercicios - Calcular puntajes de escalas usando regular expressions",
    "text": "Ejercicios - Calcular puntajes de escalas usando regular expressions\nAhora volvemos a usar con los datos brutos (sa-raw-anonymised.csv) del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. \nEn estos datos tenemos las puntuaciones crudas (e.g. WMAT_01_raw) y ya codificadas/corregidas (WMAT_01_cod) para los ítems de varias escalas Para preparar los datos de cara al análisis final, necesitamos calcular el puntaje para cada participante y escala. Empezaremos con la prueba de Matrices de WAIS (WMAT_).\n\nCalcula el puntaje para cada participante en la prueba de Matrices de WAIS (ítems WMAT_[NUMEROS]_cod)\n\nHay al menos dos estrategias posibles:\n\nSelecciona las columnas relevantes y haz la suma de columnas\nConvierte a long, filtra para quedarte con las filas correspondientes a la prueba relevante, y haz una suma agrupada\n\n\n\n\n\n\n\nPista para seleccionar o filtrar columnas:\n\n\n\n\n\nRecuerda que usamos select() para seleccionar columnas, o filter() para filtrar.\n\n\n\n\n\n\n\n\n\nPista para seleccionar columnas:\n\n\n\n\n\nPodemos usar matches(\"WMAT_[0-9]{2}_cod\") para seleccionar o filtrar todas las columnas o ítems que contienen: WMAT_, 2 números del 0 al 9, y acaban en _cod.\n\n\n\n\n\n\n\n\n\nPista para suma de columnas:\n\n\n\n\n\nrowSums() es la función que podemos usar, pero su sintaxis es algo complicada.\n\n\n\n\n\n\n\n\n\nPista para suma agrupada:\n\n\n\n\n\nUsamos group_by() |&gt; summarise() poniendo parámetros dentro de cada función.\n\n\n\n\nImportar datos:\n\n\ndf_wide_raw = read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/04-preparacion-transformacion.html#bibliografía",
    "href": "qmd/04-preparacion-transformacion.html#bibliografía",
    "title": "\n4  Preparación y transformación de datos\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nCheatsheets RStudio\nCheatsheet dplyr\nTidyexplain",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Preparación y transformación de datos</span>"
    ]
  },
  {
    "objectID": "qmd/05-combinar-datos.html",
    "href": "qmd/05-combinar-datos.html",
    "title": "\n5  Combinar datos\n",
    "section": "",
    "text": "Paquetes para este capítulo\nif (!require('dplyr')) install.packages('dplyr'); library('dplyr')\nif (!require(\"DT\")) install.packages(\"DT\"); library(\"DT\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\"); library(\"ggplot2\")\nif (!require(\"here\")) install.packages(\"here\"); library(\"here\")\nif (!require(\"janitor\")) install.packages(\"janitor\"); library(\"janitor\")\nif (!require(\"purrr\")) install.packages(\"purrr\"); library(\"purrr\")\nif (!require('readr')) install.packages('readr'); library('readr')\nif (!require(\"readxl\")) install.packages(\"readxl\"); library(\"readxl\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\"); library(\"tidyr\")\nif (!require(\"waldo\")) install.packages(\"waldo\"); library(\"waldo\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combinar datos</span>"
    ]
  },
  {
    "objectID": "qmd/05-combinar-datos.html#bind-rows-or-columns",
    "href": "qmd/05-combinar-datos.html#bind-rows-or-columns",
    "title": "\n5  Combinar datos\n",
    "section": "\n5.1 Bind rows or columns",
    "text": "5.1 Bind rows or columns\nEl método más sencillo. Simplemente unimos las filas o columnas de los data frames.\nPrimero importamos dos DFs:\n\n\nDF1 = read_csv(here::here(\"data/files/02-CSVs/01.csv\"))\nDF2 = read_csv(here::here(\"data/files/02-CSVs/02.csv\"))\n\nCon bind_rows() podemos añadir las filas de DF2 a DF1:\n\n\nDF1 |&gt; bind_rows(DF2)\n#&gt; # A tibble: 800 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 794 more rows\n\nCon bind_cols() añadimos las columnas de DF2 a DF1. bind_cols() renombra automáticamente los nombres de las columnas para que no haya coincidencias:\n\n\nDF1 |&gt; bind_cols(DF2) \n#&gt; # A tibble: 400 × 18\n#&gt;   Sex...1 Priming...2 trialN...3 Block...4 Adjective...5 Valence...6\n#&gt;   &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;      \n#&gt; 1 male    Collective           1 we        ofensivo      negative   \n#&gt; 2 male    Collective           2 we        resentido     negative   \n#&gt; 3 male    Collective           3 we        ego�sta       negative   \n#&gt; 4 male    Collective           4 we        indiscreto    negative   \n#&gt; 5 male    Collective           5 we        sumiso        negative   \n#&gt; 6 male    Collective           6 we        agradable     positive   \n#&gt; # ℹ 394 more rows\n#&gt; # ℹ 12 more variables: Answer...7 &lt;chr&gt;, Arrow...8 &lt;chr&gt;, rT...9 &lt;dbl&gt;, …",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combinar datos</span>"
    ]
  },
  {
    "objectID": "qmd/05-combinar-datos.html#joins",
    "href": "qmd/05-combinar-datos.html#joins",
    "title": "\n5  Combinar datos\n",
    "section": "\n5.2 Joins",
    "text": "5.2 Joins\nEl paquete {dplyr} tiene funciones que permiten trabajar combinando, filtrando, etc. distintos data frames. Podéis ver más detalle y algunas ilustraciones fantásticas (como la de abajo; inner_join()) en el capítulo relational data de r4ds.\n\n\nSOURCE: https://r4ds.had.co.nz/relational-data.html#mutating-joins\n\nEn https://github.com/gadenbuie/tidyexplain se pueden ver animaciones mostrando estas operaciones.\n\n\n\n\n\n\n\nTipos de Join\n\n\n\nEstas operaciones tendrán la forma: DF_x |&gt; WHATEVER_join(DF_y)\n\n\nMutating joins:\n\ninner_join(): preserva pares de observaciones de DF_x y de DF_y con claves iguales\n\nleft_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales\n\nright_join(): preserva las observaciones de DF_y, añadiendo las de DF_x con claves iguales\n\nfull_join(): preserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales\n\n\n\nFiltering joins:\n\nsemi_join(): preserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y\n\nanti_join(): preserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y\n\n\n\n\nNesting joins:\n\nnest_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales\n\n\n\n\n\n\n5.2.1 Mutating joins\nImportamos datos\nTenemos los siguientes data frames:\n\nDF_IDs: Variables demográficas de participantes\n\nDF_results: Resultados en variables de interés de participantes\n\nDF_BAD: Grupo de participantes “selectos”\n\n\n\n# Importar CSVs para los joins  \nDF_IDs = read_csv(here::here(\"data/files/02-join-IDs.csv\"))\nDF_results = read_csv(here::here(\"data/files/02-join-results.csv\"))\nDF_BAD = read_csv(here::here(\"data/files/02-join-BAD.csv\"))\n\n\n5.2.1.1 Inner join\nPreserva pares de observaciones de DF_x y de DF_y con claves iguales (fijaros en el mensaje que aparece en la Consola: Joining, by = \"ID\").\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\nDF_inner_joined = \n  DF_IDs |&gt; \n  inner_join(DF_results)\n\n#nrow(DF_inner_joined)\n\nDT::datatable(DF_inner_joined)\n\n\n\n\n\n\n5.2.1.2 Left join\nPreserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales (columnas con el mismo nombre).\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\nDF_left_joined = DF_IDs |&gt; \n   left_join(DF_results)\n\n# Vemos el número de filas de cada data frame\n# nrow(DF_left_joined)\n# map(list(\"DF_left_joined\" = DF_left_joined, \"DF_IDs\" = DF_IDs, \"DF_results\" = DF_results), nrow)\n\nDT::datatable(DF_left_joined)\n\n\n\n\n\n\nSi no tenemos columnas con el mismo nombre en ambos data frames, tenemos que indicarle a la función a partir de que dos columnas queremos unir los data frames. Por ejemplo, con by = c(\"ID\" = \"Identificador\") le decimos que la columna ID el primer data frame corresponde a Identificador del segundo data frame.\n\n\n# Renombramos el identificador para que no coincidan\nDF_results2 = DF_results |&gt; rename(Identificador = ID)\n\n# Si no hay variables en común, nos da un error:\n\n# DF_left_joined = DF_IDs |&gt; \n#    left_join(DF_results2)\n  # Error in `left_join()`:\n  # ! `by` must be supplied when `x` and `y` have no common variables.\n# ℹ use by = character()` to perform a cross-join.\n\n# Tenemos que indicar explicitamente que identificador del primer data frame (DF_IDs) \n  # coincide con que identificador del segundo data frame (DF_results2)\nDF_left_joined = DF_IDs |&gt;\n   left_join(DF_results2, by = c(\"ID\" = \"Identificador\"))\n\n# En las últimas versiones de dplyr, han implementado la función `join_by()` que \n  # permite usar una sintaxis algo más natural:\n  DF_left_joined2 = DF_IDs |&gt; \n    left_join(DF_results2, by = join_by(ID == Identificador))\n\n# Comparar si todo es =\n  # waldo::compare(DF_left_joined, DF_left_joined2)\n\n\n5.2.1.3 Full join\nPreserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales.\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\nDF_full_joined = DF_IDs |&gt; \n   full_join(DF_results)\n\n# CHECK\nmap(list(\"DF_full_joined\" = DF_full_joined, \"DF_IDs\" = DF_IDs, \"DF_results\" = DF_results), nrow)\n#&gt; $DF_full_joined\n#&gt; [1] 237\n#&gt; \n#&gt; $DF_IDs\n#&gt; [1] 235\n#&gt; \n#&gt; $DF_results\n#&gt; [1] 234\n\nDT::datatable(DF_full_joined)\n\n\n\n\n\n\n5.2.2 Filtering joins\n\n5.2.2.1 Anti join\nPreserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y.\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\n# AVOID the people present in DF_BAD\nDF_anti_joined = DF_IDs |&gt; \n  anti_join(DF_BAD, by = \"ID\") |&gt; \n  left_join(DF_results)\n\n# CHECK\nmap(list(\"DF_anti_joined\" = DF_anti_joined, \"DF_IDs\" = DF_IDs, \"DF_BAD\" = DF_BAD, \"DF_results\" = DF_results), nrow)\n#&gt; $DF_anti_joined\n#&gt; [1] 226\n#&gt; \n#&gt; $DF_IDs\n#&gt; [1] 235\n#&gt; \n#&gt; $DF_BAD\n#&gt; [1] 9\n#&gt; \n#&gt; $DF_results\n#&gt; [1] 234\n\n\nDT::datatable(DF_anti_joined)\n\n\n\n\n\n\n5.2.2.2 Semi join\nPreserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y. La diferencia con inner_join() es que NO se preservan las observaciones de DF_y.\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\n# INCLUDE ONLY the people present in DF_BAD\nDF_semi_joined = DF_IDs |&gt; \n  semi_join(DF_BAD, by = \"ID\") |&gt; \n  left_join(DF_results)\n\n# CHECK\nmap(list(\"DF_semi_joined\" = DF_semi_joined,\n         \"DF_IDs\" = DF_IDs,\n         \"DF_BAD\" = DF_BAD,\n         \"DF_results\" = DF_results),\n    nrow)\n#&gt; $DF_semi_joined\n#&gt; [1] 9\n#&gt; \n#&gt; $DF_IDs\n#&gt; [1] 235\n#&gt; \n#&gt; $DF_BAD\n#&gt; [1] 9\n#&gt; \n#&gt; $DF_results\n#&gt; [1] 234\n\nDT::datatable(DF_semi_joined)\n\n\n\n\n\n\n5.2.3 Nesting joins\n\n\nDF_nest_joined = DF_IDs |&gt; \n  nest_join(DF_results, by = \"ID\")\n\nDT::datatable(DF_nest_joined)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combinar datos</span>"
    ]
  },
  {
    "objectID": "qmd/05-combinar-datos.html#ejercicios-joins",
    "href": "qmd/05-combinar-datos.html#ejercicios-joins",
    "title": "\n5  Combinar datos\n",
    "section": "Ejercicios JOINS",
    "text": "Ejercicios JOINS\nCon los DFs de abajo, haz las siguientes operaciones:\n\n\nDF_IDs = read_csv(here::here(\"data/files/02-join-IDs2.csv\"))\nDF_results = read_csv(here::here(\"data/files/02-join-results.csv\"))\nDF_BAD = read_csv(here::here(\"data/files/02-join-BAD.csv\"))\n\n\nUne los datos demográficos con los resultados.\n\n\n\n\n\n\n\nPista para unir bases:\n\n\n\n\n\nVimos en el apartado left_join() como hacer esto\n\n\n\n\nA la base resultante, quítale los sujetos descartados de DF_BAD.\n\n\n\n\n\n\n\nPista descartar filas:\n\n\n\n\n\nanti_join()!\n\n\n\n\nCrea una nueva base con datos demográficos y resultados para los sujetos descartados.\n\n\n\n\n\n\n\nPista para filtrar a partir de una base:\n\n\n\n\n\nsemi_join()!\n\n\n\n\nComprueba si el promedio para Crystallized Intelligence de los participantes descartados difiere de la de los no descartados.\n\n\n\n\n\n\n\nPista para promedios agrupados:\n\n\n\n\n\ngroup_by() |&gt; summarise()\n\n\n\n\nHaz una gráfica donde se puedan ver las diferencias\n\n\n\nEn el ejercicio 3 de verbos avanzados creaste un DF llamado DF_split con la median split a partir de la variable Social.Adaptation.\n\n\n\nDF_wide = read_csv(\n  \"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv\"\n) |&gt;\n  janitor::clean_names()\n\nmedian_social_adaptation = DF_wide |&gt;\n  pull(social_adaptation) |&gt;\n  median(., na.rm = TRUE)\n\nDF_split = DF_wide |&gt;\n  mutate(social_adaptation_split =\n           as.factor(\n             case_when(\n               social_adaptation &gt;= median_social_adaptation ~ \"high_social_adaptation\",\n               social_adaptation &lt; median_social_adaptation ~ \"low_social_adaptation\",\n               TRUE ~ NA_character_\n             )\n           )) |&gt;\n  select(id, social_adaptation, social_adaptation_split) |&gt;\n  drop_na(social_adaptation_split)\n\nDF_long = DF_wide |&gt; pivot_longer(fluid_intelligence:working_memory)\n\nUno ese DF al DF_long que habías creado en el ejercicio 2 de la misma sección. El DF final se vera así:\n\n\n\n\n\n\n\nHaz un plot donde se vea la distribución para todas las variables de resultados de los dos niveles de social_adaptation_split.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combinar datos</span>"
    ]
  },
  {
    "objectID": "qmd/05-combinar-datos.html#datasets-interesantes",
    "href": "qmd/05-combinar-datos.html#datasets-interesantes",
    "title": "\n5  Combinar datos\n",
    "section": "\n5.3 Datasets interesantes",
    "text": "5.3 Datasets interesantes\nEn los siguientes repositorios podréis encontrar datasets interesantes para jugar.\n\nfivethirtyeight\nOur World in Data\nTidyTuesday",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combinar datos</span>"
    ]
  },
  {
    "objectID": "qmd/05-combinar-datos.html#bibliografía",
    "href": "qmd/05-combinar-datos.html#bibliografía",
    "title": "\n5  Combinar datos\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nCheatsheets RStudio\ndata-carpentry-week lesson_joins\nR4ds - Joins\nTidyexplain",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combinar datos</span>"
    ]
  },
  {
    "objectID": "qmd/06-analisis-datos-exploratorio.html",
    "href": "qmd/06-analisis-datos-exploratorio.html",
    "title": "\n6  Análisis de datos exploratorio\n",
    "section": "",
    "text": "Paquetes para este capítulo\nif (!require('corrplot')) install.packages('corrplot'); library('corrplot')\nif (!require('cowplot')) install.packages('cowplot'); library('cowplot')\nif (!require('dplyr')) install.packages('dplyr'); library('dplyr')\nif (!require('gapminder')) install.packages('gapminder'); library('gapminder')\nif (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')\nif (!require('ggridges')) install.packages('ggridges'); library('ggridges')\nif (!require('haven')) install.packages('haven'); library('haven')\nif (!require('inspectdf')) install.packages('inspectdf'); library('inspectdf')\nif (!require('tidyr')) install.packages('tidyr'); library('tidyr')\nEn este capítulo vamos a aplicar lo que hemos aprendido en los dos capítulos anteriores, combinando transformación de datos con visualización para entender nuestras bases de datos, buscar patrones interesantes, etc. Podéis encontrar una introducción más completa en el manual R 4 data science - exploratory data analysis.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análisis de datos exploratorio</span>"
    ]
  },
  {
    "objectID": "qmd/06-analisis-datos-exploratorio.html#visualizando-distribuciones",
    "href": "qmd/06-analisis-datos-exploratorio.html#visualizando-distribuciones",
    "title": "\n6  Análisis de datos exploratorio\n",
    "section": "\n6.1 Visualizando distribuciones",
    "text": "6.1 Visualizando distribuciones\nPara visualizar la distribución de nuestras variables, tendremos que seguir estrategias diferentes dependiendo de si se trata de variables categóricas o continuas.\n\n6.1.1 Variables categóricas\n\n\nggplot(gapminder, aes(continent)) +\n  geom_bar()\n\ngapminder |&gt; \n  count(continent)\n#&gt; # A tibble: 5 × 2\n#&gt;   continent     n\n#&gt;   &lt;fct&gt;     &lt;int&gt;\n#&gt; 1 Africa      624\n#&gt; 2 Americas    300\n#&gt; 3 Asia        396\n#&gt; 4 Europe      360\n#&gt; 5 Oceania      24\n\n\n\n\n\n\n\n\n6.1.2 Variables continuas\nPara ver la distribución de una variable podemos empezar con un histograma sencillo.\n\n\nggplot(gapminder, aes(lifeExp)) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\n\nsummarise() nos permite ver medias, medianas, etc.\n\n\ngapminder |&gt;\n  summarise(MEAN = mean(lifeExp),\n            MEDIAN = median(lifeExp),\n            SD = sd(lifeExp),\n            MAX = max(lifeExp),\n            MIN = min(lifeExp))\n#&gt; # A tibble: 1 × 5\n#&gt;    MEAN MEDIAN    SD   MAX   MIN\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  59.5   60.7  12.9  82.6  23.6\n\nAlternativamente, hay funciones como skimr::skim() que nos muestran una panorámica muy útil de las variables de nuestro data frame. Corre la función en tu Consola para ver el output completo.\n\nskimr::skim(gapminder)\n\nData summary\n\n\nName\ngapminder\n\n\nNumber of rows\n1704\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\ncountry\n0\n1\nFALSE\n142\nAfg: 12, Alb: 12, Alg: 12, Ang: 12\n\n\ncontinent\n0\n1\nFALSE\n5\nAfr: 624, Asi: 396, Eur: 360, Ame: 300\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nyear\n0\n1\n1979.50\n17.27\n1952.00\n1965.75\n1979.50\n1993.25\n2007.0\n▇▅▅▅▇\n\n\nlifeExp\n0\n1\n59.47\n12.92\n23.60\n48.20\n60.71\n70.85\n82.6\n▁▆▇▇▇\n\n\npop\n0\n1\n29601212.32\n106157896.74\n60011.00\n2793664.00\n7023595.50\n19585221.75\n1318683096.0\n▇▁▁▁▁\n\n\ngdpPercap\n0\n1\n7215.33\n9857.45\n241.17\n1202.06\n3531.85\n9325.46\n113523.1\n▇▁▁▁▁\n\n\nEjercicios\nVariables individuales\nUsando el DF mpg, visualiza la distribución de las variables manufacturer, y hwy. Fíjate que la primera es categórica, y la segunda continua.\n\n\n\n\n\n\nPista\n\n\n\n\n\nVas a tener que elegir entre geom_bar() y geom_histogram().\nPuedes ver que pasa si usas el parámetro binwidth = 1 en geom_histogram().\n\n\n\nUsamos geom_bar() para visualizar variables discretas:\n\n\n\n\n\n\n\n\nPara variables continuas, geom_histogram():\n\n\n\n\n\n\n\n\n\nEjercicios avanzados\nUsando como base éste código:\nggplot(gapminder, aes(lifeExp, fill = continent)) +\n  geom_histogram(binwidth = 1)\n¿Podrías replicar la visualización de abajo? Queremos mostrar un histograma por continente.\n\n\n\n\n\n\nLo mejor es dividir el proceso en varios pasos\n\n\n\n\n\n 1) Empieza con el histograma de arriba.  2) recuerda que puedes usar el parámetro fill (dentro de aes), para asignar un color de relleno por nivel de una variable categórica.  3) Finalmente, usando facetas podrás crear una gráfica para cada nivel de la variable categórica facet_wrap()! \n\n\n\n\n\n\n\n\n\n\n\n¿Como podemos añadir el histograma general para poder entender donde se ubica cada continente?\n\n\n\n\n\n\nLa solución está en el capítulo 1\n\n\n\n\n\nEl paquete gghighlight es justo lo que necesitas\n\n\n\n\n\n\n\n\n\n\n\nTambién queremos ver los descriptivos por continente, ordenados por el promedio:\n\n#&gt; # A tibble: 5 × 6\n#&gt;   continent  MEAN MEDIAN    SD   MAX   MIN\n#&gt;   &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Africa     48.9   47.8  9.15  76.4  23.6\n#&gt; 2 Asia       60.1   61.8 11.9   82.6  28.8\n#&gt; 3 Americas   64.7   67.0  9.35  80.7  37.6\n#&gt; 4 Europe     71.9   72.2  5.43  81.8  43.6\n#&gt; 5 Oceania    74.3   73.7  3.80  81.2  69.1\n\n\n6.1.3 Visualizando datasets completos\nCuando nos llega una nueva base de datos, una de las primeras cosas que haremos será familiarizarnos con los datos. Cómo se distribuyen, cual es la relación entre distintas variables, etc.\nConvertimos la base a formato largo para poder filtrar los valores perdidos (i.e. 999), y crear una columna donde introducir únicamente valores numéricos:\n\nd &lt;- gapminder |&gt;\n  pivot_longer(everything(), values_transform = list(value = as.character)) |&gt;\n  filter(value != 999) |&gt; # Si existiera algún código para missing values, filtrar\n  mutate(value_NUM = as.numeric(value))\n\nVisualiza las variables numéricas usando la variables value_NUM que hemos creado:\n\nd |&gt;\n  drop_na(value_NUM) |&gt;\n  ggplot(aes(value_NUM)) +\n    facet_wrap(~ name, scales = \"free\") +\n    geom_histogram(bins = 15) #+ scale_x_log10()\n\n\n\n\n\n\n\nVisualiza variables no numéricas. Para ello, nos quedamos solo con aquellas filas donde value_NUM es una valor perdido. Esto es porque cuando antes hicimos mutate(value_NUM = as.numeric(value)), aquellos valores de value que no se pudieron convertir a numérico, quedaron como NA en value_NUM:\n\n\nd |&gt;\n  drop_na(value) |&gt;\n  filter(is.na(value_NUM)) |&gt;\n  ggplot(aes(value)) +\n    facet_wrap(~ name, scales = \"free\") +\n    geom_bar() +\n    coord_flip()\n\n\n\n\n\n\n\nHay algunos paquetes que ayudan a la exploración inicial de bases de datos, localización de datos perdidos, etc. Por ejemplo {inspectdf}.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análisis de datos exploratorio</span>"
    ]
  },
  {
    "objectID": "qmd/06-analisis-datos-exploratorio.html#covariación",
    "href": "qmd/06-analisis-datos-exploratorio.html#covariación",
    "title": "\n6  Análisis de datos exploratorio\n",
    "section": "\n6.2 Covariación",
    "text": "6.2 Covariación\n\n6.2.1 Variable categórica y continua\nPodemos contar el numero de elementos por nivel de la variable o ver densidad, etc. Esto funciona bien si tenemos pocos niveles de la variable categórica.\n\n\nggplot(gapminder, aes(lifeExp, colour = continent)) +\n  geom_freqpoly(binwidth = 2)\n\n\n\n\n\n\n\n\nPodemos usar geom_density_ridges() para combinar puntos con distribuciones:\n\n\nggplot(gapminder, aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  )\n\n\n\n\n\n\n\n\n¿Qué estamos viendo exactamente arriba? Hay un punto por cada país, y por cada año, lo que da lugar a algo difícil de interpretar.\nPodemos ver los datos únicamente del último año:\n\n\ngapminder |&gt; filter(year == max(year)) |&gt; \n  \n  ggplot(aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  )\n\n\n\n\n\n\n\n\n6.2.2 Ejercicio avanzado - Introducción\nEn este ejercicio vamos a intentar mostrar la como la distribución de esperanza de vida ha cambiado a lo largo del tiempo. Para ello, usando la base gapminder, compararemos los valores máximos y mínimos.\nEmpezamos creando dos gráficos. En cada uno filtramos por el año deseado (e.g. filter(year == min(year))). Fíjate que usamos scale_x_continuous(n.breaks = 10, limits = c(20, 90)) para que ambas gráficas compartan la misma escala en el eje x:\n\n\nA = ggplot(gapminder |&gt; filter(year == min(year)),\n           aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  ) +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(n.breaks = 10, limits = c(20, 90)) +\n  ggtitle(\"min\")\n\nB = ggplot(gapminder |&gt; filter(year == max(year)),\n           aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  ) +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(n.breaks = 10, limits = c(20, 90)) +\n  ggtitle(\"max\")\n\ncowplot::plot_grid(A, B)\n\n\n\n\n\n\n\nPara visualizar la diferencia entre los valores máximos y mínimos, podemos calcular primero cuanto ha cambiado la esperanza de vida en cada país de cada continente, y crear una gráfica con esa variable:\n\n\n# Cálculo de la diferencia entre el máximo y mínimo de lifeExp para cada country. \n  # Incluimos continent en group_by() para poder usar esa variable en la gráfica\nDF_gapminder_max_min = gapminder |&gt;\n  group_by(continent, country) |&gt;\n  summarise(lifeExp = max(lifeExp) - min(lifeExp))\n\nggplot(DF_gapminder_max_min, aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  ) +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Diferencia entre max y min por país\")\n\n\n\n\n\n\n\n\n6.2.3 Ejercicio\nArriba estamos restando la esperanza de vida máxima y mínima de cada país. Sabemos que la esperanza de vida ha mejorado con el tiempo, por lo que asumíamos que era equivalente a comparar los datos más antiguos y los más nuevos.\nPero lo que realmente queremos ver es la diferencia entre 2007 y 1952 ¿Podrías rehacer el cálculo para mostrar la diferencia entre 2007 y 1952?\n\n\n\n\n\n\nPista\n\n\n\n\n\n1. Crear un DF para cada 2007 y otro para 1952, renombrando la variable lifeExp (e.g. max_lifeExp y min_lifeExp, respectivamente)2. Usando la función full_join(), juntamos ambas bases (tendrás que usar el parámetro by = c(\"country\", \"continent\")). 3. Con mutate() calculamos la diferencia.\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.4 Dos variables categóricas\nPodemos contar el número de valores para los niveles de dos variables categóricas con count():\n\n\ndiamonds |&gt;\n  count(color, cut)\n#&gt; # A tibble: 35 × 3\n#&gt;   color cut           n\n#&gt;   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt;\n#&gt; 1 D     Fair        163\n#&gt; 2 D     Good        662\n#&gt; 3 D     Very Good  1513\n#&gt; 4 D     Premium    1603\n#&gt; 5 D     Ideal      2834\n#&gt; 6 E     Fair        224\n#&gt; # ℹ 29 more rows\n\nUna manera de visualizar esto es con geom_tile():\n\n\ndiamonds |&gt;\n  count(color, cut) |&gt;\n  ggplot(aes(color, cut, fill = n)) +\n    geom_tile()\n\n\n\n\n\n\n\n\n6.2.5 Dos variables continuas\nUna herramienta esencial para ver como covarían dos variables continuas es un scatterplot. Usaremos geom_point():\n\n\nggplot(gapminder, aes(lifeExp, gdpPercap)) +\n  geom_point()\n\n\n\n\n\n\n\nSi añadimos color y cambiamos a escala logarítmica, podemos hacernos una mejor idea:\n\nggplot(gapminder, aes(lifeExp, gdpPercap, color = continent)) +\n  geom_point(alpha = 1 / 2) +\n  scale_y_log10()\n\n\n\n\n\n\n\nCon geom_violin() podemos hacernos una idea rápida de las distribuciones. Usamos group = cut_width(lifeExp, 10) para dividir la variable continua lifeExp en chunks de 10 unidades:\n\nggplot(gapminder, aes(lifeExp, gdpPercap)) +\n  geom_violin(draw_quantiles = .5, aes(group = cut_width(lifeExp, 10))) +\n  scale_y_log10(labels = scales::comma, n.breaks = 6)\n\n\n\n\n\n\n\nCon corrplot podemos visualizar las correlaciones entre variables numéricas de nuestra base de datos.\n\ncorrplot(cor(gapminder |&gt; select(where(is.numeric))), method = \"circle\")\ncorrplot(cor(gapminder |&gt; select(where(is.numeric))), method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.6 Ejercicio covariación 2\nUsando el DF mpg, visualiza la covariación entre:\n\n\nmanufacturer y hwy\n\n\nclass y hwy\n\n\nhwy y cty\n\n\n\n\n\n\n\n\nVisualizando una variable categórica y una continua\n\n\n\n\n\ngeom_density_ridges()!\n\n\n\n\n\n\n\n\n\nVisualizando pares de variables continuas!\n\n\n\n\n\ngeom_smooth()!",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análisis de datos exploratorio</span>"
    ]
  },
  {
    "objectID": "qmd/06-analisis-datos-exploratorio.html#ejercicios-finales",
    "href": "qmd/06-analisis-datos-exploratorio.html#ejercicios-finales",
    "title": "\n6  Análisis de datos exploratorio\n",
    "section": "\n6.3 Ejercicios finales",
    "text": "6.3 Ejercicios finales\n\n6.3.1 Ejercicio exploración base nueva\nUsando la base del paper Cancer Screening Risk Literacy of Physicians in Training, haz un primer análisis exploratorio que incluya:\n\nhistogramas de todas las variables numéricas y no-numéricas\nscatterplots de la relación entre comprensión y numeracy, y entre comprensión y screenbeliefs\n\nPuedes ir al enlace anterior y descargar el archivo Cancer screening risk literacy R1.sav en la carpeta Data and results, o directamente usar el código de abajo.\n\n\n\n\n\n\nComo visualizar todas las variables\n\n\n\n\n\nVer el apartado visualizando-datasets-completos en este mismo capítulo\n\n\n\n\n\n# Usamos haven::read_sav() para leer los archivos .sav\nDF_dafina = haven::read_sav(here::here(\"data/files/Dafina\", \"Cancer screening risk literacy R1.sav\")) |&gt; as_tibble()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análisis de datos exploratorio</span>"
    ]
  },
  {
    "objectID": "qmd/06-analisis-datos-exploratorio.html#bibliografía",
    "href": "qmd/06-analisis-datos-exploratorio.html#bibliografía",
    "title": "\n6  Análisis de datos exploratorio\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análisis de datos exploratorio</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html",
    "href": "qmd/07-analisis-datos-inferencial.html",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "",
    "text": "Paquetes para este capítulo\nif (!require('afex')) install.packages('afex'); library('afex')\nif (!require('correlation')) install.packages('correlation'); library('correlation')\nif (!require('corrr')) install.packages('corrr'); library('corrr')\nif (!require('cowplot')) install.packages('cowplot'); library('cowplot')\nif (!require('dplyr')) install.packages('dplyr'); library('dplyr')\nif (!require('gapminder')) install.packages('gapminder'); library('gapminder')\nif (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')\nif (!require('ggridges')) install.packages('ggridges'); library('ggridges')\nif (!require('gtsummary')) install.packages('gtsummary'); library('gtsummary')\nif (!require('haven')) install.packages('haven'); library('haven')\nif (!require('inspectdf')) install.packages('inspectdf'); library('inspectdf')\nif (!require('knitr')) install.packages('knitr'); library('knitr')\nif (!require('lme4')) install.packages('lme4'); library('lme4')\nif (!require('papaja')) install.packages(\"papaja\"); library('papaja')\nif (!require('parameters')) install.packages('parameters'); library('parameters')\nif (!require('performance')) install.packages('performance'); library('performance')\nif (!require('report')) install.packages('report'); library('report')\nif (!require('sjPlot')) install.packages('sjPlot'); library('sjPlot')\nif (!require('tidyr')) install.packages('tidyr'); library('tidyr')",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#análisis-de-datos-y-reporte-de-resultados",
    "href": "qmd/07-analisis-datos-inferencial.html#análisis-de-datos-y-reporte-de-resultados",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "\n7.1 Análisis de datos y reporte de resultados",
    "text": "7.1 Análisis de datos y reporte de resultados\nR es un lenguaje creado por estadísicos que ha ido evolucionando hacia un lenguaje de programación completo. No obstante, una de sus fortalezas innegables es el análisis de datos, y el reporte de resultados. En esta sección vamos a ver de manera muy general algunas de las herramientas que tenemos a nuestra disposición.\n\n7.1.1 Tablas\nHay numerosos paquetes para crear tablas descriptivas o para facilitar el reporte de resultados en R:\n\n{gtsummary}\n\n{stargazer}\n\n{papaja}\n\n{flextable}\n\n{huxtable}\n\nMostraremos algunos ejemplos usando gtsummary. Una ventaja interesante es que permite de manera sencilla transformar nuestra tabla a otros formatos.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#tablas-descriptivos",
    "href": "qmd/07-analisis-datos-inferencial.html#tablas-descriptivos",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "\n7.2 Tablas descriptivos",
    "text": "7.2 Tablas descriptivos\nPodemos crear tablas con los descriptivos de nuestros datos usando la función tbl_summary() de {gtsummary}\n\n\n# Por defecto, usa: mediana (rango inter cuartil)\ngapminder |&gt; \n  select(-country) |&gt; \n  gtsummary::tbl_summary() \n\n\n\n\n\n\n\n\n\nCharacteristic\n\nN = 1,704\n1\n\n\n\n\ncontinent\n\n\n\n    Africa\n624 (37%)\n\n\n    Americas\n300 (18%)\n\n\n    Asia\n396 (23%)\n\n\n    Europe\n360 (21%)\n\n\n    Oceania\n24 (1.4%)\n\n\nyear\n1,980 (1,966, 1,993)\n\n\nlifeExp\n61 (48, 71)\n\n\npop\n7,023,596 (2,793,664, 19,585,222)\n\n\ngdpPercap\n3,532 (1,202, 9,325)\n\n\n\n\n1\nn (%); Median (IQR)\n\n\n\n\n\n\nUsando el parámetro by podemos crear columnas para cada valor de una variable:\n\n# Por continente \ngapminder |&gt; \n  select(-country) |&gt; \n  gtsummary::tbl_summary(by = continent)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nAfrica, N = 624\n1\n\n\nAmericas, N = 300\n1\n\n\nAsia, N = 396\n1\n\n\nEurope, N = 360\n1\n\n\nOceania, N = 24\n1\n\n\n\n\nyear\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n\n\nlifeExp\n48 (42, 54)\n67 (58, 72)\n62 (51, 70)\n72 (70, 75)\n74 (71, 78)\n\n\npop\n4,579,311 (1,342,075, 10,801,490)\n6,227,510 (2,962,359, 18,340,309)\n14,530,831 (3,844,393, 46,300,348)\n8,551,125 (4,331,500, 21,802,867)\n6,403,492 (3,199,213, 14,351,625)\n\n\ngdpPercap\n1,192 (761, 2,377)\n5,466 (3,428, 7,830)\n2,647 (1,057, 8,549)\n12,082 (7,213, 20,461)\n17,983 (14,142, 22,214)\n\n\n\n\n1\nMedian (IQR)\n\n\n\n\n\n\nEl parámetro statistic nos permite controlar que estadísticos mostrar en función del tipo de variable. En el caso de abajo, usaremos “promedio (desviación estándar)” para las variables continuas y “número de observaciones (% del total)” para las variables categóricas.\n\n\ngapminder |&gt; \n  select(-country) |&gt; \n  gtsummary::tbl_summary(by = continent,\n                         statistic = list(all_continuous() ~ \"{mean} ({sd})\",\n                                          all_categorical() ~ \"{n} ({p}%)\"),\n                       missing = \"ifany\") |&gt; \n  gtsummary::add_n() |&gt; \n  gtsummary::modify_spanning_header(c(\"stat_1\", \"stat_2\", \"stat_3\", \"stat_4\", \"stat_5\") ~ \"**Continent**\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\n\n\nContinent\n\n\n\n\nAfrica, N = 624\n1\n\n\nAmericas, N = 300\n1\n\n\nAsia, N = 396\n1\n\n\nEurope, N = 360\n1\n\n\nOceania, N = 24\n1\n\n\n\n\n\nyear\n1,704\n1,980 (17)\n1,980 (17)\n1,980 (17)\n1,980 (17)\n1,980 (18)\n\n\nlifeExp\n1,704\n49 (9)\n65 (9)\n60 (12)\n72 (5)\n74 (4)\n\n\npop\n1,704\n9,916,003 (15,490,923)\n24,504,795 (50,979,430)\n77,038,722 (206,885,205)\n17,169,765 (20,519,438)\n8,874,672 (6,506,342)\n\n\ngdpPercap\n1,704\n2,194 (2,828)\n7,136 (6,397)\n7,902 (14,045)\n14,469 (9,355)\n18,622 (6,359)\n\n\n\n\n1\nMean (SD)\n\n\n\n\n\n\nEjercicio - Descriptivos\nUsando la base de datos del apartado anterior:\n\n\nDF_dafina = haven::read_sav(here::here(\"data/files/Dafina\", \"Cancer screening risk literacy R1.sav\")) |&gt; as_tibble() |&gt; \n  select(IDparticipante, resident, screenbeliefs, compR1, numeracy) |&gt;  \n  rename(comprehension = compR1) \n\nIntenta reproducir la tabla de abajo. En el manual de gtsummary tienes ejemplos para todo lo que necesitarás. Busca a la función tbl_summary().\n\n\n\n\n\n\nLa tabla me muestra demasiado detalle, pero sólo quiero los promedios\n\n\n\n\n\nSi todas tus variables son continuas, puedes usar type = list(everything() ~ 'continuous'), dentro de tbl_summary() para forzar el tratamiento de variables con pocos niveles como continuas.\n\n\n\n\n\n\n\n\n\nError al añadir valor p\n\n\n\n\n\nEn la ayuda de la función: ?add_p.tbl_summary encontrarás que puedes usar algo como: add_p(test = everything() ~ \"t.test\")\n\n\n\n\n\n\n\n\n\n¿Cómo consigo poner el titulo Resident?\n\n\n\n\n\nFíjate cómo usamos modify_spanning_header() en el ejemplo anterior. Solo tienes que adaptarlo a los datos actuales, donde tenemos únicamente dos grupos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\n\n\nResident\n\n\np-value\n2\n\n\n\n\n0, N = 54\n1\n\n\n1, N = 118\n1\n\n\n\n\n\nIDparticipante\n172\n72 (51)\n93 (48)\n0.012\n\n\nScreening beliefs\n172\n27.4 (5.0)\n28.4 (6.8)\n0.3\n\n\nComprehension of the evidence\n172\n2.91 (1.28)\n2.54 (1.16)\n0.077\n\n\nNumeracy BNT-S\n172\n3.70 (1.54)\n2.87 (1.56)\n0.001\n\n\n\n\n\n1\nMean (SD)\n\n\n\n\n2\nWelch Two Sample t-test",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#tablas-resultados-inferenciales",
    "href": "qmd/07-analisis-datos-inferencial.html#tablas-resultados-inferenciales",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "\n7.3 Tablas resultados inferenciales",
    "text": "7.3 Tablas resultados inferenciales\nPara tablas con los resultados de nuestros modelos estadísticos, usamos la función tbl_regression() de {gtsummary}\nPrimero preparamos los datos:\n\n\n# Transform variables\nDF_gapminder = gapminder |&gt; \n  # Log\n  mutate(gdpPercap_log = log(gdpPercap),\n         pop_log = log(pop)\n         ) |&gt; \n  # Mean center variables so the 0 values have meaning\n  mutate(year = year - mean(year, na.rm = TRUE),\n         gdpPercap_log = gdpPercap_log - mean(gdpPercap_log, na.rm = TRUE),\n         pop_log = pop_log - mean(pop_log, na.rm = TRUE)) |&gt; \n  # Will use only last year\n  filter(year == max(year))\n\nCreamos un modelo sencillo y mostramos la tabla de resultados.\n\n\nmodel1 = lm(lifeExp ~ gdpPercap_log + pop_log, DF_gapminder)\n\ntable_model1 = gtsummary::tbl_regression(model1, intercept = TRUE) |&gt; \n  add_global_p() |&gt;\n  bold_labels() |&gt; \n  italicize_levels() |&gt; \n  add_glance_table(include = c(\"nobs\", \"df.residual\", \"r.squared\", \"adj.r.squared\"))\n\n\ntable_model1\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n(Intercept)\n63\n62, 65\n&lt;0.001\n\n\ngdpPercap_log\n7.2\n6.4, 8.1\n&lt;0.001\n\n\npop_log\n0.81\n0.04, 1.6\n0.039\n\n\nNo. Obs.\n142\n\n\n\n\nResidual df\n139\n\n\n\n\nR²\n0.665\n\n\n\n\nAdjusted R²\n0.660\n\n\n\n\n\n\n1\nCI = Confidence Interval",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#reporte-de-resultados",
    "href": "qmd/07-analisis-datos-inferencial.html#reporte-de-resultados",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "\n7.4 Reporte de resultados",
    "text": "7.4 Reporte de resultados\nCon la función report() podemos ver una descripción completa de los resultados de nuestro modelo:\n\n  report::report(model1)\n#&gt; We fitted a linear model (estimated using OLS) to predict lifeExp with\n#&gt; gdpPercap_log and pop_log (formula: lifeExp ~ gdpPercap_log + pop_log). The\n#&gt; model explains a statistically significant and substantial proportion of\n#&gt; variance (R2 = 0.66, F(2, 139) = 137.93, p &lt; .001, adj. R2 = 0.66). The\n#&gt; model's intercept, corresponding to gdpPercap_log = 0 and pop_log = 0, is at\n#&gt; 63.28 (95% CI [61.98, 64.58], t(139) = 96.30, p &lt; .001). Within this model:\n#&gt; \n#&gt;   - The effect of gdpPercap log is statistically significant and positive\n#&gt; (beta = 7.24, 95% CI [6.38, 8.11], t(139) = 16.56, p &lt; .001; Std. beta =\n#&gt; 0.81, 95% CI [0.72, 0.91])\n#&gt;   - The effect of pop log is statistically significant and positive (beta =\n#&gt; 0.81, 95% CI [0.04, 1.58], t(139) = 2.09, p = 0.039; Std. beta = 0.10, 95%\n#&gt; CI [5.35e-03, 0.20])\n#&gt; \n#&gt; Standardized parameters were obtained by fitting the model on a standardized\n#&gt; version of the dataset. 95% Confidence Intervals (CIs) and p-values were\n#&gt; computed using a Wald t-distribution approximation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#texto-inline",
    "href": "qmd/07-analisis-datos-inferencial.html#texto-inline",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "\n7.5 Texto inline",
    "text": "7.5 Texto inline\nAlgo genial de gtsummary, es que podemos usar las propias tablas para extraer detalles de los resultados y usarlos directamente en el texto.\nEl paquete report tiene también funcionalidades muy potentes que merece la pena explorar.\nLa ventaja de escribir los resultados de esta manera es que si hacemos algún pequeño cambio en la preparación de datos, podemos volver a correr el script de generación del reporte de resultados, y los valores p, etc. se ajustarán automáticamente. Únicamente tenemos que asegurarnos que la interpretación cualitativa no cambia :)\n\n\npaste0(\n  \"Life expectancy was significantly associated with GDP per capita (log), beta = \",\n  gtsummary::inline_text(table_model1, variable = gdpPercap_log)\n)  \n#&gt; [1] \"Life expectancy was significantly associated with GDP per capita (log), beta = 7.2 (95% CI 6.4, 8.1; p&lt;0.001)\"",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#ejercicio---resultados-inferenciales",
    "href": "qmd/07-analisis-datos-inferencial.html#ejercicio---resultados-inferenciales",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "Ejercicio - Resultados inferenciales",
    "text": "Ejercicio - Resultados inferenciales\nUsando la misma base de datos del ejercicio anterior:\n\n\nDF_dafina = haven::read_sav(\"../data/files/Dafina/Cancer screening risk literacy R1.sav\") |&gt;\n  as_tibble() |&gt;\n  select(IDparticipante, resident, screenbeliefs, compR1, numeracy) |&gt;\n  rename(comprehension = compR1) \n\nHaz una regresión lineal prediciendo compresión a partir de las otras variables de la base.\nFinalmente, crea una tabla similar a la siguiente para reportar los resultados de tu análisis. Recuerda que en el manual de gtsummary tienes ejemplos para todo lo que necesitarás. En concreto, tbl_regression() es tu amiga:\n\n\n\n\n\n\nFunciones necesarias\n\n\n\n\n\nadd_global_p() para los valores p. bold_labels() para poner en negrita los nombres de variables\n\n\n\n\n\n\n\n\n\nComo añadir información en el pie de la tabla\n\n\n\n\n\nTendrás que usar la función add_glance_source_note() o add_glance_table(). Para saber que nombres poner en el parámetro include, puedes usar la función broom::glance(model), donde model es el nombre que has usado para tu modelo estadístico. \n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\n      \nBeta\n\n      \n\n95% CI\n\n1\n\n      \np-value\n\n    \n\n\n(Intercept)\n2.8\n1.9, 3.8\n&lt;0.001\n\n\nResident\n-0.23\n-0.62, 0.17\n0.3\n\n\nScreening beliefs\n-0.02\n-0.05, 0.01\n0.2\n\n\nNumeracy BNT-S\n0.14\n0.03, 0.26\n0.016\n\n\n\n\nNo. Obs. = 172; Adjusted R² = 0.047; Residual df = 168; Statistic = 3.83; p-value = 0.011; df = 3\n\n    \n\n\n1 \nCI = Confidence Interval",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#unir-tablas",
    "href": "qmd/07-analisis-datos-inferencial.html#unir-tablas",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "\n7.6 Unir tablas",
    "text": "7.6 Unir tablas\nDe manera muy sencilla podemos unir varias tablas. Esto es útil, por ejemplo, para mostrar los resultados de regresiones jerárquicas:\n\n\n# Primero creamos un modelo más sencillo, basado en el anterior\nmodel10 = lm(lifeExp ~ gdpPercap_log, DF_gapminder)\n\n# Creamos la tabla\ntable_model10 = gtsummary::tbl_regression(model10, intercept = TRUE) |&gt;\n  add_global_p() |&gt;\n  bold_labels() |&gt;\n  italicize_levels() |&gt;\n  add_glance_table(include = c(\"nobs\", \"df.residual\", \"r.squared\", \"adj.r.squared\"))\n\n# Combinamos ambas tablas\ntbl_merge(\n  tbls = list(table_model10, table_model1),\n  tab_spanner = c(\"**Baseline**\", \"**Step 1**\")) |&gt; \n  # Necesario para que los parámetros globales de los modelos se muestren al final\n  modify_table_body(~.x |&gt; arrange(row_type == \"glance_statistic\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\n\nBaseline\n\n\n\nStep 1\n\n\n\nBeta\n\n95% CI\n1\n\np-value\nBeta\n\n95% CI\n1\n\np-value\n\n\n\n\n(Intercept)\n64\n62, 65\n&lt;0.001\n63\n62, 65\n&lt;0.001\n\n\ngdpPercap_log\n7.2\n6.3, 8.1\n&lt;0.001\n7.2\n6.4, 8.1\n&lt;0.001\n\n\npop_log\n\n\n\n0.81\n0.04, 1.6\n0.039\n\n\nNo. Obs.\n142\n\n\n142\n\n\n\n\nResidual df\n140\n\n\n139\n\n\n\n\nR²\n0.654\n\n\n0.665\n\n\n\n\nAdjusted R²\n0.652\n\n\n0.660\n\n\n\n\n\n\n1\nCI = Confidence Interval",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#otros-análisis-y-sus-tablas",
    "href": "qmd/07-analisis-datos-inferencial.html#otros-análisis-y-sus-tablas",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "\n7.7 Otros análisis y sus tablas",
    "text": "7.7 Otros análisis y sus tablas\nQue test estadístico debería usar, con código en R\n\n\n\n7.7.1 Correlación simple\n\n\n# Data\niris |&gt; as_tibble()\n#&gt; # A tibble: 150 × 5\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt;          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n#&gt; 1          5.1         3.5          1.4         0.2 setosa \n#&gt; 2          4.9         3            1.4         0.2 setosa \n#&gt; 3          4.7         3.2          1.3         0.2 setosa \n#&gt; 4          4.6         3.1          1.5         0.2 setosa \n#&gt; 5          5           3.6          1.4         0.2 setosa \n#&gt; 6          5.4         3.9          1.7         0.4 setosa \n#&gt; # ℹ 144 more rows\n\n# Test\nsimple_corr_test = cor.test(iris$Sepal.Width, iris$Sepal.Length, method = \"spearman\")\n\n# Report\nsimple_corr_test |&gt; report::report()\n#&gt; Effect sizes were labelled following Funder's (2019) recommendations.\n#&gt; \n#&gt; The Spearman's rank correlation rho between iris$Sepal.Width and\n#&gt; iris$Sepal.Length is negative, statistically significant, and small (rho =\n#&gt; -0.17, S = 6.56e+05, p = 0.041)\n\n\n7.7.2 Multiples correlaciones\n\n\n# Multiple correlations\ntable_correlations = iris |&gt; \n  correlation(partial = FALSE, method = \"spearman\")\n\n# Print table\nTABLE_CORR = table_correlations |&gt; \n  summary(stars = FALSE, include_significance = TRUE, p_digits = 3) \n\n# Fancy table\nTABLE_CORR |&gt; \n  parameters::print_md()\n\n\nCorrelation Matrix (spearman-method)\n\n\n\n\n\n\n\nParameter\nPetal.Width\nPetal.Length\nSepal.Width\n\n\n\nSepal.Length\n0.83 (p &lt; .001)\n0.88 (p &lt; .001)\n-0.17 (p = 0.041)\n\n\nSepal.Width\n-0.29 (p &lt; .001)\n-0.31 (p &lt; .001)\n\n\n\nPetal.Length\n0.94 (p &lt; .001)\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n7.7.3 Anova\n\nVer paquete {afex}\n\n\n\n\ndata(obk.long, package = \"afex\")\nhead(obk.long)\n#&gt;   id treatment gender   age phase hour value\n#&gt; 1  1   control      M -4.75   pre    1     1\n#&gt; 2  1   control      M -4.75   pre    2     2\n#&gt; 3  1   control      M -4.75   pre    3     4\n#&gt; 4  1   control      M -4.75   pre    4     2\n#&gt; 5  1   control      M -4.75   pre    5     1\n#&gt; 6  1   control      M -4.75  post    1     3\n\n# estimate mixed ANOVA on the full design:\nmodel = afex::aov_ez(id = \"id\", \n                     dv = \"value\", \n                     data = obk.long, between = c(\"treatment\"), \n        within = c(\"phase\", \"hour\"))\n\n  \n  table_afex = papaja::apa_print(model)$table\n  knitr::kable(table_afex)\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nconf.int\nstatistic\ndf\ndf.residual\np.value\n\n\n\nTreatment\n.211\n[.000, .468]\n2.91\n2\n13\n.090\n\n\nPhase\n.164\n[.000, .356]\n19.29\n1.74\n22.64\n&lt; .001\n\n\nHour\n.129\n[.000, .237]\n18.44\n1.95\n25.41\n&lt; .001\n\n\nTreatment \\(\\times\\) Phase\n.099\n[.000, .212]\n5.43\n3.48\n22.64\n.004\n\n\nTreatment \\(\\times\\) Hour\n.001\n[.000, .000]\n0.08\n3.91\n25.41\n.987\n\n\nPhase \\(\\times\\) Hour\n.017\n[.000, .000]\n1.35\n4.02\n52.29\n.265\n\n\nTreatment \\(\\times\\) Phase \\(\\times\\) Hour\n.008\n[.000, .000]\n0.33\n8.05\n52.29\n.951\n\n\n\n\n\n\n7.7.4 Modelos mixtos\nPrimero preparamos los datos:\n\n\n# Transform variables\nDF_gapminder2 = gapminder |&gt; \n  # Log\n  mutate(gdpPercap_log = log(gdpPercap),\n         pop_log = log(pop)\n         ) |&gt; \n  # Mean center variables so the 0 values have meaning\n  mutate(year = year - mean(year, na.rm = TRUE),\n         gdpPercap_log = gdpPercap_log - mean(gdpPercap_log, na.rm = TRUE),\n         pop_log = pop_log - mean(pop_log, na.rm = TRUE))\n\n# Reference levels and contrast coding\nDF_gapminder2 &lt;- within(DF_gapminder2, continent &lt;- relevel(continent, ref = \"Oceania\"))\ncontrasts(DF_gapminder2$continent) = car::contr.Sum(levels(DF_gapminder2$continent))\n\nCreamos un modelo sencillo:\n\n\nmodel2 = lme4::lmer(lifeExp ~ gdpPercap_log + pop_log + year + (1|country), DF_gapminder2)\n\n# Extraemos los R2 del modelo para usar en la tabla\nR2_1 = performance::r2(model2)\n  \n\nY mostramos la tabla de resultados. Como se trata de modelos mixtos, tenemos que añadir manualmente los R2’s.\n\ntable_model2 = gtsummary::tbl_regression(model2) |&gt;  #, intercept = TRUE\n  add_global_p() |&gt;\n  bold_labels() |&gt;\n  italicize_levels() |&gt;\n  add_glance_source_note(include = c(\"nobs\", \"df.residual\"))\n\n# broomExtra::glance_performance(model2)\n\ntable_model2 |&gt; \n  as_gt() |&gt; \n  gt::tab_source_note(gt::md(\n    paste0(\n      deparse1(model2@call$formula),\n      \"&lt;BR&gt; \",\n      \"R2 conditional = \",\n      round(R2_1$R2_conditional, 3),\n      \", R2 marginal = \",\n      round(R2_1$R2_marginal, 3)\n    )\n  ))\n\n\n\n\n\nCharacteristic\n\n      \nBeta\n\n      \n\n95% CI\n\n1\n\n      \np-value\n\n    \n\n\ngdpPercap_log\n3.3\n2.8, 3.8\n&lt;0.001\n\n\npop_log\n6.1\n5.4, 6.9\n&lt;0.001\n\n\nyear\n0.15\n0.13, 0.17\n&lt;0.001\n\n\n\n\n\nNo. Obs. = 1,704; Residual df = 1,698\n\n    \n\n\nlifeExp ~ gdpPercap_log + pop_log + year + (1 | country) R2 conditional = 0.964, R2 marginal = 0.49\n\n    \n\n\n\n1 \nCI = Confidence Interval",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/07-analisis-datos-inferencial.html#bibliografía",
    "href": "qmd/07-analisis-datos-inferencial.html#bibliografía",
    "title": "\n7  Análisis de datos inferencial\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Análisis de datos inferencial</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html",
    "href": "qmd/08-quarto.html",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "",
    "text": "Paquetes para este capítulo\nif (!require('afex')) install.packages('afex'); library('afex')\n  if (!require('correlation')) install.packages(\"correlation\"); library('correlation')\n  if (!require('corrr')) install.packages('corrr'); library('corrr')\n  if (!require('dplyr')) install.packages('dplyr'); library('dplyr')\n  if (!require('DT')) install.packages('DT'); library('DT')\n  if (!require('ggraph')) install.packages('ggraph'); library('ggraph')\n  if (!require('grateful')) install.packages('grateful'); library('grateful')\n  if (!require('here')) install.packages('here'); library('here')\n  if (!require('gtsummary')) install.packages('gtsummary'); library('gtsummary')\n  if (!require('knitr')) install.packages('knitr'); library('knitr')\n  if (!require('papaja')) install.packages(\"papaja\"); library('papaja')\n  if (!require('parameters')) install.packages('parameters'); library('parameters')\n  if (!require('quarto')) install.packages(\"quarto\"); library('quarto')\n  if (!require('remotes')) install.packages('remotes'); library('remotes')\n  if (!require('renv')) install.packages(\"renv\"); library('renv')\n  if (!require('report')) install.packages(\"report\"); library('report')\n  if (!require('rticles')) install.packages('rticles'); library('rticles')\n  if (!require('see')) install.packages(\"see\"); library('see')\n  if (!require('sjPlot')) install.packages('sjPlot'); library('sjPlot')\n  if (!require('stringi')) install.packages('stringi'); library('stringi')\n  if (!require('tinytex')) install.packages('tinytex'); library('tinytex')\n  if (!require('usethis')) install.packages('usethis'); library('usethis')",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#que-es-la-reproducibilidad",
    "href": "qmd/08-quarto.html#que-es-la-reproducibilidad",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "\n8.1 Que es la reproducibilidad",
    "text": "8.1 Que es la reproducibilidad\n\n\nLa crisis de replicación (replication crisis) se inició con un paper que trató de replicar los resultados de 100 investigaciones clásicas. Esta crisis ha generado un movimiento muy interesante dentro de las Ciencias Sociales y la Psicología en particular. Cada vez es más común aplicar algunos principios de buenas prácticas como compartir materiales, datos y scripts de análisis, para que tanto los revisores como otros investigadores puedan entender, reanalizar, etc. nuestras investigaciones.\nHay algunas organizaciones que han surgido para tratar de mejorar la colaboración, transparencia, y manera de trabajar, como el Psychological Science Accelerator, la Peer Reviewer’s Openness Initiative (PRO), o la Open Science Foundation. Una de las soluciones propuestas para resolver muchos de los problemas actuales pasa por los Registered reports. En estos se da una restructured submission timeline: Before collecting data, authors submit a study protocol containing their hypotheses, planned methods, and analysis pipeline, which undergoes peer review. La última evolución de los Registered Reports es la Peer Community in Registered Reports, la cual establece un sistema de revisión de RR global, independiente de las revistas.\nAdemás de los motivos científicos para trabajar de manera más transparente y reproducible, hay también motivos prácticos. Si trabajamos de manera reproducible, las modificaciones en tablas, gráficas, número de participantes o reanálisis son triviales. En este capítulo vamos a ver algunos pasos fundamentales para tender un workflow que permita y ayude a la reproducibilidad.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#proyectos-de-r-studio",
    "href": "qmd/08-quarto.html#proyectos-de-r-studio",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "\n8.2 Proyectos de R-Studio",
    "text": "8.2 Proyectos de R-Studio\nEl primer paso empieza por crear un proyecto de RStudio. Al usar proyectos, simplificamos varias cosas, haciendo más fácil compartir nuestro trabajo con otras personas, retomar nuestro trabajo, detectar cambios, etc. Podéis leer algo más sobre esto aquí.\n Para crear un nuevo proyecto de RStudio, haz click en este icono (o File -&gt; New Project), y sigue las instrucciones paso a paso del New Project Wizard:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#quartormarkdown-openscience-y-análisis-reproducibles",
    "href": "qmd/08-quarto.html#quartormarkdown-openscience-y-análisis-reproducibles",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "\n8.3 Quarto/RMarkdown, openscience y análisis reproducibles",
    "text": "8.3 Quarto/RMarkdown, openscience y análisis reproducibles\nQuarto quarto o RMarkdown son herramientas que nos permiten combinar texto formateado con código y resultados en un mismo documento (html, pdf, docx, …). Quarto es una evolución de Rmarkdown, y que facilita la interoperabilidad entre R, Python, Julia, etc. La diferencia esencial es que usaremos archivos .qmd en lugar de .Rmd, y que tendremos que instalar quarto en nuestro ordenador. Pero en general, resulta trivial convertir nuestros archivos Rmd a qmd (solo hay que renombrarlos).\nAprovechando la potencia de estas herramientas, algunas personas han creado paquetes para preparar artículos en formato APA, o con las plantillas de decenas de editoriales.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#sintaxis-chunks-de-código-tipos-de-archivo",
    "href": "qmd/08-quarto.html#sintaxis-chunks-de-código-tipos-de-archivo",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "\n8.4 Sintaxis, chunks de código, tipos de archivo",
    "text": "8.4 Sintaxis, chunks de código, tipos de archivo\nLa sintaxis básica de Quarto / RMarkdown es sorprendentemente sencilla, como se puede ver más abajo. Eso si, lo que hay detrás es toda la potencia de latex, así que el cielo es el límite.\n\nY como no, tenemos mucha ayuda:\n\n\nquarto\n\n\nMarkdown basics\n\n\nR Markdown: The Definitive Guide\n\nWeb oficial de Rmarkdown dentro de RStudio\n\nResumiendo, tienes tres elementos básicos:\n\n8.4.1 Cabecera YAML\nCuando creas un documento .qmd nuevo verás algo similar a lo siguiente en las primeras lineas:\n---\ntitle: \"Untitled\"\n---\nEsta es la cabecera YAML, en la cual se le pueden pasar parámetros para añadir un índice, cambiar formato, y muchas otras cosas.\n\n8.4.2 Markdown\nEn el resto del documento (con la excepción de los chunks de código), el formato que usaremos será Markdown. Su sintaxis es muy sencilla pero nada tolerante. Podéis ver las bases en la Markdown basics.\nIMPORTANTE. Si algo no funciona como esperas:\n\n\n\n\n\n\nSi algo no funciona\n\n\n\n\nAñade saltos de linea entre párrafos.\n\nAñade dos espacios al final de las líneas.\n\nAñade un espacio después de #:\n\nMAL: #Título grande\n\nBIEN: # Título grande\n\n\n\n\n\n\n\n8.4.3 Chunks de código\nLos chunks de código están delimitados por:\n\nEn su interior, puedes usar código R como si estuvieras en un script de R normal.\n\n\nlibrary(dplyr)\n\nmyvariable = c(1, 2, 3)\n\nPara insertar un chunk de código, solo tienes que hacer Control + Alt + I.\nEn su cabecera puedes añadir opciones. Hay una cantidad apabullante de opciones. Por ejemplo, en el siguiente chunk:\n{r nombre_chunk, eval=TRUE, include=TRUE, fig.height=10, fig.width=12, message=FALSE, warning=FALSE, cache=TRUE, results='asis'}\n\n\n\n\n\n\nParametros chunks\n\n\n\n\n\necho=FALSE: Esconde el código pero este sigue corriendo\n\neval=TRUE: Evalúa el código\n\ninclude=TRUE: Incluye el código\n\nfig.height=10: altura de los plots (en inches)\n\nfig.width=12: ancho de los plots (en inches)\n\nmessage=FALSE: NO muestres mensajes\n\nwarning=FALSE: NO muestres warnings\n\ncache=TRUE: cachea el output del plot\n\nresults='asis': muestra el output tal cual (importante cuando el output es en latex/pdf)\n\n\n\n\nTRUCO:\n\nSi tienes un chunk llamado setup al principio de tu documento .qmd / .Rmd, cada vez que reinicies RStudio y ejecutes código en cualquier parte de tu documento, ese bloque se ejecutara automáticamente. Esto es ideal para poner tus librerías, lectura de datos…",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#ejercicio-básico-quarto-rmarkdown",
    "href": "qmd/08-quarto.html#ejercicio-básico-quarto-rmarkdown",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "Ejercicio básico Quarto / RMarkdown",
    "text": "Ejercicio básico Quarto / RMarkdown\nVamos a crear un nuevo documento .qmd:\n\nFile -&gt; New File -&gt; Quarto document\nSelecciona el formato de output que prefieras. Por ejemplo, PDF\n\nAhora hagamos lo siguiente:\n\nDale formato de artículo científico, creando las siguientes secciones:\n\n\nTitle\nAbstract\nIntroducción\n\nMaterials and Methods\n\nParticipants\nMaterials\n\n\nResults\n\nExperiment 1\n\n\nDiscussion\nBibliography\n\n\nPon texto de relleno dentro de cada sección. Para ello puedes usar la función stringi::stri_rand_lipsum(n_paragraphs = 1) del paquete {stringi}. Los chunks de código deberán ser similares a este:\n\n\n\\`\\`\\`{r, echo=FALSE, results='asis'}  \n\ncat(stringi::stri_rand_lipsum(n_paragraphs = 1))  \n\n\\`\\`\\`  \n\n\nRenderiza tu documento en formato PDF.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#section",
    "href": "qmd/08-quarto.html#section",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "",
    "text": "El resultado del ejercicio anterior deberá ser un archivo pdf con la estructura general de un artículo científico. Puedes ver el archivo qmd y su pdf resultante en data/files/07-markdown/.\nSi el botón Render no funciona, puedes renderizar el pdf usando: quarto::quarto_render(\"data/files/07-rmarkdown/ejercicio-basico.Rmd\", output_format = \"pdf\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#ejercicio-avanzado",
    "href": "qmd/08-quarto.html#ejercicio-avanzado",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "Ejercicio avanzado",
    "text": "Ejercicio avanzado\nUsando una base propia, incluye en el documento .qmd de antes:\n\nUna tabla de descriptivos.\nUna tabla con los resultados de un análisis sencillo (e.g. una regresión lineal).\n\nPodéis ver ejemplos de tablas de descriptivos o tablas de resultados inferenciales en el capítulo anterior.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#section-1",
    "href": "qmd/08-quarto.html#section-1",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "",
    "text": "El resultado de este ejercicio deberá ser un archivo pdf como el que se puede ver en data/files/07-markdown/.\nDe nuevo, si el botón Render no funciona, puedes renderizar el pdf usando: quarto::quarto_render(\"data/files/07-rmarkdown/ejercicio-avanzado.Rmd\", output_format = \"pdf\")",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#avanzado",
    "href": "qmd/08-quarto.html#avanzado",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "\n8.5 Avanzado",
    "text": "8.5 Avanzado\nPuedes crear artículos en formato APA, añadir bibliografía a tus documentos fácilmente, citar los paquetes de R que usas, etc.\n\n8.5.1 Artículos APA con Papaja\n\nPreparar artículos en formato APA\n\n\n\ninstall.packages(\"papaja\")\n\n# Create new R Markdown file\nrmarkdown::draft(\n  here::here(\"data\", \"output\", \"mymanuscript.Rmd\"), \n  \"apa6\", \n  package = \"papaja\", \n  create_dir = FALSE,\n  edit = FALSE)\n\n# Render manuscript\nrmarkdown::render(\n  here::here(\"data\", \"output\", \"mymanuscript.Rmd\"), \n  quiet = TRUE,\n  clean = TRUE)\n\nY no olvidemos el paquete {rticles}, que contiene plantillas de decenas de editoriales\n\n8.5.2 Usar bibliografía\nPuedes incluir citas en tu documento fácilmente con Rmarkdown o Quarto.\nNecesitaras un archivo .bib e incluirlo en el yaml inicial, por ejemplo: bibliography: name_file.bib.\nA partir de ahí, puedes citar artículos simplemente incluyendo Blah Blah [@wickham2015; @knuth1984]. o @knuth1984 says blah..\nPara saber más:\n\nhttps://quarto.org/docs/authoring/footnotes-and-citations.html\nhttps://blog.rstudio.com/2020/11/09/rstudio-1-4-preview-citations/\nhttps://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html\nhttps://www.r-bloggers.com/bibliography-with-knitr-cite-your-references-and-packages/\n\n8.5.3 Citar los paquetes que usamos\n¿Debemos citar los paquetes que usamos?\n\nRespuesta corta, si\n\nRespuesta larga, la mayoría de los paquetes\n\n\nUna manera muy sencilla de hacer esto es usando {grateful}.\n\n\ngrateful::cite_packages(\n  pkgs = \"All\",\n  output = \"file\",\n  out.format = \"Rmd\",\n  include.RStudio = TRUE,\n  out.dir = \"~/Downloads\"\n)\n\n\n8.5.4 Manejo de dependencias\nUsando un sistema de manejo de dependencias renv creamos un snapshot de las librerías usadas actualmente. Es muy importante para garantizar que nuestros scripts correrán en el futuro.\n\n\n\n\n\n\nFuncionamiento básico renv\n\n\n\n\nInstalamos renv: install.packages(\"renv\")\nInicializamos el entorno local de un nuevo proyecto, con una librería privada de R renv::init()\nTrabajamos en el proyecto, instalando los paquetes que necesitemos\nGuardamos el estado de las librerías usadas en el proyecto en un lockfile (llamado renv.lock), renv::snapshot()\nRestauramos el estado de las librerías a partir del lockfile generado por renv::snapshot(). renv::restore()\n\n\n\n\n8.5.5 Shortcuts!\n\nAlt+SHIFT+K: Ver shortcuts!\n\nCTRL+SHIFT+M: Pipe\nCTRL+SHIFT+A: Reformat code\n\nCTRL+I: Reindent lines\n\n8.5.6 Estilo\nEs recomendable ser consistente en la manera de escribir código. Habitualmente se recomienda seguir una guía de estilo. Por ejemplo, Hadley Wickham’s Style guide o la guia de estilo del tidyverse.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/08-quarto.html#bibliografía",
    "href": "qmd/08-quarto.html#bibliografía",
    "title": "\n8  Trabajo con Quarto para reportes reproducibles\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nGuia de estilo del tidyverse\nHadley Wickham’s Style guide\ntargets\nScheel, A. M., Schijen, M., & Lakens, D. (in press). An excess of positive results: Comparing the standard Psychology literature with Registered Reports. Advances in Methods and Practices in Psychological Science.\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nYihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html\n\nMas cosas sobre reproducibilidad:\n\nReproducibility project: Psychology\nMany labs 2",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Trabajo con Quarto para reportes reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html",
    "href": "qmd/09-git.html",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "",
    "text": "Paquetes para este capítulo\nif (!require('afex')) install.packages('afex'); library('afex')\n  if (!require('correlation')) install.packages(\"correlation\"); library('correlation')\n  if (!require('corrr')) install.packages('corrr'); library('corrr')\n  if (!require('dplyr')) install.packages('dplyr'); library('dplyr')\n  if (!require('DT')) install.packages('DT'); library('DT')\n  if (!require('ggraph')) install.packages('ggraph'); library('ggraph')\n  if (!require('here')) install.packages('here'); library('here')\n  if (!require('gtsummary')) install.packages('gtsummary'); library('gtsummary')\n  if (!require('knitr')) install.packages('knitr'); library('knitr')\n  if (!require('papaja')) install.packages(\"papaja\"); library('papaja')\n  if (!require('parameters')) install.packages('parameters'); library('parameters')\n  if (!require('remotes')) install.packages('remotes'); library('remotes')\n  if (!require('renv')) install.packages(\"renv\"); library('renv')\n  if (!require('report')) install.packages(\"report\"); library('report')\n  if (!require('rticles')) install.packages('rticles'); library('rticles')\n  if (!require('see')) install.packages(\"see\"); library('see')\n  if (!require('sjPlot')) install.packages('sjPlot'); library('sjPlot')\n  if (!require('stringi')) install.packages('stringi'); library('stringi')\n  if (!require('tinytex')) install.packages('tinytex'); library('tinytex')\n  if (!require('usethis')) install.packages('usethis'); library('usethis')",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#git",
    "href": "qmd/09-git.html#git",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "\n9.1 Git",
    "text": "9.1 Git\n\n\n\nSOURCE: https://xkcd.com/1597/\n\n\nUn segundo elemento que nos va a ayudar a trabajar en equipo, y a evitar problemas en proyectos relativamente complejos es el uso de un sistema de control de versiones como Git. Los proyectos de RStudio hacen especialmente sencillo usar algunas funcionalidades básicas de Git.\nAlgunas referencias útiles:\n\n\nOhshitGit website\n\n\nGit in practice\n\nhappygitwithr",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#github",
    "href": "qmd/09-git.html#github",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "\n9.2 Github",
    "text": "9.2 Github\n\n\n\nSOURCE: github.githubassets.com\n\n\nGithub es una plataforma web muy popular donde almacenar proyectos de programación que usa como motor. Muchos de los paquetes de R, el mismo RStudio, etc, tienen repositorios abiertos en Github. Una de las ventajas fundamentales de usar Github es que esta plataforma integra algunas herramientas para hacer más sencillo el control de versiones, como el pull request, que nos permite combinar ramas de proyectos sin apenas problemas.\nGithub tiene un programa especial para estudiantes: https://education.github.com/",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#clonar-repo",
    "href": "qmd/09-git.html#clonar-repo",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "\n9.3 Clonar un repositorio existente",
    "text": "9.3 Clonar un repositorio existente\nAlgo que podemos hacer con todos los repositorios de Github es clonarlos localmente:\n\n\n\n\n\n\nClonar repositorio Github\n\n\n\nPrimero, copiamos la repository URL del repo de Github (ver imagen de abajo). Será algo similar a https://github.com/VUESTRO_NOMBRE_DE_USUARIO/NOMBRE_REPOSITORIO.git\n\n\n\n\n\n\nSegundo, en RStudio: File &gt; New Project &gt; Version Control &gt; Git",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#crear-un-proyecto-en-rstudio-asociado-a-github",
    "href": "qmd/09-git.html#crear-un-proyecto-en-rstudio-asociado-a-github",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "\n9.4 Crear un proyecto en RStudio asociado a Github",
    "text": "9.4 Crear un proyecto en RStudio asociado a Github\nTener nuestros proyectos de RStudio asociados a repositorios en Github es muy útil para poder compartir el código y datos asociados a nuestras investigaciones, disponer de una copia de seguridad online, y, si lo usamos adecuadamente, detectar de manera más rápida cual de los últimos cambios es responsable de los errores que nos aparezcan.\n\n\n\n\n\n\nCreando personal access token\n\n\n\nLa primera vez que usemos Github asociado a RStudio tendremos que crear un personal access token.\nMétodo automático:\nusethis::create_github_token()\nMétodo manual, como los animales:\nEn tu página de Github, haz click en tu icono (arriba a la derecha) -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens -&gt; [Generate new token] -&gt; Give gist, repo and workflow permissions.\n\n\nLa manera más sencilla de tener un proyecto de RStudio vinculado a repositorio de Github es empezar creando un repositorio en Github.\n\n\n\n\n\n\nEmpezando desde 0 [recomendado]\n\n\n\nPodemos empezar creando un repositorio en Github, para después clonarlo localmente. Para eso, en Github:\n\nCreamos repositorio nuevo\nInitialize this repository with a README\nClonar repositorio\n\n\n\nAlternativamente, si ya tenemos un proyecto de RStudio y hemos avanzado en nuestra preparación, análisis de datos, etc. podemos usar usethis::use_github() para que nos cree y asocie automáticamente un repositorio de Github.\n\n\n\n\n\n\nSi ya tenemos el proyecto de RStudio creado\n\n\n\nPreparación\n\nCrear un repositorio local de git (solo si no lo tenemos aún): usethis::use_git() (se crea una carpeta oculta llamada .git)\nInsertar token en archivo .Renviron (si no lo tienes, ver arriba, Creando personal access token): usethis::edit_r_environ()\n\nAsociando a repositorio en Github\n\nCrear Github repo: usethis::use_github()\nEmpujar el repositorio local a Github: git push --set-upstream origin master",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#ejercicios",
    "href": "qmd/09-git.html#ejercicios",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "Ejercicios",
    "text": "Ejercicios\nEjercicio 1: Github-RStudio\nVamos a poner a prueba lo anterior, creando un repositorio en Github llamado Github_Rstudio, y clonándolo para tener un proyecto de RStudio asociado.\n\nAbre una cuenta en Github y/o haz login\nCrea un repositorio en Github (después podrás borrarlo si quieres)\nSigue los pasos de arriba para clonar el repositorio de Github\n\n\nEjercicio 2: RStudio-Github\nAhora podemos usar el método inverso. Si tenemos un proyecto de RStudio, vamos a crear un repositorio de Github asociado.\n\nCrea un nuevo repositorio de RStudio. Si marcas la pestaña Create a git repository te ahorrarás uno de los pasos (usethis::use_git())\nCrea un script donde hagas algo muy sencillo (puedes copiar algún fragmento de código de temas anteriores)\nSigue los pasos de arriba para crear automáticamente un repositorio de Github asociado",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#commits",
    "href": "qmd/09-git.html#commits",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "\n9.5 Commits",
    "text": "9.5 Commits\nGit es extraordinariamente potente, pero vamos a empezar por la funcionalidad básica, commit(enviar/encomendar) archivos.\nSi partimos de un nuevo proyecto de RStudio llamado mi_primer_proyecto en el que hemos añadido un repositorio de Git (usethis::use_git()), y creado un nuevo archivo llamado mi_primer_archivo.R, en el panel Git veremos algo similar a esto:\n\nSi hacemos cambios en mi_primer_archivo.R y hacemos click en Commit , aparecerá una ventana para revisar los cambios. Hacemos doble click en mi_primer_archivo.R, y veremos que se pone en verde. Añadimos un Commit message, y estamos listos para hacer click en el botón Commit.\nA partir de este momento, cualquier cambio en mi_primer_archivo.R será detectado por Git.\nPor ejemplo, si añadimos una línea, veremos que el icono junto al archivo se convierte en una M en un recuadro azul.\n\nSi hacemos de nuevo click en Commit , podemos ver los cambios en mi_primer_archivo.R.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#pull-push",
    "href": "qmd/09-git.html#pull-push",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "\n9.6 Pull, Push",
    "text": "9.6 Pull, Push\nCon los comandos pull y push:\nPull: nos aseguramos que nuestro repositorio local esta actualizado\nPush: subimos los cambios commiteados de la rama a Github\n\nEjercicio\nNuestro primer commit\n\nUsando el proyecto de RStudio de antes, crea un nuevo documento de Quarto (.qmd):\n\n\n\nHaz un commit de ese archivo y súbelo (push) a Github (asegúrate que esta allá!). No olvides hacer un pull!\n\nAhora haz cambios en el archivo localmente. Una vez hechos:\n\nCommitealos\n\nSúbelos (Pull & Push)\n\nSincroniza tu repo local (Pull final)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#workflow",
    "href": "qmd/09-git.html#workflow",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "\n9.7 Workflow",
    "text": "9.7 Workflow\n\n\n\nSOURCE: nvie.com\n\n\nHay diferentes filosofías sobre cual es la mejor manera de trabajar con Git.\nEn este post por Vincent Driessen podéis ver una explicación bien detallada, complementada con imágenes como la que se ve a continuación.\nEl modelo básico implica la existencia de dos ramas. Una main o master (“producción”), donde tenemos código que siempre debe funcionar, y una development (para desarrollo), donde experimentamos, rompemos cosas, etc.\nPodéis ver un manual super completo llamado Happy Git and GitHub for the useR elaborado por Jenny Bryan, Jim Hester, entre otros.\n\n\n\n\nEn RStudio podemos trabajar gráficamente, Usando el panel Git.\n\n\n\n\n\n\n\nUsando el entorno gráfico\n\n\n\nEmpezamos en la rama master:\n\n\nPull  : nos aseguramos que nuestro repositorio local esta actualizado\n\n\nBranch  : Creamos nueva rama llamada development\n\nHacemos cambios en nuestros scripts\n\n\nCommit  : Commiteamos los cambios\n\n\nPush  : subimos la rama a Github\n\n\nPull request (En Github):\n\n\nCompare & Pull request\n\n\n\n\nPull  : nos aseguramos que nuestro repositorio local esta actualizado\n\n\n\n\n\n\n\nComo hacerlo usando el terminal\n\n\n\n\n\n\n\n\nPull: nos aseguramos que nuestro repositorio local esta actualizado: git pull\n\n\nBranch: Creamos nueva rama llamada development: git checkout -b development\n\nHacemos cambios en nuestros scripts\n\n\nCommit: Commiteamos los cambios\n\n\n\nAñadimos archivos: git add foo.txt\n\nHacemos el commit: git commit --message \"A commit message\"\n\n\n\n\nPush: subimos la rama a Github: git push origin development\n\n\nPull request (En Github):\n\n\nCompare & Pull request\n\n\n\nPull: nos aseguramos que nuestro repositorio local esta actualizado: git pull\n\n\n\n\n\n\n\n\n\n9.7.1 Pull request en 3 sencillos pasos\nLos Pull request son una funcionalidad de Github que facilita colaborar con otras personas, contribuir a proyectos, etc. En esencia, automatizan la comprobación de cambios y, si no hay conflictos, permiten combinar el código nuevo con unos pocos clicks.\nDespués de hacer el push de arriba (paso 4), al entrar en nuestro repositorio de Github deberíamos ver algo parecido a lo siguiente (si no lo vemos, ir a branches). La única dificultad es saber cual de los botones verdes apretar:\n\nPaso 1. Compare & pull request\n\nPaso 2. Create pull request\n\nPaso 3. Merge pull request\n\n\nBorrar rama antigua",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/09-git.html#bibliografía",
    "href": "qmd/09-git.html#bibliografía",
    "title": "\n9  Control de cambios con Git y Github\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nGuia de estilo del tidyverse\nHadley Wickham’s Style guide\nHappy Git and GitHub for the useR\ntargets\nScheel, A. M., Schijen, M., & Lakens, D. (in press). An excess of positive results: Comparing the standard Psychology literature with Registered Reports. Advances in Methods and Practices in Psychological Science.\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nYihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html\n\nMas cosas sobre reproducibilidad:\n\nReproducibility project: Psychology\nMany labs 2",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Control de cambios con Git y Github</span>"
    ]
  },
  {
    "objectID": "qmd/10-experimentos-reproducibles.html",
    "href": "qmd/10-experimentos-reproducibles.html",
    "title": "\n10  Experimentos reproducibles\n",
    "section": "",
    "text": "Paquetes para este capítulo\nif (!require('jsPsychMaker')) remotes::install_github(\"gorkang/jsPsychMaker\"); library('jsPsychMaker')\nif (!require('jsPsychMonkeys')) remotes::install_github(\"gorkang/jsPsychMonkeys\"); library('jsPsychMonkeys')\nif (!require('jsPsychHelpeR')) remotes::install_github(\"gorkang/jsPsychHelpeR\"); library('jsPsychHelpeR')\nEn el CSCN usamos distintas tecnologías para desarrollar experimentos. Algunos ejemplos son Psychopy, Qualtrics, Limesurvey, jsPsych, Gorilla, etc. Cada una de estas tiene ventajas y desventajas, y en general es importante tener en cuenta aspectos pragmáticos a la hora de adoptar una u otra tecnología (costo económico, tipo de experimento [EEG/conductual, laboratorio/online]).\nAlgunos de nosotros hemos optado principalmente por jsPsych para experimentos conductuales por tratarse de una librería javascript de código abierto, basada en tecnologías web standard, y que puede ser usada online y offline. Dado que en el CSCN disponemos de servidor propio, los costos habituales de hosting no se aplican.\nEn los últimos años, hemos empezado a trabajar en un conjunto de herramientas (jsPsychR) para crear experimentos usando la librería jsPsych con jsPsychMaker, simular participantes con jspsychMonkeys y estandarizar y automatizar la preparación de datos con jsPsychHelpeR.\nNuestro objetivo final es tener un gran número de tareas disponibles para ser usadas en el repositorio de jsPsychMaker. Cada una de estas tareas funcionará en jspsychMonkeys para crear participantes virtuales. Cada tarea tendrá un script hermano en jsPsychHelpeR para automatizar la preparación de datos.\nPuedes consultar las tareas disponibles en el manual de jsPsychR para más detalles.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Experimentos reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/10-experimentos-reproducibles.html#pipeline-experimental-abierto-y-reproducible",
    "href": "qmd/10-experimentos-reproducibles.html#pipeline-experimental-abierto-y-reproducible",
    "title": "\n10  Experimentos reproducibles\n",
    "section": "\n10.1 Pipeline experimental abierto y reproducible",
    "text": "10.1 Pipeline experimental abierto y reproducible\nReplicar el experimento de una publicación no es trivial. Una de las fortalezas fundamentales de nuestro sistema es que compartir y reproducir un experimento y los análisis asociados se convierte en algo muy sencillo.\nAdemás, todos los componentes del proceso son código abierto, lo que permite que revisores, colaboradores, etc. puedan verificar que no hay errores en el código.\nCon este sistema podremos crear fácilmente el código del experimento, simular datos y preparar datos de manera casi automática (incluyendo anonimización).\nEl output del sistema es estandarizado, lo que implica que los nombres de las variables y la estructura de datos son predecibles. Finalmente, la generación de gráficas, tablas, reportes y los análisis son reproducibles.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Experimentos reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/10-experimentos-reproducibles.html#jspsychmaker-como-crear-un-protocolo-experimental",
    "href": "qmd/10-experimentos-reproducibles.html#jspsychmaker-como-crear-un-protocolo-experimental",
    "title": "\n10  Experimentos reproducibles\n",
    "section": "\n10.2 jsPsychMaker: Como crear un protocolo experimental",
    "text": "10.2 jsPsychMaker: Como crear un protocolo experimental\nEn el manual de jsPsychR puedes ver las tareas disponibles junto con una breve descripción de cada una de ellas. Alternativamente, puedes ver el documento con todos los detalles de las tareas disponibles, o simplemente ejecutar jsPsychMaker::list_available_tasks().\nSi quieres consultar los scripts de las tareas puedes hacerlo en la carpeta canonical_protocol/ del repositorio de jsPsychMaker. Si quieres crear una nueva tarea para añadir a tu protocolo, puedes seguir las instrucciones de más abajo.\n\nPara crear un protocolo con las tareas AIM, EAR e IRI, y abrirlo en un navegador:\n\njsPsychMaker::create_protocol(\n  # Pruebas a incluir\n  canonical_tasks = c(\"AIM\", \"EAR\", \"IRI\"), \n   # El directorio tiene que incluir un número (se usará como pid)\n  folder_output = \"~/Downloads/protocol999\",\n  # Abre el navegador con el protocolo\n  launch_browser = TRUE\n  )\n\n\nPodemos editar la configuración del protocolo en la carpeta que hemos indicado en folder_output, abriendo el archivo config.js. Puedes consultar la ayuda sobre la configuración de experimentos.\nEl experimento esta listo para ser utilizado localmente. Si launch_browser = TRUE se abrirá el navegador. En cualquier caso, podemos iniciar el experimento abriendo index.html en tu navegador preferido.\n\nEjercicio 1\nDiseña un sencillo protocolo:\n\nDebes usar alguna de las tareas que aparecen en en manual (máximo 2)\nOpcionalmente, puedes hacer primero el Ejercicio 2 de abajo, para añadir o adaptar una nueva tarea/escala muy sencilla\nLa duración total del “experimento” no debería superar los 5 minutos\n\nTendrás que hacer una breve presentación contándonos el diseño experimental.\nNotas\n(tareas jsPsychMaker): Usa un máximo de 2 tareas",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Experimentos reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/10-experimentos-reproducibles.html#jspsychmonkeys-como-simular-datos",
    "href": "qmd/10-experimentos-reproducibles.html#jspsychmonkeys-como-simular-datos",
    "title": "\n10  Experimentos reproducibles\n",
    "section": "\n10.3 jsPsychMonkeys: Como simular datos",
    "text": "10.3 jsPsychMonkeys: Como simular datos\nEl sistema para simular participantes utiliza Selenium dentro de un contenedor de Docker. En Linux es trivial su uso, pero en Windows su configuración puede ser más compleja.\nPuedes seguir los siguientes pasos para preparar tu sistema:\n\nCompleta el setup para tu sistema operativo\nSi no funciona, te, quedan las siguientes opciones:\n\nCorrer un par de participantes manualmente\n\nUsar un ordenador con Linux o crear una partición Linux\n\nCrear una máquina virtual linux desde la que simular participantes. Puedes usar Virtualbox para instalar Ubuntu. Una vez dentro, tendrás que seguir los pasos del manual para prepara el sistema para correr R y RStudio\n\n\nErrores comunes:\n\nError sobre elevated privileges: abre Docker desktop antes de empezar\n\n\nPara lanzar monos localmente:\n\n\n# Un solo mono\njsPsychMonkeys::release_the_monkeys(\n  # Lanza un monos con el user id 1\n  uid = \"1\",\n  local_folder_tasks = \"~/Downloads/protocol999\")\n\n\n#  Monos del 1 al 5 simultaneamente\njsPsychMonkeys::release_the_monkeys(\n  # Lanza monos desde el uid 1 hasta el 5\n  uid = \"1:5\",\n  local_folder_tasks = \"~/Downloads/protocol999\",\n  # Lanza los monos en paralelo\n  sequential_parallel = \"parallel\",\n  # Usando este número de CPUs\n  number_of_cores = 5\n)\n\nPuedes ver de los parámetros disponibles en el Manual de jsPsychMonkeys. Por ejemplo, con open_VNC = TRUE puedes ver a los monos hacer su trabajo (siempre y cuando hayas instalado realvnc).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Experimentos reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/10-experimentos-reproducibles.html#jspsychhelper-como-preparar-datos",
    "href": "qmd/10-experimentos-reproducibles.html#jspsychhelper-como-preparar-datos",
    "title": "\n10  Experimentos reproducibles\n",
    "section": "\n10.4 jsPsychHelpeR: Como preparar datos",
    "text": "10.4 jsPsychHelpeR: Como preparar datos\nCada tarea de jsPsychMaker debería tener un script hermano en jsPsychHelpeR para automatizar la preparación de datos. Una vez tengamos nuestro protocolo listo para el pilotaje, con una función de jsPsychHelpeR crearemos todo lo necesario para que la preparación de datos corra automáticamente.\n\nPara crear y abrir un nuevo proyecto de RStudio con todo listo para correr la preparación de datos de tu protocolo:\n\njsPsychHelpeR::run_initial_setup(pid = '999', \n                                 data_location = \"~/Downloads/protocol999/.data\", \n                                 folder = \"~/Downloads/jsPsychHelpeR999\")\n\nEn el nuevo proyecto, tendremos que correr la preparación de datos. Puedes abrir el archivo run.R, donde encontrarás algunas instrucciones básicas.\n\n\n# Corremos el pipeline de preparación de datos\ntargets::tar_make()\n\n\nPara ver el data frame final listo para el análisis\n\n\n  # List available objects\n  targets::tar_objects()\n  \n  # Load DF_analysis file\n  targets::tar_load(DF_analysis)\n  \n  # See DF_analysis data frame\n  DF_analysis\n  \n\n\n\n10.4.1 Como crear un reporte dentro del jsPsychHelpeR\nDentro del proyecto en el que has preparado los datos, simplemente tienes que:\n\n\nAbre la plantilla report_analysis.Rmd:\n\nrstudioapi::navigateToFile(\"Rmd/report_analysis.Rmd\")\n\n\nEn el archivo _targets.R, en la sección análisis, descomenta las dos líneas de abajo\n\n\n  # tar_render(report_analysis, \"Rmd/report_analysis.Rmd\",\n  #            output_file = paste0(\"../outputs/reports/report_analysis.html\")),\n  \n\n\nFinalmente, puedes trabajar en report_analysis.Rmd tal y como hiciste en el capítulo anterior. Cuando acabes, o quieras probar si todo funciona bien, solo tienes que correr targets::tar_make() desde la Consola.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Experimentos reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/10-experimentos-reproducibles.html#ejercicio-final",
    "href": "qmd/10-experimentos-reproducibles.html#ejercicio-final",
    "title": "\n10  Experimentos reproducibles\n",
    "section": "Ejercicio FINAL",
    "text": "Ejercicio FINAL\nYa estáis listas/os para enfrentaros al ejercicio FINAL",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Experimentos reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/10-experimentos-reproducibles.html#avanzado",
    "href": "qmd/10-experimentos-reproducibles.html#avanzado",
    "title": "\n10  Experimentos reproducibles\n",
    "section": "\n10.5 Avanzado",
    "text": "10.5 Avanzado\n\n10.5.1 Como crear una nueva tarea\nTenemos un buen número de tareas disponibles para usar (puedes verlas en el manual de jsPsychR). Si la tarea que necesitas no está disponible, puedes crearla de distintas maneras:\n\nModificando alguna de las tareas que ya existen: tareas en jsPsychMaker\nUsando las plantillas disponibles: jsPsychMaker::copy_example_tasks(destination_folder = \"~/Downloads/TEST\")\n\nVeamos como crear una nueva tarea a partir de documentos excel usando las plantillas disponibles. Ver ayuda:\n\n\nCopia las plantillas de tareas de ejemplo:\n\n\njsPsychMaker::copy_example_tasks(destination_folder = \"~/Downloads/TEST\")\n\n\nVe a la carpeta indicada en destination_folder, en este ejemplo ~/Downloads/TEST, y borra todas las carpetas menos aquellas que correspondan al plugin que quieras usar. Por ejemplo, Slider.\n\nAdapta Slider.csv a tu nueva tarea:\n\nAdapta min, max, slider_start\n\nCopia las filas existentes tantas veces como ítems necesites\n\nAsegurate que los valores en la columna ID son correlativos\n\nAdapta stimulus, labels a tus items\n\n\n\nAdapta los .html con tus instrucciones:\n\nSi necesitas más páginas de instrucciones, simplemente haz copias de las existentes\nEdita el contenido de los archivos html\n\n\nEjecuta create_protocol() con los parámetros de abajo, se creará un nuevo protocolo con tu/tus tareas.\n\n\n  jsPsychMaker::create_protocol(\n    # Incluye la tarea EAR\n    canonical_tasks = \"EAR\",\n    # Crea e incluye las tareas que estan en esta carpeta\n    folder_tasks = \"~/Downloads/TEST/\",\n    # Crea el protocolo aquí\n    folder_output = \"~/Downloads/TEST/new_protocol\",\n    # Lanza un navegador\n    launch_browser = TRUE\n    )\n\n\nEjercicio Optativo: Crear nueva tarea\nCrea la siguiente tarea en jsPsychMaker:\n\n\nThe Brief Resilience Scale (PDF versión inglesa), o en su versión española\n\n\nNotas\n(tareas jsPsychMaker): Ver instrucciones en experimentos-reproducibles - como crear una nueva tarea\nSi prefieres puedes implementar una tarea distinta a The Brief Resilience Scale. Los únicos requisitos son que sea breve y sencilla.\n\n\n10.5.1.1 Corrección de la tarea\nPara cada tarea en jsPsychMaker, aspiramos a tener un script de corrección en jsPsychHelpeR. Si has creado una nueva tarea, por favor, completa la información de NUEVAS Tareas jsPsychR para que podamos integrar tu tarea en el repositorio común.\n\n10.5.1.2 Como preparar datos para una tarea nueva\nTendremos que crear primero el script de preparación para la nueva tarea. En jsPsychHelpeR tienes una tarea que te ayudará con esto. Si has completado los datos en NUEVAS Tareas jsPsychR, el proceso será muy sencillo.\n\nInstalamos jsPsychHelper:\n\n\nif (!require('jsPsychHelpeR')) remotes::install_github(\"gorkang/jsPsychHelpeR\"); library('jsPsychHelpeR')\n\n\nCreamos el nuevo archivo prepare_NOMBRETAREA():\n\n\njsPsychHelpeR::create_new_task(\n  short_name_task = \"NAMETASK\", \n  get_info_googledoc = TRUE\n  )\n\nEsta función:\n\nCreará un nuevo archivo de corrección a partir de la plantilla\nLo adaptará para que funciones con el nombre que le has asignado a la tarea\nAbrirá el archivo para que lo puedas editar\n\nSi hay información en todas las pestañas de NUEVAS Tareas jsPsychR, en la consola se mostrará información lista para copiar y pegar en tu script sobre:\n\nnombres de dimensiones\nítems para cada dimensión\ncálculo de dimensiones\nítems invertidos\nconversión numérica",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Experimentos reproducibles</span>"
    ]
  },
  {
    "objectID": "qmd/11-ejercicios.html",
    "href": "qmd/11-ejercicios.html",
    "title": "\n11  Ejercicios\n",
    "section": "",
    "text": "11.1 Ejercicio FINAL\nPara el ejercicio final (evaluable), usaremos el protocolo que has creado en el ejercicio anterior. Usando datos simulados, con la ayuda de jsPsychHelpeR vamos a crear un proyecto de RStudio que procese los datos automáticamente, y adaptar un archivo Rmarkdown para generar un reporte automatizado con tablas, gráficas y una descripción semi-automática de nuestros resultados simulados.\nEl proyecto tiene que correr en cualquier computador.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejercicios</span>"
    ]
  },
  {
    "objectID": "qmd/11-ejercicios.html#ejercicio-final",
    "href": "qmd/11-ejercicios.html#ejercicio-final",
    "title": "\n11  Ejercicios\n",
    "section": "",
    "text": "El primer paso consiste en obtener datos de participantes virtuales.\n\n\nPodéis intentarlo simulando datos\n\nSi no os funciona jsPsychMonkeys en vuestro sistema, el profesor os ayudará a simular datos para vuestro experimento.\nAlternativamente, podéis correr el experimento un par de veces (abriendo el index.html)\n\n\nUna vez tengamos los datos:\n\n\nCrearemos un proyecto que procesará los datos automáticamente usando jsPsychHelpeR - como preparar datos\n\nCrearemos un reporte en Rmd como parte del pipeline de jsPsychHelpeR donde incluiremos:\n\nTabla/s con descriptivos ver ayuda\nGráfico/s con resultado ver ayuda y ayuda\nTabla/s con resultados de un análisis sencillo ver ayuda\nUna frase reportando resultados del análisis (usando Texto inline de gtsummary)\n\n\n\n\nIMPORTANTE\nLa nota del workshop estará basada en el resultado de esta tarea.\nTendréis que compartir el proyecto completo con el profesor, y él deberá poder correrlo y ver como resultado el reporte en pdf incluyendo los elementos detallados arriba.\nNotas\n(simulación datos): Sigue las instrucciones de simulando datos\n(preparando datos): Ver como preparar datos\nPara más información, ver el manual de jsPsychR",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ejercicios</span>"
    ]
  },
  {
    "objectID": "qmd/refs.html",
    "href": "qmd/refs.html",
    "title": "Paquetes usados",
    "section": "",
    "text": "References",
    "crumbs": [
      "Paquetes usados"
    ]
  },
  {
    "objectID": "qmd/refs.html#references",
    "href": "qmd/refs.html#references",
    "title": "Paquetes usados",
    "section": "",
    "text": "Aden-Buie, Garrick. 2024. regexplain: Rstudio Addin to Explain, Test and Build Regular Expressions. https://github.com/gadenbuie/regexplain.\n\n\nAllaire, JJ, and Christophe Dervieux. 2024. quarto: R Interface to “Quarto” Markdown Publishing System. https://github.com/quarto-dev/quarto-r.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2024. rmarkdown: Dynamic Documents for r. https://github.com/rstudio/rmarkdown.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, R Foundation, Hadley Wickham, Journal of Statistical Software, Ramnath Vaidyanathan, et al. 2024. rticles: Article Formats for r Markdown. https://CRAN.R-project.org/package=rticles.\n\n\nAllen, Micah, Davide Poggiali, Kirstie Whitaker, Tom Rhys Marshall, Jordy van Langen, and Rogier A. Kievit. 2021. “Raincloud Plots: A Multi-Platform Tool for Robust Data Visualization [Version 2; Peer Review: 2 Approved].” Wellcome Open Research 4 (63). https://doi.org/10.12688/wellcomeopenres.15191.2.\n\n\nArnold, Jeffrey B. 2024. ggthemes: Extra Themes, Scales and Geoms for “ggplot2”. https://CRAN.R-project.org/package=ggthemes.\n\n\nAust, Frederik, and Marius Barth. 2023. papaja: Prepare Reproducible APA Journal Articles with R Markdown. https://github.com/crsh/papaja.\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBryan, Jennifer. 2023. gapminder: Data from Gapminder. https://github.com/jennybc/gapminder.\n\n\nCameron, Allan, and Teun van den Brand. 2024. geomtextpath: Curved Text in “ggplot2”. https://allancameron.github.io/geomtextpath/.\n\n\nCsárdi, Gábor, and Jim Hester. 2024. pak: Another Approach to Package Installation. https://pak.r-lib.org/.\n\n\nCsárdi, Gábor, Jim Hester, Hadley Wickham, Winston Chang, Martin Morgan, and Dan Tenenbaum. 2024. remotes: R Package Installation from Remote Repositories, Including “GitHub”. https://remotes.r-lib.org.\n\n\nFirke, Sam. 2023. janitor: Simple Tools for Examining and Cleaning Dirty Data. https://github.com/sfirke/janitor.\n\n\nFox, John, and Sanford Weisberg. 2019. An R Companion to Applied Regression. Third. Thousand Oaks CA: Sage. https://socialsciences.mcmaster.ca/jfox/Books/Companion/.\n\n\nGagolewski, Marek. 2022. “stringi: Fast and Portable Character String Processing in R.” Journal of Statistical Software 103 (2): 1–59. https://doi.org/10.18637/jss.v103.i02.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, Alexandra Lauer, JooYoung Seo, Ken Brevoort, and Olivier Roy. 2024. gt: Easily Create Presentation-Ready Display Tables. https://gt.rstudio.com.\n\n\nKuhn, Max, Simon Jackson, and Jorge Cimentada. 2022. corrr: Correlations in r. https://CRAN.R-project.org/package=corrr.\n\n\nLüdecke, Daniel. 2024. sjPlot: Data Visualization for Statistics in Social Science. https://CRAN.R-project.org/package=sjPlot.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, and Dominique Makowski. 2020. “Extracting, Computing and Exploring the Parameters of Statistical Models Using R.” Journal of Open Source Software 5 (53): 2445. https://doi.org/10.21105/joss.02445.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Philip Waggoner, and Dominique Makowski. 2021. “performance: An R Package for Assessment, Comparison and Testing of Statistical Models.” Journal of Open Source Software 6 (60): 3139. https://doi.org/10.21105/joss.03139.\n\n\nLüdecke, Daniel, Indrajeet Patil, Mattan S. Ben-Shachar, Brenton M. Wiernik, Philip Waggoner, and Dominique Makowski. 2021. “see: An R Package for Visualizing Statistical Models.” Journal of Open Source Software 6 (64): 3393. https://doi.org/10.21105/joss.03393.\n\n\nMakowski, Dominique, Daniel Lüdecke, Indrajeet Patil, Rémi Thériault, Mattan S. Ben-Shachar, and Brenton M. Wiernik. 2023. “Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.” CRAN. https://easystats.github.io/report/.\n\n\nMeyer, Fanny, and Victor Perrier. 2024. esquisse: Explore and Visualize Your Data Interactively. https://dreamrs.github.io/esquisse/.\n\n\nMüller, Kirill. 2020. here: A Simpler Way to Find Your Files. https://CRAN.R-project.org/package=here.\n\n\nNavarrete, Gorka. 2024a. jsPsychHelpeR: Standardize and Automatize Data Preparation and Analysis of jsPsych Experiments Created with jsPsychMaker. https://github.com/gorkang/jsPsychHelpeR.\n\n\n———. 2024b. jsPsychMonkeys: Release Monkeys to a jsPsych Experiment Using the r Package targets, Docker and RSelenium. https://github.com/gorkang/jsPsychMonkeys.\n\n\nNavarrete, Gorka, and Herman Valencia. 2024. jsPsychMaker: Create Behavioral Experiments and Surveys Using jsPsych and r. https://github.com/gorkang/jsPsychMaker.\n\n\nNeuwirth, Erich. 2022. RColorBrewer: ColorBrewer Palettes.\n\n\nOoms, Jeroen. 2024. writexl: Export Data Frames to Excel “xlsx” Format. https://CRAN.R-project.org/package=writexl.\n\n\nPedersen, Thomas Lin. 2024. ggraph: An Implementation of Grammar of Graphics for Graphs and Networks. https://CRAN.R-project.org/package=ggraph.\n\n\nR Core Team. 2024. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRushworth, Alastair. 2022. inspectdf: Inspection, Comparison and Visualisation of Data Frames. https://CRAN.R-project.org/package=inspectdf.\n\n\nSchutten, Gerrit-Jan, Chung-hong Chan, Peter Brohan, Detlef Steuer, and Thomas J. Leeper. 2024. readODS: Read and Write ODS Files. https://docs.ropensci.org/readODS/.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSingmann, Henrik, Ben Bolker, Jake Westfall, Frederik Aust, and Mattan S. Ben-Shachar. 2024. afex: Analysis of Factorial Experiments. https://afex.singmann.science/.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nUshey, Kevin, and Hadley Wickham. 2024. renv: Project Environments. https://CRAN.R-project.org/package=renv.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, and Shannon Ellis. 2022. skimr: Compact and Flexible Summaries of Data. https://docs.ropensci.org/skimr/ (website).\n\n\nWei, Taiyun, and Viliam Simko. 2021. R Package “corrplot”: Visualization of a Correlation Matrix. https://github.com/taiyun/corrplot.\n\n\nWickham, Hadley. 2023. waldo: Find Differences Between r Objects. https://waldo.r-lib.org.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, and Andy Teucher. 2024. usethis: Automate Package and Project Setup. https://usethis.r-lib.org.\n\n\nWickham, Hadley, Thomas Lin Pedersen, and Dana Seidel. 2023. scales: Scale Functions for Visualization. https://scales.r-lib.org.\n\n\nWilke, Claus O. 2024a. cowplot: Streamlined Plot Theme and Plot Annotations for “ggplot2”. https://CRAN.R-project.org/package=cowplot.\n\n\n———. 2024b. ggridges: Ridgeline Plots in “ggplot2”. https://CRAN.R-project.org/package=ggridges.\n\n\nWilke, Claus O., and Brenton M. Wiernik. 2022. ggtext: Improved Text Rendering Support for “ggplot2”. https://wilkelab.org/ggtext/.\n\n\nXie, Yihui. 2014. “knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC.\n\n\n———. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.\n\n\n———. 2019. “TinyTeX: A Lightweight, Cross-Platform, and Easy-to-Maintain LaTeX Distribution Based on TeX Live.” TUGboat 40 (1): 30–32. https://tug.org/TUGboat/Contents/contents40-1.html.\n\n\n———. 2024a. knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/.\n\n\n———. 2024b. tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents. https://github.com/rstudio/tinytex.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown.\n\n\nXie, Yihui, Joe Cheng, and Xianying Tan. 2024. DT: A Wrapper of the JavaScript Library “DataTables”. https://CRAN.R-project.org/package=DT.\n\n\nXie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook.\n\n\nYutani, Hiroaki. 2023. gghighlight: Highlight Lines and Points in “ggplot2”. https://CRAN.R-project.org/package=gghighlight.",
    "crumbs": [
      "Paquetes usados"
    ]
  }
]