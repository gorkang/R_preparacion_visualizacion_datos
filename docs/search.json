[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R para preparación y visualización de datos",
    "section": "",
    "text": "Introducción\nEl objetivo de este seminario es aprender a usar R para preparar y visualizar datos, además de generar reportes reproducibles. Está pensado para alumnos de postgrado con conocimientos básicos de programación.\nTambién conoceremos jsPsychR, un conjunto de herramientas creado en el CSCN para ayudar a crear paradigmas experimentales con jsPsych, simular participantes, y estandarizar el proceso de preparación y análisis de datos.\nR es un lenguaje de programación abierto, con una gran comunidad orientada al trabajo, visualización y modelado de datos en contextos científicos y técnicos. Nos introduciremos de manera práctica a R, resolviendo problemas que encontramos habitualmente durante el quehacer científico, focalizándonos en el trabajo abierto, colaborativo y reproducible."
  },
  {
    "objectID": "index.html#objetivos",
    "href": "index.html#objetivos",
    "title": "R para preparación y visualización de datos",
    "section": "Objetivos",
    "text": "Objetivos\nDar las herramientas básicas a los alumnos para que puedan trabajar de manera autónoma con R y RStudio para el proceso de importación, transformación, visualización y reporte de datos.\nAl finalizar el curso deberíamos ser capaces de:\n\nImportar archivos de datos, transformar los datos, crear nuevas variables.\nRealizar análisis de datos exploratorios, visualizar distribuciones y comparar grupos.\nGenerar reportes reproducibles con RMarkdown.\nCrear paradigmas experimentales y un pipeline completo para la preparación de datos con jsPsychR."
  },
  {
    "objectID": "index.html#como-empezar",
    "href": "index.html#como-empezar",
    "title": "R para preparación y visualización de datos",
    "section": "Como empezar",
    "text": "Como empezar\nSi ya has completado los pasos A-B-C y otras dependencias a instalar indicados en preparando nuestro sistema, puedes lanzar el siguiente código en tu ordenador para descargar los materiales del curso:\n\nif (!require('usethis')) install.packages('usethis'); library('usethis')\nusethis::use_course(\"gorkang/R_preparacion_visualizacion_datos\")\n\nSigue las instrucciones que aparecen en la Consola para tener un nuevo proyecto de RStudio con todos los materiales del curso. El código anterior creará una carpeta llamada R_preparacion_visualizacion_datos-master.\nLa carpeta R_preparacion_visualizacion_datos-master contiene varias cosas. Las mas importantes son:\n\nR_preparacion_visualizacion_datos.Rproj: para abrir el proyecto de RStudio del curso. Abrelo siempre usando este archivo.\nCarpeta docs: puedes abrir docs/index.html en tu navegador para ver el “libro” de este curso. Alternativamente, puedes consultar una version online del libro\nCarpeta qmd: En esa carpeta esta el código fuente de los capítulos del libro\nCarpeta data: Cuando usemos archivos de datos, vendrán de aquí\n\n\n\n\n\n\n\nEn ocasiones encontraras un recuadro como este. En la versión online del libro, si haces click sobre el, aparecerá una pista sobre como resolver el ejercicio."
  },
  {
    "objectID": "index.html#bibliografía",
    "href": "index.html#bibliografía",
    "title": "R para preparación y visualización de datos",
    "section": "Bibliografía",
    "text": "Bibliografía\nBryan, J., & Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/\nWickham, H. (2014). Advanced r. Chapman and Hall/CRC. https://adv-r.hadley.nz/\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nYihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html"
  },
  {
    "objectID": "qmd/00-configuracion-sistema.html#empezando-en-a-b-c",
    "href": "qmd/00-configuracion-sistema.html#empezando-en-a-b-c",
    "title": "Preparando nuestro sistema",
    "section": "Empezando en A-B-C",
    "text": "Empezando en A-B-C\nPara poder iniciar el workshop necesitamos tener R y RStudio instalados, además de algunas librerías. Para tener un sistema funcional, completa los pasos A, B y C. Si ya tienes R y Rstudio instalados (recientemente), puedes pasar directamente al paso (C).\n\n(A) Instalar R\nR, es un lenguaje de programación especializado en la computación estadística y visualización de datos. Es recomendable tener instalada la última versión de R (necesitarás al menos la versión 4.2). Puedes usar uno de los enlaces siguientes:\n\nWindows: Descargar e instalar R para Windows\nMac: Descargar e instalar R para Mac\nUbuntu Linux: más detalles en la web de R.\nEn un terminal: sudo apt install r-base\n\n(B) Instalar RStudio\nRStudio es un entorno integrado de desarrollo (IDE) para la programación R.\n\n\nDescargar e instalar RStudio.\nUna vez descargado e instalado, abre RStudio. Deberías ver algo parecido a lo siguiente:\n\n\n\n\n\n\n\nSi encuentras un error de instalación en ubuntu, tendrás que instalar RStudio manualmente:\n\nsudo dpkg -i rstudio-[VERSION_NUMBER]-amd64.deb\nsudo apt --fix-broken install\n\n\n\n(C) Paquetes para el workshop\nPara instalar los paquetes del workshop, ejecuta el código de más abajo (sección sombreada en gris claro) en la consola de RStudio.\nEn este gif puedes ver como hacerlo:\n\n\n\n\n\nCopia y pega el código de abajo en la consola de RStudio y ejecútalo [tecla ENTER]:\nOtros paquetes que usaremos. Para que corran estas lineas tenemos que haber completado el paso previo.\nUsaremos un buen numero de paquetes en el workshop. El proceso de instalación requiere Internet y tardará un buen rato (en algunos sistemas puede llegar a 1 hora). Si tienes alguna dificultad en este punto, te recomiendo que veas algun tutorial básico de R o RStudio.\nHay algunos meta-paquetes que simplifican la instalación de múltiples paquetes (e.g. pacman, pak, renv, …), pero dejaremos eso para más adelante.\nOtras dependencias a instalar\nInstalar Quarto\nQuarto es un sistema de publicación de código abierto que funciona con diferentes lenguajes de programación como R o python. Lo usaremos a partir del capítulo 6.\nDescarga e instala Quarto\nInstalar latex\nPara generar pdf’s necesitaremos tener instalado Latex. tinytex nos ayudará a simplificar el proceso:\n\nif (!require('tinytex')) install.packages('tinytex'); library('tinytex')\ntinytex::install_tinytex() # Llevará un buen rato\n\nDocker\nNecesitaremos Docker para simular datos de participantes online.\nInstala Docker en: - Linux\n- Mac\n- Windows\nAdicionalmente:\n\nWindows: Update wsl (in a command prompt): wsl - update\n\nUbuntu:\n\nEn un terminal: sudo apt install libssl-dev libcurl4-openssl-dev libxml2-dev docker\n\nSi los monos hacen su trabajo pero no aparecen los csv’s, asegúrate que el usuario docker tiene acceso al directorio ~/Downloads\n\n\n\nPara más detalles, puedes consultar jsPsychMonkeys setup\nGit\nVer instrucciones para Windows, Mac y Linux.\n  Importante: en el paso Adjusting your PATH environment en en Windows, selecciona Git from the command line and also from 3rd-party software"
  },
  {
    "objectID": "qmd/00-configuracion-sistema.html#algo-más-sobre-la-instalación-de-paquetes",
    "href": "qmd/00-configuracion-sistema.html#algo-más-sobre-la-instalación-de-paquetes",
    "title": "Preparando nuestro sistema",
    "section": "Algo más sobre la instalación de paquetes",
    "text": "Algo más sobre la instalación de paquetes\nLos paquetes de R son una colección de funciones, datos y documentación que amplían las capacidades básicas de R.\nGran parte de las funciones y paquetes que utilizaremos en este workshop se encuentran contenidas en el meta-paquete tidyverse (este es un paquete de paquetes). No lo instalamos en (C), pero si quisieras instalarlo solo tendrías que ejecutar la siguiente linea en la consola de RStudio:\n\ninstall.packages(\"tidyverse\")\n\nPara instalar otro paquete diferente de “tidyverse”, remplaza su nombre entre comillas dentro de la función:\n\ninstall.packages(\"NOMBRE_DE_PAQUETE\")\n\nUna vez instalado un paquete, no es necesario volver hacerlo, a menos que reinstales R.\nCargar paquetes\nLas funciones, datos y documentación dentro de nuestros paquetes no podrán ser utilizadas hasta que se carguen en R. Una vez instalados, para cargar los paquetes se usa la función library():\n\nlibrary(ggplot2)  \n\nEn realidad las funciones también pueden ser llamadas usando su referencia absoluta ::, sin necesidad de cargarlas antes. Por ejemplo: dplyr::tibble(columna = 1). En general: nombre_paquete::nombre_de_funcion(parametros)).\nTodo en uno\nEl siguiente código simplifica lo anterior. Comprueba que el paquete esta instalado; Si no se encuentra instalado, lo instala. Finalmente lo carga.\n\nif (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')  \n\nPara instalar múltiples paquetes, podemos repetir la linea de mas arriba tantas veces como sea necesario, o usar una versión algo mas sofisticada como el código del apartado (C):\n\nif (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')\nif (!require('bookdown')) install.packages('bookdown'); library('bookdown')\n\nAl principio de cada capítulo, verás una sección llamada Paquetes para este capítulo. Si pegas el contenido de esa sección en un script de R al empezar cada capítulo, te asegurarás de tener disponibles todas las funciones que usaremos.\nInstalar paquetes de Github\nEn ocasiones querremos instalar directamente la versión en desarrollo del paquete desde Github. Para eso podemos usar la función install_github() del paquete remotes. Por ejemplo, para instalar el paquete {BayesianReasoning} desde su repositorio de Github:\n\nif (!require('remotes')) install.packages('remotes'); library('remotes')\nremotes::install_github(\"gorkang/BayesianReasoning\")"
  },
  {
    "objectID": "qmd/00-configuracion-sistema.html#bibliografía",
    "href": "qmd/00-configuracion-sistema.html#bibliografía",
    "title": "Preparando nuestro sistema",
    "section": "Bibliografía",
    "text": "Bibliografía\nAlgunos de los manuales que vamos a usar para el workshop son los siguientes:\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nBryan, J., & Hester, J. What They Forgot to Teach You About R. https://whattheyforgot.org/"
  },
  {
    "objectID": "qmd/01-introduccion_visualizacion.html#introducción-porque-la-visualización-de-datos-es-importante",
    "href": "qmd/01-introduccion_visualizacion.html#introducción-porque-la-visualización-de-datos-es-importante",
    "title": "\n1  Introducción a R y visualización de datos\n",
    "section": "\n1.1 Introducción: porque la visualización de datos es importante",
    "text": "1.1 Introducción: porque la visualización de datos es importante\n“These 13 datasets (the Datasaurus, plus 12 others) each have the same summary statistics (x/y mean, x/y standard deviation, and Pearson’s correlation) to two decimal places, while being drastically different in appearance.” (Matejka, J., & Fitzmaurice, G., 2017).\n\n\nSOURCE: https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\n1.1.1 Ejemplo del mundo real: ¿cuantos temas deberia estudiar?\nEste ejemplo viene de un experimento que realizamos junto con Carlos Santamaría hace algún tiempo. Presentamos una tarea sobre cálculo de probabilidades a personas que estaban entrando a un examen para convertirse en trabajadores del estado. Simplificando algo, digamos que la materia para el examen eran 80 temas. No es posible estudiar con profundidad todos los temas, así que los opositores se concentraban en un subconjunto de esos temas (e.g. 30 de 80). Al empezar el examen, se seleccionaban al azar 5 de los 80 temas, y cada persona elegía uno de ellos para desarrollar.\nAbajo se puede ver como cambia la probabilidad de que uno de los temas estudiados aparezca dentro de los 5 seleccionados al azar. Con 30 de los 80 temas estudiados, la probabilidad de que uno de ellos salga en la prueba es del 91%. Si estudiáramos 47, subiríamos a una probabilidad del 99%.\n\n\n\n\n\n\n En el experimento le preguntamos a las personas por la probabilidad de que les apareciera alguno de los temas estudiados en la prueba. Comparamos las siguientes dos preguntas:\n\n¿Cuál es la probabilidad de que salga uno de los temas que has estudiado?\n\n¿Cuál es la probabilidad de que no salga ninguno de los temas que has estudiado?\n\nMiramos el error promedio en función de la pregunta (cuanto se han alejado de la probabilidad correcta), y vimos que nuestra manipulación había tenido un efecto considerable:\n\n\n\n\nQuestion\nError_promedio\nSD\nN\n\n\n\np (no salga ninguno)\n4.016129\n35.82469\n31\n\n\np (salga uno)\n-30.741936\n20.01494\n31\n\n\n\n\n\n\nHay una diferencia notable entre condiciones. Pasamos de un error promedio del -30.7% a tan solo 4%, simplemente cambiando la pregunta. Hagamos un sencillo análisis de regresión para ver si la diferencia es significativa, y cuanta varianza explica nuestro modelo.\n\n\n\n\n \nError\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n4.02\n-6.41 – 14.44\n0.444\n\n\nQuestion [p (salga uno)]\n-34.76\n-49.50 – -20.02\n&lt;0.001\n\n\nObservations\n62\n\n\nR2 / R2 adjusted\n0.270 / 0.258\n\n\n\n\n\n#&gt; \n#&gt;  Shapiro-Wilk normality test\n#&gt; \n#&gt; data:  modelo_regresion$residuals\n#&gt; W = 0.96215, p-value = 0.0532\n\n\n\n\n\nTodo es hermoso. Tenemos un efecto claramente significativo de la pregunta (y con un R2-ajustado de .258, no está nada mal), y además, nuestro modelo no incumple el supuesto de normalidad de residuos (¡por los pelos!).\n\n\n\n\n\n\nNota importante sobre las pruebas de normalidad. Hack click para leerme.\n\n\n\n\n\nLas pruebas de normalidad son muy sensibles al n de la muestra\n\n\n\nPreparamos un plot con promedios y barras con error standard para nuestro paper.\n\n\n\n\n\nEstamos listos para escribir el paper. Preparemos la tabla con descriptivos…\n\n\n\n\nQuestion\nError_promedio\nSD\nN\n\n\n\np (no salga ninguno)\n4.016129\n35.82469\n31\n\n\np (salga uno)\n-30.741936\n20.01494\n31\n\n\n\n\n\n\nEs curioso que la desviación estandard sea mayor en el grupo con menos error promedio… Visualicemos las respuestas de todos los participantes, junto con la distribución de los datos.\n\n\n\n\n\nComo se puede apreciar en la gráfica, cuando usamos la pregunta ¿Cuál es la probabilidad de que no salga ninguno de los temas que has estudiado? no estamos reduciendo el error, sino convirtiendo una distribución de respuestas unimodal en bimodal.\n\nTLDR: La manera en la visualizamos la información determina las conclusiones a las que llegamos. En una sola gráfica:\n\n\n\n\n\nMoraleja: es importante mostrar los datos individuales y/o la distribución de los datos\n\n\nSOURCE: https://www.research.autodesk.com/publications/same-stats-different-graphs/"
  },
  {
    "objectID": "qmd/01-introduccion_visualizacion.html#por-qué-r",
    "href": "qmd/01-introduccion_visualizacion.html#por-qué-r",
    "title": "\n1  Introducción a R y visualización de datos\n",
    "section": "\n1.2 Por qué R?",
    "text": "1.2 Por qué R?\n\n\n\nR es uno de los programas para data science mas populares, especialmente usado en la academia. El numero de paquetes que ofrecen funcionalidades de todo tipo no ha dejado de crecer. En 2023 el numero de paquetes en R-cran ha superado los 25,000, y el ritmo de crecimiento nos acerca a la singularidad… ;)\n\n\n\n\n\n\nSOURCE: https://gist.github.com/daroczig/3cf06d6db4be2bbe3368\n\n\n\nAdemás de lo anterior, R es un programa de código abierto (algo esencial para poder hacer ciencia reproducible), con una comunidad de usuarios muy acogedora, y con un importante foco en la inclusividad.\nLa importancia de la comunidad es difícil de apreciar. Por ejemplo, es relativamente habitual que uno abra un issue en Github pidiendo una nueva característica en un paquete, y que los creadores la implementen (e.g. correlation, gtsummary, rorcid), que uno reporte un error y lo corrijan (e.g. sjPlot, gtsummary), recibir correcciones y mejoras en tus repositorios (e.g. html2latex, 2019-Chile), o poder contribuir a repositorios de otros (e.g. jsPsych, gtsummary).\nSus funciones de visualización son muy potentes (ver la r-graph-gallery para algunos ejemplos), siendo usadas como herramienta principal en medios como la BBC.\n\n\nSOURCE: BBC\n\n\nNo menos importante, hay una gran cantidad de cursos, tutoriales, presentaciones y libros de una calidad excelente, con los que podemos aprender de manera autónoma. Por ejemplo:\n\npsyTeachR team at the University of Glasgow\nA Gentle Guide to the Grammar of Graphics with ggplot2\nresulumit.com Rmd workshop\nR for Data Science\nAdvanced R\n\n\nPara ver una compilación de todos los libros disponibles: Big Book of R\n\nCon R puedes recoger datos interactivamente con shiny, preparar datos (o extraerlos de paginas web con rvest o RSelenium), visualizar datos estáticos con ggplot, animarlos con gganimate, visualizarlos con interactivamente con plotly o shiny. Puedes también analizar los datos con todas las técnicas imaginables, desde anovas con afex a modelos mixtos con lmer y/o afex, pasando por meta-análisis con metafor, SEM, Path analysis, mediación, con lavaan, análisis Bayesianos con brms o bayesfactor, y un larguísimo etc. Puedes llevar tus visualizaciones y análisis a reportes automáticos en múltiples formatos (pdf, html, docx) con Rmarkdown, o quarto, crear libros como este con bookdown, páginas web con blogdown o distill, e incluso papers completamente reproducibles (preparación y análisis de datos) en formato APA con papaja.\n\n\n1.2.1 Bienvenida al tidyverse\n\n\n\nEl tidyverse es un conjunto de paquetes que nos permitirán hacer de manera (habitualmente) intuitiva muchas tareas de preparación y visualización de datos.\n\n1.2.1.1 Tidyverse vs Base R\nMuchas de las funciones que existen en el Tidyverse tienen un equivalente en base-R (la instalación por defecto de R). El Tidyverse tiene ventajas y desventajas. La ventaja fundamental es que el código resulta (habitualmente) más fácil de leer, los nombres de las funciones son más intuitivos, y la forma de hacer las cosas tiene a ser consistente. La desventaja fundamental es que incrementamos el numero de dependencias (paquetes) de nuestro código.\nVeamos un ejemplo extraído de aquí.\n\nLa misma operación con base-R o con tidyverse:\nFilter rows with conditions evaluated within groups: iris flowers with maximum “Petal.Width” for each “Species”\nTidyverse\n\n  iris |&gt; \n    group_by(Species) |&gt; \n    filter(Petal.Width == max(Petal.Width))\n\nBase-R\n\n  # First operate in the data.frame by group (split-apply)\n  widest_petals &lt;- by(iris, \n                      INDICES = iris$Species, \n                      FUN = function(x){\n                        x[x$Petal.Width == max(x$Petal.Width), ] \n                      })\n  \n  # Then combine the results into a data.frame\n  do.call(rbind, widest_petals)\n#&gt;               Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n#&gt; setosa                 5.0         3.5          1.6         0.6     setosa\n#&gt; versicolor             5.9         3.2          4.8         1.8 versicolor\n#&gt; virginica.101          6.3         3.3          6.0         2.5  virginica\n#&gt; virginica.110          7.2         3.6          6.1         2.5  virginica\n#&gt; virginica.145          6.7         3.3          5.7         2.5  virginica\n\n\n1.2.2 Antes de empezar\nProgramar es muy difícil. Todos necesitamos ayuda. Contar con una comunidad robusta con la que compartir, preguntar, contribuir, ayuda muchísimo.\n\n\nSOURCE: http://www.keywordbasket.com/ZWZlY3RvIGR1bm5pbmcta3J1Z2Vy/\n\n\nHay algunos recursos que son imprescindibles. Nadie sabe como los antiguos podían programar antes de la llegada de Stackoverflow:\n\nStack overflow\nGoogle: avoid scientific notation R: options(scipen=999)\n\nY otros recursos que resultan muy útiles:\n\nComunidad de usuarios de Rstudio\n\nTwitter! Por ejemplo:\n\n\n @thomas_mock (#TidyTuesday)\n\n\n @dataandme\n\n\n @rivaquiroga\n\n @RLadiesSantiago\n\n\nWebs como R bloggers\n\n1.2.3 R para visualización de datos\nggplot2 es el paquete por excelencia para visualización de datos. Su potencia va asociada a un nivel de complejidad considerable, hasta el punto que hay Cheat sheets oficiales, Cheat sheets buscables, y decenas de miles de preguntas en Stack Overflow.\n\n1.2.3.1 Primeros pasos - con training wheels\nPara empezar a usar ggplot sin tener que preocuparnos de su complejidad, podemos usar la función esquisse:::esquisser() del paquete esquisse. Esta nos permite usar la potencia de ggplot para explorar una base de datos de manera muy sencilla.\n\n\nSOURCE: https://github.com/will-r-chase/blog/blob/master/static/slides/slide_img/esquisse.gif\n\n\nLa manera fácil (1, 2, 3), usando esquisse:\n\n\n# 1) Asegúrate que hemos instalado el paquete esquisse\n  if (!require('esquisse')) install.packages('esquisse'); library('esquisse')\n\n# 2) Lanza el wizard esquisser  \n  esquisse:::esquisser(iris)\n\n# 3) Crea el gráfico que quieras, exporta el código...\n\n\n1.2.3.2 Aprendamos con Garrick\nGarrick Aden-Buie ( @grrrck) ha creado una excelente introducción a ggplot2 y la gramática de gráficos. Os recomiendo revisarla para familiarizaros con las funcionalidades de ggplot."
  },
  {
    "objectID": "qmd/01-introduccion_visualizacion.html#visualización-de-datos-con-ggplot2",
    "href": "qmd/01-introduccion_visualizacion.html#visualización-de-datos-con-ggplot2",
    "title": "\n1  Introducción a R y visualización de datos\n",
    "section": "\n1.3 Visualización de datos con ggplot2",
    "text": "1.3 Visualización de datos con ggplot2\n\n1.3.1 Componentes de una gráfica\nEn esta sección vamos a ver algunos de los componentes que usaremos cuando visualicemos datos. Muchos de los ejemplos que usaremos vienen de R for data science.\n\n\n\n\n\n\nIngredientes esenciales de una gráfica\n\n\n\n\n\nAesthetic mappings (aes): Variables, colores, rellenos, formas, …\n\nGeoms (geom_): puntos, líneas, boxplots, …\n\nFacets (facet_): paneles con diferentes gráficos para cada nivel de una variable categórica, …\n\nTransformaciones estadísticas: calcular promedios, barras de error, …\n\n\n\nSOURCE: https://skillgaze.com/2017/10/31/understanding-different-visualization-layers-of-ggplot/\n\n\n\n\n\n1.3.1.1 Mi primera gráfica 1-2-3\nPara crear una gráfica con ggplot, tenemos que:\n\nindicar donde están nuestros datos y que mostraremos en los ejes x e y\n\nañadir la o las geometrias (geoms) que queramos\n\nUsaremos + para sumar instrucciones, con una lógica de capas superpuestas.\nPor ejemplo:\n\nIndicamos los datos y coordenadas: ggplot(data = mpg, aes(x = displ, y = hwy))\nAñadimos el geom de puntos para mostrar la relación entre x e y: + geom_point()\nAñadimos un segundo geom para trazar una línea de tendencia: + geom_smooth()\n\n\n\n\n\n\n\n1.3.2 Aesthetic mappings\nEn aes() vamos a indicar las variables que queremos en los ejes x e y, el color de los puntos o líneas, el relleno de las barras, la forma de los puntos, el tipo de linea, la agrupación de los datos, etc.\n\n\n\n\n\n\nParámetros estéticos\n\n\n\n\n\nx: x = gdpPercap\n\ny: y = lifeExp\n\ncolor: color = continent; color = “red”; color = “#FAA627”\n\nfill: fill = continent; fill = “red”; fill = “#FAA627”\n\nalpha: alpha = continent; alpha = 0.2\n\nsize: size = continent; size = 5\n\nshape: shape = continent; shape = 0 ver codigo de las distintas formas\n\n\nlinetype: linetype = continent; linetype = “dashed”\n\ngroup: group = continent\n\n\n\n\n1.3.2.1 x-y\nAlgo esencial es decirle a ggplot que queremos que aparezca en el eje x y en el eje y de nuestra gráfica.\nEmpezaremos usando los datos de gapminder. A ver que variables tenemos en el data-frame gapminder:\n\n\ngapminder\n#&gt; # A tibble: 1,704 × 6\n#&gt;   country     continent  year lifeExp      pop gdpPercap\n#&gt;   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia       1952    28.8  8425333      779.\n#&gt; 2 Afghanistan Asia       1957    30.3  9240934      821.\n#&gt; 3 Afghanistan Asia       1962    32.0 10267083      853.\n#&gt; 4 Afghanistan Asia       1967    34.0 11537966      836.\n#&gt; 5 Afghanistan Asia       1972    36.1 13079460      740.\n#&gt; 6 Afghanistan Asia       1977    38.4 14880372      786.\n#&gt; # ℹ 1,698 more rows\n\nVisualizamos la relación entre gdpPercap (eje x), y lifeExp (eje y):\n\nggplot(data = gapminder, \n         mapping = aes(x = gdpPercap, y = lifeExp)) + \n    geom_point()\n\n\n\n\nSi respetamos el orden de las variables, podemos simplificar nuestro código, evitando el data = y mapping =.\nPor ejemplo, podemos ver de nuevo la relación entre lifeExp y gdpPercap, invirtiendo los ejes.\n\n\n  ggplot(gapminder, aes(lifeExp, gdpPercap)) + \n    geom_point()\n\n\n\n\nEjercicio\nUsando gapminder, ¿podrías crear un gráfico de gdp per cápita por población como éste?\n\n\n\n\n\n\n1.3.2.2 Color, alpha, size\nPara asignar colores podemos usar nombres de colores en inglés, o algo llamado código HEX:\n\nEscribe colors() en la Consola de RStudio\nVer el código HEX de los colores\n\n\nEmpecemos a cambiar parámetros de nuestro gráfico inicial:\n\n\n  # Gráfico inicial\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point()\n\n\n\n\nColor “rojo” para los puntos con color = \"red\".\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point(color = \"red\")\n\n\n\n\nColor en función de la variable ‘continent’. Al usar la variable continent, tenemos que ponerlo dentro de aes().\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + \n    geom_point()\n  \n\n\n\n\nColor en función de la variable ‘continent’. Cambiamos el tamaño de los puntos a 2.\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent, size = 2)) + \n    geom_point()\n\n\n\n\nColor en función de la variable ‘continent’. Cambiamos el tamaño de los puntos a 2. Añadimos transparencia usando el parámetro ‘alpha’.\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, \n                        color = continent, \n                        size = 2, \n                        alpha = .1)) + \n    geom_point()\n  \n\n\n\n\nEjercicios\nUsando como base el plot siguiente (GDP x población):\nggplot(gapminder, aes(gdpPercap, pop)) + \n    geom_point()\n¿Podrías hacer lo siguiente?:\n\nColorear los puntos por continente\nTamaño del punto 4\nAlpha 0.5\n\n\n\n\n\n\nCada uno de los siguientes gráficos tiene un error. ¿Sabrias corregirlos?\n\n\n\n\n\n\nSolucion\n\n\n\n\n\ncolor = continent debe ir dentro de aes()\n\n\n\n\nggplot(gapminder, aes(gdpPercap, pop), color = continent) + \n    geom_point(size = 4, alpha = .5)\n\n\n\n\n\n\n\n\n\n\nSolucion\n\n\n\n\n\ncolor = “blue” debe ir fuera de aes()\n\n\n\n\nggplot(gapminder, aes(gdpPercap, pop, color = \"blue\")) + \n    geom_point(size = 4, alpha = .5)\n\n\n\n\n\n\n1.3.2.3 Shape\n\n\n\n\n\n\nCódigos para las distintas formas\n\n\n\n\n\nSOURCE: https://r4ds.had.co.nz/data-visualisation.html#aesthetic-mappings\n\n\n\nEn este ejemplo usamos la variable continent para que cada asignar una forma diferente a cada uno de los continentes.\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, shape = continent)) + \n    geom_point() \n\n\n\n\n\n1.3.2.4 Linetype\n\n\n\n\n\n\nCódigos para los distintos estilos de linea\n\n\n\n\n\nSOURCE: http://sape.inf.usi.ch/quick-reference/ggplot2/linetype\n\n\n\nPodemos definir directamente el tipo de línea que queremos en geom_line():\n\n\n  ggplot(gapminder, aes(year, lifeExp, color = continent)) + \n    stat_summary(fun = mean, geom = \"line\", linetype = \"dashed\")\n\n\n\n\nO que el tipo de línea dependa de una variable:\n\n\n  ggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) + \n    stat_summary(fun = mean, geom = \"line\") \n\n\n\n\n\n1.3.3 Geoms\nUna de las cosas más difíciles cuando nos enfrentamos a nuevos datos es elegir el método más efectivo para visualizarlos. Hay varios recursos interesantes sobre cómo elegir una gráfica. En esta sección veremos distintos tipos de geometría, o geoms_().\n\n\n\n\n\n\n\nAlgunos tipos de geoms\n\n\n\nPara una lista exhaustiva ver el manual de ggplot2.\n\n\nSOURCE: https://nbisweden.github.io/RaukR-2019/ggplot/presentation/ggplot_presentation_assets/geoms.png\n\n\n\n\n\n1.3.3.1 geom_point y geom_jitter\nSi queremos un gráfico de dispersión o scatterplot, podemos usar el geom_point()\n\n  ggplot(mpg, aes(displ, hwy)) + \n    geom_point()\n\n\n\n\nEn algunos casos, tenemos muchos puntos que se superponen. Si usamos geom_jitter() la posición de los puntos cambia levemente de manera aleatoria para evitar superposiciones. Con las propiedades ´width´ y ´height´ podemos controlar cuando desplazamiento queremos horizontal y verticalmente.\n\n  ggplot(mpg, aes(displ, hwy)) + \n    geom_jitter()\n\n\n\n\n\n1.3.3.2 geom_smooth\nPodemos usar líneas de tendencia con geom_smooth(). El method por defecto es loess, pero podemos usar otros métodos (e.g. geom_smooth(method = \"lm\") para usar una regresión lineal).\nRecuerda que las funciones que usamos (todo lo que contiene () e.g. geom_smooth()) tienen parámetros, que son instrucciones addicionales que nos permiten modificar como se comportan. Para ver que opciones tenemos, podemos ver la ayuda de las funciones : ?geom_smooth(), o poner el cursor encima y presionar F1 (ayuda).\n\n  \n  # Linea de tendencia (default loess)\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point() +\n    geom_smooth()\n    \n\n\n\n\nUsamos “lm”.\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point() +\n    geom_smooth(method = \"lm\")\n \n\n\n\n\nUn smooth por cada color (continent).\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) + \n    geom_point() +\n    geom_smooth()\n \n\n\n\n\nColoreamos puntos pero mantenemos un solo smooth introduciendo el parámetro aes(color = continent) dentro de geom_point().\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) + \n    geom_point(aes(color = continent)) +\n    geom_smooth()\n\n    \n\n\n\n\nEjercicios\nUsando como base el plot de la sección Shape:\n  ggplot(gapminder, aes(gdpPercap, lifeExp, shape = continent)) + \n    geom_point()\n\nColorea los puntos por continente\nMuestra una línea de tendencia por continente (sin el intervalo de confianza)\nHaz que el tipo de línea cambie por continente\nAñade transparencia a los puntos para que las líneas destaquen\n\n\n\n\n\n\nAhora usando el data-frame mpg, intenta crear los 6 plots que se pueden ver más abajo.\nAquí tienes el plot base, para hacer mas fácil la tarea:\n\n\nggplot(mpg, aes(displ, hwy)) + \n  geom_point() +\n  theme_grey()\n\n\n\n\nAdemás de generar uno a uno los 6 plots, serías capaz de generar la figura que se ve abajo? Esto es, un plot que incluye los 6 plots juntos.\n\n\n\n\n\n\nSolucion para combinar plots\n\n\n\n\n\nEn la sección Combinando gráficas veras un ejemplo del uso de la función cowplot::plot_grid()\n\n\n\n\n\n\n\n\n\n\n1.3.3.3 geom_boxplot y geom_violin\nPodemos crear diagramas de cajas (boxplots) con geom_boxplot o violines con geom_violin para visualizar como cambian los datos por grupo.\nBoxplot con fill.\n\n\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + \n    geom_boxplot(alpha = .2)\n\n\n\n\nViolins.\n\n\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) + \n    geom_violin(alpha = .2)\n\n\n\n\nCombinando ambos.\n\n\n  ggplot(gapminder, aes(continent, lifeExp)) + \n    geom_boxplot(alpha = .2) +\n    geom_violin(alpha = .2, aes(fill = continent))\n\n\n\n\n\n1.3.3.4 geom_histogram y geom_bar\nPodemos usar histogramas geom_histogram() con variables continuas. Como puedes ver, ahora solo le pasamos una variable a aes()\n\n  ggplot(gapminder, aes(lifeExp)) + \n    geom_histogram()\n\n\n\n\nO si tenemos variables categóricas, geom_bar().\n\n  ggplot(gapminder, aes(continent, fill = continent)) +\n    geom_bar(alpha = .6)\n\n\n\n\n\n1.3.3.5 geom_density\nPara visualizar distribuciones (cuando tenemos muchos datos), podemos usar geom_density().\n\n  \n  # Density with fill and alpha\n  ggplot(gapminder, aes(lifeExp, fill = continent)) + \n      geom_density(alpha = .2)\n\n\n\n\nEjercicio\nAñadiendo un parámetro a la gráfica de arriba, podemos transformarla en las versiones de abajo. ¿Podrías hacerlo? (recuerda que poníendote encima de geom_density() y tecleando F1 puedes ver la ayuda de la función).\nggplot(gapminder, aes(lifeExp, fill = continent)) + \n      geom_density(alpha = .2)\n\n\n\n\n\n\nSolucion\n\n\n\n\n\nposition = \"stack\" y position = \"fill\".\n\n\n\n\n\n\n\n\n\n\n\n\n1.3.3.6 geom_density_ridges\nUno de mis geoms favoritos para comparar distribuciones es geom_density_ridges:\n\n# geom_density_ridges\n  ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + \n    ggridges::geom_density_ridges(alpha = .2)\n\n\n\n\nEspecialmente porque podemos incluir en el mismo gráfico información sobre distribuciones y puntos individuales.\n\n# geom_density_ridges junto con raincloud points y histograma\nggplot(gapminder, aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.7,\n    scale = 0.9,\n    quantile_lines = TRUE,\n    quantile_fun = mean\n  ) +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(n.breaks = 10) +\n  labs(caption = \"vertical lines represent the mean lifeExp per continent\")\n\n\n\n\nEjercicios\nUsando como base el plot de la seccion geom_histogram():\n  ggplot(gapminder, aes(lifeExp)) + \n    geom_histogram()\n\nColorea los histogramas por continente\nSabrias hacer que no se amontonen unos continentes sobre otros? Necesitarás añadir transparencia para ver todos los datos\n\n\n\n\n\n\n\nSolucion\n\n\n\n\n\ngeom_histogram(position = \"identity\", alpha = .3).\n\n\n\n\n\n\n\n\n\n\n\nCon el DF diamonds, crea el siguiente plot:\n  ggplot(diamonds, aes(cut))\n\n\n\n\n\n\nPista\n\n\n\n\n\nTienes que usar el geom_bar() y el parámetro fill.\n\n\n\n\n\n\n\n\n\n\n1.3.4 Personalización básica\nUna gráfica sin elementos básicos como un título no resulta tan útil. Usaremos la función labs() para incluir o editar los siguientes elementos:\n\n\ntitle: título de la gráfica\n\nsubtitle: subtítulo\n\ncaption: pie de gráfica (abajo a la derecha)\n\ntag: etiqueta de la gráfica (arriba a la izquierda)\n\nx: eje horizontal\n\ny: eje vertical\n\nalt: alt-text, importante para que los lectores de pantalla usados por personas ciegas describan las gráficas\n\nEn el siguiente ejemplo, vamos a personalizar la gráfica del ejercicio anterior:\n\nggplot(diamonds, aes(cut, fill = clarity)) + \n  geom_bar() +\n  labs(title = \"How many diamons do we have?\",\n       subtitle = \"A lot\", \n       caption = \"Source, the ggplot2::diamonds dataset\",\n       tag = \"a)\",\n       x = \"How many diamonds\",\n       y = \"Type of cut of the diamond\", \n       alt = \"Alt text for the plot. Very useful for blind people\"\n       )\n\n\n\n\nEjercicio\nUsando como base este plot:\n\n   ggplot(mpg, aes(displ, hwy)) + \n    geom_point() +\n    geom_smooth(se = FALSE) +\n    theme_grey()\n\n\n\n\nPersonalizalo añadiendo y modificando:\n\ntítulo\n\nsubtítulo\n\ncaption\n\nejes x e y"
  },
  {
    "objectID": "qmd/01-introduccion_visualizacion.html#bibliografía",
    "href": "qmd/01-introduccion_visualizacion.html#bibliografía",
    "title": "\n1  Introducción a R y visualización de datos\n",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nMatejka, J., & Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM.\nhttps://bbc.github.io/rcookbook/\nhttps://github.com/bbc/bbplot\nhttps://github.com/dreamRs/esquisse\nGarrick Aden-Buie. A Gentle Guide to the Grammar of Graphics with ggplot2: https://github.com/gadenbuie/gentle-ggplot2\nMichael Toth. You Need to Start Branding Your Graphs. Here’s How, with ggplot!: https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html\nClaus Wilke: https://wilkelab.org/practicalgg/\n\nThomas Lin Pedersen:\n\nPart 1: https://www.youtube.com/watch?v=h29g21z0a68\nPart 2: https://www.youtube.com/watch?v=0m4yywqNPVY\n\n\nBig Book or R : https://www.bigbookofr.com/index.html"
  },
  {
    "objectID": "qmd/02-visualizacion-avanzada.html#facets",
    "href": "qmd/02-visualizacion-avanzada.html#facets",
    "title": "\n2  Visualización avanzada\n",
    "section": "\n2.1 Facets",
    "text": "2.1 Facets\nCuando queremos separar en gráficos independientes distintas categorías dentro de nuestros datos, podemos usar facetas. Hay dos funciones para esto, facet_grid() y facet_wrap().\n\n2.1.1 facet_grid\nfacet_grid(~ variable) nos devuelve una matriz simétrica de gráficas.\n\n \n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n    geom_point(alpha = .2)\n\n\n\n\nUn gráfico para cada continente.\n\n \n  ## Tip: usamos guides(color = \"none\") para que no se vea la leyenda asociada a color\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n    geom_point(alpha = .2) +\n    facet_grid(~ continent) +\n    guides(color = \"none\")\n\n\n\n\nCambiamos los ejes.\n\n \n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n    geom_point(alpha = .2) +\n    facet_grid(continent ~ .) +\n    guides(color = \"none\")\n  \n\n\n\n\nAñadimos una segunda variable. Podemos usar variables categóricas, o dicotomizar variables usando condiciones lógicas (pop &gt; 5000000).\n\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp, color = country)) +\n    geom_point(alpha = .2) +\n    facet_grid(continent ~ pop &gt; 5000000) + \n    guides(color = \"none\")\n\n\n\n\n\n2.1.2 facet_wrap\nfacet_wrap(~ variable) nos devuelve tantas facetas como niveles de la variable, pudiendo definir el número de filas y columnas que queremos.\n\n  # Plot base\n  ggplot(gapminder, aes(lifeExp, fill = continent)) +\n    geom_histogram(alpha = .5)\n\n\n\n\nFacetas por continente.\n\n  \n  ## En 2 columnas\n  ggplot(gapminder, aes(lifeExp, fill = continent)) +\n    geom_histogram(alpha = .5) +\n    facet_wrap( ~ continent, ncol = 2) +\n    guides(fill = \"none\")\n\n\n\n\n\n2.1.3 gghighlight y facet_wrap\nCon la función gghighlight() del paquete [{gghighlight}](https://cran.r-project.org/web/packages/gghighlight/index.html) podemos añadir una capa para facilitar la comparación de cada faceta con los datos completos.\n\n\nggplot(gapminder, aes(lifeExp, fill = continent)) +\n  geom_histogram(alpha = .5) +\n  facet_wrap( ~ continent, nrow = 1) +\n  guides(color = \"none\") +\n  gghighlight::gghighlight()\n\n\n\n\nEjercicios\nUsando como base el plot siguiente:\nggplot(mpg, aes(displ, hwy)) +\n  geom_point()\n\nCrea un panel para cada tipo de coche (class) en una rejilla simétrica\nCrea un panel para cada tipo de coche (class), mostrando paneles en 3 filas\n\n\n\n\n\n\n\nSolucion\n\n\n\n\n\nfacet_grid() permite crear rejillas simétricas de paneles, y el parámetro nrow de facet_wrap() nos ayuda con paneles con números de filas definidos."
  },
  {
    "objectID": "qmd/02-visualizacion-avanzada.html#transformaciones-estadísticas",
    "href": "qmd/02-visualizacion-avanzada.html#transformaciones-estadísticas",
    "title": "\n2  Visualización avanzada\n",
    "section": "\n2.2 Transformaciones estadísticas",
    "text": "2.2 Transformaciones estadísticas\nggplot2 nos permite hacer algunas transformaciones estadísticas al crear los gráficos. Para más detalles, ver r4ds.\n\n2.2.1 Computaciones con ggplot: stat_summary()\nEn ocasiones queremos visualizar estadísticas descriptivas asociadas a los datos (e.g. promedio, mínimo y máximo por condición), pero como generalmente trabajaremos con data-frames en formato long (una observación por fila), no podremos usar los geoms que hemos visto hasta ahora.\nTenemos dos opciones, la primera es preparar nuevos data-frames antes de pasar a la visualización. La segunda, realizar la computación directamente con ggplot, usando stat_summary() junto con alguna de las funciones tradicionales para extraer estadísticas descriptivas.\n\n\n\n\n\n\nEjemplos de funciones que podemos usar en los gráficos\n\n\n\n\n\nmin(): mínimo\n\nmax(): máximo\n\nmean(): media\n\nmedian(): mediana\n\nsd(): desviación estandar\n\n\n\nCon stat_summary() podemos usar funciones simples de manera directa. Por ejemplo, si queremos visualizar la mediana de lifeExp para cada continente, podemos hacer lo siguiente:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\n  stat_summary(fun = median) +\nlabs(caption = \"Mediana\")\n\n\n\n\nstat_summary() tiene un buen número de parámetros (F1 sobre la función para ver la ayuda). Por ejemplo, fun.min y fun.max nos permitiran añadir a la gráfica anterior el rango completo de los datos:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\n  stat_summary(\n    fun = median,\n    fun.min = min,\n    fun.max = max\n    ) +\n  labs(caption = \"Mediana y rango (mínimo/máximo) de los datos\")\n\n\n\n\n\nSi queremos usar funciones algo más complejas, la sintaxis es diferente. En este caso mostramos media ± desviación estandar:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\n  stat_summary(\n    fun = median,\n    fun.min = function(x) median(x) - sd(x),\n    fun.max = function(x) median(x) + sd(x)\n    ) +\nlabs(caption = \"Mediana más/menos desviación estandard\")\n\n\n\n\n\n2.2.2 Promedios por grupo\nLo interesante es que podemos añadir estas transformaciones estadísticas como una capa más en los gráficos. Esto es ideal para mostrar los puntos individuales de nuestros datos, algo crítico como vimos en el tema anterior. Así que, a este gráfico inicial…\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\ngeom_jitter()\n\n\n\n\nLe podemos añadir un punto mostrando la mediana por grupo:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\ngeom_jitter() +\nstat_summary(fun = median,\n             color = \"red\", size = 1, alpha = .7)\n\n\n\n\nO la mediana más la desviación estandard:\n\n\nggplot(gapminder, aes(continent, lifeExp)) +\ngeom_jitter() +\nstat_summary(fun = median,\n             color = \"red\", size = 1, alpha = .7,\n             fun.min = function(x) median(x) - sd(x),\n             fun.max = function(x) median(x) + sd(x))\n\n\n\n\nEjercicios\nCuando al plot A trato de añadirle líneas para cada class, me aparece algo como lo de B, porque tenemos varios puntos en cada nivel de displ.\n\nplotA = ggplot(mpg, aes(displ, hwy, color = class)) +\n  geom_point() +\n  theme(legend.position = \"bottom\")\n\nplotB = ggplot(mpg, aes(displ, hwy, color = class)) +\n  geom_point() +\n  geom_line() +\n  theme(legend.position = \"bottom\")\n\ncowplot::plot_grid(plotA, plotB, labels = c(\"A\", \"B\"))\n\n\n\n\nPero en realidad no quiero que las líneas pasen por todos los puntos, sino que muestren el promedio en cada nivel de displ para cada class de vehículo.\n\n¿Podrías reproducir el gráfico de abajo?\n\n\n\n\n\n\n\nPista\n\n\n\n\n\nTendrás que reemplazar geom_line() por stat_summary(), usando el parámetro geom = \"line\" para indicarle que quieres usar lineas en lugar de puntos.\n\n\n\n\n\n\n\n\n\nUsando como base:\n\nggplot(gapminder, aes(country, lifeExp, color = continent)) +\n  stat_summary(...) +\n  facet_grid(...) +\n  theme(axis.text.x = element_blank(), # Eliminamos etiquetas de nombres de paises del eje x\n        legend.position = \"none\") # Elimina la leyenda\n\n¿Podrías crear este gráfico? Mostramos mediana ± sd para cada país, organizado por continente.\n\n\n\n\n\n\nPista\n\n\n\n\n\nTienes que encontrar los parámetros adecuados para stat_summary() y facet_grid(). Puedes ver ejemplos en:  - computaciones con ggplot: stat_summary()  - Facet_grid."
  },
  {
    "objectID": "qmd/02-visualizacion-avanzada.html#personalización-avanzada-de-gráficas",
    "href": "qmd/02-visualizacion-avanzada.html#personalización-avanzada-de-gráficas",
    "title": "\n2  Visualización avanzada\n",
    "section": "\n2.3 Personalización avanzada de gráficas",
    "text": "2.3 Personalización avanzada de gráficas\nHabitualmente, un vez hemos creado la gráfica, querremos personalizar varias cosas, como las escalas, colores, estilos, título, etc.\n\n2.3.1 Coordenadas\n\n\n# Gráfico inicial\nggplot(gapminder, aes(continent)) +\n    geom_bar()\n\n# coord_flip()\nggplot(gapminder, aes(continent)) +\n  geom_bar() +\n  coord_flip()\n\n# coord_polar()\nggplot(gapminder, aes(continent)) +\n  geom_bar() +\n  coord_polar()\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 Scales\nUsaremos las funciones que empiezan por scale_ para multitud de cosas, por ejemplo, cambiar las etiquetas de los ejes x o y:\n\n\n# Grafico inicial\nplot_base = ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point(alpha = .1)\nplot_base\n\n# Definimos cuantos breaks queremos en cada eje, y rotamos las etiquetas del eje x\nplot_base +\n  scale_x_continuous(n.breaks = 15, guide = guide_axis(angle = 90)) +\n  scale_y_continuous(n.breaks = 15)\n\n# Separador de miles y breaks en x\nplot_base +\n  scale_y_continuous(n.breaks = 15) +\n  scale_x_continuous(n.breaks = 6, labels = scales::comma)\n\n# Con scales::dollar_format() le damos formato de $ ($M)\nplot_base +\n  scale_y_continuous(n.breaks = 15) +\n  scale_x_continuous(n.breaks = 6, labels = scales::dollar_format(prefix = \"$\", \n                                                                  suffix = \"M\"))\n\n# Escala log\nplot_base +\n  scale_y_continuous(n.breaks = 15) +\n  scale_x_log10(n.breaks = 4, labels = scales::dollar_format(prefix = \"$\", \n                                                             suffix = \"M\"))\n\n# Invertimos escala\nplot_base +\n  scale_y_reverse()\n\n# No mostramos el texto ni los ticks de los breaks de x\nplot_base +\n  scale_y_reverse() +\n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# Porcentaje\nggplot(gapminder, aes(continent, ..prop.., group = 1)) +\n  geom_bar() +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.3 Legends\nLa leyenda de las gráficas nos muestra, por defecto, los colores, rellenos, tipos de linea, etc. que hayamos usado. Por ejemplo, abajo nos muestra la leyenda asociada al color.\n\n\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter()\n\n\n\n\nPodemos hacer algunas cosas básicas como cambiar el nombre de la leyenda, o no mostrarla:\n\n\n# Usamos labs(color = \"\") o labs(fill = \"\") para cambiar el título de las leyendas\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter() +\n  labs(color = \"My new legend\")\n\n# Con guides(color = \"none\") hacemos desaparecer la leyenda asociada al color\nggplot(gapminder, aes(year, lifeExp, color = continent)) +\n  geom_jitter() +\n  guides(color = \"none\")\n\n\n\n\n\n\n\n\n2.3.3.1 Fancy pants legends\nEn ocasiones podemos simplificar notablemente las gráficas reemplazando la leyenda clásica por algo más moderno.\nPodemos usar el eje secundario (derecho) para mostrar etiquetas. Partimos del gráfico siguiente:\n\nggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) +\n  stat_summary(fun = mean, geom = \"line\")\n\n\n\n\nUsando un poco de vodoo, podemos convertirlo en esto:\n\n\ngapminder_last = gapminder |&gt;\n  group_by(continent) |&gt;\n  filter(year == max(year)) |&gt;\n  summarize(lifeExp = mean(lifeExp))\n\nggplot(gapminder, aes(year, lifeExp, linetype = continent, color = continent)) +\n  stat_summary(fun = mean, geom = \"line\") +\n  scale_y_continuous(\n    limits = c(0, max(gapminder$lifeExp)),\n    expand = c(0,0),\n    sec.axis = dup_axis(\n      breaks = gapminder_last$lifeExp,\n      labels = gapminder_last$continent,\n      name = NULL)) +\n  scale_x_continuous(expand = c(0,0)) +\n  guides(color = \"none\",\n         linetype = \"none\")\n\n\n\n\nOtra estrategia interesante es colocar las etiquetas en el camino de las líneas. Para ello, necesitaremos la función geom_labelsmooth() del paquete {geomtextpath}:\n\n\nggplot(gapminder,\n       aes(year, lifeExp, linetype = continent, color = continent)) +\n  \n  geomtextpath::geom_labelsmooth(\n    aes(label = continent),\n    text_smoothing = 30,\n    method = \"loess\",\n    formula = y ~ x,\n    size = 3,\n    linewidth = 1,\n    boxlinewidth = 0.3\n  ) +\n  \n  scale_x_continuous(expand = c(0, 0)) +\n  guides(color = \"none\",\n         linetype = \"none\")\n\n\n\n\nEjercicio\nEl plot del panel (A) tiene varios problemas:\n\nlos casos no se muestran con un separador de miles\nla leyenda esta a la derecha ocupado un espacio precioso, debería estar abajo\nal gráfico le falta el título, y caption\nla etiqueta del eje x debería ser year en lugar de as.factor(year)\n\n\nUsando el plot base (A):\nggplot(table1, aes(as.factor(year), cases)) + # Usamos as.factor(year) para evitar que se muestren decimales\n  geom_line(aes(group = country), colour = \"grey50\") +\n  geom_point(aes(colour = country)) +\n  scale_x_discrete(expand = c(.05, 0)) # Movemos las etiquetas del eje x hacia los extremos\nTrata de resolver los problemas e intenta llegar al resultado que se ve en el panel (B).\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- Recuerda la funciónscales::comma() que vimos más arriba - theme(legend.position = \"ALGO AQUI\") nos permite mover la leyenda. Si vas la ayuda de theme() y buscas legend.position, encontrarás sus opciones. - Los parámetros de labs() nos permiten añadir títulos, subtítulos, editar los valores de las etiquetas de x e y, añadir caption, etc. \n\n\n\n\n\n\n\n\nSi te sobra tiempo, puedes tratar de reproducir la siguiente versión mejorada…\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\nHemos visto como hacer esto en el primer ejemplo de fancy pants legends \n\n\n\n\n\n\n\n\n\n2.3.4 Colors and fill scales\nLas funciones scale_color_, scale_fill_ nos sirven para hacer cambios globales en los colores o rellenos de las gráficas. Algunos ejemplos:\n\n\n  # Plot inicial\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) +\n    geom_violin(alpha = .2)\n\n  # Relleno usando paleta blues\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) +\n    geom_violin(alpha = .2) +\n    scale_fill_brewer(palette = \"Blues\")\n\n  # Color grey\n  ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) +\n    geom_point() +\n    scale_color_grey(start = 0.2, end = 0.8, na.value = \"red\")\n\n  # Gradient\n  ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) +\n    geom_point() +\n    scale_color_gradient(low = \"red\", high = \"blue\")\n\n  # Gradient con un numero predefinidos de una paleta\n  ggplot(iris, aes(Petal.Width, Petal.Length, color = Petal.Width)) +\n    geom_point() +\n    scale_colour_gradientn(colours = terrain.colors(3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio\n\nUsando como base este plot, podrias cambiarle la paleta de color para usar una de las cualitativas?\n\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\nVer sección Palettes de la ayuda de scale_fill_brewer() \n\n\n\n\n\n  ggplot(gapminder, aes(continent, lifeExp, fill = continent)) +\n    geom_violin(alpha = .2) +\n    scale_fill_brewer(palette = \"Blues\")\n\n\n\n\n\nSi intentamos asignar colores manualmente a los continentes de este modo, recibimos un error:\n\n  ggplot(gapminder, aes(gdpPercap, lifeExp)) +\n    geom_point(color = c(\"red\", \"grey\", \"green\", \"purple\", \"black\"))\n  # Error: Aesthetics must be either length 1 or the same as the data (1704): colour\nPodrías resolver el error y mostrar el gráfico de abajo?\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\nTenemos que: - indicar que el color depende de continent - usar scale_color_manual(), con el parámetro values para asignar los colores (ver ejemplos en la ayuda de la función)\n\n\n\n\n\n\n\n\n\n2.3.5 Combinando gráficas\nCon {cowplot} podemos combinar gráficas de manera muy simple. Otro paquete muy interesante es {patchwork}.\n\n\nplot1 = ggplot(gapminder, aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point(alpha = .1) +\n  scale_y_continuous(breaks = seq(0, 100, 5)) +\n  scale_x_log10(labels = scales::dollar_format(prefix = \"$\", suffix = \"M\")) +\n  theme(legend.position = \"top\")\n\nplot2 = ggplot(gapminder, aes(continent, ..prop.., group = 1)) +\n  geom_bar() +\n  scale_y_continuous(labels = scales::percent) +\n  coord_flip()\n\ncowplot::plot_grid(plot2, plot1, rel_widths = c(.3, 0.7))\n\n\n\n\nEjercicio\n\nCombina los dos plots del ejercicio anterior, con las siguientes modificaciones:\n\n\nElimina las leyendas asociadas a colores y rellenos\nUsa la paleta “Accent” para los colores y rellenos\n\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- guides(fill = “none”) quita la leyenda asociada a fill… - scale_fill_brewer(palette = “Accent”) asigna la paleta “Accent” a los rellenos (fill)\n\n\n\n\n\n\n\n\n\n\n2.3.5.1 Combinando múltiples gráficas\nPodemos combinar múltiples gráficas y llegar a hacer cosas mucho más complejas como combinar un scatteplot con un par de histogramas:\n\n\n# Set up scatterplot\nscatterplot &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) +\n  geom_point(size = 3, alpha = 0.6) +\n  guides(color = \"none\") +\n  theme(plot.margin = margin())\n\n\n# Define marginal histogram\nmarginal_distribution &lt;- function(x, var, group) {\n  ggplot(x, aes_string(x = var, fill = group)) +\n    geom_histogram(bins = 30, alpha = 0.4, position = \"identity\") +\n    # geom_density(alpha = 0.4, size = 0.1) +\n    guides(fill = \"none\") +\n    theme_void() +\n    theme(plot.margin = margin())\n}\n\n# Set up marginal histograms\nx_hist &lt;- marginal_distribution(iris, \"Sepal.Length\", \"Species\")\ny_hist &lt;- marginal_distribution(iris, \"Sepal.Width\", \"Species\") +\n  coord_flip()\n\n# Align histograms with scatterplot\naligned_x_hist &lt;- align_plots(x_hist, scatterplot, align = \"v\")[[1]]\naligned_y_hist &lt;- align_plots(y_hist, scatterplot, align = \"h\")[[1]]\n\n\n# Arrange plots\ncowplot::plot_grid(\n  aligned_x_hist, NULL, scatterplot, aligned_y_hist,\n  ncol = 2, nrow = 2,\n  rel_heights = c(0.2, 1), rel_widths = c(1, 0.2)\n  )\n\n\n\n\n\n2.3.6 Estilos\nLos estilos nos permiten personalizar los gráficos de manera muy sencilla, por ejemplo, usando {ggtheme}. Podéis ver un tutorial aquí.\nPrimero creamos un gráfico sobre el que aplicaremos estilos.\n\n\np &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) +\n  geom_point() +\n  labs(title = 'A ggplot simple graph',\n       subtitle = 'Simple tweaks to improve plots, or not',\n       x = '',\n       y = '',\n       caption = 'https://github.com/gorkang / @gorkang') +\n    theme_gray() # This is the default. Needed here because of the Bookdown theme\n\np\n\n\n\n\nUsando el tema fivethirtyeight:\n\n\np +\n  ggthemes::scale_color_fivethirtyeight() +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\nUsando el tema economist:\n\n\np +\n  ggthemes::scale_color_economist() +\n  ggthemes::theme_economist()\n\n\n\n\nEjercicios\n\nSerías capaz de reproducir este gráfico, usando el dataframe diamonds y el theme_economist?\n\nGráfica inicial:\nggplot(diamonds, aes(price, cut, fill = cut, color = cut)) +\n  ggridges::geom_density_ridges(alpha = .6)\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- scale_x_log10() nos permite transformar el eje x a una escala logarítmica - Hay que aplicar un ggthemes::scale_* para cada elemento: color, fill… \n\n\n\n\n\n\n\n\n\n\nSerías capaz de reproducir este gráfico, usando el dataframe gapminder y la paleta Accent?\n\nGráfica inicial:\nggplot(gapminder, aes(gdpPercap, continent, fill = continent, color = continent)) +\n  ggridges::geom_density_ridges(alpha = .6)\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n- scales::dollar_format() aplicado al parámetro labels de las funciones scale_x_* nos permite darle formato de moneda a las etiquetas de la escala x\n\n\n\n\n\n\n\n\n\n2.3.7 Estilos en textos\nCon {ggtext} podemos incluir estilos en los textos, por ejemplo, en el título de nuestras gráficas.\n\n\n# Ejemplo adaptado de https://wilkelab.org/ggtext/articles/theme_elements.html\nmtcars |&gt;\n  mutate(\n    transmission = ifelse(am == 1, \"automatic\", \"manual\")\n  ) |&gt;\n  ggplot(aes(hp, mpg, color = transmission)) +\n  geom_point(size = 2) +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  scale_color_manual(\n    values = c(automatic = \"#0072B2\", manual = \"#D55E00\"),\n    guide = \"none\"\n  ) +\n  labs(\n    x = \"Horse power\",\n    y = \"Miles per gallon (MPG)\",\n    title = \"Transmission type impacts fuel efficiency\",\n    subtitle = \"MPG is higher for &lt;span style = 'color:#0072B2;'&gt;automatic&lt;/span&gt;\n            than for &lt;span style = 'color:#D55E00;'&gt;manual&lt;/span&gt; transmissions\"\n\n  ) +\n  theme_minimal() +\n  theme(\n    # plot.title.position = \"plot\",\n    plot.subtitle = element_markdown(size = 11, lineheight = 1.2)\n  )"
  },
  {
    "objectID": "qmd/02-visualizacion-avanzada.html#otras-gráficas",
    "href": "qmd/02-visualizacion-avanzada.html#otras-gráficas",
    "title": "\n2  Visualización avanzada\n",
    "section": "\n2.4 Otras gráficas",
    "text": "2.4 Otras gráficas\nUn tipo de gráfica genial para mostrar simultáneamente observaciones individuales, distribuciones, y cambios, es el raincloudplot.\n\n\n# Transforma datos para adaptarlos a la estructura necesaria para raincloudplot\ndf_1x1 &lt;- data_1x1(\n  array_1 = iris$Sepal.Length[1:50],\n  array_2 = iris$Sepal.Length[51:100],\n  jit_distance = .09,\n  jit_seed = 321)\n\n# Crea raincloudplot\nraincloud_1x1_repmes(\n  data = df_1x1,\n  colors = (c('dodgerblue', 'darkorange')),\n  fills = (c('dodgerblue', 'darkorange')),\n  line_color = 'gray',\n  line_alpha = .3,\n  size = 1,\n  alpha = .6,\n  align_clouds = FALSE) +\n\n  scale_x_continuous(breaks = c(1, 2),\n                     labels = c(\"Pre\", \"Post\"),\n                     limits = c(0, 3)) +\n  xlab(\"Time\") +\n  ylab(\"Score\")"
  },
  {
    "objectID": "qmd/02-visualizacion-avanzada.html#visualización-interactiva",
    "href": "qmd/02-visualizacion-avanzada.html#visualización-interactiva",
    "title": "\n2  Visualización avanzada\n",
    "section": "\n2.5 Visualización interactiva",
    "text": "2.5 Visualización interactiva\nEl paquete {plotly} nos permite crear gráficas con algunos niveles de interactividad usando funciones propias, o modificando gráficas creadas con ggplot.\n\n2.5.1 ggplots interactivos con plotly\nScatterplot creado con ggplot donde se puede ver el valor de los puntos, seleccionar áreas, etc.\n\n\nplotly::ggplotly(\n  ggplot(\n    gapminder |&gt; filter(year == 2007),\n    aes(gdpPercap, lifeExp, color = continent, size = country)\n  ) +\n    geom_point(alpha = .3, point = 2) +\n    scale_y_continuous(breaks = seq(0, 100, 5)) +\n    scale_x_log10(labels = scales::dollar_format(prefix = \"$\", suffix = \"M\")) +\n    theme(legend.position = \"none\")\n)\n\n\n\n\n\n\n2.5.2 Surface plots con plotly\nSurface plot creado con plotly donde se muestra la relación entre 3 variables en un entorno interactivo 3D.\n\n\nDF_RAW = structure(c(181, 163, 60, 124, 76, 62, 73, 59, 17, 21, 26, 7, 1, 2, 3,\n                     188, 145, 61, 130, 61, 59, 62, 57, 20, 22, 22, 6, 4, 5, 5,\n                     137, 154, 54, 191, 75, 56, 65, 56, 22, 27, 33, 14, 5, 5, 5,\n                     126, 185, 65, 109, 51, 71, 57, 38, 25, 23, 21, 10, 5, 5, 5,\n                     150, 144, 44, 123, 58, 24, 48, 41, 19, 26, 21, 5, 5, 5, 5,\n                     138, 137, 61, 130, 67, 34, 60, 44, 19, 21, 16, 4, 5, 5, 5,\n                     121, 146, 101, 92, 70, 74, 88, 33, 18, 39, 24, 12, 5, 5, 5,\n                     100, 160, 129, 117, 70, 61, 42, 35, 22, 25, 21, 7, 10, 23, 8,\n                     100, 129, 130, 107, 64, 61, 44, 25, 23, 30, 18, 11, 20, 58, 40,\n                     100, 136, 131, 96, 53, 31, 51, 37, 43, 31, 19, 2, 22, 40, 41,\n                     100, 124, 154, 74, 62, 44, 34, 15, 26, 23, 20, 6, 23, 10, 19,\n                     100, 126, 251, 76, 73, 84, 47, 40, 32, 25, 32, 6, 13, 10, 13,\n                     100, 129, 194, 91, 53, 99, 46, 34, 60, 21, 17, 6, 14, 14, 26,\n                     100, 115, 119, 88, 64, 108, 37, 24, 49, 26, 17, 6, 15, 15, 47),\n                   .Dim = 15:14,\n                   .Dimnames = list(c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \n                                      \"10\", \"11\", \"12\", \"13\", \"14\", \"15\"),\n                                    c(\"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \n                                      \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \n                                      \"2016\", \"2017\", \"2018\", \"2019\")))\n\nDF = DF_RAW\nplot1 = plotly::plot_ly(x = ~ colnames(DF),\n                        y = ~ rownames(DF),\n                        z = ~ DF) |&gt;\n  plotly::add_surface(\n    name = \"3D mesh\",\n    connectgaps = TRUE,\n    hidesurface = TRUE,\n    showscale = FALSE,\n    contours = list(\n      x = list(\n        show = TRUE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      y = list(\n        show = TRUE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      z = list(\n        show = FALSE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = FALSE\n      )\n    )\n  ) |&gt;\n  plotly::add_surface(\n    name = \"surface\",\n    connectgaps = FALSE,\n    contours = list(\n      x = list(\n        show = F,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      y = list(\n        show = F,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = TRUE\n      ),\n      z = list(\n        show = FALSE,\n        width = 1,\n        highlightwidth = 2,\n        highlightcolor = \"#41a7b3\",\n        highlight = FALSE\n      )\n    )\n  )\n\nif (!knitr::is_latex_output()) plot1\n\n\n\n\n\n\n2.5.3 Animando gráficas con gganimate\n{gganimate} nos permite crear ggplots añadiendo la dimensión temporal\n\n\nif (!require('gganimate')) remotes::install_github('thomasp85/gganimate'); library('gganimate')\n#sudo apt-get install ffmpeg\n\np = ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  scale_x_log10() +\n  facet_wrap(~continent) +\n\n  # Here comes the gganimate specific bits\n  labs(title = 'Year: {frame_time}', x = 'GDP per capita', y = 'life expectancy') +\n  transition_time(year) +\n  ease_aes('linear')\n\n  # Create animated plot\n  animate(p, renderer = ffmpeg_renderer(), \n          height = 6, width = 10, units = \"in\", res = 300)\n\n  # Save plot\n    # anim_save(\"name_file.mp4\", animation = last_animation())\n\nVideo"
  },
  {
    "objectID": "qmd/02-visualizacion-avanzada.html#bibliografía",
    "href": "qmd/02-visualizacion-avanzada.html#bibliografía",
    "title": "\n2  Visualización avanzada\n",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nMatejka, J., & Fitzmaurice, G. (2017, May). Same stats, different graphs: Generating datasets with varied appearance and identical statistics through simulated annealing. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 1290-1294). ACM.\nhttps://bbc.github.io/rcookbook/\nhttps://github.com/bbc/bbplot\nhttps://github.com/dreamRs/esquisse\nGarrick Aden-Buie. A Gentle Guide to the Grammar of Graphics with ggplot2: https://github.com/gadenbuie/gentle-ggplot2\nMichael Toth. You Need to Start Branding Your Graphs. Here’s How, with ggplot!: https://michaeltoth.me/you-need-to-start-branding-your-graphs-heres-how-with-ggplot.html\nClaus Wilke: https://wilkelab.org/practicalgg/\n\nThomas Lin Pedersen:\n\nPart 1: https://www.youtube.com/watch?v=h29g21z0a68\nPart 2: https://www.youtube.com/watch?v=0m4yywqNPVY\n\n\nBig Book or R : https://www.bigbookofr.com/index.html"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#importar-y-exportar-datos",
    "href": "qmd/03-preparacion_transformacion.html#importar-y-exportar-datos",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "\n3.1 Importar y exportar datos",
    "text": "3.1 Importar y exportar datos\nHasta ahora hemos trabajado con data-frames como mpg o gaminder, que forman parte de la instalación por defecto de R, o alguno de sus paquetes. Pero habitualmente trabajaremos con datos propios, por lo que necesitaremos leer uno o varios archivos. RStudio tiene un menú para ayudar a importar datos en formatos habituales , pero aquí aprenderemos a hacerlo todo en código, para que nuestros scripts sean autocontenidos.\nPodemos ver algunas de las funciones de esta sección y cómo usarlas en la Cheatsheet importar datos\n\n3.1.1 Importar un solo archivo\nEmpezaremos por la situación básica más común, cómo importar un solo archivo. Vamos a ver con más detalle los archivos CSV (comma separated values). Las funciones para importar archivos excel, Libreoffice, SPSS, etc. tienen parámetros muy similares.\n\n3.1.1.1 Archivos CSV\nUsaremos las siguientes funciones del paquete readr:\n\n\n\n\n\n\nFunciones para leer archivos csv\n\n\n\n\n\nreadr::read_csv(): valores separados por coma (“,”)\n\n\nreadr::read_csv2(): valores separados por punto y coma (“;”)\n\n\nreadr::read_delim( , delim = \"|\"): valores separados por un delimitador arbitrario\n\n\n\nLeemos el archivo 02-read-csv.csv de la carpeta data/files/:\n\n\nDF_name = read_csv(\"data/files/02-read-csv.csv\")\n\nSi estamos usando rmarkdown, o similar, es recomendable usar here::here() para evitar problemas con los paths a los archivos.\n\n  \nname_of_file = here::here(\"data/files/02-read-csv.csv\")\nDF_name = read_csv(name_of_file)\n\nDF_name\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nSi usamos un repositorio online para almacenar los archivos, podemos leer directamente de una URL.\n\n\nURL = \"https://raw.githubusercontent.com/gorkang/R_preparacion_visualizacion_datos/master/data/files/02-read-csv.csv\"\nread_csv(URL)\n\n\n3.1.1.2 Otros tipos de archivos\nArchivos excel\n\n\nname_of_file = here::here(\"data/files/02-read-xlsx.xlsx\")\nreadxl::read_excel(name_of_file)\n\nArchivos SPSS\n\n\nname_of_file = here::here(\"data/files/02-read-sav.sav\")\nhaven::read_sav(name_of_file)\n\nArchivos Libreoffice\n\n\nname_of_file = here::here(\"data/files/02-read-ods.ods\")\ndf_ODS = readODS::read_ods(name_of_file)\n\n# Vemos las primeras filas\nhead(df_ODS)\n\nGoogle sheets\nPara poder leer una gsheet debemos:\n\nCrear un enlace para compartirla: \"Share\" -&gt; \"Get shareable link\"\n\nExtraemos el identificador de la google sheet:\n\n\n\nDe https://docs.google.com/spreadsheets/d/1KFmnYnKhPCi3zRJpkZzZii8H-aGSTwr97lonoaz76AY/edit?usp=sharing\n\nUsaremos: 1KFmnYnKhPCi3zRJpkZzZii8H-aGSTwr97lonoaz76AY\n\n\n\n\nif (!require(\"googlesheets4\")) install.packages(\"googlesheets4\"); library(\"googlesheets4\")\nname_of_sheet = \"1KFmnYnKhPCi3zRJpkZzZii8H-aGSTwr97lonoaz76AY\"\ngooglesheets4::read_sheet(name_of_sheet)   \n\nEjercicios - Importar datos\nEn el repositorio R para preparación y visualización de datos - DNSC - UAI de la Open Science Foundation podrás ver una carpeta llamada Capitulo 3. Si no tenéis conexión a internet, podéis encontrar los archivos en data/files/OSF_files.\nDescarga e importa los archivos que ahí aparecen, asegurándote que los nombres de columna se leen adecuadamente:\n\n\n\n\n\n\nSolución\n\n\n\n\n\nLa función read_excel() tiene parámetros como skip, que permite no leer las primeras n lineas, o sheet, con la que puedes indicar que pestaña leer.\n\n\n\n\n02-extralines-1.xlsx\n02-extralines-2.xlsx\n02-extralines-3.xlsx\n02-spanish.csv\n\n3.1.2 Importar múltiples archivos\nEn ocasiones tenemos múltiples archivos en una carpeta (e.g. uno por participante) y queremos combinarlos todos en un solo DF.\nPor suerte, las funciones como read_csv() admiten un vector con varios archivos.\nPara importar todos los archivos que están en la carpeta data/files/02-CSVs:\n\n\n# Directorio donde se encuentran los archivos\nname_of_folder = here::here(\"data/files/02-CSVs\")\n\n# Listamos los archivos a leer\nfiles &lt;- list.files(name_of_folder, full.names = TRUE)\n\n# Leemos todos los archivos, combinandolos en un dataframe\nfull &lt;- read_csv(files)\n\nfull\n#&gt; # A tibble: 1,600 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,594 more rows\n\nLamentablemente, cuando leamos otro tipo de archivos, como archivos .xlsx, no podemos usar la funcion read_csv(). Veamos una manera de hacer lo mismo, con la que se puede usar cualquier función para leer datos.\nUsaremos map_df(), que aplica la función que queramos a cada uno de los archivos que le indiquemos, de uno en uno:\n\n\n# Directorio donde se encuentran los archivos\nname_of_folder = here::here(\"data/files/02-CSVs\")\n\n# Listamos los archivos a leer\nfiles &lt;- list.files(name_of_folder, full.names = TRUE)\n\n# Leemos todos los archivos de uno en uno, combinandolos en un dataframe\nfull &lt;- purrr::map_df(files, read_csv)\n\nfull\n#&gt; # A tibble: 1,600 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,594 more rows\n\n\n3.1.2.1 Incluir nombres de archivos\nHabitualmente será importante saber a que archivo pertenecen los datos que hemos leído.\nPodemos incluir los nombres de archivo en una columna:\n\n\nlibrary(magrittr) # Para poder usar %&gt;%\n\nname_of_folder = here::here(\"data/files/02-CSVs\")\n\nfiles &lt;- list.files(name_of_folder, full.names = TRUE) %&gt;% # Necesitamos esta pipe\n  # Asignamos nombres a los elementos del vector\n  set_names(basename(.))\n\n# Con el parámetro .id, almacenamos los nombres en la columna \"file\"\nfull2 &lt;- map_df(files, read_csv, .id = \"file\")\n\nfull2\n#&gt; # A tibble: 1,600 × 10\n#&gt;   file   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 01.csv male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 01.csv male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 01.csv male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 01.csv male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 01.csv male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 01.csv male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,594 more rows\n\n\n3.1.2.2 Con parametros\nAñadimos parámetros a la función de lectura. En este caso, definimos el tipo de columna esperado con la función col_types(). Con esto nos aseguraremos que si alguno de los archivos tiene el tipo de datos “incorrecto”, aparecerán warnings en la importación:\n\n\nname_of_folder = here::here(\"data/files/02-CSVs\")\nfiles &lt;- list.files(name_of_folder, full.names = TRUE)\nfull &lt;- map_df(files, read_csv, \n               col_types = cols(\n                 Sex = col_factor(),\n                 Priming = col_character(),\n                 trialN = col_integer(),\n                 Block = col_character(),\n                 Adjective = col_character(),\n                 Valence = col_factor(),\n                 Answer = col_character(),\n                 Arrow = col_character(),\n                 rT = col_double()))\n\nfull\n#&gt; # A tibble: 1,600 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;fct&gt; &lt;chr&gt;       &lt;int&gt; &lt;chr&gt; &lt;chr&gt;      &lt;fct&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,594 more rows\n\nEjercicios - Importar múltiples archivos\n\nCuando más arriba importamos los archivos que están en la carpeta data/files/02-CSVs:\n\n\n¿Qué archivos importamos exáctamente?\n\n\n\n\n\n\n\n¿Ves algún problema en lo que hicimos?\n\n\n\n\n\nRevisa el número de filas y la variable files.\n\n\n\nEl resultado final debería ser así:\n\n#&gt; # A tibble: 1,200 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,194 more rows\n\n\nLeed los archivos .xlsx de la carpeta data/files/02-XLSs, combinándolos en un único DF. El resultado final debería ser como se ve a continuación:\n\n\n\n\n\n\n\nPista\n\n\n\n\n\nTendréis que list.files() usando el parámetro pattern\n\nTe recomiendo abrir los archivos excel para ver su estructura, las pestañas que tienen… ahí te darás cuenta de que necesitas otros parámetros de read_xlsx() como sheet o skip\n\n\n\n\n\n\n#&gt; # A tibble: 1,200 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 1,194 more rows\n\n\n3.1.3 Exportar datos\nMuchas veces guardaremos los datos una vez procesados. Esto se puede hacer con la familia de funciones write_*.\n\n3.1.3.1 Archivos CSV\n\n\n# Versión simple\nwrite_csv(DF_name, \"data/files/02-write-csv.csv\")\n\n# Versión para Rmarkdown\nname_of_file = here::here(\"data/files/02-write-csv.csv\")\nwrite_csv(DF_name, name_of_file)\n\n\n3.1.3.2 Otros Archivos\n\n\nname_of_file = here::here(\"data/files/02-write-xlsx.xlsx\")\nwritexl::write_xlsx(DF_name, name_of_file)\n\nname_of_file = here::here(\"data/files/02-write-sav.sav\")\nhaven::write_sav(DF_name, name_of_file)\n\nname_of_file = here::here(\"data/files/02-write-ods.ods\")\nreadODS::write_ods(DF_name, name_of_file)"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#preparación-y-transformación-de-datos",
    "href": "qmd/03-preparacion_transformacion.html#preparación-y-transformación-de-datos",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "\n3.2 Preparación y transformación de datos",
    "text": "3.2 Preparación y transformación de datos\nPara la preparación y transformación de datos usaremos fundamentalmente dplyr. Hay otros paquetes más rápidos como data.table. Si trabajas con datos gigantescos (millones de filas), sin duda notarás la diferencia. La desventaja es que la sintaxis es (habitualmente) menos intuitiva.\n\n3.2.1 Tidy data\nExisten tres sencillas reglas que definen la Tidy data:\n\nCada variable tiene su columna propia\nCada observación tiene su fila propia\nCada valor tiene su celda propia\n\nLas ventajas fundamentales son:\n\nUso de una manera consistente de trabajar, que se alinea con el tidyverse\n\nFacilidad para trabajar con la lógica vectorizada\n\n\nPor ejemplo. De manera muy sencilla y rápida podemos crear una nueva columna realizando algún cómputo arbitrario con los valores de otra columna.\n\n\n# Computa ratio por 100,000\ntable1 |&gt; \n  mutate(rate_per_100K = cases / population * 100000)\n#&gt; # A tibble: 6 × 5\n#&gt;   country      year  cases population rate_per_100K\n#&gt;   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n#&gt; 1 Afghanistan  1999    745   19987071          3.73\n#&gt; 2 Afghanistan  2000   2666   20595360         12.9 \n#&gt; 3 Brazil       1999  37737  172006362         21.9 \n#&gt; 4 Brazil       2000  80488  174504898         46.1 \n#&gt; 5 China        1999 212258 1272915272         16.7 \n#&gt; 6 China        2000 213766 1280428583         16.7\n\nO contar el número de casos por valor de una variable.\n\n\n# Computa casos para cada año\ntable1 |&gt; \n  count(year, cases)\n#&gt; # A tibble: 6 × 3\n#&gt;    year  cases     n\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  1999    745     1\n#&gt; 2  1999  37737     1\n#&gt; 3  1999 212258     1\n#&gt; 4  2000   2666     1\n#&gt; 5  2000  80488     1\n#&gt; 6  2000 213766     1\n\n# La suma total de casos para cada año\ntable1 |&gt; \n  count(year, wt = cases)\n#&gt; # A tibble: 2 × 2\n#&gt;    year      n\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  1999 250740\n#&gt; 2  2000 296920\n\nY, como no, ggplot funciona con datos tidy, en formato long.\n\n\n# Visualizar cambios a lo largo del tiempo\nggplot(table1, aes(as.factor(year), cases)) + \n  geom_line(aes(group = country), colour = \"grey50\") + \n  geom_point(aes(colour = country))\n\n\n\n\n\n3.2.2 Verbos dplyr\nUsaremos {dplyr}, un paquete muy potente para la manipulación de datos. Su sintaxis, además, es bastante intuitiva (¡son verbos en inglés!).\nUsando pipes |&gt; (CONTROL + SHIFT + M) podemos enlazar operaciones de transformación de datos de manera muy sencilla (una vez nos aprendamos los verbos).\nPodemos ver más detalle y ejemplos en la Cheatsheet de dplyr.\nEn general usaremos la pipe nativa de R (desde la versión 4.1.0) |&gt;, pero en alguna ocasión usaremos %&gt;% (requiere el paquete magrittr).\n\n\n\n\n\n\nVerbos esenciales\n\n\n\n\nfilter(): filtrar filas\n\narrange(): ordenar filas\n\nselect(): seleccionar columnas\n\nrename(): renombrar columnas\n\nmutate(): crear columnas, modificar columnas, etc.\n\n\n\nTabla resumen dplyr\n\n\n\n\n\n\n\n\n3.2.2.1 Filtrar y ordenar filas\n\n\n# DF original\nname_of_file = here::here(\"data/files/02-read-csv.csv\")\nDF_name = read_csv(name_of_file)\nDF_name\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n# Filtrar\nDF_name |&gt; \n  filter(Educacion &gt; 8)\n#&gt; # A tibble: 3 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1   157 12207      1    26         9       57 PPV_Cond2 100RInt   \n#&gt; 2   287 60873      1    72        10       51 PPV_Cond3 100RAmp   \n#&gt; 3   381 64486      2    19         9       80 PPV_Cond4 100RAmp   \n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n# Ordenar\nDF_name |&gt; \n  arrange(Educacion, desc(Genero))\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1   350 20439      2    41         1       81 PPV_Cond4 90LAmp    \n#&gt; 2   399 81379      1    36         1       90 PPV_Cond4 90RAmp    \n#&gt; 3    42 20361      2    37         2       60 PPV_Cond1 100LInt   \n#&gt; 4   364 19201      2    21         2       67 PPV_Cond4 90LAmp    \n#&gt; 5   412 60292      1    28         2       90 PPV_Cond4 100LAmp   \n#&gt; 6    44 92735      2    30         3       95 PPV_Cond1 100RInt   \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n\n3.2.2.2 Seleccionar, ordenar y renombrar columnas\n\n\n# Seleccionar columnas\nDF_name |&gt; \n  select(Genero, Edad)\n#&gt; # A tibble: 103 × 2\n#&gt;   Genero  Edad\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1      1    47\n#&gt; 2      2    21\n#&gt; 3      2    29\n#&gt; 4      2    27\n#&gt; 5      1    29\n#&gt; 6      2    28\n#&gt; # ℹ 97 more rows\n\n# Eliminar columnas  \nDF_name |&gt; \n  select(-...1)\n#&gt; # A tibble: 103 × 8\n#&gt;      ID Genero  Edad Educacion FollowUP condition condition2 PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;             &lt;dbl&gt;\n#&gt; 1 41904      1    47         8       80 PPV_Cond1 90LInt               99\n#&gt; 2 95041      2    21         6       90 PPV_Cond1 90RInt               99\n#&gt; 3 74594      2    29         6       10 PPV_Cond1 100LInt              99\n#&gt; 4 72903      2    27         7       75 PPV_Cond1 100RInt               1\n#&gt; 5 21260      1    29         5       35 PPV_Cond1 90LInt               24\n#&gt; 6 50315      2    28         6       14 PPV_Cond1 90RInt               NA\n#&gt; # ℹ 97 more rows\n\n# Ordenar y eliminar columnas\nDF_name |&gt; \n  select(ID, Edad, Genero, everything(), -...1) \n#&gt; # A tibble: 103 × 8\n#&gt;      ID  Edad Genero Educacion FollowUP condition condition2 PPV_DECLARED\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;             &lt;dbl&gt;\n#&gt; 1 41904    47      1         8       80 PPV_Cond1 90LInt               99\n#&gt; 2 95041    21      2         6       90 PPV_Cond1 90RInt               99\n#&gt; 3 74594    29      2         6       10 PPV_Cond1 100LInt              99\n#&gt; 4 72903    27      2         7       75 PPV_Cond1 100RInt               1\n#&gt; 5 21260    29      1         5       35 PPV_Cond1 90LInt               24\n#&gt; 6 50315    28      2         6       14 PPV_Cond1 90RInt               NA\n#&gt; # ℹ 97 more rows\n\n\n\n# Renombrar columnas\nDF_name |&gt; \n  rename(Identificador = ID,\n         Sexo = Genero)\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1 Identificador  Sexo  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4         41904     1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5         95041     2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6         74594     2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15         72903     2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16         21260     1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18         50315     2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n# Renombrar usando la posicion (DANGER!)\nDF_name |&gt; \n  rename(Identificador = 2)\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1 Identificador Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4         41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5         95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6         74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15         72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16         21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18         50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n# Renombrar usando vectores\noldnames = c(\"ID\",\"Genero\")\nnewnames = c(\"Identificador\",\"Sexo\")\nDF_name |&gt; rename_at(all_of(oldnames), ~ newnames)\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1 Identificador  Sexo  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4         41904     1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5         95041     2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6         74594     2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15         72903     2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16         21260     1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18         50315     2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\nEjercicios - verbos dplyr simples\n\nCuenta los registros por año en el dataframe mpg\n\nFiltra los datos para quedarnos solo con los del año 1999\nRenombra la variable displ para que se llame “engine displacement”\n\nSi aparece el error Error: unexpected symbol in ..., puedes ver la ayuda de la función ?make.names, o este post\n\n\n\nOrdena los datos (no las columnas) por consumo en ciudad cty y clase de vehículo class\n\nCrea un data-frame que no contenga la variable model\n\n\n\n\n\n\n\n\nSoluciones\n\n\n\n\n\n - mpg |&gt; count(year)\n- mpg |&gt; filter(year == 1999)\n- mpg |&gt; rename(engine displacement = displ) #ERROR\n- mpg |&gt; rename(engine_displacement = displ) #SOLUCION1\n- mpg |&gt; rename(`engine displacement` = displ) #SOLUCION2\n- mpg |&gt; arrange(cty, class)\n- mpg |&gt; select(-model) \n\n\n\n\n3.2.2.3 Selección avanzada con select_helpers()\nEl everything() que usamos dentro de select() más arriba es uno de los select_helpers() existentes. Estos nos ayudan a realizar operaciones de selección de variables sin necesidad de escribir a mano todas las variables.\n\n\n\n\n\n\nselect_helpers()\n\n\n\n\nstarts_with(): Empieza con un prefijo (e.g. starts_with(“CI_”))\n\nends_with(): Acaba con un sufijo\n\ncontains(): Contiene una cadena de texto específica\n\nmatches(): Matches a regular expression\n\nnum_range(): Matches a numerical range like x01, x02, x03\n\none_of(): Matches variable names in a character vector\n\neverything(): Matches all variables\n\nlast_col(): Select last variable\n\n\n\nTrabajaremos con los datos del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base RAW en formato wide.\n\n\n  # DF original  \n  df_wide = read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\")  \n  cat(names(df_wide))\n#&gt; ID dem_genero dem_edad dem_nivedu WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod WVOC_06_cod WVOC_07_cod WVOC_08_cod WVOC_09_cod WVOC_10_cod WVOC_11_cod WVOC_12_cod WVOC_13_cod WVOC_14_cod WVOC_15_cod WVOC_16_cod WVOC_17_cod WVOC_18_cod WVOC_19_cod WVOC_20_cod WVOC_21_cod WVOC_22_cod WVOC_23_cod WVOC_24_cod WVOC_25_cod WVOC_26_cod WVOC_27_cod WVOC_28_cod WVOC_29_cod WVOC_30_cod WVOC_31_cod WVOC_32_cod WVOC_33_cod WVOC_TOTAL WVOC_TOTAL_STD WMAT_01_cod WMAT_01_raw WMAT_02_cod WMAT_02_raw WMAT_03_cod WMAT_03_raw WMAT_04_cod WMAT_04_raw WMAT_05_cod WMAT_05_raw WMAT_06_cod WMAT_06_raw WMAT_07_cod WMAT_07_raw WMAT_08_cod WMAT_08_raw WMAT_09_cod WMAT_09_raw WMAT_10_cod WMAT_10_raw WMAT_11_cod WMAT_11_raw WMAT_12_cod WMAT_12_raw WMAT_13_cod WMAT_13_raw WMAT_14_cod WMAT_14_raw WMAT_15_cod WMAT_15_raw WMAT_16_cod WMAT_16_raw WMAT_17_cod WMAT_17_raw WMAT_18_cod WMAT_18_raw WMAT_19_cod WMAT_19_raw WMAT_20_cod WMAT_20_raw WMAT_21_cod WMAT_21_raw WMAT_22_cod WMAT_22_raw WMAT_23_cod WMAT_23_raw WMAT_24_cod WMAT_24_raw WMAT_25_cod WMAT_25_raw WMAT_26_cod WMAT_26_raw WMAT_A WMAT_B WMAT_C wmat_total wmat_total_std bfbs_01_cod bfbs_01_conf bfbs_01_raw bfbs_03_cod bfbs_03_conf bfbs_03_raw bfbs_04_cod bfbs_04_conf bfbs_04_raw bfbs_10_cod bfbs_10_conf bfbs_10_raw bfbs_12_cod bfbs_12_conf bfbs_12_raw bfbs_14_cod bfbs_14_conf bfbs_14_raw bfbs_17_cod bfbs_17_conf bfbs_17_raw bfbs_23_cod bfbs_23_conf bfbs_23_raw bfbs_conf_total bfbs_cong_conf bfbs_cong_total bfbs_creib_conf bfbs_creib_total bfbs_incong_conf bfbs_incon_total bfbs_increib_conf bfbs_increib_total bfbs_invalid_conf bfbs_invalid_total bfbs_total bfbs_valid_conf bfbs_valid_total EA_01_raw EA_02_raw EA_03_raw EA_04_raw EA_05_raw EA_06_raw EA_07_raw EA_08_raw EA_09_raw EA_10_raw EA_11_raw EA_12_raw EA_13_raw EA_14_raw EA_15_raw EA_16_raw EA_17_raw EA_18_raw EA_19_raw EA_20_raw EA_21_raw EA_22_raw EA_23_raw EA_24_raw EA_azar_TOTAL EA_control_interno_TOTAL EA_otros_poderosos_TOTAL EAR_01_raw EAR_02_raw EAR_03_raw EAR_04_raw EAR_05_raw EAR_06_raw EAR_07_raw EAR_08_raw EAR_09_raw EAR_10_raw EAR_TOTAL ECRRS_ansiedad_TOTAL ECRRS_evitacion_TOTAL ECRRS_madre_01_raw ECRRS_madre_02_raw ECRRS_madre_03_raw ECRRS_madre_04_raw ECRRS_madre_05_raw ECRRS_madre_06_raw ECRRS_madre_07_raw ECRRS_madre_08_raw ECRRS_madre_09_raw ECRRS_madre_ansiedad_TOTAL ECRRS_madre_evitacion_TOTAL ECRRS_mejoramig_01_raw ECRRS_mejoramig_02_raw ECRRS_mejoramig_03_raw ECRRS_mejoramig_04_raw ECRRS_mejoramig_05_raw ECRRS_mejoramig_06_raw ECRRS_mejoramig_07_raw ECRRS_mejoramig_08_raw ECRRS_mejoramig_09_raw ECRRS_mejoramigo_ansiedad_TOTAL ECRRS_mejoramigo_evitacion_TOTAL ECRRS_padre_01_raw ECRRS_padre_02_raw ECRRS_padre_03_raw ECRRS_padre_04_raw ECRRS_padre_05_raw ECRRS_padre_06_raw ECRRS_padre_07_raw ECRRS_padre_08_raw ECRRS_padre_09_raw ECRRS_padre_ansiedad_TOTAL ECRRS_padre_evitacion_TOTAL ECRRS_pareja_01_raw ECRRS_pareja_02_raw ECRRS_pareja_03_raw ECRRS_pareja_04_raw ECRRS_pareja_05_raw ECRRS_pareja_06_raw ECRRS_pareja_07_raw ECRRS_pareja_08_raw ECRRS_pareja_09_raw ECRRS_pareja_ansiedad_TOTAL ECRRS_pareja_evitacion_TOTAL GHQ_01 GHQ_02 GHQ_03 GHQ_04 GHQ_05 GHQ_06 GHQ_07 GHQ_08 GHQ_09 GHQ_10 GHQ_11 GHQ_12 GHQ_autoestima_TOTAL GHQ_estres_TOTAL GHQ_exito_afrontamiento_TOTAL GHQ_TOTAL wdig_dir_total wdig_inv_total WDIGSIMB_TOTAL wdig_total wdig_total_std lkns_01_cod lkns_01_raw lkns_02_cod lkns_02_raw lkns_03_cod lkns_03_raw lkns_04_cod lkns_04_raw lkns_05_cod lkns_05_raw lkns_06_cod lkns_06_raw lkns_07_cod lkns_07_raw lkns_08_cod lkns_08_raw lkns_09_cod lkns_09_raw lkns_10_cod lkns_10_raw lkns_11_cod lkns_11_raw lkns_total SASS_01_raw SASS_02_raw SASS_03_raw SASS_04_raw SASS_05_raw SASS_06_raw SASS_07_raw SASS_08_raw SASS_09_raw SASS_10_raw SASS_11_raw SASS_12_raw SASS_13_raw SASS_14_raw SASS_15_raw SASS_16_raw SASS_17_raw SASS_18_raw SASS_19_raw SASS_20_raw SASS_21_raw SASS_TOTAL SASS_trabajo bayes_all_accuracy bayes_all_confidence bayes_pictorial_qualitative_accuracy bayes_pictorial_quantitative_accuracy bayes_text_qualitative_accuracy bayes_text_quantitative_accuracy\n\n  # Seleccionamos variables que contienen la cadena de texto \"dem\"\n  df_wide |&gt; \n    select(contains(\"dem\"))\n#&gt; # A tibble: 232 × 3\n#&gt;   dem_genero dem_edad dem_nivedu\n#&gt;        &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1          1       38          4\n#&gt; 2          0       67          2\n#&gt; 3          0       24          4\n#&gt; 4          0       30          4\n#&gt; 5          0       38          3\n#&gt; 6          0       45          4\n#&gt; # ℹ 226 more rows\n\n  # Seleccionamos variables que acacan con la cadena de texto \"cod\"\n  df_wide |&gt; \n    select(ID, ends_with(\"cod\"))\n#&gt; # A tibble: 232 × 79\n#&gt;      ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod\n#&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1     1           2           2           2           1           2\n#&gt; 2     2           2           2           2           1           0\n#&gt; 3     3           2           2           2           1           2\n#&gt; 4     4           2           1           1           1           2\n#&gt; 5     5           2           2           1           1           0\n#&gt; 6     6           1           1           2           1           2\n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 73 more variables: WVOC_06_cod &lt;dbl&gt;, WVOC_07_cod &lt;dbl&gt;, …\n\n  # Lo mismo, pero usando expresiones regulares\n  df_wide |&gt; \n    select(ID, matches(\"cod$\")) # $: fin de la cadena de texto\n#&gt; # A tibble: 232 × 79\n#&gt;      ID WVOC_01_cod WVOC_02_cod WVOC_03_cod WVOC_04_cod WVOC_05_cod\n#&gt;   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1     1           2           2           2           1           2\n#&gt; 2     2           2           2           2           1           0\n#&gt; 3     3           2           2           2           1           2\n#&gt; 4     4           2           1           1           1           2\n#&gt; 5     5           2           2           1           1           0\n#&gt; 6     6           1           1           2           1           2\n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 73 more variables: WVOC_06_cod &lt;dbl&gt;, WVOC_07_cod &lt;dbl&gt;, …\n\n\n3.2.2.4 Modificar y añadir variables\n\n\n# DF original\nDF_name\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n\n# Modificar variable reemplazando valor\nDF_name |&gt; \n  mutate(PPV_DECLARED = PPV_DECLARED/100)\n#&gt; # A tibble: 103 × 9\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: PPV_DECLARED &lt;dbl&gt;\n  \n# Añadir variable\nDF_name |&gt; \n  mutate(PPV_DECLARED_PCT = PPV_DECLARED/100)\n#&gt; # A tibble: 103 × 10\n#&gt;    ...1    ID Genero  Edad Educacion FollowUP condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8       80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6       90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6       10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7       75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5       35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6       14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 2 more variables: PPV_DECLARED &lt;dbl&gt;, PPV_DECLARED_PCT &lt;dbl&gt;\n\n# Añadir variable destruyendo el resto del DF\nDF_name |&gt; \n  transmute(PPV_DECLARED_PCT = PPV_DECLARED/100)\n#&gt; # A tibble: 103 × 1\n#&gt;   PPV_DECLARED_PCT\n#&gt;              &lt;dbl&gt;\n#&gt; 1             0.99\n#&gt; 2             0.99\n#&gt; 3             0.99\n#&gt; 4             0.01\n#&gt; 5             0.24\n#&gt; 6            NA   \n#&gt; # ℹ 97 more rows\n\n# Limpiar nombres con el paquete {janitor}\nDF_name |&gt; \n  janitor::clean_names()\n#&gt; # A tibble: 103 × 9\n#&gt;      x1    id genero  edad educacion follow_up condition condition2\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     \n#&gt; 1     4 41904      1    47         8        80 PPV_Cond1 90LInt    \n#&gt; 2     5 95041      2    21         6        90 PPV_Cond1 90RInt    \n#&gt; 3     6 74594      2    29         6        10 PPV_Cond1 100LInt   \n#&gt; 4    15 72903      2    27         7        75 PPV_Cond1 100RInt   \n#&gt; 5    16 21260      1    29         5        35 PPV_Cond1 90LInt    \n#&gt; 6    18 50315      2    28         6        14 PPV_Cond1 90RInt    \n#&gt; # ℹ 97 more rows\n#&gt; # ℹ 1 more variable: ppv_declared &lt;dbl&gt;\n\n\n3.2.2.5 Resúmenes agrupados\nLa combinación de verbos group_by() y summarise() es una de las más usadas. Con esta podemos calcular promedios, medianas, etc. por condición de manera sencilla.\n\n\n# Resumen\nDF_name |&gt; \n  summarise(Promedio_PPV = mean(PPV_DECLARED), \n            N = n())\n#&gt; # A tibble: 1 × 2\n#&gt;   Promedio_PPV     N\n#&gt;          &lt;dbl&gt; &lt;int&gt;\n#&gt; 1           NA   103\n\n# Resumen agrupado\nDF_name |&gt; \n  group_by(Genero) |&gt; \n  summarise(Promedio_PPV = mean(PPV_DECLARED), \n            N = n())\n#&gt; # A tibble: 2 × 3\n#&gt;   Genero Promedio_PPV     N\n#&gt;    &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      1           NA    40\n#&gt; 2      2           NA    63\n\n# Resumen agrupando por multiples variables, y calculando varias cosas  \nDF_name |&gt; \n  group_by(Genero, condition) |&gt; \n  summarise(promedio_PPV = mean(PPV_DECLARED),\n            mediana_PPV = median(PPV_DECLARED),\n            SD = sd(PPV_DECLARED),\n            N = n())\n#&gt; # A tibble: 8 × 6\n#&gt; # Groups:   Genero [2]\n#&gt;   Genero condition promedio_PPV mediana_PPV    SD     N\n#&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1      1 PPV_Cond1         63.8          88  43.1     9\n#&gt; 2      1 PPV_Cond2         NA            NA  NA      13\n#&gt; 3      1 PPV_Cond3         75.6          80  32.5     5\n#&gt; 4      1 PPV_Cond4         NA            NA  NA      13\n#&gt; 5      2 PPV_Cond1         NA            NA  NA      19\n#&gt; 6      2 PPV_Cond2         49.4          46  16.3     8\n#&gt; # ℹ 2 more rows\n\nEjercicios - verbos dplyr\n\nUsando la base df_wide, haz las siguientes cosas, una a una:\n\n\nImporta los datos (ver código abajo)\nFiltra el DF para quedarnos solo con edades entre 18 y 50 años\n\nOrdena los datos por genero y edad, esta última decreciente\n\nSelecciona las columnas para quedarnos solo con ID, variables demograficas, y respuestas crudas (raw)\n\nCrea una nueva variable que sea niv_edu_porc, en la que calcules cual es el porcentaje de nivel educativo al que han llegado relativo al máximo de la base de datos (nivel educativo persona / nivel educativo maximo; en porcentaje)\n\n\nAhora combina el resultado de todas las operaciones anteriores en un DF\nCalcula el promedio y desviación típica de edad para cada género\n\n3.2.3 Pistas\n\n\nPaso a paso:\n\nfilter(CONDICION1 & CONDICION2)\n\narrange() o arrange(desc())\n\n\nselect() o select(contains(\"ALGUN_PATRON\"))\n\n\nmutate() usando también max()\n\n\n\nDF_resultado = df_wide |&gt; operacion1 |&gt; operation2 |&gt; ...\ngroup_by() |&gt; summarize()\n\n:::\n\n\n\n  df_wide = read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\")"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#verbos-avanzados-y-otras-criaturas-indómitas",
    "href": "qmd/03-preparacion_transformacion.html#verbos-avanzados-y-otras-criaturas-indómitas",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "\n3.3 Verbos avanzados y otras criaturas indómitas",
    "text": "3.3 Verbos avanzados y otras criaturas indómitas\n\n3.3.1 Wide to long simple\nEmpecemos con un ejemplo muy sencillo. 3 participantes, 2 items.\n\n\n# Creamos un DF\ndf_simple_wide = \n  tibble(\n    ID = c(\"Participante1\", \"Participante2\", \"Participante3\", \"Participante4\"),\n    condition = c(\"calor\", \"calor\", \"frio\", \"frio\"),\n    Item1 = c(22, 33, 44, 55),\n    Item2 = c(88, 99, 77, 66)\n    )\n\ndf_simple_wide\n#&gt; # A tibble: 4 × 4\n#&gt;   ID            condition Item1 Item2\n#&gt;   &lt;chr&gt;         &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Participante1 calor        22    88\n#&gt; 2 Participante2 calor        33    99\n#&gt; 3 Participante3 frio         44    77\n#&gt; 4 Participante4 frio         55    66\n\n# Wide to long\ndf_simple_long = df_simple_wide |&gt; \n  pivot_longer(Item1:Item2, names_to = \"Item\", values_to = \"Response\")\n  \n\ndf_simple_long\n#&gt; # A tibble: 8 × 4\n#&gt;   ID            condition Item  Response\n#&gt;   &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 Participante1 calor     Item1       22\n#&gt; 2 Participante1 calor     Item2       88\n#&gt; 3 Participante2 calor     Item1       33\n#&gt; 4 Participante2 calor     Item2       99\n#&gt; 5 Participante3 frio      Item1       44\n#&gt; 6 Participante3 frio      Item2       77\n#&gt; # ℹ 2 more rows\n\n\n3.3.2 Long to wide simple\nRetomamos el ejemplo simple de antes:\n\n\n# Long to wide simple\ndf_simple_long |&gt; \n  pivot_wider(names_from = Item, values_from = Response)\n#&gt; # A tibble: 4 × 4\n#&gt;   ID            condition Item1 Item2\n#&gt;   &lt;chr&gt;         &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Participante1 calor        22    88\n#&gt; 2 Participante2 calor        33    99\n#&gt; 3 Participante3 frio         44    77\n#&gt; 4 Participante4 frio         55    66\n\n\n3.3.2.1 ¿Para que sirve tener los datos en formato long?\nHay algunos análisis para los que necesitamos formato long (anovas, modelos mixtos…), y varias cosas que se simplifican cuando los datos estan en formato largo.\nPor ejemplo, si queremos usar resúmenes agrupados para obtener la media, mediana, desviación estandard… por ítem, con el formato WIDE necesitaremos 3 lineas de código para cada ítem que tenga nuestra base (imagina con 100 items…). Con el formato long, el código de abajo es suficiente.\n\n# En formato wide podriamos usar cosas como:  \n  # skimr::skim(df_simple_wide)\n\n# Añadir para cada item 3 líneas\ndf_simple_wide |&gt;\n  summarise(mean_Item1 = mean(Item1),\n            mean_Item2 = mean(Item2),\n            # ...\n            median_Item1 = median(Item1),\n            median_Item2 = median(Item2),\n            # ...\n            sd_Item1 = sd(Item1),\n            sd_Item2 = sd(Item2),\n            # ...\n            N = n()\n            # NO aparece N por item\n            )\n#&gt; # A tibble: 1 × 7\n#&gt;   mean_Item1 mean_Item2 median_Item1 median_Item2 sd_Item1 sd_Item2     N\n#&gt;        &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;\n#&gt; 1       38.5       82.5         38.5         82.5     14.2     14.2     4\n\n# Sirve para 1 item o para 10 millones de items\ndf_simple_long |&gt;\n  group_by(Item) |&gt;\n  summarise(MEAN = mean(Response),\n            MEDIAN = median(Response),\n            SD = sd(Response),\n            N = n())\n#&gt; # A tibble: 2 × 5\n#&gt;   Item   MEAN MEDIAN    SD     N\n#&gt;   &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Item1  38.5   38.5  14.2     4\n#&gt; 2 Item2  82.5   82.5  14.2     4\n\n\n# Análisis modelos mixtos\nmodel = lme4::lmer(Response ~ condition + (1|ID), df_simple_long)\nsjPlot::tab_model(model)\n\n\n\n\n \nResponse\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n60.50\n20.10 – 100.90\n0.014\n\n\ncondition [frio]\n0.00\n-57.14 – 57.14\n1.000\n\n\nRandom Effects\n\n\nσ2\n\n847.00\n\n\nτ00ID\n\n0.00\n\n\n\nN ID\n\n4\n\n\nObservations\n8\n\n\nMarginal R2 / Conditional R2\n\n0.000 / NA\n\n\n\n\n\n3.3.3 Wide to long complex\nAhora pasemos a un ejemplo mas complejo. Tenemos las puntuaciones a los 11 items de la lipkus numeracy scale de 232 participantes, ademas de datos demográficos.\n\n\n# Leemos documento en formato WIDE\ndf_wide_complex = read_csv(\n  \"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\"\n) |&gt;\n  # Seleccionamos solo algunas de las filas\n  select(ID,\n         dem_genero,\n         dem_edad,\n         dem_nivedu,\n         matches(\"lkns_[0-9]{2}_raw\"))\n\nDT::datatable(df_wide_complex)\n\n\n\n\n\n\n\n# Wide to long\ndf_long_complex =\n  df_wide_complex |&gt;\n  pivot_longer(\n    cols = lkns_01_raw:lkns_11_raw,\n    names_to = \"Item\",\n    values_to = \"Response\",\n    values_transform = list(Response = as.character)\n  )\n\n# Podemos usar select_helpers!\n  # Reemplaza lkns_01_raw:lkns_11_raw por matches(\"lkns\")\n\n\nDT::datatable(df_long_complex)\n\n\n\n\n\n\n\n3.3.4 Long to wide complex\nNos sirve el mismo código que con el ejemplo más simple:\n\n\n# Long to wide\ndf_long_complex |&gt;  \n  pivot_wider(names_from = Item, values_from = Response)\n#&gt; # A tibble: 232 × 15\n#&gt;      ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw\n#&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;      \n#&gt; 1     1          1       38          4 500         10          10         \n#&gt; 2     2          0       67          2 0           0           0          \n#&gt; 3     3          0       24          4 700         100         0.1        \n#&gt; 4     4          0       30          4 500         30          1          \n#&gt; 5     5          0       38          3 6           2           3          \n#&gt; 6     6          0       45          4 40          200         2          \n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 8 more variables: lkns_04_raw &lt;chr&gt;, lkns_05_raw &lt;chr&gt;, …"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#ejercicios---wide-to-long",
    "href": "qmd/03-preparacion_transformacion.html#ejercicios---wide-to-long",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "Ejercicios - wide to long",
    "text": "Ejercicios - wide to long\nTrabajaremos con los datos procesados del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. Estos se pueden encontrar en un repositorio público de la OSF. Empezaremos con la base final en formato wide (Dentro de https://osf.io/egxy5/, ver archivo: /outputs/data/sa-prepared.csv).\n\nCambia el orden de las variables para que ID sea la primera columna.\nTransforma la base a formato long (eso sí, mantén las variables demográficas en formato wide).\nAprovechando que tenemos la base en formato long, sabrías hacer una gráfica con un histograma o densidad para cada una de las variables no deográficas?\n\n\n\n\n\n\n\nPistas\n\n\n\n\n\n\nTendras que usar la función select() y el select helper everything()\npivot_longer(primera_variable:ultima_variable)\nfacet_wrap(~name, scales = \"free\") te ayudara a crear paneles para cada nombre, donde las escalas x/y pueden variar libremente.\n\n\n\n\n\nImportamos datos, y limpiamos nombres de variables:\n\n\nDF_wide = read_csv(\n  \"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv\"\n) |&gt;\n  janitor::clean_names()"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#separate-omit-ifelse-case_when-tipos-de-variables",
    "href": "qmd/03-preparacion_transformacion.html#separate-omit-ifelse-case_when-tipos-de-variables",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "\n3.4 Separate, omit, ifelse, case_when, tipos de variables…",
    "text": "3.4 Separate, omit, ifelse, case_when, tipos de variables…\nPara transformaciones algo más complejas, pero muy habituales, usaremos algunos verbos del paquete {tidyr}, y variaciones con {dplyr}\n\n# Base original\nDF_name = read_csv(\"../data/files/02-read-csv.csv\") |&gt; \n  select(-...1, -Educacion, -Edad, -condition2)\n\nDT::datatable(DF_name)\n\n\n\n\n\n\n\nPodemos separar la columna de condicion usando un separador. La separación puede ser en columnas o en filas:\n\n# Separate\nDF_separated = DF_name |&gt; \n  separate(condition, c(\"primer_chunk\", \"segundo_chunk\"), sep = \"_\")\n\nDF_separated\n#&gt; # A tibble: 103 × 6\n#&gt;      ID Genero FollowUP primer_chunk segundo_chunk PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV          Cond1                   99\n#&gt; 2 95041      2       90 PPV          Cond1                   99\n#&gt; 3 74594      2       10 PPV          Cond1                   99\n#&gt; 4 72903      2       75 PPV          Cond1                    1\n#&gt; 5 21260      1       35 PPV          Cond1                   24\n#&gt; 6 50315      2       14 PPV          Cond1                   NA\n#&gt; # ℹ 97 more rows\n\n# Separate in rows\nDF_name |&gt; \n  separate_rows(condition, sep = \"_\")\n#&gt; # A tibble: 206 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV                 99\n#&gt; 2 41904      1       80 Cond1               99\n#&gt; 3 95041      2       90 PPV                 99\n#&gt; 4 95041      2       90 Cond1               99\n#&gt; 5 74594      2       10 PPV                 99\n#&gt; 6 74594      2       10 Cond1               99\n#&gt; # ℹ 200 more rows\n\nCon unite() podemos hacer lo contrario, unir columnas con un separador definido:\n\n\n# Unite: inversa de separate\nDF_separated |&gt; \n  unite(condition, c(primer_chunk, segundo_chunk), sep = \"_\")\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV_Cond1           99\n#&gt; 2 95041      2       90 PPV_Cond1           99\n#&gt; 3 74594      2       10 PPV_Cond1           99\n#&gt; 4 72903      2       75 PPV_Cond1            1\n#&gt; 5 21260      1       35 PPV_Cond1           24\n#&gt; 6 50315      2       14 PPV_Cond1           NA\n#&gt; # ℹ 97 more rows\n\nSi necesitamos recodificar variables, cambiar valores condicionalmente,… podemos usar ifelse(), case_when() o recode():\n\n# If else\nDF_name |&gt;\n  mutate(Genero = ifelse(Genero == 1, \"Hombre\", \"Mujer\"))\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904 Hombre       80 PPV_Cond1           99\n#&gt; 2 95041 Mujer        90 PPV_Cond1           99\n#&gt; 3 74594 Mujer        10 PPV_Cond1           99\n#&gt; 4 72903 Mujer        75 PPV_Cond1            1\n#&gt; 5 21260 Hombre       35 PPV_Cond1           24\n#&gt; 6 50315 Mujer        14 PPV_Cond1           NA\n#&gt; # ℹ 97 more rows\n\n# Case when\n## las condiciones lógicas pueden ser arbitrariamente complejas\nDF_name |&gt;\n  mutate(Genero = \n           case_when(\n             Genero == 1 ~ \"Hombre\",\n             Genero == 2 ~ \"Mujer\",\n             Genero == 3 ~ \"No binario\",\n             TRUE ~ NA_character_)\n         )\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904 Hombre       80 PPV_Cond1           99\n#&gt; 2 95041 Mujer        90 PPV_Cond1           99\n#&gt; 3 74594 Mujer        10 PPV_Cond1           99\n#&gt; 4 72903 Mujer        75 PPV_Cond1            1\n#&gt; 5 21260 Hombre       35 PPV_Cond1           24\n#&gt; 6 50315 Mujer        14 PPV_Cond1           NA\n#&gt; # ℹ 97 more rows\n\n  # Función recode\n  DF_name |&gt;\n    \n    # De número a texto\n    mutate(Genero = recode(\n      Genero,\n      `1` = \"Hombre\",\n      `2` = \"Mujer\",\n      .default = \"No definido\"\n    )) |&gt;\n    \n    # De texto a número\n    mutate(Genero2 = recode(\n      Genero,\n      \"Hombre\" = 1,\n      \"Mujer\" = 2,\n      .default = 999\n    ))\n#&gt; # A tibble: 103 × 6\n#&gt;      ID Genero FollowUP condition PPV_DECLARED Genero2\n#&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 41904 Hombre       80 PPV_Cond1           99       1\n#&gt; 2 95041 Mujer        90 PPV_Cond1           99       2\n#&gt; 3 74594 Mujer        10 PPV_Cond1           99       2\n#&gt; 4 72903 Mujer        75 PPV_Cond1            1       2\n#&gt; 5 21260 Hombre       35 PPV_Cond1           24       1\n#&gt; 6 50315 Mujer        14 PPV_Cond1           NA       2\n#&gt; # ℹ 97 more rows\n\nOtras funciones útiles, extraer los valores de una columna con pull() o descartar los NA de una columna con drop_na():\n\n\n# Pull\nDF_name |&gt; pull(PPV_DECLARED)\n#&gt;   [1] 99 99 99  1 24 NA 99 99 99  1 94 99 88  0  1 99 99 99 70 99  1 99 99  7\n#&gt;  [25] 10 99 99 99 46 45 46 40 NA 46 46 73 46 50 46 45 46 87 46 49 30 46 50 70\n#&gt;  [49] 44 80 99 99 99 99 80 51 99 20 30  1 20  5 30 99 99 99 99 80 98 99 80 59\n#&gt;  [73] 64 16 79 92 92 80 90 60 93 92 28 92 92 77 74 90 10 92 92 92 65 20 92 92\n#&gt;  [97] 92 92 90 92 NA 92 80\n\n# Promedio de una columna (con pipes)\nDF_name |&gt; pull(PPV_DECLARED) |&gt; mean()\n#&gt; [1] NA\n\n# Eliminando los NA's!\nDF_name |&gt; pull(PPV_DECLARED) |&gt; mean(na.rm = TRUE)\n#&gt; [1] 68.06\n\n# Más sencillo, en base R (no siempre son necesarias las pipes)\n mean(DF_name$PPV_DECLARED, na.rm = TRUE)\n#&gt; [1] 68.06\n\n# Drop NAs\nDF_name |&gt;\n  drop_na(PPV_DECLARED)\n#&gt; # A tibble: 100 × 5\n#&gt;      ID Genero FollowUP condition PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 41904      1       80 PPV_Cond1           99\n#&gt; 2 95041      2       90 PPV_Cond1           99\n#&gt; 3 74594      2       10 PPV_Cond1           99\n#&gt; 4 72903      2       75 PPV_Cond1            1\n#&gt; 5 21260      1       35 PPV_Cond1           24\n#&gt; 6 21774      2        2 PPV_Cond1           99\n#&gt; # ℹ 94 more rows"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#ejercicios---verbos-avanzados-dplyr",
    "href": "qmd/03-preparacion_transformacion.html#ejercicios---verbos-avanzados-dplyr",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "Ejercicios - verbos avanzados dplyr",
    "text": "Ejercicios - verbos avanzados dplyr\n\nImporta los datos y limpia los nombres de columna:\n\n\n\n\n\n\n\nPara limpiar nombres de columnas automáticamente:\n\n\n\n\n\nclean_names()\n\n\n\n\n\n# Leemos los datos y usamos janitor::clean_names() para limpiar los nombres de las columnas\n DF_wide = \n  read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv\")\n\n\nEn un nuevo DF (DF_split), crea una variable llamada social_adaptation_split con la median split para la variable social_adaptation. La mitad superior se llamará high_social_adaptation y la mitad inferior low_social_adaptation.\n\n\n\n\n\n\n\nSuele ser más facil si dividimos la tarea en varios pasos\n\n\n\n\n\n1. Calculamos mediana 2. Usamos case_when()\n\n\n\n\nAsegúrate que no hay valores NA.\n\n\n\n\n\n\n\nPista\n\n\n\n\n\nLa función drop_na() .\n\n\n\n\nEl resultado final debería ser:"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#regular-expressions",
    "href": "qmd/03-preparacion_transformacion.html#regular-expressions",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "\n3.5 Regular expressions",
    "text": "3.5 Regular expressions\nLas expresiones regulares son una herramienta tan potente como dificil de utilizar. Eso si, podemos hacer algunas cosas básicas muy útiles, sin demasiado esfuerzo. Hay cheatsheets (Basic Regular Expressions Cheatsheet) y libros (introduction to Regular Expressions) que nos pueden ayudar a familiarizarnos con ellas.\n\n\n\nSOURCE: https://xkcd.com/208/\n\n\nImagina que tenemos que trabajar con la columna condition2, donde están codificadas 3 variables importantes:\n\n\nDF_regexp = read_csv(here::here(\"data/files/02-read-csv.csv\")) |&gt; \n  select(-...1, -Educacion, -Edad, -condition)\n\nDF_regexp\n#&gt; # A tibble: 103 × 5\n#&gt;      ID Genero FollowUP condition2 PPV_DECLARED\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n#&gt; 1 41904      1       80 90LInt               99\n#&gt; 2 95041      2       90 90RInt               99\n#&gt; 3 74594      2       10 100LInt              99\n#&gt; 4 72903      2       75 100RInt               1\n#&gt; 5 21260      1       35 90LInt               24\n#&gt; 6 50315      2       14 90RInt               NA\n#&gt; # ℹ 97 more rows\n\nCuando no tenemos separadores explícitos como vimos antes con separate(), podemos usar mutate() junto a gsub() y expresiones regulares para extraer, una a una, las condiciones.\nLa función gsub() nos sirve para eliminar partes de una cadena de texto, para extraer un número, etc.:\n\n\nDF_regexp |&gt; \n  mutate(cond_NM = gsub(\"([0-9]{2,3}).*\", \"\\\\1\", condition2),\n         cond_LR = gsub(\"[0-9]{2,3}([LR]).*\", \"\\\\1\", condition2),\n         cond_IA = gsub(\"[0-9]{2,3}[LR](.*)\", \"\\\\1\", condition2))\n#&gt; # A tibble: 103 × 8\n#&gt;      ID Genero FollowUP condition2 PPV_DECLARED cond_NM cond_LR cond_IA\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1 41904      1       80 90LInt               99 90      L       Int    \n#&gt; 2 95041      2       90 90RInt               99 90      R       Int    \n#&gt; 3 74594      2       10 100LInt              99 100     L       Int    \n#&gt; 4 72903      2       75 100RInt               1 100     R       Int    \n#&gt; 5 21260      1       35 90LInt               24 90      L       Int    \n#&gt; 6 50315      2       14 90RInt               NA 90      R       Int    \n#&gt; # ℹ 97 more rows\n\nExtraemos la misma información, de una manera ligeramente distinta, siendo mucho más explícitos sobre la estructura esperada de la columna condition2:\n\n\nDF_regexp |&gt; \n  mutate(cond_NM = gsub(\"^([0-9]{2,3})([LR])(.*)$\", \"\\\\1\", condition2),\n         cond_LR = gsub(\"^([0-9]{2,3})([LR])(.*)$\", \"\\\\2\", condition2),\n         cond_IA = gsub(\"^([0-9]{2,3})([LR])(.*)$\", \"\\\\3\", condition2))\n#&gt; # A tibble: 103 × 8\n#&gt;      ID Genero FollowUP condition2 PPV_DECLARED cond_NM cond_LR cond_IA\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1 41904      1       80 90LInt               99 90      L       Int    \n#&gt; 2 95041      2       90 90RInt               99 90      R       Int    \n#&gt; 3 74594      2       10 100LInt              99 100     L       Int    \n#&gt; 4 72903      2       75 100RInt               1 100     R       Int    \n#&gt; 5 21260      1       35 90LInt               24 90      L       Int    \n#&gt; 6 50315      2       14 90RInt               NA 90      R       Int    \n#&gt; # ℹ 97 more rows\n\nCon select() y matches() seleccionamos columnas usando la siguiente regular expression lkns_[0-9]{2}_raw:\n\n\nlkns_ contiene esta cadena de texto\n\n\n[0-9]{2} a continuación, contiene cualquier dígito del 0 al 9, dos veces.\n\n_rawa continuación, contiene esta cadena de texto\n\n\n\nread_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\") |&gt; \n  # Seleccionamos solo algunas de las filas\n  select(ID, dem_genero, dem_edad, dem_nivedu, matches(\"lkns_[0-9]{2}_raw\"))\n#&gt; # A tibble: 232 × 15\n#&gt;      ID dem_genero dem_edad dem_nivedu lkns_01_raw lkns_02_raw lkns_03_raw\n#&gt;   &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n#&gt; 1     1          1       38          4         500          10        10  \n#&gt; 2     2          0       67          2           0           0         0  \n#&gt; 3     3          0       24          4         700         100         0.1\n#&gt; 4     4          0       30          4         500          30         1  \n#&gt; 5     5          0       38          3           6           2         3  \n#&gt; 6     6          0       45          4          40         200         2  \n#&gt; # ℹ 226 more rows\n#&gt; # ℹ 8 more variables: lkns_04_raw &lt;chr&gt;, lkns_05_raw &lt;chr&gt;, …\n\n\n\n3.5.1 Ayuda con regular expressions\nEs muy fácil cometer errores cuando usamos expresiones regulares. Algunas recomendaciones:\n\nSolo usar expresiones regulares cuando sea necesario\nUsar expresiones regulares lo más explícitas y definidas posible\nVerificar que estan funcionando bien!\n\n\n\nSOURCE: https://xkcd.com/1171/\n\nHay una aplicación Shiny muy útil que nos ayudará a construir Regular Expressions:\n\n\nregexplain::regexplain_gadget()"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#ejercicios---calcular-puntajes-de-escalas-usando-regular-expressions",
    "href": "qmd/03-preparacion_transformacion.html#ejercicios---calcular-puntajes-de-escalas-usando-regular-expressions",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "Ejercicios - Calcular puntajes de escalas usando regular expressions",
    "text": "Ejercicios - Calcular puntajes de escalas usando regular expressions\nAhora volvemos a usar con los datos brutos (sa-raw-anonymised.csv) del paper Cognitive and Socio-affective Predictors of Social Adaptation, de Neely et al. \nEn estos datos tenemos las puntuaciones crudas (e.g. WMAT_01_raw) y ya codificadas/corregidas (WMAT_01_cod) para los ítems de varias escalas Para preparar los datos de cara al análisis final, necesitamos calcular el puntaje para cada participante y escala. Empezaremos con la prueba de Matrices de WAIS (WMAT_).\n\nCalcula el puntaje para cada participante en la prueba de Matrices de WAIS (ítems WMAT_[NUMEROS]_cod)\n\nHay al menos dos estrategias posibles:\n\nSelecciona las columnas relevantes y haz la suma de columnas\nConvierte a long, filtra para quedarte con las filas correspondientes a la prueba relevante, y haz una suma agrupada\n\n\n\n\n\n\n\nPista para seleccionar o filtrar columnas:\n\n\n\n\n\nRecuerda que usamos select() para seleccionar columnas, o filter() para filtrar.\n\n\n\n\n\n\n\n\n\nPista para seleccionar columnas:\n\n\n\n\n\nPodemos usar matches(\"WMAT_[0-9]{2}_cod\") para seleccionar o filtrar todas las columnas o ítems que contienen: WMAT_, 2 numeros del 0 al 9, y acaban en _cod.\n\n\n\n\n\n\n\n\n\nPista para suma de columnas:\n\n\n\n\n\nrowSums() es la función que podemos usar, pero su sintaxis es algo complicada.\n\n\n\n\n\n\n\n\n\nPista para suma agrupada:\n\n\n\n\n\nUsamos group_by() |&gt; summarise() poniendo parámetros dentro de cada función.\n\n\n\n\nImportar datos:\n\n\ndf_wide_raw = read_csv(\"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/data-raw/sa-raw-anonymised.csv\")"
  },
  {
    "objectID": "qmd/03-preparacion_transformacion.html#bibliografía",
    "href": "qmd/03-preparacion_transformacion.html#bibliografía",
    "title": "\n3  Preparación y transformación de datos\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nCheatsheets RStudio\nCheatsheet dplyr\nTidyexplain"
  },
  {
    "objectID": "qmd/04-combinar-datos.html#bind-rows-or-columns",
    "href": "qmd/04-combinar-datos.html#bind-rows-or-columns",
    "title": "\n4  Combinar datos\n",
    "section": "\n4.1 Bind rows or columns",
    "text": "4.1 Bind rows or columns\nEl método más sencillo. Simplemente unimos las filas o columnas de los data-frames.\n\n\n# Importar CSVs\nDF1 = read_csv(here::here(\"data/files/02-CSVs/01.csv\"))\nDF2 = read_csv(here::here(\"data/files/02-CSVs/02.csv\"))\n\n\n# Bind DFs añadiendo las *filas* de DF2 a DF1\nDF1 |&gt; \n   bind_rows(DF2)\n#&gt; # A tibble: 800 × 9\n#&gt;   Sex   Priming    trialN Block Adjective  Valence  Answer Arrow    rT\n#&gt;   &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n#&gt; 1 male  Collective      1 we    ofensivo   negative yes    left    623\n#&gt; 2 male  Collective      2 we    resentido  negative no     right  1235\n#&gt; 3 male  Collective      3 we    ego�sta    negative yes    left    335\n#&gt; 4 male  Collective      4 we    indiscreto negative yes    left    355\n#&gt; 5 male  Collective      5 we    sumiso     negative yes    left    618\n#&gt; 6 male  Collective      6 we    agradable  positive yes    left    328\n#&gt; # ℹ 794 more rows\n\n\n# Bind DFs añadiendo las *columnas* de DF2 a DF1\n  ## bind_cols renombra automaticamente los nombres de las columnas para que no \n  # haya coincidencias\nDF1 |&gt; \n  bind_cols(DF2) \n#&gt; # A tibble: 400 × 18\n#&gt;   Sex...1 Priming...2 trialN...3 Block...4 Adjective...5 Valence...6\n#&gt;   &lt;chr&gt;   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;      \n#&gt; 1 male    Collective           1 we        ofensivo      negative   \n#&gt; 2 male    Collective           2 we        resentido     negative   \n#&gt; 3 male    Collective           3 we        ego�sta       negative   \n#&gt; 4 male    Collective           4 we        indiscreto    negative   \n#&gt; 5 male    Collective           5 we        sumiso        negative   \n#&gt; 6 male    Collective           6 we        agradable     positive   \n#&gt; # ℹ 394 more rows\n#&gt; # ℹ 12 more variables: Answer...7 &lt;chr&gt;, Arrow...8 &lt;chr&gt;, rT...9 &lt;dbl&gt;, …"
  },
  {
    "objectID": "qmd/04-combinar-datos.html#joins",
    "href": "qmd/04-combinar-datos.html#joins",
    "title": "\n4  Combinar datos\n",
    "section": "\n4.2 Joins",
    "text": "4.2 Joins\nEl paquete {dplyr} tiene funciones que permiten trabajar combinando, filtrando, etc. distintos dataframes. Podéis ver más detalle y algunas ilustraciones fantásticas (como la de abajo; inner_join()) en el capítulo relational data de r4ds.\n\n\nSOURCE: https://r4ds.had.co.nz/relational-data.html#mutating-joins\n\nEn https://github.com/gadenbuie/tidyexplain se pueden ver animaciones mostrando estas operaciones.\n\n\n\n\n\n\n\nTipos de Join\n\n\n\nEstas operaciones tendrán la forma: DF_x |&gt; WHATEVER_join(DF_y)\n\n\nMutating joins:\n\ninner_join(): preserva pares de observaciones de DF_x y de DF_y con claves iguales\n\nleft_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales\n\nright_join(): preserva las observaciones de DF_y, añadiendo las de DF_x con claves iguales\n\nfull_join(): preserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales\n\n\n\nFiltering joins:\n\nsemi_join(): preserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y\n\nanti_join(): preserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y\n\n\n\n\nNesting joins:\n\nnest_join(): preserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales\n\n\n\n\n\n\n4.2.1 Mutating joins\nImportamos datos\nTenemos los siguientes dataframes:\n\nDF_IDs: Variables demográficas de participantes\n\nDF_results: Resultados en variables de interés de participantes\n\nDF_BAD: Grupo de participantes “selectos”\n\n\n\n# Importar CSVs para los joins  \nDF_IDs = read_csv(here::here(\"data/files/02-join-IDs.csv\"))\nDF_results = read_csv(here::here(\"data/files/02-join-results.csv\"))\nDF_BAD = read_csv(here::here(\"data/files/02-join-BAD.csv\"))\n\n\n4.2.1.1 Inner join\nPreserva pares de observaciones de DF_x y de DF_y con claves iguales (fijaros en el mensaje que aparece en la Consola: Joining, by = \"ID\").\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\nDF_inner_joined = \n  DF_IDs |&gt; \n  inner_join(DF_results)\n\n#nrow(DF_inner_joined)\n\nDT::datatable(DF_inner_joined)\n\n\n\n\n\n\n\n4.2.1.2 Left join\nPreserva las observaciones de DF_x, añadiendo las de DF_y con claves iguales (columnas con el mismo nombre).\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\nDF_left_joined = DF_IDs |&gt; \n   left_join(DF_results)\n\n# Vemos el número de filas de cada dataframe\n# nrow(DF_left_joined)\n# map(list(\"DF_left_joined\" = DF_left_joined, \"DF_IDs\" = DF_IDs, \"DF_results\" = DF_results), nrow)\n\nDT::datatable(DF_left_joined)\n\n\n\n\n\n\n\nSi no tenemos columnas con el mismo nombre en ambos dataframes, tenemos que indicarle a la función a partir de que dos columnas queremos unir los dataframes. Por ejemplo, con by = c(\"ID\" = \"Identificador\") le decimos que la columna ID el primer dataframe corresponde a Identificador del segundo dataframe.\n\n\n# Renombramos el identificador para que no coincidan\nDF_results2 = DF_results |&gt; rename(Identificador = ID)\n\n# Si no hay variables en común, nos da un error:\n\n# DF_left_joined = DF_IDs |&gt; \n#    left_join(DF_results2)\n  # Error in `left_join()`:\n  # ! `by` must be supplied when `x` and `y` have no common variables.\n# ℹ use by = character()` to perform a cross-join.\n\n# Tenemos que indicar explicitamente que identificador del primer dataframe (DF_IDs) \n  # coincide con que identificador del segundo dataframe (DF_results2)\nDF_left_joined = DF_IDs |&gt;\n   left_join(DF_results2, by = c(\"ID\" = \"Identificador\"))\n\n# En las últimas versiones de dplyr, han implementado la función `join_by()` que \n  # permite usar una sintaxis algo más natural:\n  DF_left_joined2 = DF_IDs |&gt; \n    left_join(DF_results2, by = join_by(ID == Identificador))\n\n# Comparar si todo es =\n  # waldo::compare(DF_left_joined, DF_left_joined2)\n\n\n4.2.1.3 Full join\nPreserva todas las observaciones de DF_x y DF_y, alineándolas cuando tengan claves iguales.\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\nDF_full_joined = DF_IDs |&gt; \n   full_join(DF_results)\n\n# CHECK\n# map(list(\"DF_full_joined\" = DF_full_joined, \"DF_IDs\" = DF_IDs, \"DF_results\" = DF_results), nrow)\n\nDT::datatable(DF_full_joined)\n\n\n\n\n\n\n\n4.2.2 Filtering joins\n\n4.2.2.1 Anti join\nPreserva solo aquellas observaciones de DF_x cuyas claves NO aparezcan en DF_y.\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\n# AVOID the people present in DF_BAD\nDF_anti_joined = DF_IDs |&gt; \n  anti_join(DF_BAD, by = \"ID\") |&gt; \n  left_join(DF_results)\n\n# CHECK\n# map(list(\"DF_anti_joined\" = DF_anti_joined, \"DF_IDs\" = DF_IDs, \"DF_BAD\" = DF_BAD, \"DF_results\" = DF_results), nrow)\n\n\nDT::datatable(DF_anti_joined)\n\n\n\n\n\n\n\n4.2.2.2 Semi join\nPreserva solo aquellas observaciones de DF_x cuyas claves aparezcan en DF_y. La diferencia con inner_join() es que NO se preservan las observaciones de DF_y.\n\n\nSOURCE: https://github.com/gadenbuie/tidyexplain\n\n\n\n# INCLUDE ONLY the people present in DF_BAD\nDF_semi_joined = DF_IDs |&gt; \n  semi_join(DF_BAD, by = \"ID\") |&gt; \n  left_join(DF_results)\n\n# CHECK\n# map(\n# list(\n#   \"DF_semi_joined\" = DF_semi_joined,\n#   \"DF_IDs\" = DF_IDs,\n#   \"DF_BAD\" = DF_BAD,\n#   \"DF_results\" = DF_results\n# ),\n# nrow\n# )\n\nDT::datatable(DF_semi_joined)\n\n\n\n\n\n\n\n4.2.3 Nesting joins\n\n\nDF_nest_joined = DF_IDs |&gt; \n  nest_join(DF_results, by = \"ID\")\n\nDT::datatable(DF_nest_joined)"
  },
  {
    "objectID": "qmd/04-combinar-datos.html#ejercicios-joins",
    "href": "qmd/04-combinar-datos.html#ejercicios-joins",
    "title": "\n4  Combinar datos\n",
    "section": "Ejercicios JOINS",
    "text": "Ejercicios JOINS\nCon los DFs de abajo, haz las siguientes operaciones:\n\n\nDF_IDs = read_csv(here::here(\"data/files/02-join-IDs2.csv\"))\nDF_results = read_csv(here::here(\"data/files/02-join-results.csv\"))\nDF_BAD = read_csv(here::here(\"data/files/02-join-BAD.csv\"))\n\n\nUne los datos demográficos con los resultados.\n\n\n\n\n\n\n\nPista para unir bases:\n\n\n\n\n\nVimos en el apartado left_join() como hacer esto\n\n\n\n\nA la base resultante, quítale los sujetos descartados de DF_BAD.\n\n\n\n\n\n\n\nPista descartar filas:\n\n\n\n\n\nanti_join()!\n\n\n\n\nCrea una nueva base con datos demográficos y resultados para los sujetos descartados.\n\n\n\n\n\n\n\nPista para filtrar a partir de una base:\n\n\n\n\n\nsemi_join()!\n\n\n\n\nComprueba si el promedio para Crystallized Intelligence de los participantes descartados difiere de la de los no descartados.\n\n\n\n\n\n\n\nPista para promedios agrupados:\n\n\n\n\n\ngroup_by() |&gt; summarise()\n\n\n\n\nHaz una gráfica donde se puedan ver las diferencias\n\n\n\nEn el ejercicio 3 de verbos avanzados creaste un DF llamado DF_split con la median split a partir de la variable Social.Adaptation.\n\n\n\nDF_wide = read_csv(\n  \"https://raw.githubusercontent.com/gorkang/cognitive-and-socio-affective-predictors-of-social-adaptation/master/outputs/data/sa-prepared.csv\"\n) |&gt;\n  janitor::clean_names()\n\nmedian_social_adaptation = DF_wide |&gt;\n  pull(social_adaptation) |&gt;\n  median(., na.rm = TRUE)\n\nDF_split = DF_wide |&gt;\n  mutate(social_adaptation_split =\n           as.factor(\n             case_when(\n               social_adaptation &gt;= median_social_adaptation ~ \"high_social_adaptation\",\n               social_adaptation &lt; median_social_adaptation ~ \"low_social_adaptation\",\n               TRUE ~ NA_character_\n             )\n           )) |&gt;\n  select(id, social_adaptation, social_adaptation_split) |&gt;\n  drop_na(social_adaptation_split)\n\nDF_long = DF_wide |&gt; pivot_longer(fluid_intelligence:working_memory)\n\nUno ese DF al DF_long que habías creado en el ejercicio 2 de la misma sección. El DF final se vera así:\n\n\n\n\n\n\n\n\nHaz un plot donde se vea la distribución para todas las variables de resultados de los dos niveles de social_adaptation_split."
  },
  {
    "objectID": "qmd/04-combinar-datos.html#datasets-interesantes",
    "href": "qmd/04-combinar-datos.html#datasets-interesantes",
    "title": "\n4  Combinar datos\n",
    "section": "\n4.3 Datasets interesantes",
    "text": "4.3 Datasets interesantes\nEn los siguientes repositorios podréis encontrar datasets interesantes para jugar.\n\nfivethirtyeight\nOur World in Data\nTidyTuesday"
  },
  {
    "objectID": "qmd/04-combinar-datos.html#bibliografía",
    "href": "qmd/04-combinar-datos.html#bibliografía",
    "title": "\n4  Combinar datos\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nCheatsheets RStudio\ndata-carpentry-week lesson_joins\nR4ds - Joins\nTidyexplain"
  },
  {
    "objectID": "qmd/05-analisis-datos-exploratorio.html#visualizando-distribuciones",
    "href": "qmd/05-analisis-datos-exploratorio.html#visualizando-distribuciones",
    "title": "\n5  Análisis de datos exploratorio\n",
    "section": "\n5.1 Visualizando distribuciones",
    "text": "5.1 Visualizando distribuciones\nPara visualizar la distribución de nuestras variables, tendremos que seguir estrategias diferentes dependiendo de si se trata de variables categóricas o continuas.\n\n5.1.1 Variables categóricas\n\n\nggplot(gapminder, aes(continent)) +\n  geom_bar()\n\ngapminder |&gt; \n  count(continent)\n#&gt; # A tibble: 5 × 2\n#&gt;   continent     n\n#&gt;   &lt;fct&gt;     &lt;int&gt;\n#&gt; 1 Africa      624\n#&gt; 2 Americas    300\n#&gt; 3 Asia        396\n#&gt; 4 Europe      360\n#&gt; 5 Oceania      24\n\n\n\n\n\n5.1.2 Variables continuas\nPara ver la distribución de una variable podemos empezar con un histograma sencillo.\n\n\nggplot(gapminder, aes(lifeExp)) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\nsummarise() nos permite ver medias, medianas, etc.\n\n\ngapminder |&gt;\n  summarise(MEAN = mean(lifeExp),\n            MEDIAN = median(lifeExp),\n            SD = sd(lifeExp),\n            MAX = max(lifeExp),\n            MIN = min(lifeExp))\n#&gt; # A tibble: 1 × 5\n#&gt;    MEAN MEDIAN    SD   MAX   MIN\n#&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  59.5   60.7  12.9  82.6  23.6\n\nAlternativamente, hay funciones como skimr::skim() que nos muestran una panorámica muy util de las variables de nuestro dataframe. Corre la función en tu Consola para ver el output completo.\n\nskimr::skim(gapminder)\n\n\nData summary\n\n\nName\ngapminder\n\n\nNumber of rows\n1704\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\ncountry\n0\n1\nFALSE\n142\nAfg: 12, Alb: 12, Alg: 12, Ang: 12\n\n\ncontinent\n0\n1\nFALSE\n5\nAfr: 624, Asi: 396, Eur: 360, Ame: 300\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nyear\n0\n1\n1979.50\n17.27\n1952.00\n1965.75\n1979.50\n1993.25\n2007.0\n▇▅▅▅▇\n\n\nlifeExp\n0\n1\n59.47\n12.92\n23.60\n48.20\n60.71\n70.85\n82.6\n▁▆▇▇▇\n\n\npop\n0\n1\n29601212.32\n106157896.74\n60011.00\n2793664.00\n7023595.50\n19585221.75\n1318683096.0\n▇▁▁▁▁\n\n\ngdpPercap\n0\n1\n7215.33\n9857.45\n241.17\n1202.06\n3531.85\n9325.46\n113523.1\n▇▁▁▁▁\n\n\n\n\nEjercicios\nVariables individuales\nUsando el DF mpg, visualiza la distribucion de las variables manufacturer, y hwy. Fijate que la primera es categórica, y la segunda continua.\n\n\n\n\n\n\nPista\n\n\n\n\n\nVas a tener que elegir entre geom_bar() y geom_histogram().\nPuedes ver que pasa si usas el parámetro binwidth = 1 en geom_histogram().\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicios avanzados\nUsando como base éste código:\nggplot(gapminder, aes(lifeExp, fill = continent)) +\n  geom_histogram(binwidth = 1)\n¿Podrías replicar la visualización de abajo? Queremos mostrar un histograma por continente.\n\n\n\n\n\n\nLo mejor es dividir el proceso en varios pasos\n\n\n\n\n\n 1) Empieza con el histograma de arriba.  2) recuerda que puedes usar el parámetro fill (dentro de aes), para asignar un color de relleno por nivel de una variable categórica.  3) Finalmente, usando facetas podrás crear una gráfica para cada nivel de la variable categórica facet_wrap()! \n\n\n\n\n\n\n\n\n¿Como podemos añadir el histograma general para poder entender donde se ubica cada continente?\n\n\n\n\n\n\nLa solución está en el capítulo 1\n\n\n\n\n\nEl paquete gghighlight es justo lo que necesitas\n\n\n\n\n\n\n\n\nTambién queremos ver los descriptivos por continente, ordenados por el promedio:\n\n#&gt; # A tibble: 5 × 6\n#&gt;   continent  MEAN MEDIAN    SD   MAX   MIN\n#&gt;   &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Africa     48.9   47.8  9.15  76.4  23.6\n#&gt; 2 Asia       60.1   61.8 11.9   82.6  28.8\n#&gt; 3 Americas   64.7   67.0  9.35  80.7  37.6\n#&gt; 4 Europe     71.9   72.2  5.43  81.8  43.6\n#&gt; 5 Oceania    74.3   73.7  3.80  81.2  69.1\n\n\n5.1.3 Visualizando datasets completos\nCuando nos llega una nueva base de datos, una de las primeras cosas que haremos será familiarizarnos con los datos. Cómo se distribuyen, cual es la relación entre distintas variables, etc.\n\n\n# Wide to long\nd &lt;- gapminder |&gt;\n  pivot_longer(everything(), values_transform = list(value = as.character)) |&gt;\n  filter(value != 999) |&gt; # Si existiera algun codigo para missing values, filtrar\n  mutate(value_NUM = as.numeric(value))\n\n# Plot numeric variables\nd |&gt;\n  drop_na(value_NUM) |&gt;\n  ggplot(aes(value_NUM)) +\n    facet_wrap(~ name, scales = \"free\") +\n    geom_histogram(bins = 15) #+ scale_x_log10()\n\n# Plot non-numeric variables\nd |&gt;\n  drop_na(value) |&gt;\n  filter(is.na(value_NUM)) |&gt;\n  ggplot(aes(value)) +\n    facet_wrap(~ name, scales = \"free\") +\n    geom_bar() +\n    coord_flip()"
  },
  {
    "objectID": "qmd/05-analisis-datos-exploratorio.html#covariación",
    "href": "qmd/05-analisis-datos-exploratorio.html#covariación",
    "title": "\n5  Análisis de datos exploratorio\n",
    "section": "\n5.2 Covariación",
    "text": "5.2 Covariación\n\n5.2.1 Variable categórica y continua\nPodemos contar el numero de elementos por nivel de la variable o ver densidad, etc. Esto funciona bien si tenemos pocos niveles de la variable categórica.\n\n\nggplot(gapminder, aes(lifeExp, colour = continent)) +\n  geom_freqpoly(binwidth = 2)\n\n\n\n\n\nPodemos usar geom_density_ridges() para combinar puntos con distribuciones:\n\n\nggplot(gapminder, aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  )\n\n\n\n\n\n¿Qué estamos viendo exáctamente arriba? Hay un punto por cada pais, y por cada año, lo que da lugar aalgo bien dificil de interpretar. Podemos ver los datos únicamente del último año:\n\n\ngapminder |&gt; group_by(year) |&gt; summarise(n())\n#&gt; # A tibble: 12 × 2\n#&gt;    year `n()`\n#&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1  1952   142\n#&gt; 2  1957   142\n#&gt; 3  1962   142\n#&gt; 4  1967   142\n#&gt; 5  1972   142\n#&gt; 6  1977   142\n#&gt; # ℹ 6 more rows\n\nggplot(gapminder |&gt; filter(year &gt; 1995),\n       aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  )\n\n\n\n\n\n5.2.2 Ejercicio avanzado - Introducción\nEn este ejercicio vamos a intentar mostrar la como la distribución de esperanza de vida ha cambiado a lo largo del tiempo. Para ello, usando la base gapminder, compararemos las distribuciones por continente del año 1952 con el año 2007.\nEmpezamos creando dos gráficos. En cada uno filtramos por el año deseado (e.g. filter(year == 1952)). Fíjate que usamos scale_x_continuous(n.breaks = 10, limits = c(20, 90)) para que ambas gráficas compartan la misma escala en el eje x:\n\n\nA = ggplot(gapminder |&gt; filter(year == 1952),\n           aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  ) +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(n.breaks = 10, limits = c(20, 90)) +\n  ggtitle(\"1952\")\n\nB = ggplot(gapminder |&gt; filter(year == 2007),\n           aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  ) +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(n.breaks = 10, limits = c(20, 90)) +\n  ggtitle(\"2007\")\n\ncowplot::plot_grid(A, B)\n\n\n\n\nPara visualizar la diferencia entre 2007 y 1952, podemos calcular primero cuanto ha cambiado la esperanza de vida en cada pais de cada continente, y crear una gráfica con esa variable:\n\n\n# Cálculo de la diferencia entre el máximo y mínimo de lifeExp para cada country. \n  # Incluimos continent en group_by() para poder usar esa variable en la gráfica\nDF_gapminder_max_min = gapminder |&gt;\n  group_by(continent, country) |&gt;\n  summarise(lifeExp = max(lifeExp) - min(lifeExp))\n\nggplot(DF_gapminder_max_min, aes(lifeExp, continent, fill = continent)) +\n  ggridges::geom_density_ridges(\n    stat = \"binline\",\n    bins = 20,\n    scale = 0.95,\n    draw_baseline = FALSE,\n    alpha = .3\n  ) +\n  ggridges::geom_density_ridges(\n    jittered_points = TRUE,\n    position = \"raincloud\",\n    alpha = 0.5,\n    scale = 0.9\n  ) +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Diferencia entre max y min por país\")\n\n\n\n\n\n5.2.3 Ejercicio\nArriba estamos restando la esperanza de vida máxima y mínima de cada pais, pero querríamos ver la diferencia entre 2007 y 1952 ¿Podrías rehacer el cálculo para mostrar la diferencia entre 2007 y 1952?\n\n\n\n\n\n\nPista\n\n\n\n\n\n1. Crear un DF para cada 2007 y otro para 1952, renombrando la variable lifeExp (e.g. max_lifeExp y min_lifeExp, respectivamente)2. Usando la funcion full_join(), juntamos ambas bases (tendras que usar el parametro by = c(\"country\", \"continent\")). 3. Con mutate() calculamos la diferencia.\n\n\n\n\n\n\n\n\n\n5.2.4 Dos variables categóricas\n\n\nggplot(diamonds, aes(cut, color)) +\n  geom_count()\n\ndiamonds |&gt;\n  count(color, cut)\n#&gt; # A tibble: 35 × 3\n#&gt;   color cut           n\n#&gt;   &lt;ord&gt; &lt;ord&gt;     &lt;int&gt;\n#&gt; 1 D     Fair        163\n#&gt; 2 D     Good        662\n#&gt; 3 D     Very Good  1513\n#&gt; 4 D     Premium    1603\n#&gt; 5 D     Ideal      2834\n#&gt; 6 E     Fair        224\n#&gt; # ℹ 29 more rows\n\ndiamonds |&gt;\n  count(color, cut) |&gt;\n  ggplot(aes(color, cut, fill = n)) +\n    geom_tile()\n\n\n\n\n\n\n\n\n5.2.5 Dos variables continuas\n\n\nggplot(gapminder, aes(lifeExp, gdpPercap)) +\n  geom_point()\n\nggplot(gapminder, aes(lifeExp, gdpPercap, color = continent)) +\n  geom_point(alpha = 1 / 2) +\n  scale_y_log10()\n\n\nggplot(gapminder, aes(lifeExp, gdpPercap)) +\n  geom_hex()\n\n\nggplot(gapminder, aes(lifeExp, gdpPercap)) +\n  geom_boxplot(mapping = aes(group = cut_width(lifeExp, 10))) +\n  scale_y_log10()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.6 Ejercicio covariación 2\nUsando el DF mpg, visualiza la covariación entre:\n\n\nmanufacturer y hwy\n\n\nclass y hwy\n\n\nhwy y cty\n\n\n\n\n\n\n\n\nVisualizando una variable categórica y una continua\n\n\n\n\n\ngeom_density_ridges()!\n\n\n\n\n\n\n\n\n\nVisualizando pares de variables continuas!\n\n\n\n\n\ngeom_smooth()!"
  },
  {
    "objectID": "qmd/05-analisis-datos-exploratorio.html#ejercicios-finales",
    "href": "qmd/05-analisis-datos-exploratorio.html#ejercicios-finales",
    "title": "\n5  Análisis de datos exploratorio\n",
    "section": "\n5.3 Ejercicios finales",
    "text": "5.3 Ejercicios finales\n\n5.3.1 Ejercicio exploración base nueva\nUsando la base del paper Cancer Screening Risk Literacy of Physicians in Training, haz un primer análisis exploratorio que incluya:\n\nhistogramas de todas las variables numéricas y no-numéricas\nscatterplots de la relación entre comprensión y numeracy, y entre comprensión y screenbeliefs\n\nPuedes ir al enlace anterior y descargar el archivo Cancer screening risk literacy R1.sav en la carpeta Data and results, o directamente usar el codigo de abajo.\n\n\n\n\n\n\nComo visualizar todas las variables\n\n\n\n\n\nVer el apartado visualizando-datasets-completos en este mismo capítulo\n\n\n\n\n\n# Usamos haven::read_sav() para leer los archivos .sav\nDF_dafina = haven::read_sav(here::here(\"data/files/Dafina\", \"Cancer screening risk literacy R1.sav\")) |&gt; as_tibble()"
  },
  {
    "objectID": "qmd/05-analisis-datos-exploratorio.html#bibliografía",
    "href": "qmd/05-analisis-datos-exploratorio.html#bibliografía",
    "title": "\n5  Análisis de datos exploratorio\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/"
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#análisis-de-datos-y-reporte-de-resultados",
    "href": "qmd/06-analisis-datos-inferencial.html#análisis-de-datos-y-reporte-de-resultados",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "\n6.1 Análisis de datos y reporte de resultados",
    "text": "6.1 Análisis de datos y reporte de resultados\nR es un lenguaje creado por estadísicos que ha ido evolucionando hacia un lenguaje de programación completo. No obstante, una de sus fortalezas innegables es el análisis de datos, y el reporte de resultados. En esta sección vamos a ver de manera muy general algunas de las herramientas que tenemos a nuestra disposición.\n\n6.1.1 Tablas\nHay numerosos paquetes para crear tablas descriptivas o para facilitar el reporte de resultados en R:\n\n{gtsummary}\n\n{stargazer}\n\n{papaja}\n\n{flextable}\n\n{huxtable}\n\nMostraremos algunos ejemplos usando gtsummary. Una ventaja interesante es que permite de manera sencilla transformar nuestra tabla a otros formatos."
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#tablas-descriptivos",
    "href": "qmd/06-analisis-datos-inferencial.html#tablas-descriptivos",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "\n6.2 Tablas descriptivos",
    "text": "6.2 Tablas descriptivos\nPodemos crear tablas con los descriptivos de nuestros datos usando la función tbl_summary() de {gtsummary}\n\n\n# Por defecto, usa: mediana (rango inter cuartil)\ngapminder |&gt; \n  select(-country) |&gt; \n  gtsummary::tbl_summary() \n\n\n\n\n\n\nCharacteristic\n      \nN = 1,7041\n\n    \n\n\ncontinent\n\n\n\n    Africa\n624 (37%)\n\n\n    Americas\n300 (18%)\n\n\n    Asia\n396 (23%)\n\n\n    Europe\n360 (21%)\n\n\n    Oceania\n24 (1.4%)\n\n\nyear\n1,980 (1,966, 1,993)\n\n\nlifeExp\n61 (48, 71)\n\n\npop\n7,023,596 (2,793,664, 19,585,222)\n\n\ngdpPercap\n3,532 (1,202, 9,325)\n\n\n\n\n1 n (%); Median (IQR)\n    \n\n\n\n\nUsando el parámetro by podemos crear columnas para cada valor de una variable:\n\n# Por continente \ngapminder |&gt; \n  select(-country) |&gt; \n  gtsummary::tbl_summary(by = continent)\n\n\n\n\n\n\nCharacteristic\n      \nAfrica, N = 6241\n\n      \nAmericas, N = 3001\n\n      \nAsia, N = 3961\n\n      \nEurope, N = 3601\n\n      \nOceania, N = 241\n\n    \n\n\nyear\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n1,980 (1,966, 1,993)\n\n\nlifeExp\n48 (42, 54)\n67 (58, 72)\n62 (51, 70)\n72 (70, 75)\n74 (71, 78)\n\n\npop\n4,579,311 (1,342,075, 10,801,490)\n6,227,510 (2,962,359, 18,340,309)\n14,530,831 (3,844,393, 46,300,348)\n8,551,125 (4,331,500, 21,802,867)\n6,403,492 (3,199,213, 14,351,625)\n\n\ngdpPercap\n1,192 (761, 2,377)\n5,466 (3,428, 7,830)\n2,647 (1,057, 8,549)\n12,082 (7,213, 20,461)\n17,983 (14,142, 22,214)\n\n\n\n\n1 Median (IQR)\n    \n\n\n\n\nEl parámetro statistic nos permite controlar que estadísticos mostrar en función del tipo de variable:\n\n# Usando promedio (desviación estandard)\ngapminder |&gt; \n  select(-country) |&gt; \n  gtsummary::tbl_summary(by = continent,\n                         statistic = list(all_continuous() ~ \"{mean} ({sd})\",\n                                          all_categorical() ~ \"{n} / {N} ({p}%)\"),\n                         \n                       missing = \"ifany\") |&gt; \n  gtsummary::add_n()\n\n\n\n\n\n\nCharacteristic\n      N\n      \nAfrica, N = 6241\n\n      \nAmericas, N = 3001\n\n      \nAsia, N = 3961\n\n      \nEurope, N = 3601\n\n      \nOceania, N = 241\n\n    \n\n\nyear\n1,704\n1,980 (17)\n1,980 (17)\n1,980 (17)\n1,980 (17)\n1,980 (18)\n\n\nlifeExp\n1,704\n49 (9)\n65 (9)\n60 (12)\n72 (5)\n74 (4)\n\n\npop\n1,704\n9,916,003 (15,490,923)\n24,504,795 (50,979,430)\n77,038,722 (206,885,205)\n17,169,765 (20,519,438)\n8,874,672 (6,506,342)\n\n\ngdpPercap\n1,704\n2,194 (2,828)\n7,136 (6,397)\n7,902 (14,045)\n14,469 (9,355)\n18,622 (6,359)\n\n\n\n\n1 Mean (SD)\n    \n\n\n\n\nEjercicio - Descriptivos\nUsando la base de datos del apartado anterior:\n\n\nDF_dafina = haven::read_sav(here::here(\"data/files/Dafina\", \"Cancer screening risk literacy R1.sav\")) |&gt; as_tibble() |&gt; \n  select(IDparticipante, resident, screenbeliefs, compR1, numeracy) |&gt;  \n  rename(comprehension = compR1) \n\nIntenta reproducir la siguiente tabla:\n\n\n\n\n\n\nDonde encontrar ayuda\n\n\n\n\n\nEn el manual de gtsummary tienes ejemplos para todo lo que necesitarás. Busca a la función tbl_summary()\n\n\n\n\n\n\n\n\n\nDemasiado detalle, solo quiero los promedios\n\n\n\n\n\nPuedes usar type = list(everything() ~ 'continuous'), dentro de tbl_summary() para forzar el tratamiento de variables con pocos niveles como continuas.\n\n\n\n\n\n\n\n\n\nError al añadir valor p\n\n\n\n\n\nEn la ayuda de la funcion: ?add_p.tbl_summary encontrarás que puedes usar algo como: `add_p(test = everything() ~ “t.test\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n      N\n      \n        Resident\n      \n      \np-value2\n\n    \n\n\n0, N = 541\n\n      \n1, N = 1181\n\n    \n\n\n\nIDparticipante\n172\n72 (51)\n93 (48)\n0.012\n\n\nScreening beliefs\n172\n27.4 (5.0)\n28.4 (6.8)\n0.3\n\n\nComprehension of the evidence\n172\n2.91 (1.28)\n2.54 (1.16)\n0.077\n\n\nNumeracy BNT-S\n172\n3.70 (1.54)\n2.87 (1.56)\n0.001\n\n\n\n\n\n1 Mean (SD)\n    \n\n\n2 Welch Two Sample t-test"
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#tablas-resultados-inferenciales",
    "href": "qmd/06-analisis-datos-inferencial.html#tablas-resultados-inferenciales",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "\n6.3 Tablas resultados inferenciales",
    "text": "6.3 Tablas resultados inferenciales\nPara tablas con los resultados de nuestros modelos estadísticos, usamos la función tbl_regression() de {gtsummary}\nPrimero preparamos los datos:\n\n\n# Transform variables\nDF_gapminder = gapminder |&gt; \n  # Log\n  mutate(gdpPercap_log = log(gdpPercap),\n         pop_log = log(pop)\n         ) |&gt; \n  # Mean center variables so the 0 values have meaning\n  mutate(year = year - mean(year, na.rm = TRUE),\n         gdpPercap_log = gdpPercap_log - mean(gdpPercap_log, na.rm = TRUE),\n         pop_log = pop_log - mean(pop_log, na.rm = TRUE)) |&gt; \n  # Will use only last year\n  filter(year == max(year))\n\nCreamos un modelo sencillo y mostramos la tabla de resultados.\n\n\nmodel1 = lm(lifeExp ~ gdpPercap_log + pop_log, DF_gapminder)\n\ntable_model1 = gtsummary::tbl_regression(model1, intercept = TRUE) |&gt; \n  add_global_p() |&gt;\n  bold_labels() |&gt; \n  italicize_levels() |&gt; \n  add_glance_table(include = c(\"nobs\", \"df.residual\", \"r.squared\", \"adj.r.squared\"))\n\n\ntable_model1\n\n\n\n\n\n\nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n63\n62, 65\n\n\n\ngdpPercap_log\n7.2\n6.4, 8.1\n\n\n\npop_log\n0.81\n0.04, 1.6\n0.039\n\n\nNo. Obs.\n142\n\n\n\n\nResidual df\n139\n\n\n\n\nR²\n0.665\n\n\n\n\nAdjusted R²\n0.660\n\n\n\n\n\n\n1 CI = Confidence Interval"
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#unir-tablas",
    "href": "qmd/06-analisis-datos-inferencial.html#unir-tablas",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "\n6.4 Unir tablas",
    "text": "6.4 Unir tablas\nDe manera muy sencilla podemos unir varias tablas:\n\n\n# Primero creamos un modelo más sencillo, basado en el anterior\nmodel10 = lm(lifeExp ~ gdpPercap_log, DF_gapminder)\n\n# Creamos la tabla\ntable_model10 = gtsummary::tbl_regression(model10, intercept = TRUE) |&gt;\n  add_global_p() |&gt;\n  bold_labels() |&gt;\n  italicize_levels() |&gt;\n  add_glance_table(include = c(\"nobs\", \"df.residual\", \"r.squared\", \"adj.r.squared\"))\n\n# Combinamos ambas tablas\ntbl_merge(\n  tbls = list(table_model10, table_model1),\n  tab_spanner = c(\"**Baseline**\", \"**Step 1**\")) |&gt; \n  # Necesario para que los parámetros globales de los modelos se muestren al final\n  modify_table_body(~.x |&gt; arrange(row_type == \"glance_statistic\")\n  )\n\n\n\n\n\n\n\nCharacteristic\n      \n        Baseline\n      \n      \n        Step 1\n      \n    \n\nBeta\n      \n95% CI1\n\n      p-value\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n\n(Intercept)\n64\n62, 65\n\n\n63\n62, 65\n\n\n\ngdpPercap_log\n7.2\n6.3, 8.1\n\n\n7.2\n6.4, 8.1\n\n\n\npop_log\n\n\n\n0.81\n0.04, 1.6\n0.039\n\n\nNo. Obs.\n142\n\n\n142\n\n\n\n\nResidual df\n140\n\n\n139\n\n\n\n\nR²\n0.654\n\n\n0.665\n\n\n\n\nAdjusted R²\n0.652\n\n\n0.660\n\n\n\n\n\n\n1 CI = Confidence Interval"
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#reporte-de-resultados",
    "href": "qmd/06-analisis-datos-inferencial.html#reporte-de-resultados",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "\n6.5 Reporte de resultados",
    "text": "6.5 Reporte de resultados\nCon la función report() podemos ver una descripción completa de los resultados de nuestro modelo:\n\n  report::report(model1)\n#&gt; We fitted a linear model (estimated using OLS) to predict lifeExp with\n#&gt; gdpPercap_log and pop_log (formula: lifeExp ~ gdpPercap_log + pop_log). The\n#&gt; model explains a statistically significant and substantial proportion of\n#&gt; variance (R2 = 0.66, F(2, 139) = 137.93, p &lt; .001, adj. R2 = 0.66). The\n#&gt; model's intercept, corresponding to gdpPercap_log = 0 and pop_log = 0, is at\n#&gt; 63.28 (95% CI [61.98, 64.58], t(139) = 96.30, p &lt; .001). Within this model:\n#&gt; \n#&gt;   - The effect of gdpPercap log is statistically significant and positive\n#&gt; (beta = 7.24, 95% CI [6.38, 8.11], t(139) = 16.56, p &lt; .001; Std. beta =\n#&gt; 0.81, 95% CI [0.72, 0.91])\n#&gt;   - The effect of pop log is statistically significant and positive (beta =\n#&gt; 0.81, 95% CI [0.04, 1.58], t(139) = 2.09, p = 0.039; Std. beta = 0.10, 95%\n#&gt; CI [5.35e-03, 0.20])\n#&gt; \n#&gt; Standardized parameters were obtained by fitting the model on a standardized\n#&gt; version of the dataset. 95% Confidence Intervals (CIs) and p-values were\n#&gt; computed using a Wald t-distribution approximation."
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#texto-inline",
    "href": "qmd/06-analisis-datos-inferencial.html#texto-inline",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "\n6.6 Texto inline",
    "text": "6.6 Texto inline\nAlgo genial de gtsummary, es que podemos usar las propias tablas para extraer detalles de los resultados y usarlos directamente en el texto.\nEl paquete report tiene también funcionalidades muy potentes que merece la pena explorar.\nLa ventaja de escribir los resultados de esta manera es que si hacemos algun pequeño cambio en la preparación de datos, podemos volver a correr el script de generación del reporte de resultados, y los valores p, etc. se ajustarán automáticamente. Únicamente tenemos que asegurarnos que la interpretación cualitativa no cambia :)\n\n\npaste0(\n  \"Life expectancy was significantly associated with GDP per capita (log), beta = \",\n  gtsummary::inline_text(table_model1, variable = gdpPercap_log)\n)  \n#&gt; [1] \"Life expectancy was significantly associated with GDP per capita (log), beta = 7.2 (95% CI 6.4, 8.1; p&lt;0.001)\""
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#ejercicio---resultados-inferenciales",
    "href": "qmd/06-analisis-datos-inferencial.html#ejercicio---resultados-inferenciales",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "Ejercicio - Resultados inferenciales",
    "text": "Ejercicio - Resultados inferenciales\nUsando la misma base de datos del ejercicio anterior:\n\n\nDF_dafina = haven::read_sav(\"../data/files/Dafina/Cancer screening risk literacy R1.sav\") |&gt;\n  as_tibble() |&gt;\n  select(IDparticipante, resident, screenbeliefs, compR1, numeracy) |&gt;\n  rename(comprehension = compR1) \n\nHaz una regresión lineal preciciendo compresion a partir de las variables de la base.\nFinalmente, crea una tabla para reportar los resultados de tu análisis, como la siguiente:\n\n\n\n\n\n\nDonde encontrar ayuda\n\n\n\n\n\nEn el manual de gtsummary tienes ejemplos para todo lo que necesitarás. tbl_regression() es tu amiga.\n\n\n\n\n\n\n\n\n\nComo añadir información en el pie de la tabla\n\n\n\n\n\nTendrás que usar la función add_glance_source_note() o add_glance_table(). Para saber que nombres poner en el paràmetro include, puedes usar la función broom::glance(model) \n\n\n\n\n\n\n\n\n\n\nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\n(Intercept)\n2.8\n1.9, 3.8\n\n\n\nResident\n-0.23\n-0.62, 0.17\n0.3\n\n\nScreening beliefs\n-0.02\n-0.05, 0.01\n0.2\n\n\nNumeracy BNT-S\n0.14\n0.03, 0.26\n0.016\n\n\n\nNo. Obs. = 172; Adjusted R² = 0.047; Residual df = 168; Statistic = 3.83; p-value = 0.011; df = 3\n    \n\n\n1 CI = Confidence Interval"
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#otros-análisis-y-sus-tablas",
    "href": "qmd/06-analisis-datos-inferencial.html#otros-análisis-y-sus-tablas",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "\n6.7 Otros análisis y sus tablas",
    "text": "6.7 Otros análisis y sus tablas\nQue test estadístico debería usar, con código en R\n\n\n\n6.7.1 Correlación simple\n\n\n# Data\niris |&gt; as_tibble()\n#&gt; # A tibble: 150 × 5\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt;          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n#&gt; 1          5.1         3.5          1.4         0.2 setosa \n#&gt; 2          4.9         3            1.4         0.2 setosa \n#&gt; 3          4.7         3.2          1.3         0.2 setosa \n#&gt; 4          4.6         3.1          1.5         0.2 setosa \n#&gt; 5          5           3.6          1.4         0.2 setosa \n#&gt; 6          5.4         3.9          1.7         0.4 setosa \n#&gt; # ℹ 144 more rows\n\n# Test\nsimple_corr_test = cor.test(iris$Sepal.Width, iris$Sepal.Length, method = \"spearman\")\n\n# Report\nsimple_corr_test |&gt; report::report()\n#&gt; Effect sizes were labelled following Funder's (2019) recommendations.\n#&gt; \n#&gt; The Spearman's rank correlation rho between iris$Sepal.Width and\n#&gt; iris$Sepal.Length is negative, statistically significant, and small (rho =\n#&gt; -0.17, S = 6.56e+05, p = 0.041)\n\n\n6.7.2 Multiples correlaciones\n\n\n# Multiple correlations\ntable_correlations = iris |&gt; \n  correlation(partial = FALSE, method = \"spearman\")\n\n# Print table\nTABLE_CORR = table_correlations |&gt; \n  summary(stars = FALSE, include_significance = TRUE, p_digits = 3) \n\n# Fancy table\nTABLE_CORR |&gt; \n  parameters::print_md()\n\n\nCorrelation Matrix (spearman-method)\n\n\n\n\n\n\n\nParameter\nPetal.Width\nPetal.Length\nSepal.Width\n\n\n\nSepal.Length\n0.83 (p &lt; .001)\n0.88 (p &lt; .001)\n-0.17 (p = 0.041)\n\n\nSepal.Width\n-0.29 (p &lt; .001)\n-0.31 (p &lt; .001)\n\n\n\nPetal.Length\n0.94 (p &lt; .001)\n\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.7.3 Anova\n\nVer paquete {afex}\n\n\n\n\ndata(obk.long, package = \"afex\")\nhead(obk.long)\n#&gt;   id treatment gender   age phase hour value\n#&gt; 1  1   control      M -4.75   pre    1     1\n#&gt; 2  1   control      M -4.75   pre    2     2\n#&gt; 3  1   control      M -4.75   pre    3     4\n#&gt; 4  1   control      M -4.75   pre    4     2\n#&gt; 5  1   control      M -4.75   pre    5     1\n#&gt; 6  1   control      M -4.75  post    1     3\n\n# estimate mixed ANOVA on the full design:\nmodel = afex::aov_ez(id = \"id\", \n                     dv = \"value\", \n                     data = obk.long, between = c(\"treatment\"), \n        within = c(\"phase\", \"hour\"))\n\n  \n  table_afex = papaja::apa_print(model)$table\n  knitr::kable(table_afex)\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nconf.int\nstatistic\ndf\ndf.residual\np.value\n\n\n\nTreatment\n.211\n[.000, .468]\n2.91\n2\n13\n.090\n\n\nPhase\n.164\n[.000, .356]\n19.29\n1.74\n22.64\n&lt; .001\n\n\nHour\n.129\n[.000, .237]\n18.44\n1.95\n25.41\n&lt; .001\n\n\nTreatment \\(\\times\\) Phase\n.099\n[.000, .212]\n5.43\n3.48\n22.64\n.004\n\n\nTreatment \\(\\times\\) Hour\n.001\n[.000, .000]\n0.08\n3.91\n25.41\n.987\n\n\nPhase \\(\\times\\) Hour\n.017\n[.000, .000]\n1.35\n4.02\n52.29\n.265\n\n\nTreatment \\(\\times\\) Phase \\(\\times\\) Hour\n.008\n[.000, .000]\n0.33\n8.05\n52.29\n.951\n\n\n\n\n\n\n6.7.4 Modelos mixtos\nPrimero preparamos los datos:\n\n\n# Transform variables\nDF_gapminder2 = gapminder |&gt; \n  # Log\n  mutate(gdpPercap_log = log(gdpPercap),\n         pop_log = log(pop)\n         ) |&gt; \n  # Mean center variables so the 0 values have meaning\n  mutate(year = year - mean(year, na.rm = TRUE),\n         gdpPercap_log = gdpPercap_log - mean(gdpPercap_log, na.rm = TRUE),\n         pop_log = pop_log - mean(pop_log, na.rm = TRUE))\n\n# Reference levels and contrast coding\nDF_gapminder2 &lt;- within(DF_gapminder2, continent &lt;- relevel(continent, ref = \"Oceania\"))\ncontrasts(DF_gapminder2$continent) = car::contr.Sum(levels(DF_gapminder2$continent))\n\nCreamos un modelo sencillo:\n\n\nmodel2 = lme4::lmer(lifeExp ~ gdpPercap_log + pop_log + year + (1|country), DF_gapminder2)\n\n# Extraemos los R2 del modelo para usar en la tabla\nR2_1 = performance::r2(model2)\n  \n\nY mostramos la tabla de resultados. Como se trata de modelos mixtos, tenemos que añadir manualmente los R2’s.\n\ntable_model2 = gtsummary::tbl_regression(model2) |&gt;  #, intercept = TRUE\n  add_global_p() |&gt;\n  bold_labels() |&gt;\n  italicize_levels() |&gt;\n  add_glance_source_note(include = c(\"nobs\", \"df.residual\"))\n\n# broomExtra::glance_performance(model2)\n\ntable_model2 |&gt; \n  as_gt() |&gt; \n  gt::tab_source_note(gt::md(\n    paste0(\n      deparse1(model2@call$formula),\n      \"&lt;BR&gt; \",\n      \"R2 conditional = \",\n      round(R2_1$R2_conditional, 3),\n      \", R2 marginal = \",\n      round(R2_1$R2_marginal, 3)\n    )\n  ))\n\n\n\n\n\n\nCharacteristic\n      Beta\n      \n95% CI1\n\n      p-value\n    \n\n\ngdpPercap_log\n3.3\n2.8, 3.8\n\n\n\npop_log\n6.1\n5.4, 6.9\n\n\n\nyear\n0.15\n0.13, 0.17\n\n\n\n\n\nNo. Obs. = 1,704; Residual df = 1,698\n    \n\nlifeExp ~ gdpPercap_log + pop_log + year + (1 | country) R2 conditional = 0.964, R2 marginal = 0.49\n    \n\n\n\n1 CI = Confidence Interval"
  },
  {
    "objectID": "qmd/06-analisis-datos-inferencial.html#bibliografía",
    "href": "qmd/06-analisis-datos-inferencial.html#bibliografía",
    "title": "\n6  Análisis de datos inferencial\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O’Reilly Media, Inc. https://r4ds.had.co.nz/"
  },
  {
    "objectID": "qmd/07-rmarkdown.html#que-es-la-reproducibilidad",
    "href": "qmd/07-rmarkdown.html#que-es-la-reproducibilidad",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "\n7.1 Que es la reproducibilidad",
    "text": "7.1 Que es la reproducibilidad\n\n\nLa crisis de replicación (replication crisis) se inició con un paper que trató de replicar los resultados de 100 investigaciones clásicas. Esta crisis ha generado un movimiento muy interesante dentro de las Ciencias Sociales y la Psicología en particular. Cada vez es más común aplicar algunos principios de buenas prácticas como compartir materiales, datos y scripts de análisis, para que tanto los revisores como otros investigadores puedan entender, reanalizar, etc. nuestras investigaciones.\nHay algunas organizaciones que han surgido para tratar de mejorar la colaboración, transparencia, y manera de trabajar, como el Psychological Science Accelerator, la Peer Reviewer’s Openness Initiative (PRO), o la Open Science Foundation. Una de las soluciones propuestas para resolver muchos de los problemas actuales pasa por los Registered reports. En estos se da una restructured submission timeline: Before collecting data, authors submit a study protocol containing their hypotheses, planned methods, and analysis pipeline, which undergoes peer review. La última evolución de los Registered Reports es la Peer Community in Registered Reports, la cual establece un sistema de revisión de RR global, independiente de las revistas.\nAdemás de los motivos científicos para trabajar de manera más transparente y reproducible, hay también motivos prácticos. Si trabajamos de manera reproducible, las modificaciones en tablas, gráficas, número de participantes o reanálisis son triviales. En este capítulo vamos a ver algunos pasos fundamentales para tender un workflow que permita y ayude a la reproducibilidad."
  },
  {
    "objectID": "qmd/07-rmarkdown.html#proyectos-de-r-studio",
    "href": "qmd/07-rmarkdown.html#proyectos-de-r-studio",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "\n7.2 Proyectos de R-Studio",
    "text": "7.2 Proyectos de R-Studio\nEl primer paso empieza por crear un proyecto de RStudio. Al usar proyectos, simplificamos varias cosas, haciendo automáticamente más fácil compartir nuestro trabajo con otras personas. Podéis leer algo más sobre esto aquí."
  },
  {
    "objectID": "qmd/07-rmarkdown.html#rmarkdownquarto-openscience-y-análisis-reproducibles",
    "href": "qmd/07-rmarkdown.html#rmarkdownquarto-openscience-y-análisis-reproducibles",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "\n7.3 RMarkdown/Quarto, openscience y análisis reproducibles",
    "text": "7.3 RMarkdown/Quarto, openscience y análisis reproducibles\nRMarkdown/Quarto son herramientas que nos permiten combinar texto formateado con código y resultados en un mismo documento (html, pdf, docx, …). Existe una evolución de Rmarkdown que reemplazará a Rmarkdown en el futuro, y que facilita la interoperabilidad entre R, Python, Julia, etc. llamada quarto. La diferencia esencial es que usaremos archivos .qmd en lugar de .Rmd, y que tendremos que instalar quarto en nuestro ordenador. Pero en general, resulta trivial convertir nuestros archivos Rmd a qmd (solo hay que renombrarlos).\nAprovechando la potencia de estas herramientas, algunas personas han creado paquetes para preparar artículos en formato APA, o con las plantillas de decenas de editoriales."
  },
  {
    "objectID": "qmd/07-rmarkdown.html#sintaxis-chunks-de-código-tipos-de-archivo",
    "href": "qmd/07-rmarkdown.html#sintaxis-chunks-de-código-tipos-de-archivo",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "\n7.4 Sintaxis, chunks de código, tipos de archivo",
    "text": "7.4 Sintaxis, chunks de código, tipos de archivo\nLa sintáxis básica de RMarkdown es sorprendentemente sencilla, como se puede ver más abajo. Eso si, lo que hay detrás es toda la potencia de latex, así que el cielo es el límite.\n\nY como no, tenemos mucha ayuda:\n\n\nMarkdown basics\n\n\nR Markdown: The Definitive Guide\n\n\nWeb oficial de Rmarkdown dentro de RStudio y\nquarto\n\nResumiendo, tienes tres elementos básicos:\n\n7.4.1 Cabecera YAML\nCuando creas un documento .qmd nuevo verás algo similar a lo siguiente en las primeras lineas:\n---\ntitle: \"Untitled\"\n---\nEsta es la cabecera YAML, en la cual se le pueden pasar parámetros para añadir un índice, cambiar formato, y muchas otras cosas.\n\n7.4.2 Rmarkdown\nEn el resto del documento (con la excepción de los chunks de código), el formato que usaremos será Rmarkdown. Su sintaxis es muy sencilla pero nada tolerante. Podéis ver las bases en la Markdown basics.\nIMPORTANTE. Si algo no funciona como esperas:\n\n\n\n\n\n\nSi algo no funciona\n\n\n\n\nAñade saltos de linea entre párrafos.\n\nAñade dos espacios al final de las líneas.\n\nAñade un espacio después de #:\n\nMAL: #Título grande\n\nBIEN: # Título grande\n\n\n\n\n\n\n\n7.4.3 Chunks de código\nLos chunks de código están delimitados por:\n\nEn su interior, puedes usar código R como si estuvieras en un script de R normal.\n\n\nlibrary(dplyr)\n\nmyvariable = c(1, 2, 3)\n\nEn la cabecera puedes añadir opciones. Hay una cantidad apabullante de opciones. Por ejemplo, en el siguiente chunk:\n{r nombre_chunk, eval=TRUE, include=TRUE, fig.height=10, fig.width=12, message=FALSE, warning=FALSE, cache=TRUE, results='asis'}\n\n\n\n\n\n\nParametros chunks\n\n\n\n\n\neval=TRUE: Muestra el código\n\ninclude=TRUE: Corre el código\n\nfig.height=10: altura de los plots (en inches)\n\nfig.width=12: ancho de los plots (en inches)\n\nmessage=FALSE: NO muestres mensajes\n\nwarning=FALSE: NO muestres warnings\n\ncache=TRUE: cachea el output del plot\n\nresults='asis': muestra el output tal cual (importante cuando el output es en latex/pdf)\n\n\n\nHaciendo click en la herramienta de la derecha del chunk  puedes controlar varios parámetros esenciales.\n\nTRUCO:\n\nSi tienes un chunk llamado setup al principio de tu documento .Rmd/.qmd, cada vez que reinicies RStudio y ejecutes código en cualquier parte de tu documento, ese bloque se ejecutara automaticamente. Esto es ideal para poner tus librerias, lectura de datos…"
  },
  {
    "objectID": "qmd/07-rmarkdown.html#ejercicio-básico-rmarkdown",
    "href": "qmd/07-rmarkdown.html#ejercicio-básico-rmarkdown",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "Ejercicio básico RMarkdown",
    "text": "Ejercicio básico RMarkdown\nVolvamos al archivo .Rmd/.qmd que creamos antes. Hagamos lo siguiente:\n\nDale formato de artículo científico, creando las siguientes secciones:\n\n\nTitle\nAbstract\nIntroducción\n\nMaterials and Methods\n\nParticipants\nMaterials\n\n\nResults\n\nExperiment 1\n\n\nDiscussion\nBibliography\n\n\nPon texto de relleno dentro de cada sección. Para ello puedes usar la función stringi::stri_rand_lipsum(n_paragraphs = 1) del paquete {stringi}.\n\nLos chunks de código deberán ser similares a este:\n\n``{r abstract, echo=FALSE, results='asis'}  \n\ncat(stringi::stri_rand_lipsum(n_paragraphs = 1))  \n\n``  \n\n\nRenderiza tu documento en formato PDF."
  },
  {
    "objectID": "qmd/07-rmarkdown.html#section",
    "href": "qmd/07-rmarkdown.html#section",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "",
    "text": "El resultado del ejercicio anterior deberá ser un archivo pdf con la estructura general de un artículo científico. Puedes ver el archivo Rmd y su pdf resultante en data/files/07-markdown/.\nSi el botón knit no funciona, puedes renderizar el pdf usando: rmarkdown::render(\"data/files/07-markdown/ejercicio-basico.Rmd\")"
  },
  {
    "objectID": "qmd/07-rmarkdown.html#ejercicio-avanzado",
    "href": "qmd/07-rmarkdown.html#ejercicio-avanzado",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "Ejercicio avanzado",
    "text": "Ejercicio avanzado\nUsando una base propia, incluye en el documento .Rmd de antes:\n\nUna tabla de descriptivos.\nUna tabla con los resultados de un análisis sencillo (e.g. una regresión lineal).\n\nPodéis ver ejemplos de tablas de descriptivos o tablas de resultados inferenciales en el capítulo anterior."
  },
  {
    "objectID": "qmd/07-rmarkdown.html#section-1",
    "href": "qmd/07-rmarkdown.html#section-1",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "",
    "text": "El resultado de este ejercicio deberá ser un archivo pdf como el que se puede ver en data/files/07-markdown/.\nDe nuevo, si el botón knit no funciona, puedes renderizar el pdf usando: rmarkdown::render(\"data/files/07-markdown/ejercicio-basico.Rmd\")"
  },
  {
    "objectID": "qmd/07-rmarkdown.html#avanzado",
    "href": "qmd/07-rmarkdown.html#avanzado",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "\n7.5 Avanzado",
    "text": "7.5 Avanzado\nPuedes crear artículos en formato APA, añadir bibliografía a tus documentos facilmente, citar los paquetes de R que usas, etc.\n\n7.5.1 Artículos APA con Papaja\n\nPreparar artículos en formato APA\n\n\n\ninstall.packages(\"papaja\")\n\n# Create new R Markdown file\nrmarkdown::draft(\n  here::here(\"data\", \"output\", \"mymanuscript.Rmd\"), \n  \"apa6\", \n  package = \"papaja\", \n  create_dir = FALSE,\n  edit = FALSE)\n\n# Render manuscript\nrmarkdown::render(\n  here::here(\"data\", \"output\", \"mymanuscript.Rmd\"), \n  quiet = TRUE,\n  clean = TRUE)\n\nY no olvidemos el paquete {rticles}, que contiene plantillas de decenas de editoriales\n\n7.5.2 Usar bibliografía\nPuedes incluir citas en tu documento facilmente con Rmarkdown o Quarto.\nNecesitaras un archivo .bib e incluirlo en el yaml inicial, por ejemplo: bibliography: name_file.bib.\nA partir de ahí, puedes citar artículos simplemente incluyendo Blah Blah [@wickham2015; @knuth1984]. o @knuth1984 says blah..\nPara saber más:\n\nhttps://quarto.org/docs/authoring/footnotes-and-citations.html\nhttps://blog.rstudio.com/2020/11/09/rstudio-1-4-preview-citations/\nhttps://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html\nhttps://www.r-bloggers.com/bibliography-with-knitr-cite-your-references-and-packages/\n\n7.5.3 Citar los paquetes que usamos\n¿Debemos citar los paquetes que usamos?\n\nRespuesta corta, si\n\nRespuesta larga, la mayoría de los paquetes\n\n\nUna manera muy sencilla de hacer esto es usando {grateful}.\n\n\ngrateful::cite_packages(\n  pkgs = \"All\",\n  output = \"file\",\n  out.format = \"Rmd\",\n  include.RStudio = TRUE,\n  out.dir = \"~/Downloads\"\n)\n\n\n7.5.4 Manejo de dependencias\nUsando un sistema de manejo de dependencias renv creamos un snapshot de las librerías usadas actualmente. Es muy importante para garantizar que nuestros scripts correran en el futuro.\n\n\n\n\n\n\nFuncionamiento básico renv\n\n\n\n\nInstalamos renv: install.packages(\"renv\")\nInicializamos el entorno local de un nuevo proyecto, con una librería privada de R renv::init()\nTrabajamos en el proyecto, instalando los paquetes que necesitemos\nGuardamos el estado de las librerías usadas en el proyecto en un lockfile (llamado renv.lock), renv::snapshot()\nRestauramos el estado de las librerías a partir del lockfile generado por renv::snapshot(). renv::restore()\n\n\n\n\n7.5.5 Shortcuts!\n\nAlt+SHIFT+K: Ver shortcuts!\n\nCTRL+SHIFT+M: Pipe\nCTRL+SHIFT+A: Reformat code\n\nCTRL+I: Reindent lines\n\n7.5.6 Estilo\nEs recomendable ser consistente en la manera de escribir código. Habitualmente se recomienda seguir una guía de estilo. Por ejemplo, Hadley Wickham’s Style guide o la guia de estilo del tidyverse."
  },
  {
    "objectID": "qmd/07-rmarkdown.html#bibliografía",
    "href": "qmd/07-rmarkdown.html#bibliografía",
    "title": "\n7  Trabajo con RMarkdown para reportes reproducibles\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nGuia de estilo del tidyverse\nHadley Wickham’s Style guide\ntargets\nScheel, A. M., Schijen, M., & Lakens, D. (in press). An excess of positive results: Comparing the standard Psychology literature with Registered Reports. Advances in Methods and Practices in Psychological Science.\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nYihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html\n\nMas cosas sobre reproducibilidad:\n\nReproducibility project: Psychology\nMany labs 2"
  },
  {
    "objectID": "qmd/08-git.html#git",
    "href": "qmd/08-git.html#git",
    "title": "\n8  Control de cambios con Git y Github\n",
    "section": "\n8.1 Git",
    "text": "8.1 Git\n\n\n\nSOURCE: https://xkcd.com/1597/\n\n\nUn segundo elemento que nos va a ayudar a trabajar en equipo, y a evitar problemas en proyectos relativamente complejos es el uso de un sistema de control de versiones como Git. Los proyectos de RStudio hacen especialmente sencillo usar algunas funcionalidades básicas de Git.\nAlgunas referencias útiles:\n\n\nOhshitGit website\n\n\nGit in practice\n\nhappygitwithr"
  },
  {
    "objectID": "qmd/08-git.html#github",
    "href": "qmd/08-git.html#github",
    "title": "\n8  Control de cambios con Git y Github\n",
    "section": "\n8.2 Github",
    "text": "8.2 Github\n\n\n\nSOURCE: github.githubassets.com\n\n\nGithub es una plataforma web muy popular donde almacenar proyectos de programación que usa como motor. Muchos de los paquetes de R, el mismo RStudio, etc, tienen repositorios abiertos en Github. Una de las ventajas fundamentales de usar Github es que esta plataforma integra algunas herramientas para hacer más sencillo el control de versiones, como el pull request, que nos permite combinar ramas de proyectos sin apenas problemas.\nGithub tiene un programa especial para estudiantes: https://education.github.com/"
  },
  {
    "objectID": "qmd/08-git.html#clonar-repo",
    "href": "qmd/08-git.html#clonar-repo",
    "title": "\n8  Control de cambios con Git y Github\n",
    "section": "\n8.3 Clonar un repositorio existente",
    "text": "8.3 Clonar un repositorio existente\nAlgo que podemos hacer con todos los repositorios de Github es clonarlos localmente:\n\n\n\n\n\n\nClonar repositorio Github\n\n\n\nPrimero, copiamos la repository URL del repo de Github (ver imagen de abajo). Será algo similar a https://github.com/VUESTRO_NOMBRE_DE_USUARIO/NOMBRE_REPOSITORIO.git\n\n\n\n\n\n\nSegundo, en RStudio: File &gt; New Project &gt; Version Control &gt; Git"
  },
  {
    "objectID": "qmd/08-git.html#crear-un-proyecto-en-rstudio-asociado-a-github",
    "href": "qmd/08-git.html#crear-un-proyecto-en-rstudio-asociado-a-github",
    "title": "\n8  Control de cambios con Git y Github\n",
    "section": "\n8.4 Crear un proyecto en RStudio asociado a Github",
    "text": "8.4 Crear un proyecto en RStudio asociado a Github\nPodemos empezar creando un repositorio en Github, para después clonarlo localmente. Si necesitamos crear un personal access token, podemos consultar la ayuda de Github.\n# Puedes usar:  \n\nusethis::create_github_token()\n\n# O manualmente, como los animales:  \n\n  # En tu página de Github, haz click en tu icon (arriba a la derecha) -&gt; Settings -&gt; Developer settings -&gt; Personal access tokens -&gt; [Generate new token] -&gt; Give gist, repo and workflow permissions.\n\n\n\n\n\n\nVersión simple [recomendado]\n\n\n\nEn Github:\n\nCreamos repositorio nuevo\nInitialize this repository with a README\nClonar repositorio\n\n\n\nAlternativamente, si ya tenemos un proyecto de RStudio, podemos crear un repositorio de Github asociado automágicamente.\n\n\n\n\n\n\nUsando el terminal\n\n\n\n\nCrear local git repo (solo si no lo tenemos aún): usethis::use_git() (se crea una carpeta oculta llamada .git)\nCrear Github Token: usethis::create_github_token()\nInsertar token en archivo .Renviron: usethis::edit_r_environ()\nCrear Github repo: usethis::use_github()\n\n\nEmpujar el repositorio local a Github: git push --set-upstream origin master"
  },
  {
    "objectID": "qmd/08-git.html#ejercicio-git-github",
    "href": "qmd/08-git.html#ejercicio-git-github",
    "title": "\n8  Control de cambios con Git y Github\n",
    "section": "Ejercicio Git-Github",
    "text": "Ejercicio Git-Github\n\nCrea un proyecto de RStudio\nAbre una cuenta en Github y/o haz login\nSigue los pasos de arriba para crear un repositorio público y asociarlo a un repositorio local"
  },
  {
    "objectID": "qmd/08-git.html#workflow",
    "href": "qmd/08-git.html#workflow",
    "title": "\n8  Control de cambios con Git y Github\n",
    "section": "\n8.5 Workflow",
    "text": "8.5 Workflow\n\n\n\nSOURCE: nvie.com\n\n\nHay diferentes filosofias sobre cual es la mejor manera de trabajar con Git.\nEn este post por Vincent Driessen podeis ver una explicación bien detallada, complementada con imagenes como la que se ve a continuación.\nEl modelo básico implica la existencia de dos ramas. Una master (“producción”), que siempre debe funcionar, y una develop (para desarrollo), donde experimentamos, rompemos cosas, etc.\nPodeis ver un manual super completo llamado Happy Git and GitHub for the useR elaborado por Jenny Bryan, Jim Hester, entre otros.\n\n\n\n\n8.5.1 Modelo básico\nEn RStudio podemos trabajar gráficamente, Usando el panel Git.\n\n\n\n\n\n\n\nUsando el entorno gráfico\n\n\n\nEmpezamos en la rama master:\n\n\nPull  : nos aseguramos que nuestro repositorio local esta actualizado\n\n\nBranch  : Creamos nueva rama llamada development\n\nHacemos cambios en nuestros scripts\n\n\nCommit  : Commiteamos los cambios\n\n\nPush  : subimos la rama a Github\n\n\nPull request (En Github):\n\n\nCompare & Pull request\n\n\n\n\nPull  : nos aseguramos que nuestro repositorio local esta actualizado\n\n\n\n\n\n\n\nComo hacerlo usando el terminal\n\n\n\n\n\n\n\n\nPull: nos aseguramos que nuestro repositorio local esta actualizado: git pull\n\n\nBranch: Creamos nueva rama llamada development: git checkout -b development\n\nHacemos cambios en nuestros scripts\n\n\nCommit: Commiteamos los cambios\n\n\n\nAñadimos archivos: git add foo.txt\n\nHacemos el commit: git commit --message \"A commit message\"\n\n\n\n\nPush: subimos la rama a Github: git push origin development\n\n\nPull request (En Github):\n\n\nCompare & Pull request\n\n\n\nPull: nos aseguramos que nuestro repositorio local esta actualizado: git pull\n\n\n\n\n\n\n\n\n\n8.5.2 Pull request en 3 + 1 sencillos pasos\nDespués de hacer el push de arriba, al entrar en nuestro repositorio deberíamos ver algo parecido a lo siguiente (si no lo vemos, ir a branches). La única dificultad es saber cual de los botones verdes apretar:\n\n8.5.2.1 Paso 1. Compare & pull request\n\n\n8.5.2.2 Paso 2. Create pull request\n\n\n8.5.2.3 Paso 3. Merge pull request\n\n\nBorrar rama antigua\n\nEjercicio\nNuestro primer commit\n\nUsando el proyecto de RStudio de antes, crea una rama nueva llamada development\nCrea un nuevo archivo en formato .Rmd:\n\n\n\nHaz un commit de ese archivo y subelo (push) a Github (asegurate que esta allá!). No olvides hacer un pull!\nAhora haz cambios en el archivo, commitealos, súbelos, y sincroniza tu repo local"
  },
  {
    "objectID": "qmd/08-git.html#bibliografía",
    "href": "qmd/08-git.html#bibliografía",
    "title": "\n8  Control de cambios con Git y Github\n",
    "section": "Bibliografía",
    "text": "Bibliografía\nGuia de estilo del tidyverse\nHadley Wickham’s Style guide\nHappy Git and GitHub for the useR\ntargets\nScheel, A. M., Schijen, M., & Lakens, D. (in press). An excess of positive results: Comparing the standard Psychology literature with Registered Reports. Advances in Methods and Practices in Psychological Science.\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R Markdown: The Definitive Guide. CRC Press. https://bookdown.org/yihui/rmarkdown/\nYihui Xie (2018). bookdown: Authoring Books and Technical Documents with R Markdown https://bookdown.org/yihui/bookdown/markdown-syntax.html\n\nMas cosas sobre reproducibilidad:\n\nReproducibility project: Psychology\nMany labs 2"
  },
  {
    "objectID": "qmd/09-experimentos-reproducibles.html#pipeline-experimental-abierto-y-reproducible",
    "href": "qmd/09-experimentos-reproducibles.html#pipeline-experimental-abierto-y-reproducible",
    "title": "\n9  Experimentos reproducibles\n",
    "section": "\n9.1 Pipeline experimental abierto y reproducible",
    "text": "9.1 Pipeline experimental abierto y reproducible\nReplicar el experimento de una publicación no es trivial. Una de las fortalezas fundamentales de nuestro sistema es que compartir y reproducir un experimento y los análisis asociados se convierte en algo muy sencillo.\nAdemás, todos los componentes del proceso son código abierto, lo que permite que revisores, colaboradores, etc. puedan verificar que no hay errores en el código.\nCon este sistema podremos crear fácilmente el código del experimento, simular datos y preparar datos de manera casi automática (incluyendo anonimización).\nEl output del sistema es estandarizado, lo que implica que los nombres de las variables y la estructura de datos son predecibles. Finalmente, la generación de gráficas, tablas, reportes y los análisis son reproducibles."
  },
  {
    "objectID": "qmd/09-experimentos-reproducibles.html#jspsychmaker-como-crear-un-protocolo-experimental",
    "href": "qmd/09-experimentos-reproducibles.html#jspsychmaker-como-crear-un-protocolo-experimental",
    "title": "\n9  Experimentos reproducibles\n",
    "section": "\n9.2 jsPsychMaker: Como crear un protocolo experimental",
    "text": "9.2 jsPsychMaker: Como crear un protocolo experimental\nEn el manual de jsPsychR puedes ver las tareas disponibles junto con una breve descripción de cada una de ellas. Alternativamente, puedes ver el documento con todos los detalles de las tareas disponibles, o simplemente ejecutar jsPsychMaker::list_available_tasks().\nSi quieres consultar los scripts de las tareas puedes hacerlo en la carpeta canonical_protocol/ del repositorio de jsPsychMaker. Si quieres crear una nueva tarea para añadir a tu protocolo, puedes seguir las instrucciones de más abajo.\n\nPara crear un protocolo con las tareas AIM, EAR e IRI, y abrirlo en un navegador:\n\njsPsychMaker::create_protocol(\n  # Pruebas a incluir\n  canonical_tasks = c(\"AIM\", \"EAR\", \"IRI\"), \n   # El directorio tiene que incluir un número (se usará como pid)\n  folder_output = \"~/Downloads/protocol999\",\n  # Abre el navegador con el protocolo\n  launch_browser = TRUE\n  )\n\n\nPodemos editar la configuración del protocolo en la carpeta que hemos indicado en folder_output, abriendo el archivo config.js. Puedes consultar la ayuda sobre la configuración de experimentos.\nEl experimento esta listo para ser utilizado localmente. Si launch_browser = TRUE se abrirá el navegador. En cualquier caso, podemos iniciar el experimento abriendo index.html en tu navegador preferido.\n\nEjercicio 1\nDiseña un sencillo protocolo:\n\nDebes usar alguna de las tareas que aparecen en en manual (máximo 2)\nOpcionalmente, puedes hacer primero el Ejercicio 2 de abajo, para añadir o adaptar una nueva tarea/escala muy sencilla\nLa duración total del “experimento” no debería superar los 5 minutos\n\nTendrás que hacer una breve presentación contándonos el diseño experimental.\nNotas\n(tareas jsPsychMaker): Usa un máximo de 2 tareas"
  },
  {
    "objectID": "qmd/09-experimentos-reproducibles.html#jspsychmonkeys-como-simular-datos",
    "href": "qmd/09-experimentos-reproducibles.html#jspsychmonkeys-como-simular-datos",
    "title": "\n9  Experimentos reproducibles\n",
    "section": "\n9.3 jsPsychMonkeys: Como simular datos",
    "text": "9.3 jsPsychMonkeys: Como simular datos\nEl sistema para simular participantes utiliza Selenium dentro de un contenedor de Docker. En Linux es trivial su uso, pero en Windows su configuración puede ser más compleja.\nPuedes seguir los siguientes pasos para preparar tu sistema:\n\nCompleta el setup para tu sistema operativo\nSi no funciona, te, quedan las siguientes opciones:\n\nCorrer un par de participantes manualmente\n\nUsar un ordenador con Linux o crear una partición Linux\n\nCrear una máquina virtual linux desde la que simular participantes. Puedes usar Virtualbox para instalar Ubuntu. Una vez dentro, tendrás que seguir los pasos del manual para prepara el sistema para correr R y RStudio\n\n\nErrores comunes:\n\nError sobre elevated privileges: abre Docker desktop antes de empezar\n\n\nPara lanzar monos localmente:\n\n\n# Un solo mono\njsPsychMonkeys::release_the_monkeys(\n  # Lanza un monos con el user id 1\n  uid = \"1\",\n  local_folder_tasks = \"~/Downloads/protocol999\")\n\n\n#  Monos del 1 al 5 simultaneamente\njsPsychMonkeys::release_the_monkeys(\n  # Lanza monos desde el uid 1 hasta el 5\n  uid = \"1:5\",\n  local_folder_tasks = \"~/Downloads/protocol999\",\n  # Lanza los monos en paralelo\n  sequential_parallel = \"parallel\",\n  # Usando este número de CPUs\n  number_of_cores = 5\n)\n\nPuedes ver de los parametros disponibles en el Manual de jsPsychMonkeys. Por ejemplo, con open_VNC = TRUE puedes ver a los monos hacer su trabajo (siempre y cuando hayas instalado realvnc)."
  },
  {
    "objectID": "qmd/09-experimentos-reproducibles.html#jspsychhelper-como-preparar-datos",
    "href": "qmd/09-experimentos-reproducibles.html#jspsychhelper-como-preparar-datos",
    "title": "\n9  Experimentos reproducibles\n",
    "section": "\n9.4 jsPsychHelpeR: Como preparar datos",
    "text": "9.4 jsPsychHelpeR: Como preparar datos\nCada tarea de jsPsychMaker debería tener un script hermano en jsPsychHelpeR para automatizar la preparación de datos. Una vez tengamos nuestro protocolo listo para el pilotaje, con una función de jsPsychHelpeR crearemos todo lo necesario para que la preparación de datos corra automáticamente.\n\nPara crear y abrir un nuevo proyecto de RStudio con todo listo para correr la preparación de datos de tu protocolo:\n\njsPsychHelpeR::run_initial_setup(pid = '999', \n                                 data_location = \"~/Downloads/protocol999/.data\", \n                                 folder = \"~/Downloads/jsPsychHelpeR999\")\n\nEn el nuevo proyecto, tendremos que correr la preparación de datos. Puedes abrir el archivo run.R, donde encontrarás algunas instrucciones básicas.\n\n\n# Corremos el pipeline de preparación de datos\ntargets::tar_make()\n\n\nPara ver el data frame final listo para el análisis\n\n\n  # List available objects\n  targets::tar_objects()\n  \n  # Load DF_analysis file\n  targets::tar_load(DF_analysis)\n  \n  # See DF_analysis dataframe\n  DF_analysis\n  \n\n\n\n9.4.1 Como crear un reporte dentro del jsPsychHelpeR\nDentro del proyecto en el que has preparado los datos, simplemente tienes que:\n\n\nAbre la plantilla report_analysis.Rmd:\n\nrstudioapi::navigateToFile(\"Rmd/report_analysis.Rmd\")\n\n\nEn el archivo _targets.R, en la sección análisis, descomenta las dos líneas de abajo\n\n\n  # tar_render(report_analysis, \"Rmd/report_analysis.Rmd\",\n  #            output_file = paste0(\"../outputs/reports/report_analysis.html\")),\n  \n\n\nFinalmente, puedes trabajar en report_analysis.Rmd tal y como hiciste en el capítulo anterior. Cuando acabes, o quieras probar si todo funciona bien, solo tienes que correr targets::tar_make() desde la Consola."
  },
  {
    "objectID": "qmd/09-experimentos-reproducibles.html#ejercicio-final",
    "href": "qmd/09-experimentos-reproducibles.html#ejercicio-final",
    "title": "\n9  Experimentos reproducibles\n",
    "section": "Ejercicio FINAL",
    "text": "Ejercicio FINAL\nYa estáis listas/os para enfrentaros al ejercicio FINAL"
  },
  {
    "objectID": "qmd/09-experimentos-reproducibles.html#avanzado",
    "href": "qmd/09-experimentos-reproducibles.html#avanzado",
    "title": "\n9  Experimentos reproducibles\n",
    "section": "\n9.5 Avanzado",
    "text": "9.5 Avanzado\n\n9.5.1 Como crear una nueva tarea\nTenemos un buen número de tareas disponibles para usar (puedes verlas en el manual de jsPsychR). Si la tarea que necesitas no está disponible, puedes crearla de distintas maneras:\n\nModificando alguna de las tareas que ya existen: tareas en jsPsychMaker\nUsando las plantillas disponibles: jsPsychMaker::copy_example_tasks(destination_folder = \"~/Downloads/TEST\")\n\nVeamos como crear una nueva tarea a partir de documentos excel usando las plantillas disponibles. Ver ayuda:\n\n\nCopia las plantillas de tareas de ejemplo:\n\n\njsPsychMaker::copy_example_tasks(destination_folder = \"~/Downloads/TEST\")\n\n\nVe a la carpeta indicada en destination_folder, en este ejemplo ~/Downloads/TEST, y borra todas las carpetas menos aquellas que correspondan al plugin que quieras usar. Por ejemplo, Slider.\n\nAdapta Slider.csv a tu nueva tarea:\n\nAdapta min, max, slider_start\n\nCopia las filas existentes tantas veces como ítems necesites\n\nAsegurate que los valores en la columna ID son correlativos\n\nAdapta stimulus, labels a tus items\n\n\n\nAdapta los .html con tus instrucciones:\n\nSi necesitas más páginas de instrucciones, simplemente haz copias de las existentes\nEdita el contenido de los archivos html\n\n\nEjecuta create_protocol() con los parámetros de abajo, se creará un nuevo protocolo con tu/tus tareas.\n\n\n  jsPsychMaker::create_protocol(\n    # Incluye la tarea EAR\n    canonical_tasks = \"EAR\",\n    # Crea e incluye las tareas que estan en esta carpeta\n    folder_tasks = \"~/Downloads/TEST/\",\n    # Crea el protocolo aquí\n    folder_output = \"~/Downloads/TEST/new_protocol\",\n    # Lanza un navegador\n    launch_browser = TRUE\n    )\n\n\nEjercicio Optativo: Crear nueva tarea\nCrea la siguiente tarea en jsPsychMaker:\n\n\nThe Brief Resilience Scale (PDF version inglesa), o en su versión española\n\n\nNotas\n(tareas jsPsychMaker): Ver instrucciones en experimentos-reproducibles - como crear una nueva tarea\nSi prefieres puedes implementar una tarea distinta a The Brief Resilience Scale. Los únicos requisitos son que sea breve y sencilla.\n\n\n9.5.1.1 Corrección de la tarea\nPara cada tarea en jsPsychMaker, aspiramos a tener un script de corrección en jsPsychHelpeR. Si has creado una nueva tarea, por favor, completa la información de NUEVAS Tareas jsPsychR para que podamos integrar tu tarea en el repositorio común.\n\n9.5.1.2 Como preparar datos para una tarea nueva\nTendremos que crear primero el script de preparación para la nueva tarea. En jsPsychHelpeR tienes una tarea que te ayudará con esto. Si has completado los datos en NUEVAS Tareas jsPsychR, el proceso será muy sencillo.\n\nInstalamos jsPsychHelper:\n\n\nif (!require('jsPsychHelpeR')) remotes::install_github(\"gorkang/jsPsychHelpeR\"); library('jsPsychHelpeR')\n\n\nCreamos el nuevo archivo prepare_NOMBRETAREA():\n\n\njsPsychHelpeR::create_new_task(\n  short_name_task = \"NAMETASK\", \n  get_info_googledoc = TRUE\n  )\n\nEsta función:\n\nCreará un nuevo archivo de corrección a partir de la plantilla\nLo adaptará para que funciones con el nombre que le has asignado a la tarea\nAbrirá el archivo para que lo puedas editar\n\nSi hay información en todas las pestañas de NUEVAS Tareas jsPsychR, en la consola se mostrará información lista para copiar y pegar en tu script sobre:\n\nnombres de dimensiones\nítems para cada dimensión\ncálculo de dimensiones\nítems invertidos\nconversión numérica"
  },
  {
    "objectID": "qmd/10-ejercicios.html#ejercicio-final",
    "href": "qmd/10-ejercicios.html#ejercicio-final",
    "title": "\n10  Ejercicios\n",
    "section": "\n10.1 Ejercicio FINAL",
    "text": "10.1 Ejercicio FINAL\nPara el ejercicio final (evaluable), usaremos el protocolo que has creado en el ejercicio anterior. Usando datos simulados, con la ayuda de jsPsychHelpeR vamos a crear un proyecto de RStudio que procese los datos automáticamente, y adaptar un archivo Rmarkdown para generar un reporte automatizado con tablas, gráficas y una descripción semi-automática de nuestros resultados simulados.\n\nEl primer paso consiste en obtener datos de participantes virtuales.\n\n\nPodéis intentarlo simulando datos\n\nSi no os funciona jsPsychMonkeys en vuestro sistema, el profesor os ayudará a simular datos para vuestro experimento.\nAlternativamente, podéis correr el experimento un par de veces (abriendo el index.html)\n\n\nUna vez tengamos los datos:\n\n\nCrearemos un proyecto que procesará los datos automáticamente usando jsPsychHelpeR - como preparar datos\n\nCrearemos un reporte en Rmd como parte del pipeline de jsPsychHelpeR donde incluiremos:\n\nTabla/s con descriptivos ver ayuda\nGráfico/s con resultado ver ayuda y ayuda\nTabla/s con resultados de un análisis sencillo ver ayuda\nUna frase reportando resultados del análisis (usando Texto inline de gtsummary)\n\n\n\nEl proyecto tiene que correr en cualquier computador.\nIMPORTANTE\nLa nota del workshop estará basada en el resultado de esta tarea.\nTendréis que compartir el proyecto completo con el profesor, y él deberá poder correrlo y ver como resultado el reporte en pdf incluyendo los elementos detallados arriba.\nNotas\n(simulación datos): Sigue las instrucciones de simulando datos\n(preparando datos): Ver como preparar datos\nPara más información, ver el manual de jsPsychR"
  },
  {
    "objectID": "qmd/refs.html#references",
    "href": "qmd/refs.html#references",
    "title": "Paquetes usados",
    "section": "References",
    "text": "References\n\n\n\n\nAden-Buie, Garrick. 2023. regexplain: Rstudio Addin to Explain, Test and Build Regular Expressions. https://github.com/gadenbuie/regexplain.\n\n\nAllaire, JJ. 2022. quarto: R Interface to “Quarto” Markdown Publishing System. https://github.com/quarto-dev/quarto-r.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, et al. 2023. rmarkdown: Dynamic Documents for r. https://github.com/rstudio/rmarkdown.\n\n\nAllaire, JJ, Yihui Xie, Christophe Dervieux, R Foundation, Hadley Wickham, Journal of Statistical Software, Ramnath Vaidyanathan, et al. 2023. rticles: Article Formats for r Markdown. https://CRAN.R-project.org/package=rticles.\n\n\nArnold, Jeffrey B. 2021. ggthemes: Extra Themes, Scales and Geoms for “ggplot2”. https://github.com/jrnold/ggthemes.\n\n\nAust, Frederik, and Marius Barth. 2022. papaja: Prepare Reproducible APA Journal Articles with R Markdown. https://github.com/crsh/papaja.\n\n\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear Mixed-Effects Models Using lme4.” Journal of Statistical Software 67 (1): 1–48. https://doi.org/10.18637/jss.v067.i01.\n\n\nBryan, Jennifer. 2023. gapminder: Data from Gapminder.\n\n\nCameron, Allan, and Teun van den Brand. 2022. geomtextpath: Curved Text in “ggplot2”. https://allancameron.github.io/geomtextpath/.\n\n\nCarr, Dan, ported by Nicholas Lewin-Koh, Martin Maechler, and contains copies of lattice functions written by Deepayan Sarkar. 2023. hexbin: Hexagonal Binning Routines. https://github.com/edzer/hexbin.\n\n\nCsárdi, Gábor, Jim Hester, Hadley Wickham, Winston Chang, Martin Morgan, and Dan Tenenbaum. 2021. remotes: R Package Installation from Remote Repositories, Including “GitHub”.\n\n\nFirke, Sam. 2023. janitor: Simple Tools for Examining and Cleaning Dirty Data.\n\n\nFox, John, and Sanford Weisberg. 2019. An R Companion to Applied Regression. Third. Thousand Oaks CA: Sage. https://socialsciences.mcmaster.ca/jfox/Books/Companion/.\n\n\nGagolewski, Marek. 2022. “stringi: Fast and Portable Character String Processing in R.” Journal of Statistical Software 103 (2): 1–59. https://doi.org/10.18637/jss.v103.i02.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, Alexandra Lauer, and JooYoung Seo. 2023. gt: Easily Create Presentation-Ready Display Tables.\n\n\nKuhn, Max, Simon Jackson, and Jorge Cimentada. 2022. corrr: Correlations in r.\n\n\nLüdecke, Daniel. 2023. sjPlot: Data Visualization for Statistics in Social Science. https://CRAN.R-project.org/package=sjPlot.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, and Dominique Makowski. 2020. “Extracting, Computing and Exploring the Parameters of Statistical Models Using R.” Journal of Open Source Software 5 (53): 2445. https://doi.org/10.21105/joss.02445.\n\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, Philip Waggoner, and Dominique Makowski. 2021. “performance: An R Package for Assessment, Comparison and Testing of Statistical Models.” Journal of Open Source Software 6 (60): 3139. https://doi.org/10.21105/joss.03139.\n\n\nLüdecke, Daniel, Indrajeet Patil, Mattan S. Ben-Shachar, Brenton M. Wiernik, Philip Waggoner, and Dominique Makowski. 2021. “see: An R Package for Visualizing Statistical Models.” Journal of Open Source Software 6 (64): 3393. https://doi.org/10.21105/joss.03393.\n\n\nMakowski, Dominique, Daniel Lüdecke, Indrajeet Patil, Rémi Thériault, Mattan S. Ben-Shachar, and Brenton M. Wiernik. 2023. “Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.” CRAN. https://easystats.github.io/report/.\n\n\nMeyer, Fanny, and Victor Perrier. 2022. esquisse: Explore and Visualize Your Data Interactively.\n\n\nMüller, Kirill. 2020. here: A Simpler Way to Find Your Files. https://CRAN.R-project.org/package=here.\n\n\nNavarrete, Gorka. 2023a. jsPsychHelpeR: Standardize and Automatize Data Preparation and Analysis of jsPsych Experiments Created with jsPsychMaker. https://github.com/gorkang/jsPsychHelpeR.\n\n\n———. 2023b. jsPsychMaker: Create Behavioral Experiments and Surveys Using jsPsych and r. https://github.com/gorkang/jsPsychMaker.\n\n\n———. 2023c. jsPsychMonkeys: Release Monkeys to a jsPsych Experiment Using the r Package targets, Docker and RSelenium. https://github.com/gorkang/jsPsychMonkeys.\n\n\nOoms, Jeroen. 2023. writexl: Export Data Frames to Excel “xlsx” Format.\n\n\nPedersen, Thomas Lin. 2022. ggraph: An Implementation of Grammar of Graphics for Graphs and Networks.\n\n\nperson). 2023. raincloudplots: The Easy Way to Create Raincloud Plots. https://github.com/jorvlan/raincloudplots.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRushworth, Alastair. 2022. inspectdf: Inspection, Comparison and Visualisation of Data Frames. https://alastairrushworth.github.io/inspectdf/.\n\n\nSchutten, Gerrit-Jan, Chung-hong Chan, Thomas J. Leeper, and Detlef Steuer. 2023. readODS: Read and Write ODS Files. https://github.com/ropensci/readODS.\n\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n\nSingmann, Henrik, Ben Bolker, Jake Westfall, Frederik Aust, and Mattan S. Ben-Shachar. 2023. afex: Analysis of Factorial Experiments.\n\n\nSjoberg, Daniel D., Karissa Whiting, Michael Curry, Jessica A. Lavery, and Joseph Larmarange. 2021. “Reproducible Summary Tables with the Gtsummary Package.” The R Journal 13: 570–80. https://doi.org/10.32614/RJ-2021-053.\n\n\nUshey, Kevin, and Hadley Wickham. 2023. renv: Project Environments. https://CRAN.R-project.org/package=renv.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, and Shannon Ellis. 2022. skimr: Compact and Flexible Summaries of Data.\n\n\nWickham, Hadley. 2023. waldo: Find Differences Between r Objects. https://CRAN.R-project.org/package=waldo.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, and Andy Teucher. 2023. usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, and Dana Seidel. 2022. scales: Scale Functions for Visualization.\n\n\nWilke, Claus O. 2020. cowplot: Streamlined Plot Theme and Plot Annotations for “ggplot2”. https://wilkelab.org/cowplot/.\n\n\n———. 2022. ggridges: Ridgeline Plots in “ggplot2”. https://wilkelab.org/ggridges/.\n\n\nWilke, Claus O., and Brenton M. Wiernik. 2022. ggtext: Improved Text Rendering Support for “ggplot2”. https://wilkelab.org/ggtext/.\n\n\nXie, Yihui. 2014. “knitr: A Comprehensive Tool for Reproducible Research in R.” In Implementing Reproducible Computational Research, edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. Chapman; Hall/CRC.\n\n\n———. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.\n\n\n———. 2019. “TinyTeX: A Lightweight, Cross-Platform, and Easy-to-Maintain LaTeX Distribution Based on TeX Live.” TUGboat 40 (1): 30–32. https://tug.org/TUGboat/Contents/contents40-1.html.\n\n\n———. 2023a. knitr: A General-Purpose Package for Dynamic Report Generation in r. https://yihui.org/knitr/.\n\n\n———. 2023b. tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents. https://github.com/rstudio/tinytex.\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown.\n\n\nXie, Yihui, Joe Cheng, and Xianying Tan. 2023. DT: A Wrapper of the JavaScript Library “DataTables”. https://github.com/rstudio/DT.\n\n\nXie, Yihui, Christophe Dervieux, and Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook.\n\n\nYutani, Hiroaki. 2022. gghighlight: Highlight Lines and Points in “ggplot2”."
  }
]